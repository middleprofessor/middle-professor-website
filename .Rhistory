blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::update_meta_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
library(pwr)
library(pwr)
# something like d=.05, power=.06 replicates Gelman
true_Cohens_d <- .4
goal_power <- .06 #This replicates Gelman
#goal_power <- .2
# set goal power and compute sample size needed to find statistically significant given true difference.
n <- ceiling(pwr.t.test(d = true_Cohens_d, sig.level = 0.05, power=goal_power, type = "two.sample")$n)
# compute true power
power <- pwr.t.test(n = n, d = true_Cohens_d, sig.level = 0.05, type = "two.sample")$power
niter <- 10^4
post_hoc_power  <- numeric(niter)
observed_d <- numeric(niter)
cohens_d <- numeric(niter)
p_value <- numeric(niter)
for(i in 1:niter){
Y <- c(rnorm(n),(rnorm(n)+true_Cohens_d))
X <- rep(c('A','B'),each=n)
observed_d[i] <- mean(Y[X=='B'])-mean(Y[X=='A']) # B is bigger so make the true direction positive
pooled_sd <- (sd(Y[X=='B'])+sd(Y[X=='A']))/2
cohens_d[i] <- abs(observed_d[i])/pooled_sd
post_hoc_power[i] <- pwr.t.test(n = n, d = abs(observed_d[i]), sig.level = 0.05, type = "two.sample")$power
p_value[i] <- t.test(Y~factor(X))$p.value
}
# the true power
power
# distribution of post hoc power
hist(post_hoc_power)
# distribution of Cohen's d
hist(cohens_d)
median(post_hoc_power)
length(post_hoc_power[post_hoc_power>0.5])/niter
length(post_hoc_power[post_hoc_power>power])/niter
times_bigger <- abs(observed_d/true_Cohens_d)
times_bigger
fold <- log2(times_bigger)
hist(fold)
hist(times_bigger)
my_bibfile <- "source/walker.bib"
out_fold   <- "source/walker_md"
mypubs   <- data.table(ReadBib(bibfile, check = "warn", .Encoding =
my_bibfile <- "source/walker.bib"
out_fold   <- "source/walker_md"
mypubs   <- data.table(ReadBib(bibfile, check = "warn", .Encoding = "UTF-8") %>% as.data.frame())
library(RefManageR)
library(dplyr)
library(stringr)
library(anytime)
library(data.table)
mypubs   <- data.table(ReadBib(bibfile, check = "warn", .Encoding = "UTF-8") %>% as.data.frame())
write_it <- function(x, out_folder){
filename <- paste(x$year, x$title %>%
str_replace_all(fixed(" "), "_") %>%
str_remove_all(fixed(":")) %>%
str_sub(1, 20) %>%
paste0(".md"), sep = "_")
fileConn <- file.path(out_folder, filename)
write("+++", fileConn)
# Title and date
write(paste0("title = \"", x$title, "\""), fileConn, append = T)
write(paste0("date = \"", anydate(x$year), "\""), fileConn, append = T)
# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
auth_hugo <- str_replace_all(x$author, " and ", "\", \"")
auth_hugo <- stringi::stri_trans_general(auth_hugo, "latin-ascii")
write(paste0("authors = [\"", auth_hugo,"\"]"), fileConn, append = T)
# Publication type. Legend:
# 0 = Uncategorized, 1 = Conference paper, 2 = Journal article
# 3 = Manuscript, 4 = Report, 5 = Book,  6 = Book section
write(paste0("publication_types = [\"", x[["bibtype"]],"\"]"),
fileConn, append = T)
# Publication details: journal, volume, issue, page numbers and doi link
publication <- x$journal
if (!is.na(x$volume)) publication <- paste0(publication,
", (", x[["volume"]], ")")
if (!is.na(x$number)) publication <- paste0(publication,
", ", x[["number"]])
if (!is.na(x$pages)) publication <- paste0(publication,
", _pp. ", x[["pages"]], "_")
if (!is.na(x$doi)) publication <- paste0(publication,
", ", paste0("https://doi.org/",
x[["doi"]]))
write(paste0("publication = \"", publication,"\""), fileConn, append = T)
write(paste0("publication_short = \"", publication,"\""),fileConn, append = T)
# Abstract and optional shortened version.
if (!is.na(x$abstract)) {
write(paste0("abstract = \"", x$abstract,"\""), fileConn, append = T)
} else {
write("abstract = \"\"", fileConn, append = T)
}
write(paste0("abstract_short = \"","\""), fileConn, append = T)
write("image_preview = \"\"", fileConn, append = T)
write("selected = false", fileConn, append = T)
write("projects = []", fileConn, append = T)
write("tags = []", fileConn, append = T)
#links
write("url_pdf = \"\"", fileConn, append = T)
write("url_preprint = \"\"", fileConn, append = T)
write("url_code = \"\"", fileConn, append = T)
write("url_dataset = \"\"", fileConn, append = T)
write("url_project = \"\"", fileConn, append = T)
write("url_slides = \"\"", fileConn, append = T)
write("url_video = \"\"", fileConn, append = T)
write("url_poster = \"\"", fileConn, append = T)
write("url_source = \"\"", fileConn, append = T)
#other stuff
write("math = true", fileConn, append = T)
write("highlight = true", fileConn, append = T)
# Featured image
write("[header]", fileConn, append = T)
write("image = \"\"", fileConn, append = T)
write("caption = \"\"", fileConn, append = T)
write("+++", fileConn, append = T)
}
bibtex_2academic <- function(bibfile,
outfold,
abstract = FALSE,
overwrite = FALSE) {
require(RefManageR)
require(dplyr)
require(stringr)
require(anytime)
# Import the bibtex file and convert to data.frame
mypubs   <- ReadBib(bibfile, check = "warn", .Encoding = "UTF-8") %>%
as.data.frame()
# assign "categories" to the different types of publications
mypubs   <- mypubs %>%
dplyr::mutate(
pubtype = dplyr::case_when(document_type == "Article" ~ "2",
document_type == "Article in Press" ~ "2",
document_type == "InProceedings" ~ "1",
document_type == "Proceedings" ~ "1",
document_type == "Conference" ~ "1",
document_type == "Conference Paper" ~ "1",
document_type == "MastersThesis" ~ "3",
document_type == "PhdThesis" ~ "3",
document_type == "Manual" ~ "4",
document_type == "TechReport" ~ "4",
document_type == "Book" ~ "5",
document_type == "InCollection" ~ "6",
document_type == "InBook" ~ "6",
document_type == "Misc" ~ "0",
TRUE ~ "0"))
# create a function which populates the md template based on the info
# about a publication
create_md <- function(x) {
# define a date and create filename by appending date and start of title
if (!is.na(x[["year"]])) {
x[["date"]] <- paste0(x[["year"]], "-01-01")
} else {
x[["date"]] <- "2999-01-01"
}
filename <- paste(x[["date"]], x[["title"]] %>%
str_replace_all(fixed(" "), "_") %>%
str_remove_all(fixed(":")) %>%
str_sub(1, 20) %>%
paste0(".md"), sep = "_")
# start writing
if (!file.exists(file.path(outfold, filename)) | overwrite) {
fileConn <- file.path(outfold, filename)
write("+++", fileConn)
# Title and date
write(paste0("title = \"", x[["title"]], "\""), fileConn, append = T)
write(paste0("date = \"", anydate(x[["date"]]), "\""), fileConn, append = T)
# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
auth_hugo <- str_replace_all(x["author"], " and ", "\", \"")
auth_hugo <- stringi::stri_trans_general(auth_hugo, "latin-ascii")
write(paste0("authors = [\"", auth_hugo,"\"]"), fileConn, append = T)
# Publication type. Legend:
# 0 = Uncategorized, 1 = Conference paper, 2 = Journal article
# 3 = Manuscript, 4 = Report, 5 = Book,  6 = Book section
write(paste0("publication_types = [\"", x[["pubtype"]],"\"]"),
fileConn, append = T)
# Publication details: journal, volume, issue, page numbers and doi link
publication <- x[["journal"]]
if (!is.na(x[["volume"]])) publication <- paste0(publication,
", (", x[["volume"]], ")")
if (!is.na(x[["number"]])) publication <- paste0(publication,
", ", x[["number"]])
if (!is.na(x[["pages"]])) publication <- paste0(publication,
", _pp. ", x[["pages"]], "_")
if (!is.na(x[["doi"]])) publication <- paste0(publication,
", ", paste0("https://doi.org/",
x[["doi"]]))
write(paste0("publication = \"", publication,"\""), fileConn, append = T)
write(paste0("publication_short = \"", publication,"\""),fileConn, append = T)
# Abstract and optional shortened version.
if (abstract) {
write(paste0("abstract = \"", x[["abstract"]],"\""), fileConn, append = T)
} else {
write("abstract = \"\"", fileConn, append = T)
}
write(paste0("abstract_short = \"","\""), fileConn, append = T)
# other possible fields are kept empty. They can be customized later by
# editing the created md
write("image_preview = \"\"", fileConn, append = T)
write("selected = false", fileConn, append = T)
write("projects = []", fileConn, append = T)
write("tags = []", fileConn, append = T)
#links
write("url_pdf = \"\"", fileConn, append = T)
write("url_preprint = \"\"", fileConn, append = T)
write("url_code = \"\"", fileConn, append = T)
write("url_dataset = \"\"", fileConn, append = T)
write("url_project = \"\"", fileConn, append = T)
write("url_slides = \"\"", fileConn, append = T)
write("url_video = \"\"", fileConn, append = T)
write("url_poster = \"\"", fileConn, append = T)
write("url_source = \"\"", fileConn, append = T)
#other stuff
write("math = true", fileConn, append = T)
write("highlight = true", fileConn, append = T)
# Featured image
write("[header]", fileConn, append = T)
write("image = \"\"", fileConn, append = T)
write("caption = \"\"", fileConn, append = T)
write("+++", fileConn, append = T)
}
}
# apply the "create_md" function over the publications list to generate
# the different "md" files.
apply(mypubs, FUN = function(x) create_md(x), MARGIN = 1)
}
my_bibfile <- "source/walker.bib"
out_folder   <- "source/walker_md"
mypubs   <- data.table(ReadBib(my_bibfile, check = "warn", .Encoding = "UTF-8") %>% as.data.frame())
mypubs
for(i in 1:nrow(mypubs)){
x <- mypubs[i, ]
write_it(x, out_folder)
}
x
x
names(x)
x$bibtype
write_it <- function(x, out_folder){
filename <- paste(x$year, x$title %>%
str_replace_all(fixed(" "), "_") %>%
str_remove_all(fixed(":")) %>%
str_sub(1, 20) %>%
paste0(".md"), sep = "_")
fileConn <- file.path(out_folder, filename)
write("+++", fileConn)
# Title and date
write(paste0("title = \"", x$title, "\""), fileConn, append = T)
write(paste0("date = \"", anydate(x$year), "\""), fileConn, append = T)
# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
auth_hugo <- str_replace_all(x$author, " and ", "\", \"")
auth_hugo <- stringi::stri_trans_general(auth_hugo, "latin-ascii")
write(paste0("authors = [\"", auth_hugo,"\"]"), fileConn, append = T)
# Publication type. Legend:
# 0 = Uncategorized, 1 = Conference paper, 2 = Journal article
# 3 = Manuscript, 4 = Report, 5 = Book,  6 = Book section
if(x$bibtype=='Article')
write(paste0("publication_types = [\"", "2","\"]"),
fileConn, append = T)
# Publication details: journal, volume, issue, page numbers and doi link
publication <- x$journal
if (!is.na(x$volume)) publication <- paste0(publication,
", (", x[["volume"]], ")")
if (!is.na(x$number)) publication <- paste0(publication,
", ", x[["number"]])
if (!is.na(x$pages)) publication <- paste0(publication,
", _pp. ", x[["pages"]], "_")
if (!is.na(x$doi)) publication <- paste0(publication,
", ", paste0("https://doi.org/",
x[["doi"]]))
write(paste0("publication = \"", publication,"\""), fileConn, append = T)
write(paste0("publication_short = \"", publication,"\""),fileConn, append = T)
# Abstract and optional shortened version.
if (!is.na(x$abstract)) {
write(paste0("abstract = \"", x$abstract,"\""), fileConn, append = T)
} else {
write("abstract = \"\"", fileConn, append = T)
}
write(paste0("abstract_short = \"","\""), fileConn, append = T)
write("image_preview = \"\"", fileConn, append = T)
write("selected = false", fileConn, append = T)
write("projects = []", fileConn, append = T)
write("tags = []", fileConn, append = T)
#links
write("url_pdf = \"\"", fileConn, append = T)
write("url_preprint = \"\"", fileConn, append = T)
write("url_code = \"\"", fileConn, append = T)
write("url_dataset = \"\"", fileConn, append = T)
write("url_project = \"\"", fileConn, append = T)
write("url_slides = \"\"", fileConn, append = T)
write("url_video = \"\"", fileConn, append = T)
write("url_poster = \"\"", fileConn, append = T)
write("url_source = \"\"", fileConn, append = T)
#other stuff
write("math = true", fileConn, append = T)
write("highlight = true", fileConn, append = T)
# Featured image
write("[header]", fileConn, append = T)
write("image = \"\"", fileConn, append = T)
write("caption = \"\"", fileConn, append = T)
write("+++", fileConn, append = T)
}
for(i in 1:nrow(mypubs)){
x <- mypubs[i, ]
write_it(x, out_folder)
}
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
