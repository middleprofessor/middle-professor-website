<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Best practices – issues in inference | Elements of Statistical Modeling for Experimental Biology</title>
  <meta name="description" content="A first course in statistical modeling for experimental biology researchers" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Best practices – issues in inference | Elements of Statistical Modeling for Experimental Biology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for experimental biology researchers" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Best practices – issues in inference | Elements of Statistical Modeling for Experimental Biology" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for experimental biology researchers" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="model-fitting-and-model-fit-ols.html"/>
<link rel="next" href="part-vi-more-than-one-x-multivariable-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#math"><i class="fa fa-check"></i><b>0.1</b> Math</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#r-and-programming"><i class="fa fa-check"></i><b>0.2</b> R and programming</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-getting-started.html"><a href="part-i-getting-started.html"><i class="fa fa-check"></i>Part I: Getting Started</a></li>
<li class="chapter" data-level="1" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html"><i class="fa fa-check"></i><b>1</b> Getting Started – R Projects and R Markdown</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#r-vs-r-studio"><i class="fa fa-check"></i><b>1.1</b> R vs R Studio</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#download-and-install-r-and-r-studio"><i class="fa fa-check"></i><b>1.2</b> Download and install R and R studio</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#install-r-markdown"><i class="fa fa-check"></i><b>1.3</b> Install R Markdown</a></li>
<li class="chapter" data-level="1.4" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#importing-packages"><i class="fa fa-check"></i><b>1.4</b> Importing Packages</a></li>
<li class="chapter" data-level="1.5" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-an-r-studio-project-for-this-textbook"><i class="fa fa-check"></i><b>1.5</b> Create an R Studio Project for this textbook</a><ul>
<li class="chapter" data-level="1.5.1" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-an-r-markdown-file-for-this-chapter"><i class="fa fa-check"></i><b>1.5.1</b> Create an R Markdown file for this Chapter</a></li>
<li class="chapter" data-level="1.5.2" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-a-fake-data-chunk"><i class="fa fa-check"></i><b>1.5.2</b> Create a “fake-data” chunk</a></li>
<li class="chapter" data-level="1.5.3" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-a-plot-chunk"><i class="fa fa-check"></i><b>1.5.3</b> Create a “plot” chunk</a></li>
<li class="chapter" data-level="1.5.4" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#knit"><i class="fa fa-check"></i><b>1.5.4</b> Knit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model.html"><a href="part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model.html"><i class="fa fa-check"></i>Part II: An introduction to the analysis of experimental data with a linear model</a></li>
<li class="chapter" data-level="2" data-path="analyzing-experimental-data-with-a-linear-model.html"><a href="analyzing-experimental-data-with-a-linear-model.html"><i class="fa fa-check"></i><b>2</b> Analyzing experimental data with a linear model</a><ul>
<li class="chapter" data-level="2.1" data-path="analyzing-experimental-data-with-a-linear-model.html"><a href="analyzing-experimental-data-with-a-linear-model.html#this-text-is-about-the-estimation-of-treatment-effects-and-the-uncertainty-in-our-estimates-using-linear-models.-this-raises-the-question-what-is-an-effect"><i class="fa fa-check"></i><b>2.1</b> This text is about the estimation of treatment effects and the uncertainty in our estimates using linear models. This, raises the question, what is “an effect”?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><i class="fa fa-check"></i>Background physiology to the experiments in Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a></li>
<li class="chapter" data-level="" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><i class="fa fa-check"></i>Analyses for Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a><ul>
<li class="chapter" data-level="2.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#setup"><i class="fa fa-check"></i><b>2.2</b> Setup</a></li>
<li class="chapter" data-level="2.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#data-source"><i class="fa fa-check"></i><b>2.3</b> Data source</a></li>
<li class="chapter" data-level="2.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#control-the-color-palette"><i class="fa fa-check"></i><b>2.4</b> control the color palette</a></li>
<li class="chapter" data-level="2.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#useful-functions"><i class="fa fa-check"></i><b>2.5</b> useful functions</a></li>
<li class="chapter" data-level="2.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-effect-of-ask1-deletion-on-growth-body-weight"><i class="fa fa-check"></i><b>2.6</b> figure 2b – effect of ASK1 deletion on growth (body weight)</a><ul>
<li class="chapter" data-level="2.6.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-import"><i class="fa fa-check"></i><b>2.6.1</b> figure 2b – import</a></li>
<li class="chapter" data-level="2.6.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-exploratory-plots"><i class="fa fa-check"></i><b>2.6.2</b> figure 2b – exploratory plots</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-effect-of-ask1-deletion-on-final-body-weight"><i class="fa fa-check"></i><b>2.7</b> Figure 2c – Effect of ASK1 deletion on final body weight</a><ul>
<li class="chapter" data-level="2.7.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-import"><i class="fa fa-check"></i><b>2.7.1</b> Figure 2c – import</a></li>
<li class="chapter" data-level="2.7.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-own-computation-of-weight-change-v-imported-value"><i class="fa fa-check"></i><b>2.7.2</b> Figure 2c – check own computation of weight change v imported value</a></li>
<li class="chapter" data-level="2.7.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-exploratory-plots"><i class="fa fa-check"></i><b>2.7.3</b> Figure 2c – exploratory plots</a></li>
<li class="chapter" data-level="2.7.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-fit-the-model-m1-lm"><i class="fa fa-check"></i><b>2.7.4</b> Figure 2c – fit the model: m1 (lm)</a></li>
<li class="chapter" data-level="2.7.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-the-model-m1"><i class="fa fa-check"></i><b>2.7.5</b> Figure 2c – check the model: m1</a></li>
<li class="chapter" data-level="2.7.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-fit-the-model-m2-gamma-glm"><i class="fa fa-check"></i><b>2.7.6</b> Figure 2c – fit the model: m2 (gamma glm)</a></li>
<li class="chapter" data-level="2.7.7" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-the-model-m2"><i class="fa fa-check"></i><b>2.7.7</b> Figure 2c – check the model, m2</a></li>
<li class="chapter" data-level="2.7.8" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-inference-from-the-model"><i class="fa fa-check"></i><b>2.7.8</b> Figure 2c – inference from the model</a></li>
<li class="chapter" data-level="2.7.9" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-plot-the-model"><i class="fa fa-check"></i><b>2.7.9</b> Figure 2c – plot the model</a></li>
<li class="chapter" data-level="2.7.10" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-report"><i class="fa fa-check"></i><b>2.7.10</b> Figure 2c – report</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve"><i class="fa fa-check"></i><b>2.8</b> Figure 2d – Effect of ASK1 KO on glucose tolerance (whole curve)</a><ul>
<li class="chapter" data-level="2.8.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-import"><i class="fa fa-check"></i><b>2.8.1</b> Figure 2d – Import</a></li>
<li class="chapter" data-level="2.8.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-exploratory-plots"><i class="fa fa-check"></i><b>2.8.2</b> Figure 2d – exploratory plots</a></li>
<li class="chapter" data-level="2.8.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-fit-the-model"><i class="fa fa-check"></i><b>2.8.3</b> Figure 2d – fit the model</a></li>
<li class="chapter" data-level="2.8.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-check-the-model"><i class="fa fa-check"></i><b>2.8.4</b> Figure 2d – check the model</a></li>
<li class="chapter" data-level="2.8.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-inference"><i class="fa fa-check"></i><b>2.8.5</b> Figure 2d – inference</a></li>
<li class="chapter" data-level="2.8.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-plot-the-model"><i class="fa fa-check"></i><b>2.8.6</b> Figure 2d – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure"><i class="fa fa-check"></i><b>2.9</b> Figure 2e – Effect of ASK1 deletion on glucose tolerance (summary measure)</a><ul>
<li class="chapter" data-level="2.9.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-message-the-data"><i class="fa fa-check"></i><b>2.9.1</b> Figure 2e – message the data</a></li>
<li class="chapter" data-level="2.9.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-exploratory-plots"><i class="fa fa-check"></i><b>2.9.2</b> Figure 2e – exploratory plots</a></li>
<li class="chapter" data-level="2.9.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-fit-the-model"><i class="fa fa-check"></i><b>2.9.3</b> Figure 2e – fit the model</a></li>
<li class="chapter" data-level="2.9.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-check-the-model"><i class="fa fa-check"></i><b>2.9.4</b> Figure 2e – check the model</a></li>
<li class="chapter" data-level="2.9.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-inference-from-the-model"><i class="fa fa-check"></i><b>2.9.5</b> Figure 2e – inference from the model</a></li>
<li class="chapter" data-level="2.9.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-plot-the-model"><i class="fa fa-check"></i><b>2.9.6</b> Figure 2e – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate"><i class="fa fa-check"></i><b>2.10</b> Figure 2f – Effect of ASK1 deletion on glucose infusion rate</a><ul>
<li class="chapter" data-level="2.10.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-import"><i class="fa fa-check"></i><b>2.10.1</b> Figure 2f – import</a></li>
<li class="chapter" data-level="2.10.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-exploratory-plots"><i class="fa fa-check"></i><b>2.10.2</b> Figure 2f – exploratory plots</a></li>
<li class="chapter" data-level="2.10.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-fit-the-model"><i class="fa fa-check"></i><b>2.10.3</b> Figure 2f – fit the model</a></li>
<li class="chapter" data-level="2.10.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-check-the-model"><i class="fa fa-check"></i><b>2.10.4</b> Figure 2f – check the model</a></li>
<li class="chapter" data-level="2.10.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-inference"><i class="fa fa-check"></i><b>2.10.5</b> Figure 2f – inference</a></li>
<li class="chapter" data-level="2.10.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-plot-the-model"><i class="fa fa-check"></i><b>2.10.6</b> Figure 2f – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake"><i class="fa fa-check"></i><b>2.11</b> Figure 2g – Effect of ASK1 deletion on tissue-specific glucose uptake</a><ul>
<li class="chapter" data-level="2.11.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-import"><i class="fa fa-check"></i><b>2.11.1</b> Figure 2g – import</a></li>
<li class="chapter" data-level="2.11.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-exploratory-plots"><i class="fa fa-check"></i><b>2.11.2</b> Figure 2g – exploratory plots</a></li>
<li class="chapter" data-level="2.11.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-fit-the-model"><i class="fa fa-check"></i><b>2.11.3</b> Figure 2g – fit the model</a></li>
<li class="chapter" data-level="2.11.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-check-the-model"><i class="fa fa-check"></i><b>2.11.4</b> Figure 2g – check the model</a></li>
<li class="chapter" data-level="2.11.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-inference"><i class="fa fa-check"></i><b>2.11.5</b> Figure 2g – inference</a></li>
<li class="chapter" data-level="2.11.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-plot-the-model"><i class="fa fa-check"></i><b>2.11.6</b> Figure 2g – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2h"><i class="fa fa-check"></i><b>2.12</b> Figure 2h</a></li>
<li class="chapter" data-level="2.13" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-effect-of-ask1-deletion-on-liver-tg"><i class="fa fa-check"></i><b>2.13</b> Figure 2i – Effect of ASK1 deletion on liver TG</a><ul>
<li class="chapter" data-level="2.13.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-fit-the-model"><i class="fa fa-check"></i><b>2.13.1</b> Figure 2i – fit the model</a></li>
<li class="chapter" data-level="2.13.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-check-the-model"><i class="fa fa-check"></i><b>2.13.2</b> Figure 2i – check the model</a></li>
<li class="chapter" data-level="2.13.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-inference"><i class="fa fa-check"></i><b>2.13.3</b> Figure 2i – inference</a></li>
<li class="chapter" data-level="2.13.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-plot-the-model"><i class="fa fa-check"></i><b>2.13.4</b> Figure 2i – plot the model</a></li>
<li class="chapter" data-level="2.13.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-report-the-model"><i class="fa fa-check"></i><b>2.13.5</b> Figure 2i – report the model</a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2j"><i class="fa fa-check"></i><b>2.14</b> Figure 2j</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-r-fundamentals.html"><a href="part-iii-r-fundamentals.html"><i class="fa fa-check"></i>Part III: R fundamentals</a></li>
<li class="chapter" data-level="3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html"><i class="fa fa-check"></i><b>3</b> Data – Reading, Wrangling, and Writing</a><ul>
<li class="chapter" data-level="3.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#learning-from-this-chapter"><i class="fa fa-check"></i><b>3.1</b> Learning from this chapter</a></li>
<li class="chapter" data-level="3.2" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#data-working-in-r"><i class="fa fa-check"></i><b>3.2</b> Working in R</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#importing-data"><i class="fa fa-check"></i><b>3.2.1</b> Importing data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#data-wrangling"><i class="fa fa-check"></i><b>3.3</b> Data wrangling</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#reshaping-data-wide-to-long"><i class="fa fa-check"></i><b>3.3.1</b> Reshaping data – Wide to long</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#reshaping-data-transpose-turning-the-columns-into-rows"><i class="fa fa-check"></i><b>3.3.2</b> Reshaping data – Transpose (turning the columns into rows)</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#combining-data"><i class="fa fa-check"></i><b>3.3.3</b> Combining data</a></li>
<li class="chapter" data-level="3.3.4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#subsetting-data"><i class="fa fa-check"></i><b>3.3.4</b> Subsetting data</a></li>
<li class="chapter" data-level="3.3.5" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#wrangling-columns"><i class="fa fa-check"></i><b>3.3.5</b> Wrangling columns</a></li>
<li class="chapter" data-level="3.3.6" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#missing-data"><i class="fa fa-check"></i><b>3.3.6</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#saving-data"><i class="fa fa-check"></i><b>3.4</b> Saving data</a></li>
<li class="chapter" data-level="3.5" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#exercises"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plotting-models.html"><a href="plotting-models.html"><i class="fa fa-check"></i><b>4</b> Plotting Models</a><ul>
<li class="chapter" data-level="4.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plots-show-the-model-and-the-data"><i class="fa fa-check"></i><b>4.1</b> Pretty good plots show the model and the data</a><ul>
<li class="chapter" data-level="4.1.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-1-modeled-effects-plot"><i class="fa fa-check"></i><b>4.1.1</b> Pretty good plot component 1: Modeled effects plot</a></li>
<li class="chapter" data-level="4.1.2" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot"><i class="fa fa-check"></i><b>4.1.2</b> Pretty good plot component 2: Modeled mean and CI plot</a></li>
<li class="chapter" data-level="4.1.3" data-path="plotting-models.html"><a href="plotting-models.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><i class="fa fa-check"></i><b>4.1.3</b> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="plotting-models.html"><a href="plotting-models.html#some-comments-on-plot-components"><i class="fa fa-check"></i><b>4.2</b> Some comments on plot components</a></li>
<li class="chapter" data-level="4.3" data-path="plotting-models.html"><a href="plotting-models.html#working-in-r"><i class="fa fa-check"></i><b>4.3</b> Working in R</a><ul>
<li class="chapter" data-level="4.3.1" data-path="plotting-models.html"><a href="plotting-models.html#unpooled-se-bars-and-confidence-intervals"><i class="fa fa-check"></i><b>4.3.1</b> Unpooled SE bars and confidence intervals</a></li>
<li class="chapter" data-level="4.3.2" data-path="plotting-models.html"><a href="plotting-models.html#adding-bootstrap-intervals"><i class="fa fa-check"></i><b>4.3.2</b> Adding bootstrap intervals</a></li>
<li class="chapter" data-level="4.3.3" data-path="plotting-models.html"><a href="plotting-models.html#adding-modeled-means-and-error-intervals"><i class="fa fa-check"></i><b>4.3.3</b> Adding modeled means and error intervals</a></li>
<li class="chapter" data-level="4.3.4" data-path="plotting-models.html"><a href="plotting-models.html#adding-p-values"><i class="fa fa-check"></i><b>4.3.4</b> Adding p-values</a></li>
<li class="chapter" data-level="4.3.5" data-path="plotting-models.html"><a href="plotting-models.html#adding-custom-p-values"><i class="fa fa-check"></i><b>4.3.5</b> Adding custom p-values</a></li>
<li class="chapter" data-level="4.3.6" data-path="plotting-models.html"><a href="plotting-models.html#plotting-two-factors"><i class="fa fa-check"></i><b>4.3.6</b> Plotting two factors</a></li>
<li class="chapter" data-level="4.3.7" data-path="plotting-models.html"><a href="plotting-models.html#interaction-plot"><i class="fa fa-check"></i><b>4.3.7</b> Interaction plot</a></li>
<li class="chapter" data-level="4.3.8" data-path="plotting-models.html"><a href="plotting-models.html#plot-components"><i class="fa fa-check"></i><b>4.3.8</b> Plot components</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iv-some-fundamentals-of-statistical-modeling.html"><a href="part-iv-some-fundamentals-of-statistical-modeling.html"><i class="fa fa-check"></i>Part IV: Some Fundamentals of Statistical Modeling</a></li>
<li class="chapter" data-level="5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="chapter" data-level="5.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#the-sample-standard-deviation-vs.-the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>5.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="5.1.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#sample-standard-deviation"><i class="fa fa-check"></i><b>5.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="5.1.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>5.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>5.2</b> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="5.2.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#steps"><i class="fa fa-check"></i><b>5.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>5.3</b> Using R to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="5.3.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-i"><i class="fa fa-check"></i><b>5.3.1</b> part I</a></li>
<li class="chapter" data-level="5.3.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-ii---means"><i class="fa fa-check"></i><b>5.3.2</b> part II - means</a></li>
<li class="chapter" data-level="5.3.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>5.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="5.3.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>5.3.4</b> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#bootstrap"><i class="fa fa-check"></i><b>5.4</b> Bootstrapped standard errors</a><ul>
<li class="chapter" data-level="5.4.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#an-example-of-bootstrapped-standard-errors-using-vole-data"><i class="fa fa-check"></i><b>5.4.1</b> An example of bootstrapped standard errors using vole data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#confidence-interval"><i class="fa fa-check"></i><b>5.5</b> Confidence Interval</a><ul>
<li class="chapter" data-level="5.5.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#interpretation-of-a-confidence-interval"><i class="fa fa-check"></i><b>5.5.1</b> Interpretation of a confidence interval</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>6</b> P-values</a><ul>
<li class="chapter" data-level="6.1" data-path="p-values.html"><a href="p-values.html#a-p-value-is-the-probability-of-sampling-a-value-as-or-more-extreme-than-the-test-statistic-if-sampling-from-a-null-distribution"><i class="fa fa-check"></i><b>6.1</b> A <em>p</em>-value is the probability of sampling a value as or more extreme than the test statistic if sampling from a null distribution</a></li>
<li class="chapter" data-level="6.2" data-path="p-values.html"><a href="p-values.html#pump-your-intuition-creating-a-null-distribution"><i class="fa fa-check"></i><b>6.2</b> Pump your intuition – Creating a null distribution</a></li>
<li class="chapter" data-level="6.3" data-path="p-values.html"><a href="p-values.html#a-null-distribution-of-t-values-the-t-distribution"><i class="fa fa-check"></i><b>6.3</b> A null distribution of <em>t</em>-values – the <em>t</em> distribution</a></li>
<li class="chapter" data-level="6.4" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>6.4</b> P-values from the perspective of permutation</a></li>
<li class="chapter" data-level="6.5" data-path="p-values.html"><a href="p-values.html#parametric-vs.-non-parametric-statistics"><i class="fa fa-check"></i><b>6.5</b> Parametric vs. non-parametric statistics</a></li>
<li class="chapter" data-level="6.6" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>6.6</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="6.6.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>6.6.1</b> Background</a></li>
<li class="chapter" data-level="6.6.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>6.6.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <em>p</em>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="6.6.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>6.6.3</b> Two interpretations of the <em>p</em>-value</a></li>
<li class="chapter" data-level="6.6.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>6.6.4</b> NHST</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>6.7</b> Some major misconceptions of the <em>p</em>-value</a><ul>
<li class="chapter" data-level="6.7.1" data-path="p-values.html"><a href="p-values.html#misconception-p-is-the-probability-that-the-null-is-true-and-1-p-is-probability-that-the-alternative-is-true"><i class="fa fa-check"></i><b>6.7.1</b> Misconception: <em>p</em> is the probability that the null is true <em>and</em> <span class="math inline">\(1-p\)</span> is probability that the alternative is true</a></li>
<li class="chapter" data-level="6.7.2" data-path="p-values.html"><a href="p-values.html#misconception-a-p-value-is-repeatable"><i class="fa fa-check"></i><b>6.7.2</b> Misconception: a <em>p</em>-value is repeatable</a></li>
<li class="chapter" data-level="6.7.3" data-path="p-values.html"><a href="p-values.html#misconception-0.05-is-the-lifetime-rate-of-false-discoveries"><i class="fa fa-check"></i><b>6.7.3</b> Misconception: 0.05 is the lifetime rate of false discoveries</a></li>
<li class="chapter" data-level="6.7.4" data-path="p-values.html"><a href="p-values.html#misconception-a-low-p-value-indicates-an-important-effect"><i class="fa fa-check"></i><b>6.7.4</b> Misconception: a low <em>p</em>-value indicates an important effect</a></li>
<li class="chapter" data-level="6.7.5" data-path="p-values.html"><a href="p-values.html#misconception-a-low-p-value-indicates-high-model-fit-or-high-predictive-capacity"><i class="fa fa-check"></i><b>6.7.5</b> Misconception: a low <em>p</em>-value indicates high model fit or high predictive capacity</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="p-values.html"><a href="p-values.html#what-the-p-value-does-not-mean"><i class="fa fa-check"></i><b>6.8</b> What the <em>p</em>-value does not mean</a></li>
<li class="chapter" data-level="6.9" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>6.9</b> Recommendations</a><ul>
<li class="chapter" data-level="6.9.1" data-path="p-values.html"><a href="p-values.html#primary-sources-for-recommendations"><i class="fa fa-check"></i><b>6.9.1</b> Primary sources for recommendations</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="p-values.html"><a href="p-values.html#problems"><i class="fa fa-check"></i><b>6.10</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="errors-in-inference.html"><a href="errors-in-inference.html"><i class="fa fa-check"></i><b>7</b> Errors in inference</a><ul>
<li class="chapter" data-level="7.1" data-path="errors-in-inference.html"><a href="errors-in-inference.html#classical-nhst-concepts-of-wrong"><i class="fa fa-check"></i><b>7.1</b> Classical NHST concepts of wrong</a><ul>
<li class="chapter" data-level="7.1.1" data-path="errors-in-inference.html"><a href="errors-in-inference.html#type-i-error"><i class="fa fa-check"></i><b>7.1.1</b> Type I error</a></li>
<li class="chapter" data-level="7.1.2" data-path="errors-in-inference.html"><a href="errors-in-inference.html#power"><i class="fa fa-check"></i><b>7.1.2</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="errors-in-inference.html"><a href="errors-in-inference.html#a-non-neyman-pearson-concept-of-power"><i class="fa fa-check"></i><b>7.2</b> A non-Neyman-Pearson concept of power</a><ul>
<li class="chapter" data-level="7.2.1" data-path="errors-in-inference.html"><a href="errors-in-inference.html#estimation-error"><i class="fa fa-check"></i><b>7.2.1</b> Estimation error</a></li>
<li class="chapter" data-level="7.2.2" data-path="errors-in-inference.html"><a href="errors-in-inference.html#coverage"><i class="fa fa-check"></i><b>7.2.2</b> Coverage</a></li>
<li class="chapter" data-level="7.2.3" data-path="errors-in-inference.html"><a href="errors-in-inference.html#type-s-error"><i class="fa fa-check"></i><b>7.2.3</b> Type S error</a></li>
<li class="chapter" data-level="7.2.4" data-path="errors-in-inference.html"><a href="errors-in-inference.html#type-m-error"><i class="fa fa-check"></i><b>7.2.4</b> Type M error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-introduction-to-linear-models.html"><a href="part-v-introduction-to-linear-models.html"><i class="fa fa-check"></i>Part V: Introduction to Linear Models</a></li>
<li class="chapter" data-level="8" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html"><i class="fa fa-check"></i><b>8</b> An introduction to linear models</a><ul>
<li class="chapter" data-level="8.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#two-specifications-of-a-linear-model"><i class="fa fa-check"></i><b>8.1</b> Two specifications of a linear model</a><ul>
<li class="chapter" data-level="8.1.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#the-error-draw-specification"><i class="fa fa-check"></i><b>8.1.1</b> The “error draw” specification</a></li>
<li class="chapter" data-level="8.1.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#the-conditional-draw-specification"><i class="fa fa-check"></i><b>8.1.2</b> The “conditional draw” specification</a></li>
<li class="chapter" data-level="8.1.3" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#comparing-the-two-ways-of-specifying-the-linear-model"><i class="fa fa-check"></i><b>8.1.3</b> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables"><i class="fa fa-check"></i><b>8.2</b> A linear model can be fit to data with continuous, discrete, or categorical <span class="math inline">\(X\)</span> variables</a><ul>
<li class="chapter" data-level="8.2.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-continuous-or-discrete"><i class="fa fa-check"></i><b>8.2.1</b> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is continuous or discrete</a></li>
<li class="chapter" data-level="8.2.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-categorical"><i class="fa fa-check"></i><b>8.2.2</b> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is categorical</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>8.3</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="8.4" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#what-do-we-call-the-x-and-y-variables"><i class="fa fa-check"></i><b>8.4</b> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li class="chapter" data-level="8.5" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#modeling-strategy"><i class="fa fa-check"></i><b>8.5</b> Modeling strategy</a></li>
<li class="chapter" data-level="8.6" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#predictions-from-the-model"><i class="fa fa-check"></i><b>8.6</b> Predictions from the model</a></li>
<li class="chapter" data-level="8.7" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#inference-from-the-model"><i class="fa fa-check"></i><b>8.7</b> Inference from the model</a><ul>
<li class="chapter" data-level="8.7.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>8.7.1</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="8.7.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>8.7.2</b> Specific assumptions for inference with a linear model</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#linear-modelregression-model-orstatistical-model"><i class="fa fa-check"></i><b>8.8</b> “linear model,”regression model“, or”statistical model"?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html"><i class="fa fa-check"></i><b>9</b> Linear models with a single, continuous <em>X</em></a><ul>
<li class="chapter" data-level="9.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><i class="fa fa-check"></i><b>9.1</b> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="9.1.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#analysis-of-green-down-data"><i class="fa fa-check"></i><b>9.1.1</b> Analysis of “green-down” data</a></li>
<li class="chapter" data-level="9.1.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#learning-from-the-green-down-example"><i class="fa fa-check"></i><b>9.1.2</b> Learning from the green-down example</a></li>
<li class="chapter" data-level="9.1.3" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#using-a-regression-model-for-explanation-causal-models"><i class="fa fa-check"></i><b>9.1.3</b> Using a regression model for “explanation” – causal models</a></li>
<li class="chapter" data-level="9.1.4" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#using-a-regression-model-for-prediction-prediction-models"><i class="fa fa-check"></i><b>9.1.4</b> Using a regression model for prediction – prediction models</a></li>
<li class="chapter" data-level="9.1.5" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#using-a-regression-model-for-creating-a-new-response-variable-comparing-slopes-of-longitudinal-data"><i class="fa fa-check"></i><b>9.1.5</b> Using a regression model for creating a new response variable – comparing slopes of longitudinal data</a></li>
<li class="chapter" data-level="9.1.6" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#using-a-regression-model-for-for-calibration"><i class="fa fa-check"></i><b>9.1.6</b> Using a regression model for for calibration</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#working-in-r-1"><i class="fa fa-check"></i><b>9.2</b> Working in R</a><ul>
<li class="chapter" data-level="9.2.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> Fitting the linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>9.2.2</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="9.2.3" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#inference-the-coefficient-table-and-confidence-intervals"><i class="fa fa-check"></i><b>9.2.3</b> Inference – the coefficient table and Confidence intervals</a></li>
<li class="chapter" data-level="9.2.4" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#how-good-is-our-model-model-checking"><i class="fa fa-check"></i><b>9.2.4</b> How good is our model? – Model checking</a></li>
<li class="chapter" data-level="9.2.5" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#plotting-models-with-continuous-x"><i class="fa fa-check"></i><b>9.2.5</b> Plotting models with continuous <em>X</em></a></li>
<li class="chapter" data-level="9.2.6" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#creating-a-table-of-predicted-values-and-95-prediction-intervals"><i class="fa fa-check"></i><b>9.2.6</b> Creating a table of predicted values and 95% prediction intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#hidden-code"><i class="fa fa-check"></i><b>9.3</b> Hidden code</a><ul>
<li class="chapter" data-level="9.3.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#import-and-plot-of-fig2c-ecosystem-warming-experimental-data"><i class="fa fa-check"></i><b>9.3.1</b> Import and plot of fig2c (ecosystem warming experimental) data</a></li>
<li class="chapter" data-level="9.3.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#import-and-plot-efig_3d-ecosysem-warming-observational-data"><i class="fa fa-check"></i><b>9.3.2</b> Import and plot efig_3d (Ecosysem warming observational) data</a></li>
<li class="chapter" data-level="9.3.3" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#import-and-plot-of-fig1f-methionine-restriction-data"><i class="fa fa-check"></i><b>9.3.3</b> Import and plot of fig1f (methionine restriction) data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#try-it"><i class="fa fa-check"></i><b>9.4</b> Try it</a><ul>
<li class="chapter" data-level="9.4.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#a-prediction-model-from-the-literature"><i class="fa fa-check"></i><b>9.4.1</b> A prediction model from the literature</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#intuition-pumps"><i class="fa fa-check"></i><b>9.5</b> Intuition pumps</a><ul>
<li class="chapter" data-level="9.5.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#correlation-and-r2"><i class="fa fa-check"></i><b>9.5.1</b> Correlation and $R^2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>10</b> Linear models with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="10.1" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response."><i class="fa fa-check"></i><b>10.1</b> A linear model with a single, categorical <em>X</em> variable estimates the effects of the levels of <em>X</em> on the response.</a><ul>
<li class="chapter" data-level="10.1.1" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#example-1-two-treatment-levels-groups"><i class="fa fa-check"></i><b>10.1.1</b> Example 1 – two treatment levels (“groups”)</a></li>
<li class="chapter" data-level="10.1.2" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#understanding-the-analysis-with-two-treatment-levels"><i class="fa fa-check"></i><b>10.1.2</b> Understanding the analysis with two treatment levels</a></li>
<li class="chapter" data-level="10.1.3" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#example-2-three-treatment-levels-groups"><i class="fa fa-check"></i><b>10.1.3</b> Example 2 – three treatment levels (“groups”)</a></li>
<li class="chapter" data-level="10.1.4" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#understanding-the-analysis-with-three-or-more-treatment-levels"><i class="fa fa-check"></i><b>10.1.4</b> Understanding the analysis with three (or more) treatment levels</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#working-in-r-2"><i class="fa fa-check"></i><b>10.2</b> Working in R</a><ul>
<li class="chapter" data-level="10.2.1" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#specifying-the-contrasts"><i class="fa fa-check"></i><b>10.2.1</b> Specifying the contrasts</a></li>
<li class="chapter" data-level="10.2.2" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#adjustment-for-multiple-comparisons"><i class="fa fa-check"></i><b>10.2.2</b> Adjustment for multiple comparisons</a></li>
<li class="chapter" data-level="10.2.3" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#plotting-models-with-a-single-categorical-x"><i class="fa fa-check"></i><b>10.2.3</b> Plotting models with a single, categorical <span class="math inline">\(X\)</span></a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#issues-in-inference-in-models-with-a-single-categorical-x"><i class="fa fa-check"></i><b>10.3</b> Issues in inference in models with a single, categorical <span class="math inline">\(X\)</span></a><ul>
<li class="chapter" data-level="10.3.1" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#lack-of-independence"><i class="fa fa-check"></i><b>10.3.1</b> Lack of independence</a></li>
<li class="chapter" data-level="10.3.2" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#heterogeneity-of-variances"><i class="fa fa-check"></i><b>10.3.2</b> Heterogeneity of variances</a></li>
<li class="chapter" data-level="10.3.3" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#the-conditional-response-isnt-normal"><i class="fa fa-check"></i><b>10.3.3</b> The conditional response isn’t Normal</a></li>
<li class="chapter" data-level="10.3.4" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#pre-post-designs"><i class="fa fa-check"></i><b>10.3.4</b> Pre-post designs</a></li>
<li class="chapter" data-level="10.3.5" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#longitudinal-designs"><i class="fa fa-check"></i><b>10.3.5</b> Longitudinal designs</a></li>
<li class="chapter" data-level="10.3.6" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#comparing-responses-normalized-to-a-standard"><i class="fa fa-check"></i><b>10.3.6</b> Comparing responses normalized to a standard</a></li>
<li class="chapter" data-level="10.3.7" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#comparing-responses-that-are-ratios"><i class="fa fa-check"></i><b>10.3.7</b> Comparing responses that are ratios</a></li>
<li class="chapter" data-level="10.3.8" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#researcher-degrees-of-freedom"><i class="fa fa-check"></i><b>10.3.8</b> Researcher degrees of freedom</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#hidden-code-1"><i class="fa fa-check"></i><b>10.4</b> Hidden Code</a><ul>
<li class="chapter" data-level="10.4.1" data-path="linear-models-with-a-single-categorical-x.html"><a href="linear-models-with-a-single-categorical-x.html#fig1b-data"><i class="fa fa-check"></i><b>10.4.1</b> fig1b data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>11</b> Model Checking</a><ul>
<li class="chapter" data-level="11.1" data-path="model-checking.html"><a href="model-checking.html#all-statistical-analyses-should-be-followed-by-model-checking"><i class="fa fa-check"></i><b>11.1</b> All statistical analyses should be followed by model checking</a></li>
<li class="chapter" data-level="11.2" data-path="model-checking.html"><a href="model-checking.html#linear-model-assumptions"><i class="fa fa-check"></i><b>11.2</b> Linear model assumptions</a><ul>
<li class="chapter" data-level="11.2.1" data-path="model-checking.html"><a href="model-checking.html#a-bit-about-iid"><i class="fa fa-check"></i><b>11.2.1</b> A bit about IID</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="model-checking.html"><a href="model-checking.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><i class="fa fa-check"></i><b>11.3</b> Diagnostic plots use the residuals from the model fit</a><ul>
<li class="chapter" data-level="11.3.1" data-path="model-checking.html"><a href="model-checking.html#residuals"><i class="fa fa-check"></i><b>11.3.1</b> Residuals</a></li>
<li class="chapter" data-level="11.3.2" data-path="model-checking.html"><a href="model-checking.html#a-normal-q-q-plot-is-used-to-check-for-characteristic-departures-from-normality"><i class="fa fa-check"></i><b>11.3.2</b> A Normal Q-Q plot is used to check for characteristic departures from Normality</a></li>
<li class="chapter" data-level="11.3.3" data-path="model-checking.html"><a href="model-checking.html#mapping-qq-plot-departures-from-normality"><i class="fa fa-check"></i><b>11.3.3</b> Mapping QQ-plot departures from Normality</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="model-checking.html"><a href="model-checking.html#model-checking-homoskedasticity"><i class="fa fa-check"></i><b>11.4</b> Model checking homoskedasticity</a></li>
<li class="chapter" data-level="11.5" data-path="model-checking.html"><a href="model-checking.html#using-r"><i class="fa fa-check"></i><b>11.5</b> Using R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html"><i class="fa fa-check"></i><b>12</b> Model Fitting and Model Fit (OLS)</a><ul>
<li class="chapter" data-level="12.1" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#least-squares-estimation-and-the-decomposition-of-variance"><i class="fa fa-check"></i><b>12.1</b> Least Squares Estimation and the Decomposition of Variance</a></li>
<li class="chapter" data-level="12.2" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#ols-regression"><i class="fa fa-check"></i><b>12.2</b> OLS regression</a></li>
<li class="chapter" data-level="12.3" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>12.3</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html"><i class="fa fa-check"></i><b>13</b> Best practices – issues in inference</a><ul>
<li class="chapter" data-level="13.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing"><i class="fa fa-check"></i><b>13.1</b> Multiple testing</a><ul>
<li class="chapter" data-level="13.1.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#some-background"><i class="fa fa-check"></i><b>13.1.1</b> Some background</a></li>
<li class="chapter" data-level="13.1.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing-working-in-r"><i class="fa fa-check"></i><b>13.1.2</b> Multiple testing – working in R</a></li>
<li class="chapter" data-level="13.1.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#false-discovery-rate"><i class="fa fa-check"></i><b>13.1.3</b> False Discovery Rate</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#difference-in-p-is-not-different"><i class="fa fa-check"></i><b>13.2</b> difference in p is not different</a></li>
<li class="chapter" data-level="13.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#inference-when-data-are-not-normal"><i class="fa fa-check"></i><b>13.3</b> Inference when data are not Normal</a><ul>
<li class="chapter" data-level="13.3.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#working-in-r-3"><i class="fa fa-check"></i><b>13.3.1</b> Working in R</a></li>
<li class="chapter" data-level="13.3.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>13.3.2</b> Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="13.3.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#permutation-test"><i class="fa fa-check"></i><b>13.3.3</b> Permutation test</a></li>
<li class="chapter" data-level="13.3.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#non-parametric-tests"><i class="fa fa-check"></i><b>13.3.4</b> Non-parametric tests</a></li>
<li class="chapter" data-level="13.3.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#log-transformations"><i class="fa fa-check"></i><b>13.3.5</b> Log transformations</a></li>
<li class="chapter" data-level="13.3.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#performance-of-parametric-tests-and-alternatives"><i class="fa fa-check"></i><b>13.3.6</b> Performance of parametric tests and alternatives</a></li>
</ul></li>
</ul></li>
<li><a href="part-vi-more-than-one-x-multivariable-models.html#part-vi-more-than-one-x-multivariable-models">Part VI: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="chapter" data-level="14" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html"><i class="fa fa-check"></i><b>14</b> Adding covariates to a linear model</a><ul>
<li class="chapter" data-level="14.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>14.1</b> Adding covariates can increases the precision of the effect of interest</a></li>
<li class="chapter" data-level="14.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-decrease-prediction-error-in-predictive-models"><i class="fa fa-check"></i><b>14.2</b> Adding covariates can decrease prediction error in predictive models</a></li>
<li class="chapter" data-level="14.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-reduce-bias-due-to-confounding-in-explanatory-models"><i class="fa fa-check"></i><b>14.3</b> Adding covariates can reduce bias due to confounding in explanatory models</a></li>
<li class="chapter" data-level="14.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-1-a-pre-treatment-measure-of-the-response-should-be-a-covariate-and-not-subtracted-from-the-post-treatment-measure-regression-to-the-mean"><i class="fa fa-check"></i><b>14.4</b> Best practices 1: A pre-treatment measure of the response should be a covariate and not subtracted from the post-treatment measure (regression to the mean)</a><ul>
<li class="chapter" data-level="14.4.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-words"><i class="fa fa-check"></i><b>14.4.1</b> Regression to the mean in words</a></li>
<li class="chapter" data-level="14.4.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-pictures"><i class="fa fa-check"></i><b>14.4.2</b> Regression to the mean in pictures</a></li>
<li class="chapter" data-level="14.4.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>14.4.3</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="14.4.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>14.4.4</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-2-use-a-covariate-instead-of-normalizing-a-response"><i class="fa fa-check"></i><b>14.5</b> Best practices 2: Use a covariate instead of normalizing a response</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>15</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="15.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>15.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="15.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>15.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="15.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>15.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="15.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-interpretation-of-the-coefficients-in-a-factorial-model-is-entirely-dependent-on-the-reference"><i class="fa fa-check"></i><b>15.1.3</b> The interpretation of the coefficients in a factorial model is entirely dependent on the reference…</a></li>
<li class="chapter" data-level="15.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#estimated-marginal-means"><i class="fa fa-check"></i><b>15.1.4</b> Estimated marginal means</a></li>
<li class="chapter" data-level="15.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#in-a-factorial-model-there-are-multiple-effects-of-each-factor-simple-effects"><i class="fa fa-check"></i><b>15.1.5</b> In a factorial model, there are multiple effects of each factor (simple effects)</a></li>
<li class="chapter" data-level="15.1.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects"><i class="fa fa-check"></i><b>15.1.6</b> Marginal effects</a></li>
<li class="chapter" data-level="15.1.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>15.1.7</b> The additive model</a></li>
<li class="chapter" data-level="15.1.8" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reduce-models-for-the-right-reason"><i class="fa fa-check"></i><b>15.1.8</b> Reduce models for the right reason</a></li>
<li class="chapter" data-level="15.1.9" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>15.1.9</b> What about models with more than two factors?</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results"><i class="fa fa-check"></i><b>15.2</b> Reporting results</a><ul>
<li class="chapter" data-level="15.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>15.2.1</b> Text results</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-4"><i class="fa fa-check"></i><b>15.3</b> Working in R</a><ul>
<li class="chapter" data-level="15.3.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-formula"><i class="fa fa-check"></i><b>15.3.1</b> Model formula</a></li>
<li class="chapter" data-level="15.3.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#modeled-means"><i class="fa fa-check"></i><b>15.3.2</b> Modeled means</a></li>
<li class="chapter" data-level="15.3.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-means"><i class="fa fa-check"></i><b>15.3.3</b> Marginal means</a></li>
<li class="chapter" data-level="15.3.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts"><i class="fa fa-check"></i><b>15.3.4</b> Contrasts</a></li>
<li class="chapter" data-level="15.3.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#simple-effects"><i class="fa fa-check"></i><b>15.3.5</b> Simple effects</a></li>
<li class="chapter" data-level="15.3.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects-1"><i class="fa fa-check"></i><b>15.3.6</b> Marginal effects</a></li>
<li class="chapter" data-level="15.3.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#plotting-results"><i class="fa fa-check"></i><b>15.3.7</b> Plotting results</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-1"><i class="fa fa-check"></i><b>15.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>16</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="16.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>16.1</b> Summary of usage</a></li>
<li class="chapter" data-level="16.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>16.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="16.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>16.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="16.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>16.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="16.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>16.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="16.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>16.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>16.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="16.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="16.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>16.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="16.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>16.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-5"><i class="fa fa-check"></i><b>16.5</b> Working in R</a><ul>
<li class="chapter" data-level="16.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>16.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="16.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="predictive-models.html"><a href="predictive-models.html"><i class="fa fa-check"></i><b>17</b> Predictive Models</a><ul>
<li class="chapter" data-level="17.1" data-path="predictive-models.html"><a href="predictive-models.html#overfitting"><i class="fa fa-check"></i><b>17.1</b> Overfitting</a></li>
<li class="chapter" data-level="17.2" data-path="predictive-models.html"><a href="predictive-models.html#model-building-vs.-variable-selection-vs.-model-selection"><i class="fa fa-check"></i><b>17.2</b> Model building vs. Variable selection vs. Model selection</a><ul>
<li class="chapter" data-level="17.2.1" data-path="predictive-models.html"><a href="predictive-models.html#stepwise-regression"><i class="fa fa-check"></i><b>17.2.1</b> Stepwise regression</a></li>
<li class="chapter" data-level="17.2.2" data-path="predictive-models.html"><a href="predictive-models.html#cross-validation"><i class="fa fa-check"></i><b>17.2.2</b> Cross-validation</a></li>
<li class="chapter" data-level="17.2.3" data-path="predictive-models.html"><a href="predictive-models.html#penalization"><i class="fa fa-check"></i><b>17.2.3</b> Penalization</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="predictive-models.html"><a href="predictive-models.html#shrinkage"><i class="fa fa-check"></i><b>17.3</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-vii-expanding-the-linear-model.html"><a href="part-vii-expanding-the-linear-model.html"><i class="fa fa-check"></i>Part VII – Expanding the Linear Model</a></li>
<li class="chapter" data-level="18" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>18</b> Linear mixed models</a><ul>
<li class="chapter" data-level="18.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>18.1</b> Random effects</a></li>
<li class="chapter" data-level="18.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>18.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="18.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>18.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="18.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#blocking"><i class="fa fa-check"></i><b>18.4</b> Blocking</a><ul>
<li class="chapter" data-level="18.4.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualing-variation-due-to-blocks"><i class="fa fa-check"></i><b>18.4.1</b> Visualing variation due to blocks</a></li>
<li class="chapter" data-level="18.4.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#blocking-increases-precision-of-point-estimates"><i class="fa fa-check"></i><b>18.4.2</b> Blocking increases precision of point estimates</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#pseudoreplication"><i class="fa fa-check"></i><b>18.5</b> Pseudoreplication</a><ul>
<li class="chapter" data-level="18.5.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-pseduoreplication"><i class="fa fa-check"></i><b>18.5.1</b> Visualizing pseduoreplication</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model"><i class="fa fa-check"></i><b>18.6</b> Mapping NHST to estimation: A paired t-test is a special case of a linear mixed model</a></li>
<li class="chapter" data-level="18.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>18.7</b> Advanced topic – Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="18.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-6"><i class="fa fa-check"></i><b>18.8</b> Working in R</a><ul>
<li class="chapter" data-level="18.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>18.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>19</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="19.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>19.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="19.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>19.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="19.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy-1"><i class="fa fa-check"></i><b>19.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="19.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>19.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="19.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>19.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="19.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>19.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="19.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>19.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="19.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>19.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="19.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>19.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-7"><i class="fa fa-check"></i><b>19.3</b> Working in R</a><ul>
<li class="chapter" data-level="19.3.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-to-count-data"><i class="fa fa-check"></i><b>19.3.1</b> Fitting a GLM to count data</a></li>
<li class="chapter" data-level="19.3.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-generalized-linear-mixed-model-glmm-to-count-data"><i class="fa fa-check"></i><b>19.3.2</b> Fitting a generalized linear mixed model (GLMM) to count data</a></li>
<li class="chapter" data-level="19.3.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-generalized-linear-model-to-continouus-data"><i class="fa fa-check"></i><b>19.3.3</b> Fitting a generalized linear model to continouus data</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-2"><i class="fa fa-check"></i><b>19.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html"><i class="fa fa-check"></i><b>20</b> Linear models with heterogenous variance</a><ul>
<li class="chapter" data-level="20.1" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html#gls"><i class="fa fa-check"></i><b>20.1</b> gls</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><i class="fa fa-check"></i>Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="chapter" data-level="21" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html"><i class="fa fa-check"></i><b>21</b> Plotting functions (#ggplotsci)</a><ul>
<li class="chapter" data-level="21.1" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#odd-even"><i class="fa fa-check"></i><b>21.1</b> odd-even</a></li>
<li class="chapter" data-level="21.2" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#estimate-response-and-effects-with-emmeans"><i class="fa fa-check"></i><b>21.2</b> estimate response and effects with emmeans</a></li>
<li class="chapter" data-level="21.3" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#emm_table"><i class="fa fa-check"></i><b>21.3</b> emm_table</a></li>
<li class="chapter" data-level="21.4" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#pairs_table"><i class="fa fa-check"></i><b>21.4</b> pairs_table</a></li>
<li class="chapter" data-level="21.5" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_mean_error"><i class="fa fa-check"></i><b>21.5</b> gg_mean_error</a></li>
<li class="chapter" data-level="21.6" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_ancova"><i class="fa fa-check"></i><b>21.6</b> gg_ancova</a></li>
<li class="chapter" data-level="21.7" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_mean_ci_ancova"><i class="fa fa-check"></i><b>21.7</b> gg_mean_ci_ancova</a></li>
<li class="chapter" data-level="21.8" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_effects"><i class="fa fa-check"></i><b>21.8</b> gg_effects</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="21.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>21.9</b> Get your computer ready</a><ul>
<li class="chapter" data-level="21.9.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-here"><i class="fa fa-check"></i><b>21.9.1</b> Start here</a></li>
<li class="chapter" data-level="21.9.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>21.9.2</b> Install R</a></li>
<li class="chapter" data-level="21.9.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>21.9.3</b> Install R Studio</a></li>
<li class="chapter" data-level="21.9.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-markdown-1"><i class="fa fa-check"></i><b>21.9.4</b> Install R Markdown</a></li>
<li class="chapter" data-level="21.9.5" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#optional-alternative-latex-installations"><i class="fa fa-check"></i><b>21.9.5</b> (optional) Alternative LaTeX installations</a></li>
</ul></li>
<li class="chapter" data-level="21.10" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning-r-studio"><i class="fa fa-check"></i><b>21.10</b> Start learning R Studio</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="chapter" data-level="" data-path="appendix-3-fake-data-simulations.html"><a href="appendix-3-fake-data-simulations.html"><i class="fa fa-check"></i>Appendix 3: Fake Data Simulations</a><ul>
<li class="chapter" data-level="21.11" data-path="appendix-3-fake-data-simulations.html"><a href="appendix-3-fake-data-simulations.html#performance-of-blocking-relative-to-a-linear-model"><i class="fa fa-check"></i><b>21.11</b> Performance of Blocking relative to a linear model</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elements of Statistical Modeling for Experimental Biology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="best-practices-issues-in-inference" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Best practices – issues in inference</h1>
<div id="multiple-testing" class="section level2">
<h2><span class="header-section-number">13.1</span> Multiple testing</h2>
<p><strong>Multiple testing</strong> is the practice of adjusting <em>p</em>-values (and less commonly confidence intervals) to account for the expected increase in the frequency of Type I error when there are multiple tests (typically Null Hypothesis Significance Tests). Multiple testing tends to arise in two types of situations:</p>
<ol style="list-style-type: decimal">
<li>Multiple pairwise contrasts among treatment levels (or combinations of levels) are estimated.</li>
<li>The effects of a treatment on multiple responses are estimated. This can arise if
<ol style="list-style-type: lower-alpha">
<li>there are multiple ways of measuring the consequences of something – for example, an injurious treatment on plant health might effect root biomass, shoot biomass, leaf number, leaf area, etc.</li>
<li>one is exploring the consequences of an effect on many, many outcomes – for example, the expression levels of 10,000 genes between normal and obese mice.</li>
</ol></li>
</ol>
<p>Despite the ubiquitous presence of multiple testing in elementary biostatistics textbooks, in the applied biology literature, and in journal guidelines, the practice of adjusting <em>p</em>-values for multiple tests is highly controversial among statisticians. My thoughts:</p>
<ol style="list-style-type: decimal">
<li>In situations like (1) above, I advocate that researchers <strong>do not adjust p-values for multiple tests</strong>. In general, its a best practice to only estimate contrasts for which you care about because of some <em>a priori</em> model of how the system works. If you compare all pairwise contrasts of an experiment with many treatment levels and/or combinations, expect to find some false discoveries.</li>
<li>In situations like (2a) above, I advocate that researchers <strong>do not adjust p-values for multiple tests</strong>.</li>
<li>In situations like (2b) above, adjusting for the <strong>False Discovery Rate</strong> is an interesting approach. But, recognize that tests with small <em>p</em>-values are <em>highly provisional</em> discoveries of a patterns only and not a discovery of the causal sequelae of the treatment. For that, one needs to do the hard work of designing experiments that rigorously probe a working, mechanistic model of the system.</li>
</ol>
<p>Finally, recognize that anytime there are multiple tests, Type M errors will arise due to the vagaries of sampling. This means that in a rank-ordered list of the effects, those at the top have measured effects that are probably bigger than the true effect. An alternative to adjusted <em>p</em>-values is a <strong>penalized regression</strong> model that shrinks effects toward the mean effect.</p>
<div id="some-background" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Some background</h3>
<div id="family-wise-error-rate" class="section level4">
<h4><span class="header-section-number">13.1.1.1</span> Family-wise error rate</h4>
<p>The logic of multiple testing goes something like this: the more tests that a researcher does, the higher the probability that a false positive (Type I error) will occur, therefore a researcher should should adjust <em>p</em>-values so that the Type I error over the set (or “family”) of tests is 5%. This adjusted Type I error rate is the “family-wise error rate”.</p>
<p>If a researcher carries out multiple tests <em>of data in which the null hypothesis is true</em>, what is the probability of finding at least one Type I error? This is easy to compute. If the frequency of Type I error for a single test is <span class="math inline">\(\alpha\)</span>, then the probability of no Type I error is <span class="math inline">\(1 - \alpha\)</span>. For two tests, the probability of no Type I error in either test is the product of the probability for each test, or <span class="math inline">\((1 - \alpha)^2\)</span>. By the same logic, for <span class="math inline">\(m\)</span> tests, the probabilty of no type I error in any of the tests is <span class="math inline">\((1 - \alpha)^m\)</span>. The probability of at least one type one error, across the <span class="math inline">\(m\)</span> tests, then, is <span class="math inline">\(1 - (1 - \alpha)^m\)</span>. A table of these probabilities for different <span class="math inline">\(m\)</span> is given below. If the null is true in all tests, then at least one Type I error is more likely than not if there are 14 tests, and close to certain if there more than 50 tests. Don’t skip over this paragraph – the logic is important even if I don’t advocate adjusting for multiple tests.</p>
<table>
<caption><span id="tab:best-type1-table">Table 13.1: </span>Probability of at least one type I error within the set of multiple tests, for data in which the null hypothesis is true. The Type I error rate for a single test is 0.05. The number of tests is m. The probability is p.</caption>
<thead>
<tr class="header">
<th align="right">m</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0.14</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="right">0.26</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">0.40</td>
</tr>
<tr class="odd">
<td align="right">50</td>
<td align="right">0.92</td>
</tr>
<tr class="even">
<td align="right">100</td>
<td align="right">0.99</td>
</tr>
<tr class="odd">
<td align="right">#### F</td>
<td align="right">alse discovery rate</td>
</tr>
</tbody>
</table>
<p>If a researcher carries out thousands of tests to “discover” new facts, and uses <span class="math inline">\(p &lt; 0.05\)</span> as evidence of discovery, then what is the frequency of <strong>false discoveries</strong>?</p>
</div>
<div id="p-value-filter-i-inflated-effects" class="section level4">
<h4><span class="header-section-number">13.1.1.2</span> p-value filter I – Inflated effects</h4>
<p>If a researcher caries out many tests, and ranks the effects by magnitude or <em>p</em>-value, then the effect sizes of the largest effects will be inflated. Before explaining why, let’s simulate this using an experiment of allelopathic effects of the invasive garlic mustard (<em>Alliaria petiolata</em>) on gene expression in the native American ginseng (<em>Panax quinquefolius</em>). In the treated group, we have ten pots, each with an American ginseng plant grown in a container with a mustard plant. In the control group, we have ten pots, each with an American ginseng plant grown in a container with another American ginseng. I’ve simulated the response of 10,000 genes. The treatment has a true effect in 10% of the 10,000 genes but most effects are very small.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="best-practices-issues-in-inference.html#cb347-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb347-2"><a href="best-practices-issues-in-inference.html#cb347-2"></a>p &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">4</span> <span class="co"># number of genes</span></span>
<span id="cb347-3"><a href="best-practices-issues-in-inference.html#cb347-3"></a>pt &lt;-<span class="st"> </span><span class="fl">0.1</span><span class="op">*</span>p <span class="co"># number of genes with true response to treatment</span></span>
<span id="cb347-4"><a href="best-practices-issues-in-inference.html#cb347-4"></a>n &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb347-5"><a href="best-practices-issues-in-inference.html#cb347-5"></a></span>
<span id="cb347-6"><a href="best-practices-issues-in-inference.html#cb347-6"></a><span class="co"># sample the gene effects from an exponential distribution</span></span>
<span id="cb347-7"><a href="best-practices-issues-in-inference.html#cb347-7"></a>theta &lt;-<span class="st"> </span><span class="fl">.3</span></span>
<span id="cb347-8"><a href="best-practices-issues-in-inference.html#cb347-8"></a>beta &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rexp</span>(pt, <span class="dt">rate=</span><span class="dv">1</span><span class="op">/</span>theta),</span>
<span id="cb347-9"><a href="best-practices-issues-in-inference.html#cb347-9"></a>          <span class="kw">rep</span>(<span class="dv">0</span>, (p<span class="op">-</span>pt))) <span class="co"># the set of 10,000 effects</span></span>
<span id="cb347-10"><a href="best-practices-issues-in-inference.html#cb347-10"></a></span>
<span id="cb347-11"><a href="best-practices-issues-in-inference.html#cb347-11"></a><span class="co"># sample the variance of the expression level with a gamma, and set a minimum</span></span>
<span id="cb347-12"><a href="best-practices-issues-in-inference.html#cb347-12"></a>sigma &lt;-<span class="st"> </span><span class="kw">rgamma</span>(p, <span class="dt">shape=</span><span class="dv">2</span>, <span class="dt">scale=</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.58</span></span>
<span id="cb347-13"><a href="best-practices-issues-in-inference.html#cb347-13"></a><span class="co"># quantile(sigma, c(0.001, 0.1, 0.5, 0.9, 0.999))</span></span>
<span id="cb347-14"><a href="best-practices-issues-in-inference.html#cb347-14"></a></span>
<span id="cb347-15"><a href="best-practices-issues-in-inference.html#cb347-15"></a>Y1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n<span class="op">*</span>p, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="kw">rep</span>(sigma, <span class="dt">each=</span>n)), <span class="dt">nrow=</span>n)</span>
<span id="cb347-16"><a href="best-practices-issues-in-inference.html#cb347-16"></a>Y2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n<span class="op">*</span>p, <span class="dt">mean=</span><span class="kw">rep</span>(beta, <span class="dt">each=</span>n), <span class="dt">sd=</span><span class="kw">rep</span>(sigma, <span class="dt">each=</span>n)), <span class="dt">nrow=</span>n) <span class="co"># check</span></span>
<span id="cb347-17"><a href="best-practices-issues-in-inference.html#cb347-17"></a><span class="co"># use n &lt;- 10^4 to check</span></span>
<span id="cb347-18"><a href="best-practices-issues-in-inference.html#cb347-18"></a><span class="co"># apply(y2, 2, mean)[1:5]</span></span>
<span id="cb347-19"><a href="best-practices-issues-in-inference.html#cb347-19"></a><span class="co"># b[1:5]</span></span>
<span id="cb347-20"><a href="best-practices-issues-in-inference.html#cb347-20"></a>x &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>,<span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)</span>
<span id="cb347-21"><a href="best-practices-issues-in-inference.html#cb347-21"></a>bhat &lt;-<span class="st"> </span><span class="kw">numeric</span>(p)</span>
<span id="cb347-22"><a href="best-practices-issues-in-inference.html#cb347-22"></a>p.value &lt;-<span class="st"> </span><span class="kw">numeric</span>(p)</span>
<span id="cb347-23"><a href="best-practices-issues-in-inference.html#cb347-23"></a>sigma_hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(p)</span>
<span id="cb347-24"><a href="best-practices-issues-in-inference.html#cb347-24"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>p){</span>
<span id="cb347-25"><a href="best-practices-issues-in-inference.html#cb347-25"></a>  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">c</span>(Y1[,j], Y2[, j]) <span class="op">~</span><span class="st"> </span>x)</span>
<span id="cb347-26"><a href="best-practices-issues-in-inference.html#cb347-26"></a>  bhat[j] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(fit))[<span class="st">&quot;xtr&quot;</span>, <span class="st">&quot;Estimate&quot;</span>]</span>
<span id="cb347-27"><a href="best-practices-issues-in-inference.html#cb347-27"></a>  p.value[j] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(fit))[<span class="st">&quot;xtr&quot;</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb347-28"><a href="best-practices-issues-in-inference.html#cb347-28"></a>  sigma_hat[j] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>(fit<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>fit<span class="op">$</span>df.residual)</span>
<span id="cb347-29"><a href="best-practices-issues-in-inference.html#cb347-29"></a>}</span></code></pre></div>
<div class="figure"><span id="fig:inflation-histogram"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/inflation-histogram-1.png" alt="A histogram of the distribution of the 10,000 effects" width="576" />
<p class="caption">
Figure 13.1: A histogram of the distribution of the 10,000 effects
</p>
</div>
<table>
<caption><span id="tab:unnamed-chunk-213">Table 13.2: </span>The top 10 genes ranked by p-value. Rank is the rank of the true effect, from large to small.</caption>
<thead>
<tr class="header">
<th align="right">effect</th>
<th align="right">estimate</th>
<th align="right">sigma</th>
<th align="right">sd</th>
<th align="right">p.value</th>
<th align="right">relative true effect</th>
<th align="right">rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2.23</td>
<td align="right">2.67</td>
<td align="right">0.81</td>
<td align="right">0.55</td>
<td align="right">0.0000000</td>
<td align="right">1.00</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1.59</td>
<td align="right">1.92</td>
<td align="right">0.62</td>
<td align="right">0.57</td>
<td align="right">0.0000005</td>
<td align="right">0.71</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="right">1.46</td>
<td align="right">1.86</td>
<td align="right">0.84</td>
<td align="right">0.71</td>
<td align="right">0.0000159</td>
<td align="right">0.65</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">1.47</td>
<td align="right">1.78</td>
<td align="right">0.83</td>
<td align="right">0.74</td>
<td align="right">0.0000409</td>
<td align="right">0.66</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="right">0.00</td>
<td align="right">1.95</td>
<td align="right">1.10</td>
<td align="right">0.85</td>
<td align="right">0.0000717</td>
<td align="right">0.00</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">0.48</td>
<td align="right">1.26</td>
<td align="right">0.67</td>
<td align="right">0.56</td>
<td align="right">0.0000816</td>
<td align="right">0.21</td>
<td align="right">212</td>
</tr>
<tr class="odd">
<td align="right">0.97</td>
<td align="right">1.32</td>
<td align="right">0.69</td>
<td align="right">0.60</td>
<td align="right">0.0001004</td>
<td align="right">0.43</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="right">0.54</td>
<td align="right">1.68</td>
<td align="right">1.06</td>
<td align="right">0.78</td>
<td align="right">0.0001321</td>
<td align="right">0.24</td>
<td align="right">173</td>
</tr>
<tr class="odd">
<td align="right">0.00</td>
<td align="right">2.05</td>
<td align="right">1.39</td>
<td align="right">0.96</td>
<td align="right">0.0001488</td>
<td align="right">0.00</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">0.43</td>
<td align="right">-1.78</td>
<td align="right">1.33</td>
<td align="right">0.84</td>
<td align="right">0.0001733</td>
<td align="right">0.19</td>
<td align="right">244</td>
</tr>
</tbody>
</table>
<p>The table above lists the top 10 genes ranked by <em>p</em>-value, using the logic that the genes with the smallest <em>p</em> values are the genes that we should pursue with further experiments to understand the system. Some points</p>
<ol style="list-style-type: decimal">
<li>Six of the top ten genes with biggest true effects are <em>not</em> on this list. And, in the list are three genes with true effects that have relatively low ranks based on true effect size (column "rank") <em>and</em> two genes that have no true effect at all. Also in this list is one gene with an estimated effect (-1.78) that is <em>opposite</em> in sign of the true effect (but look at the <em>p</em>-value!)</li>
<li>The estimate of the effect size for all top-ten genes are inflated. The average estimate for these 10 genes is 1.47 while the average true effect for these 10 genes is 0.92 (the estimate ).</li>
<li>The sample standard deviation (sd) for all top-ten genes is less than the true standard deviation (sigma), in some cases substantially.</li>
</ol>
<p>The consequence of an inflated estimate of the effect and a deflated estimate of the variance is a large <em>t</em> (not shown) and small <em>p</em>. What is going on is an individual gene’s estimated effect and standard deviation are functions of 1) the true value and 2) a random sampling component. The random component will be symmetric, some effects will be overestimated and some underestimated. When we rank the genes by the estimate of the effect or <em>t</em> or <em>p</em>, some of the genes that have “risen to the top” will be there because of a large, positive, sampling (random) component of the effect and/or a large, negative, sampling component of the variance. Thus some genes’ high rank is artificial in the sense that it is high because of a random fluke. If the experiment were re-done, these genes at the top because of a large, random component would (probably) fall back to a position closer to their expected rank (regression to the mean again).</p>
<p>In the example here, all genes at the top have inflated estimates of the effect because of the positive, random component. This inflation effect is a function of the signal to noise ratio, which is controled by theta and sigma in the simulation. If theta is increased (try theta=1), or if sigma is decreased, the signal to noise ratio increases (try it and look at the histogram of the new distribution of effects) and both the 1) inflation and the 2) rise to the top phenomenon decrease.</p>
</div>
<div id="p-hacking" class="section level4">
<h4><span class="header-section-number">13.1.1.3</span> p-hacking</h4>
</div>
</div>
<div id="multiple-testing-working-in-r" class="section level3">
<h3><span class="header-section-number">13.1.2</span> Multiple testing – working in R</h3>
<div id="tukey-hsd-adjustment-of-all-pairwise-comparisons" class="section level4">
<h4><span class="header-section-number">13.1.2.1</span> Tukey HSD adjustment of all pairwise comparisons</h4>
<p>The <code>adjust</code> argument in <code>emmeans::contrast()</code> controls the method for <em>p</em>-value adjustment. The default is “tukey”.</p>
<ol style="list-style-type: decimal">
<li>“none” – no adjustment, in general my preference.</li>
<li>“tukey” – Tukey’s HSD, the default</li>
<li>“bonferroni” – the standard bonferroni, which is conservative</li>
<li>“fdr” – the false discovery rate</li>
<li>“mvt” – based on the multivariate <em>t</em> distribution and using covariance structure of the variables</li>
</ol>
<p>The data are those from Fig. 2D of “Data from The enteric nervous system promotes intestinal health by constraining microbiota composition”. There is a single factor with four treatment levels. The response is neutrophil count.</p>
<p>No adjustment:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="best-practices-issues-in-inference.html#cb348-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>donor, <span class="dt">data=</span>exp2d)</span>
<span id="cb348-2"><a href="best-practices-issues-in-inference.html#cb348-2"></a>m1.emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, <span class="dt">specs=</span><span class="st">&quot;donor&quot;</span>)</span>
<span id="cb348-3"><a href="best-practices-issues-in-inference.html#cb348-3"></a>m1.pairs.none &lt;-<span class="st"> </span><span class="kw">contrast</span>(m1.emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>, <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb348-4"><a href="best-practices-issues-in-inference.html#cb348-4"></a><span class="kw">summary</span>(m1.pairs.none, <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  contrast       estimate   SE df lower.CL upper.CL t.ratio p.value
##  gf - wt          -1.502 1.48 58    -4.47     1.47 -1.013  0.3153 
##  sox10 - wt        4.679 1.23 58     2.23     7.13  3.817  0.0003 
##  sox10 - gf        6.182 1.45 58     3.29     9.08  4.276  0.0001 
##  iap_mo - wt      -0.384 1.53 58    -3.45     2.68 -0.251  0.8025 
##  iap_mo - gf       1.118 1.71 58    -2.31     4.54  0.654  0.5159 
##  iap_mo - sox10   -5.064 1.49 58    -8.05    -2.07 -3.391  0.0013 
## 
## Confidence level used: 0.95</code></pre>
<p>Tukey HSD:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="best-practices-issues-in-inference.html#cb350-1"></a>m1.pairs.tukey &lt;-<span class="st"> </span><span class="kw">contrast</span>(m1.emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>, <span class="dt">adjust=</span><span class="st">&quot;tukey&quot;</span>)</span>
<span id="cb350-2"><a href="best-practices-issues-in-inference.html#cb350-2"></a><span class="kw">summary</span>(m1.pairs.tukey, <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  contrast       estimate   SE df lower.CL upper.CL t.ratio p.value
##  gf - wt          -1.502 1.48 58    -5.43     2.42 -1.013  0.7426 
##  sox10 - wt        4.679 1.23 58     1.44     7.92  3.817  0.0018 
##  sox10 - gf        6.182 1.45 58     2.36    10.01  4.276  0.0004 
##  iap_mo - wt      -0.384 1.53 58    -4.43     3.66 -0.251  0.9944 
##  iap_mo - gf       1.118 1.71 58    -3.41     5.64  0.654  0.9138 
##  iap_mo - sox10   -5.064 1.49 58    -9.01    -1.11 -3.391  0.0067 
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 4 estimates 
## P value adjustment: tukey method for comparing a family of 4 estimates</code></pre>
</div>
</div>
<div id="false-discovery-rate" class="section level3">
<h3><span class="header-section-number">13.1.3</span> False Discovery Rate</h3>
</div>
</div>
<div id="difference-in-p-is-not-different" class="section level2">
<h2><span class="header-section-number">13.2</span> difference in p is not different</h2>
</div>
<div id="inference-when-data-are-not-normal" class="section level2">
<h2><span class="header-section-number">13.3</span> Inference when data are not Normal</h2>
<p>No real data are normal, although many are pretty good approximations of a normal distribution.</p>
<p>I’ll come back to this point, but first, let’s back up. Inference in statistical models (standard errors, confidence intervals, <em>p</em>-values) are a function of the modeled distributions of the parameters (for linear models, this parameter is the conditional (or error) variance <span class="math inline">\(\sigma^2\)</span>); if the data do not approximate the modeled distribution, then inferential statistics might be to liberal (standard errors are too small, confidence intervals are too narrow, Type I error is more than nominal) or to conservative (standard errors are too large, confidence intervals are too wide, Type I error is less than nominal).</p>
<p>Linear models assume that “the data” (specifically, the conditional response, or, equivalently, the residuals from the model) approximate a Normal distribution. Chapter xxx showed how to qualitatively assess how well residuals approximate a Normal distribution using a Q-Q plot. If the researcher concludes that the data poorly approximate a normal distribution because of outliers, the researcher can use robust methods to estimate the parameters. If the approximation is poor because the residuals suggest a skewed distribution or one with heavy or light tails, the researcher can choose among several strategies</p>
<ol style="list-style-type: decimal">
<li>continue to use the linear model; inference can be fairly robust to non-normal data, especially when the sample size is not small.</li>
<li>use a generalized linear model (GLM), which is appropriate if the conditional response approximates any of the distributions that can be modeled using GLM (Chapter xxx)</li>
<li>use bootstrap for confidence intervals and permutation test for <em>p</em>-values</li>
<li>transform the data in a way that makes the conditional response more closely approximate a normal distribution.</li>
<li>use a classic non-parametric test, which are methods that do not assume a particular distribution</li>
</ol>
<p>This list is roughly in the order of how I would advise researchers, although the order of 1-3 is pretty arbitrary. I would rarely advise a researcher to use (4) and never advise (5). Probably the most common strategies in the biology literature are (4) and (5). The first is also common but probably more from lack of recognition of issues or because a “test of normality” failed to reject that the data are “not normal”.</p>
<p>On this last point, do not use the <em>p</em>-value from a “test for normality” (such as a Shapiro-Wilk test) to decide between using the linear model (or t-test or ANOVA) and an alternative such as a generalized linear model (or transformation or non-parametric test). No real data is normal. Tests of normality will tend to “not reject” normality (p &gt; 0.05) when the sample size is small and “reject” normality (p &lt; 0.05) when the sample size is very large. But again, a “not rejected” hypothesis test does not mean the null (in this case, the data are normal) is true. More importantly, where the test for normality tends to fail to reject (encouraging a researcher to use parametric statistics) is where parametric inference performs the worst (because of small <em>n</em>) and where the test for normality tends to reject (encouraging a researcher to use non-parametric statistics) is where the parametric inference performs the best (because of large sample size) (Lumley xxx).</p>
<div id="working-in-r-3" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Working in R</h3>
<p>The data for demonstrating different strategies are from Fig. 4A of “Data from The enteric nervous system promotes intestinal health by constraining microbiota composition”. There is a single factor with two treatment levels. The response is neutrophil count.</p>
<div class="figure"><span id="fig:best-import-non-normal-counts"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/best-import-non-normal-counts-1.png" alt="Distribution of the counts in the wildtype (WT) and sox10 knockout (sox10-) groups. Both groups show a strong right skew, which is common with count data." width="576" />
<p class="caption">
Figure 13.2: Distribution of the counts in the wildtype (WT) and sox10 knockout (sox10-) groups. Both groups show a strong right skew, which is common with count data.
</p>
</div>
<p>A linear model to estimate the treatment effect and 95% confidence interval.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="best-practices-issues-in-inference.html#cb352-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span>
<span id="cb352-2"><a href="best-practices-issues-in-inference.html#cb352-2"></a>m1_emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, <span class="dt">specs=</span><span class="st">&quot;treatment&quot;</span>)</span>
<span id="cb352-3"><a href="best-practices-issues-in-inference.html#cb352-3"></a><span class="kw">summary</span>(<span class="kw">contrast</span>(m1_emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>),</span>
<span id="cb352-4"><a href="best-practices-issues-in-inference.html#cb352-4"></a>        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  contrast   estimate   SE  df lower.CL upper.CL t.ratio p.value
##  sox10 - wt     5.16 1.75 174      1.7     8.62 2.947   0.0037 
## 
## Confidence level used: 0.95</code></pre>
</div>
<div id="bootstrap-confidence-intervals" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Bootstrap Confidence Intervals</h3>
<p>A bootstrap confidence interval is computed from the distribution of a statistic from many sets of re-sampled data. The basic algorithm is</p>
<ol style="list-style-type: decimal">
<li>compute the statistic for the observed data, assign this to <span class="math inline">\(\theta_1\)</span></li>
<li>resample <span class="math inline">\(n\)</span> rows of the data, with replacement. “with replacement” means to sample from the entire set of data and not the set that has yet to be sampled. <span class="math inline">\(n\)</span> is the original sample size; by resampling <span class="math inline">\(n\)</span> rows with replacement, some rows will be sampled more than once, and some rows will not be sampled at all.</li>
<li>compute the statistic for the resampled data, assign these to <span class="math inline">\(\theta_{2..m}\)</span></li>
<li>repeat 2 and 3 <span class="math inline">\(m-1\)</span> times</li>
<li>Given the distribution of <span class="math inline">\(m\)</span> estimates, compute the lower interval as the <span class="math inline">\(\frac{\alpha}{2}\)</span>th percentile and the upper interval as the <span class="math inline">\(1 - \frac{\alpha}{2}\)</span>th percentile. For 95% confidence intervals, these are the 2.5th and 97.5th percentiles.</li>
</ol>
<p>Let’s apply this algorithm to the data from fig4A neutrophil count data in the coefficient table above. The focal statistic in these data is the difference in the mean count for the sox10 and wild type groups (the parameter for <span class="math inline">\(treatment\)</span> in the linear model). The script below, which computes the 95% confidence intervals of this difference, resamples within <strong>strata</strong>, that is, within each group; it does this to preserve the original sample size within each group.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="best-practices-issues-in-inference.html#cb354-1"></a>n_iter &lt;-<span class="st"> </span><span class="dv">5000</span></span>
<span id="cb354-2"><a href="best-practices-issues-in-inference.html#cb354-2"></a>b1 &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">5000</span>)</span>
<span id="cb354-3"><a href="best-practices-issues-in-inference.html#cb354-3"></a>inc &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(fig4a) <span class="co"># the rows for the first iteration are all rows, so this is the observed effect</span></span>
<span id="cb354-4"><a href="best-practices-issues-in-inference.html#cb354-4"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_iter){</span>
<span id="cb354-5"><a href="best-practices-issues-in-inference.html#cb354-5"></a>  <span class="co"># inc creates the index of rows to resample preserving the sample size specific to each group</span></span>
<span id="cb354-6"><a href="best-practices-issues-in-inference.html#cb354-6"></a>  b1[i] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a[inc, ]))[<span class="st">&quot;treatmentsox10&quot;</span>]</span>
<span id="cb354-7"><a href="best-practices-issues-in-inference.html#cb354-7"></a>  inc &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">sample</span>(<span class="kw">which</span>(fig4a[, treatment] <span class="op">==</span><span class="st"> &quot;wt&quot;</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>),</span>
<span id="cb354-8"><a href="best-practices-issues-in-inference.html#cb354-8"></a>           <span class="kw">sample</span>(<span class="kw">which</span>(fig4a[, treatment] <span class="op">==</span><span class="st"> &quot;sox10&quot;</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>))</span>
<span id="cb354-9"><a href="best-practices-issues-in-inference.html#cb354-9"></a>}</span>
<span id="cb354-10"><a href="best-practices-issues-in-inference.html#cb354-10"></a>ci &lt;-<span class="st"> </span><span class="kw">quantile</span>(b1, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb354-11"><a href="best-practices-issues-in-inference.html#cb354-11"></a><span class="kw">c</span>(<span class="dt">contrast =</span> b1[<span class="dv">1</span>], ci[<span class="dv">1</span>], ci[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## contrast     2.5%    97.5% 
## 5.163215 2.077892 8.264316</code></pre>
<p>The intervals calculated in step 5 are <strong>percentile intervals</strong>. A histogram of the the re-sampled differences helps to visualize the bootstrap (this is a pedagogical tool, not something you would want to publish).</p>
<div class="figure"><span id="fig:best-bootstrap-histogram"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/best-bootstrap-histogram-1.png" alt="Distribution of the 5000 resampled estimates of the difference in means between the sox10 and wt treatment levels. The dashed lines are located at the 2.5th and 97.5th percentiles of the distribution." width="576" />
<p class="caption">
Figure 13.3: Distribution of the 5000 resampled estimates of the difference in means between the sox10 and wt treatment levels. The dashed lines are located at the 2.5th and 97.5th percentiles of the distribution.
</p>
</div>
<div id="some-r-packages-for-bootstrap-confidence-intervals" class="section level4">
<h4><span class="header-section-number">13.3.2.1</span> Some R packages for bootstrap confidence intervals</h4>
<p>Percentile intervals are known to be biased, meaning the intervals are shifted. The <code>boot</code> package computes a bias-corrected interval in addition to a percentile interval. <code>boot</code> is a very powerful bootstrap package but requires the researcher to write functions to compute the parameter of interest. <code>simpleboot</code> provides functions for common analysis that does this for you (in R speak, we say that <code>simpleboot</code> is a “wrapper” to <code>boot</code>). The function <code>simpleboot::two.boot</code> computes a <code>boot</code>-like object that returns, among other values, the distribution of <span class="math inline">\(m\)</span> statistics. The <code>simpleboot</code> object is then be fed to <code>boot::boot.ci</code> to get bias-corrected intervals.</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="best-practices-issues-in-inference.html#cb356-1"></a>bs_diff &lt;-<span class="st"> </span><span class="kw">two.boot</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count],</span>
<span id="cb356-2"><a href="best-practices-issues-in-inference.html#cb356-2"></a>                    fig4a[treatment<span class="op">==</span><span class="st">&quot;wt&quot;</span>, count],</span>
<span id="cb356-3"><a href="best-practices-issues-in-inference.html#cb356-3"></a>                    mean, </span>
<span id="cb356-4"><a href="best-practices-issues-in-inference.html#cb356-4"></a>                    <span class="dt">R=</span><span class="dv">5000</span>)</span>
<span id="cb356-5"><a href="best-practices-issues-in-inference.html#cb356-5"></a><span class="kw">boot.ci</span>(bs_diff, <span class="dt">type=</span><span class="st">&quot;bca&quot;</span>)</span></code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 5000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = bs_diff, type = &quot;bca&quot;)
## 
## Intervals : 
## Level       BCa          
## 95%   ( 2.087,  8.410 )  
## Calculations and Intervals on Original Scale</code></pre>
</div>
</div>
<div id="permutation-test" class="section level3">
<h3><span class="header-section-number">13.3.3</span> Permutation test</h3>
<p>A permutation test effectively computes the probability that a random assignment of a response to a particular value of <em>X</em> generates a test statistic as large or larger than the observed statistic. If this probability is small, then this “random assignment” is unlikely. From this we infer that the actual assignment matters, which implies a treatment effect.</p>
<p>The basic algorithm is</p>
<ol style="list-style-type: decimal">
<li>compute the test statistic for the observed data, assign this to <span class="math inline">\(\theta_1\)</span></li>
<li>permute the response</li>
<li>compute the test statistic for the permuted data, assign these to <span class="math inline">\(\theta_{2..m}\)</span></li>
<li>repeat 2 and 3 <span class="math inline">\(m-1\)</span> times</li>
<li>compute <span class="math inline">\(p\)</span> as</li>
</ol>
<p><span class="math display">\[\begin{equation}
p_{perm} = \frac{N_{\theta_i \ge \theta_{1}}}{m}
\end{equation}\]</span></p>
<p>This is easily done with a <strong>for loop</strong> in which the observed statistic is the first value in the vector of statistics. If this is done, the minimum value in the numerator for the computation of <span class="math inline">\(p_{perm}\)</span> is 1, which insures that <span class="math inline">\(p_{perm}\)</span> is not zero.</p>
<p>The test statistic depends on the analysis. For the simple comparison of means, a simple test statistic is the difference in means. This is the numerator of the test statistic in a <em>t</em>-test. The test has more power if the test-statistic is scaled (Manley xxx), so a better test statistic would be <em>t</em>, which scales the difference by its standard error.</p>
<p>Here, I implement this algorithm. The test is two-tailed, so the absolute difference is recorded. The first value computed is the observed absolute difference.</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="best-practices-issues-in-inference.html#cb358-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb358-2"><a href="best-practices-issues-in-inference.html#cb358-2"></a>n_permutations &lt;-<span class="st"> </span><span class="dv">5000</span></span>
<span id="cb358-3"><a href="best-practices-issues-in-inference.html#cb358-3"></a>d &lt;-<span class="st"> </span><span class="kw">numeric</span>(n_permutations)</span>
<span id="cb358-4"><a href="best-practices-issues-in-inference.html#cb358-4"></a></span>
<span id="cb358-5"><a href="best-practices-issues-in-inference.html#cb358-5"></a><span class="co"># create a new column which will contain the permuted response</span></span>
<span id="cb358-6"><a href="best-practices-issues-in-inference.html#cb358-6"></a><span class="co"># for the first iteration, this will be the observed order</span></span>
<span id="cb358-7"><a href="best-practices-issues-in-inference.html#cb358-7"></a>fig4a[, count_perm <span class="op">:</span><span class="er">=</span><span class="st"> </span>count]</span>
<span id="cb358-8"><a href="best-practices-issues-in-inference.html#cb358-8"></a></span>
<span id="cb358-9"><a href="best-practices-issues-in-inference.html#cb358-9"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_permutations){</span>
<span id="cb358-10"><a href="best-practices-issues-in-inference.html#cb358-10"></a>  d[i] &lt;-<span class="st"> </span><span class="kw">abs</span>(<span class="kw">t.test</span>(count_perm <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data =</span> fig4a)<span class="op">$</span>statistic)</span>
<span id="cb358-11"><a href="best-practices-issues-in-inference.html#cb358-11"></a>  </span>
<span id="cb358-12"><a href="best-practices-issues-in-inference.html#cb358-12"></a>  <span class="co"># permute the count_perm column for the next iteration</span></span>
<span id="cb358-13"><a href="best-practices-issues-in-inference.html#cb358-13"></a>  fig4a[, count_perm <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">sample</span>(count)]</span>
<span id="cb358-14"><a href="best-practices-issues-in-inference.html#cb358-14"></a>}</span>
<span id="cb358-15"><a href="best-practices-issues-in-inference.html#cb358-15"></a>p &lt;-<span class="st"> </span><span class="kw">sum</span>(d <span class="op">&gt;=</span><span class="st"> </span>d[<span class="dv">1</span>])<span class="op">/</span>n_permutations</span>
<span id="cb358-16"><a href="best-practices-issues-in-inference.html#cb358-16"></a>p</span></code></pre></div>
<pre><code>## [1] 0.002</code></pre>
<div id="some-r-packages-with-permutation-tests." class="section level4">
<h4><span class="header-section-number">13.3.3.1</span> Some R packages with permutation tests.</h4>
<p><code>lmPerm::lmp</code> generates permutation p-values for parameters of any kind of linear model. The test statistic is the sum of squares of the term scaled by the residual sum of squares of the model.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="best-practices-issues-in-inference.html#cb360-1"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb360-2"><a href="best-practices-issues-in-inference.html#cb360-2"></a><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>, </span>
<span id="cb360-3"><a href="best-practices-issues-in-inference.html#cb360-3"></a>                 <span class="dt">data=</span>fig4a)))</span></code></pre></div>
<pre><code>## [1] &quot;Settings:  unique SS &quot;</code></pre>
<pre><code>##              Estimate Iter Pr(Prob)
## (Intercept) 13.694815 5000   0.0042
## treatment1  -2.581608 5000   0.0042</code></pre>
</div>
</div>
<div id="non-parametric-tests" class="section level3">
<h3><span class="header-section-number">13.3.4</span> Non-parametric tests</h3>
<ol style="list-style-type: decimal">
<li>In general, the role of a non-parametric test is a better-behaved <em>p</em>-value, that is, one whose Type I error is well controlled. As such, non-parametric tests are more about Null-Hypothesis Statistical Testing and less (or not at all) about Estimation.</li>
<li>In general, classic non-parametric tests are only available for fairly simple experimental designs. Classic non-parametric tests include
<ul>
<li>Independent sample (Student’s) <em>t</em> test: Mann-Whitney-Wilcoxan</li>
<li>Paired <em>t</em> test: Wilcoxan signed-rank test</li>
</ul></li>
</ol>
<p>One rarely sees non-parametric tests for more complex designs that include covariates, or multiple factors, but for these, one could 1) convert the response to ranks and fit the usual linear model, or 2) implement a permutation test that properly preserves <strong>exchangeability</strong>.</p>
<p>Permutation tests control Type I error and are powerful. That said, I would recommend a permutation test as a supplment to, and not replacement of, inference from a generalized linear model.</p>
<p>A non-parametric (Mann-Whitney-Wilcoxon) test of the fake data generated above</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="best-practices-issues-in-inference.html#cb363-1"></a><span class="kw">wilcox.test</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  count by treatment
## W = 2275, p-value = 0.001495
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="log-transformations" class="section level3">
<h3><span class="header-section-number">13.3.5</span> Log transformations</h3>
<p>Many response variables within biology, including count data, and almost anything that grows, are right skewed and have variances that increase with the mean. A log transform of a response variable with this kind of distribution will tend to make the residuals more approximately normal and the variance less dependent of the mean. At least two issues arise</p>
<ol style="list-style-type: decimal">
<li>if the response is count data, and the data include counts of zero, then a fudge factor has to be added to the response since log(0) doesn’t exist. The typical fudge factor is to add 1 to <em>all</em> values, but this is arbitrary and results do depend on the magnitude of this fudge factor.</li>
<li>the estimates are on a log scale and do not have the units of the response. The estimates can be back-transformed by taking the exponent of a coefficient or contrast but this itself produces problems. For example, the backtransformed mean of the log-transformed response is not the mean on the origianl scale (the arithmetic mean) but the <strong>geometric mean</strong>. Geometric means are smaller than arithmetic means, appreciably so if the data are heavily skewed. Do we want our understanding of a system to be based on geometric means?</li>
</ol>
<div id="working-in-r-log-transformations" class="section level4">
<h4><span class="header-section-number">13.3.5.1</span> Working in R – log transformations</h4>
<p>If we fit a linear model to a log-transformed response then the resulting coefficients and predictions are on the <strong>log scale</strong>. To make interpretation of the analysies easier, we probably want to <strong>back-transform</strong> the coefficients or the predictions to the original scale of the response, which is called the <strong>response scale</strong>.</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="best-practices-issues-in-inference.html#cb365-1"></a>m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(count <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span>
<span id="cb365-2"><a href="best-practices-issues-in-inference.html#cb365-2"></a>(m2_emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m2,</span>
<span id="cb365-3"><a href="best-practices-issues-in-inference.html#cb365-3"></a>                  <span class="dt">specs=</span><span class="st">&quot;treatment&quot;</span>,</span>
<span id="cb365-4"><a href="best-practices-issues-in-inference.html#cb365-4"></a>                  <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))</span></code></pre></div>
<pre><code>##  treatment response    SE  df lower.CL upper.CL
##  wt            8.22 0.965 174      6.5     10.3
##  sox10        12.59 0.934 174     10.9     14.6
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log(mu + 1) scale</code></pre>
<p>The emmeans package is amazing. Using the argument <code>type = "response"</code> not only backtransforms the means to the response scale but also substracts the 1 that was added to all values in the model.</p>
<p>What about the effect of treatment on count?</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="best-practices-issues-in-inference.html#cb367-1"></a><span class="kw">summary</span>(<span class="kw">contrast</span>(m2_emm, </span>
<span id="cb367-2"><a href="best-practices-issues-in-inference.html#cb367-2"></a>                 <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>,</span>
<span id="cb367-3"><a href="best-practices-issues-in-inference.html#cb367-3"></a>                 <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb367-4"><a href="best-practices-issues-in-inference.html#cb367-4"></a>        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  contrast   ratio    SE  df lower.CL upper.CL t.ratio p.value
##  sox10 / wt  1.47 0.185 174     1.15     1.89 3.100   0.0023 
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale 
## Tests are performed on the log scale</code></pre>
<p>It isn’t necessary to backtransform the estimated marginal means prior to computing the contrasts as this can be done in the contrast function itself. Here, the <code>type = "response"</code> argument in the contrast function is redundant since this was done in the computation of the means. But it is transparent so I want it there.</p>
<p><strong>Don’t skip this paragraph</strong> Look at the value in the “contrast” column – it is “sox10 / wt” and not “sox10 - wt”. The backtransformed effect is a ratio instead of a difference. <strong>A difference on the log scale is a ratio on the response scale</strong> because of this equality</p>
<p><span class="math display">\[\begin{equation}
\mathrm{exp}(\mu_2-\mu_1) = \frac{\mathrm{exp}(\mu_2)}{\mathrm{exp}(\mu_1)})
\end{equation}\]</span></p>
<p>The interpretation is: If <span class="math inline">\(b^*\)</span> is the backtransformed effect, then, given a one unit increase in <span class="math inline">\(X\)</span>, the expected value of the response increases <span class="math inline">\(b^*\times\)</span>. For a categorical <span class="math inline">\(X\)</span>, this means the backtransformed effect is the ratio of backtransformed means – its what you have to multiply the mean of the reference by to get the mean of the treated group. And, because it is the response that is log-transformed, these means are not arithemetic means but geometric means. Here, this is complicated by the model – the response is not a simple log transformation but log(response + 1). It is easy enough to get the geometric mean of the treated group – multiply the backtransformed intercept by the backtransformed coefficient and then subtract 1 – but because of this subtraction of 1, the interpretation of the backtransformed effect is awkward at best (recall that I told you that a linear model of a log transformed response, and especially the log of the response plus one, leads to difficulty in interpreting the effects).</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="best-practices-issues-in-inference.html#cb369-1"></a><span class="co"># backtransformed control mean -- a geometric mean</span></span>
<span id="cb369-2"><a href="best-practices-issues-in-inference.html#cb369-2"></a>mu_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">coef</span>(m2)[<span class="dv">1</span>])</span>
<span id="cb369-3"><a href="best-practices-issues-in-inference.html#cb369-3"></a></span>
<span id="cb369-4"><a href="best-practices-issues-in-inference.html#cb369-4"></a><span class="co"># backtransformed effect</span></span>
<span id="cb369-5"><a href="best-practices-issues-in-inference.html#cb369-5"></a>b1_star &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">coef</span>(m2)[<span class="dv">2</span>])</span>
<span id="cb369-6"><a href="best-practices-issues-in-inference.html#cb369-6"></a></span>
<span id="cb369-7"><a href="best-practices-issues-in-inference.html#cb369-7"></a><span class="co"># product minus 1</span></span>
<span id="cb369-8"><a href="best-practices-issues-in-inference.html#cb369-8"></a>mu_<span class="dv">1</span><span class="op">*</span>b1_star <span class="dv">-1</span></span></code></pre></div>
<pre><code>## (Intercept) 
##    12.59357</code></pre>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="best-practices-issues-in-inference.html#cb371-1"></a><span class="co"># geometric mean of treatment group</span></span>
<span id="cb371-2"><a href="best-practices-issues-in-inference.html#cb371-2"></a>n &lt;-<span class="st"> </span><span class="kw">length</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count])</span>
<span id="cb371-3"><a href="best-practices-issues-in-inference.html#cb371-3"></a><span class="kw">exp</span>(<span class="kw">mean</span>(<span class="kw">log</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count<span class="op">+</span><span class="dv">1</span>])))<span class="op">-</span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 12.59357</code></pre>
<p>Back-transformed effect</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="best-practices-issues-in-inference.html#cb373-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span></code></pre></div>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="best-practices-issues-in-inference.html#cb374-1"></a><span class="kw">exp</span>(<span class="kw">coef</span>(m2)) </span></code></pre></div>
<pre><code>##    (Intercept) treatmentsox10 
##       9.219770       1.474394</code></pre>
</div>
</div>
<div id="performance-of-parametric-tests-and-alternatives" class="section level3">
<h3><span class="header-section-number">13.3.6</span> Performance of parametric tests and alternatives</h3>
<div id="type-i-error-1" class="section level4">
<h4><span class="header-section-number">13.3.6.1</span> Type I error</h4>
<p>If we are going to compute a <span class="math inline">\(p\)</span>-value, we want it to be uniformly distributed “under the null”. A simple way to check this is to compute Type I error. If we set <span class="math inline">\(\alpha = 0.05\)</span>, then we’d expect 5% of tests of an experiment with no effect to have <span class="math inline">\(p &lt; 0.05\)</span>.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="best-practices-issues-in-inference.html#cb376-1"></a><span class="co"># first create a matrix with a bunch of data sets, each in its own column</span></span>
<span id="cb376-2"><a href="best-practices-issues-in-inference.html#cb376-2"></a>n &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb376-3"><a href="best-practices-issues-in-inference.html#cb376-3"></a>n_sets &lt;-<span class="st"> </span><span class="dv">4000</span></span>
<span id="cb376-4"><a href="best-practices-issues-in-inference.html#cb376-4"></a>fake_matrix &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n),</span>
<span id="cb376-5"><a href="best-practices-issues-in-inference.html#cb376-5"></a>                   <span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n))</span>
<span id="cb376-6"><a href="best-practices-issues-in-inference.html#cb376-6"></a>treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>, <span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)</span>
<span id="cb376-7"><a href="best-practices-issues-in-inference.html#cb376-7"></a></span>
<span id="cb376-8"><a href="best-practices-issues-in-inference.html#cb376-8"></a>tests &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>, <span class="st">&quot;log_lm&quot;</span>,<span class="st">&quot;mww&quot;</span>, <span class="st">&quot;perm&quot;</span>)</span>
<span id="cb376-9"><a href="best-practices-issues-in-inference.html#cb376-9"></a>res_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_sets, <span class="dt">ncol=</span><span class="kw">length</span>(tests))</span>
<span id="cb376-10"><a href="best-practices-issues-in-inference.html#cb376-10"></a><span class="kw">colnames</span>(res_matrix) &lt;-<span class="st"> </span>tests</span>
<span id="cb376-11"><a href="best-practices-issues-in-inference.html#cb376-11"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sets){</span>
<span id="cb376-12"><a href="best-practices-issues-in-inference.html#cb376-12"></a>  res_matrix[j, <span class="st">&quot;lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb376-13"><a href="best-practices-issues-in-inference.html#cb376-13"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb376-14"><a href="best-practices-issues-in-inference.html#cb376-14"></a>  res_matrix[j, <span class="st">&quot;log_lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(fake_matrix[,j] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb376-15"><a href="best-practices-issues-in-inference.html#cb376-15"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb376-16"><a href="best-practices-issues-in-inference.html#cb376-16"></a>  res_matrix[j, <span class="st">&quot;mww&quot;</span>] &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb376-17"><a href="best-practices-issues-in-inference.html#cb376-17"></a>                                      <span class="dt">exact=</span><span class="ot">FALSE</span>)<span class="op">$</span>p.value</span>
<span id="cb376-18"><a href="best-practices-issues-in-inference.html#cb376-18"></a>  res_matrix[j, <span class="st">&quot;perm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb376-19"><a href="best-practices-issues-in-inference.html#cb376-19"></a>                                 <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>)))[<span class="dv">2</span>, <span class="st">&quot;Pr(Prob)&quot;</span>]</span>
<span id="cb376-20"><a href="best-practices-issues-in-inference.html#cb376-20"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="best-practices-issues-in-inference.html#cb377-1"></a><span class="kw">apply</span>(res_matrix, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span>)<span class="op">/</span>n_sets)</span></code></pre></div>
<pre><code>##      lm  log_lm     mww    perm 
## 0.04150 0.05250 0.04350 0.04675</code></pre>
<p>Type I error is computed for the linear model, the linear model with a log transformed responpse, Mann-Whitney-Wilcoxon, and permutation tests. All four tests are slightly conservative for data that look like that modeled. The computed Type I error of the permutation test is closest to the nominal value of 0.05.</p>
</div>
<div id="power-1" class="section level4">
<h4><span class="header-section-number">13.3.6.2</span> Power</h4>
<p>Power is the probability of a test to reject the null hypothesis if the null hypothesis is false (that is, if an effect exists)</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Power} = \mathrm{Prob}(p &lt; \alpha | mathrm{effect} \neq 0)
\end{equation}\]</span></p>
<p>If all we care about is a <span class="math inline">\(p-value\)</span> then we want to use a test that is most powerful. But, while power is defined using <span class="math inline">\(\alpha\)</span>, we <em>can</em> care about power even if we don’t consider <span class="math inline">\(\alpha\)</span> to be a very useful concept because increased power also increases the precision of an estimate (that is, narrows confidence intervals).</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="best-practices-issues-in-inference.html#cb379-1"></a><span class="co"># first create a matrix with a bunch of data sets, each in its own column</span></span>
<span id="cb379-2"><a href="best-practices-issues-in-inference.html#cb379-2"></a>n &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb379-3"><a href="best-practices-issues-in-inference.html#cb379-3"></a>n_sets &lt;-<span class="st"> </span><span class="dv">4000</span></span>
<span id="cb379-4"><a href="best-practices-issues-in-inference.html#cb379-4"></a>fake_matrix &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n),</span>
<span id="cb379-5"><a href="best-practices-issues-in-inference.html#cb379-5"></a>                   <span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">20</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n))</span>
<span id="cb379-6"><a href="best-practices-issues-in-inference.html#cb379-6"></a>treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>, <span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)</span>
<span id="cb379-7"><a href="best-practices-issues-in-inference.html#cb379-7"></a></span>
<span id="cb379-8"><a href="best-practices-issues-in-inference.html#cb379-8"></a>tests &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>, <span class="st">&quot;log_lm&quot;</span>,<span class="st">&quot;mww&quot;</span>, <span class="st">&quot;perm&quot;</span>)</span>
<span id="cb379-9"><a href="best-practices-issues-in-inference.html#cb379-9"></a>res_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_sets, <span class="dt">ncol=</span><span class="kw">length</span>(tests))</span>
<span id="cb379-10"><a href="best-practices-issues-in-inference.html#cb379-10"></a><span class="kw">colnames</span>(res_matrix) &lt;-<span class="st"> </span>tests</span>
<span id="cb379-11"><a href="best-practices-issues-in-inference.html#cb379-11"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sets){</span>
<span id="cb379-12"><a href="best-practices-issues-in-inference.html#cb379-12"></a>  res_matrix[j, <span class="st">&quot;lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb379-13"><a href="best-practices-issues-in-inference.html#cb379-13"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb379-14"><a href="best-practices-issues-in-inference.html#cb379-14"></a>  res_matrix[j, <span class="st">&quot;log_lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(fake_matrix[,j] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb379-15"><a href="best-practices-issues-in-inference.html#cb379-15"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb379-16"><a href="best-practices-issues-in-inference.html#cb379-16"></a>  res_matrix[j, <span class="st">&quot;mww&quot;</span>] &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb379-17"><a href="best-practices-issues-in-inference.html#cb379-17"></a>                                      <span class="dt">exact=</span><span class="ot">FALSE</span>)<span class="op">$</span>p.value</span>
<span id="cb379-18"><a href="best-practices-issues-in-inference.html#cb379-18"></a>  res_matrix[j, <span class="st">&quot;perm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb379-19"><a href="best-practices-issues-in-inference.html#cb379-19"></a>                                 <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>)))[<span class="dv">2</span>, <span class="st">&quot;Pr(Prob)&quot;</span>]</span>
<span id="cb379-20"><a href="best-practices-issues-in-inference.html#cb379-20"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="best-practices-issues-in-inference.html#cb380-1"></a><span class="kw">apply</span>(res_matrix, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span>)<span class="op">/</span>n_sets)</span></code></pre></div>
<pre><code>##      lm  log_lm     mww    perm 
## 0.09200 0.12525 0.08375 0.10600</code></pre>
<p>As above, Power is computed for the linear model, linear model with a log-transformed response, Mann-Whitney-Wilcoxan, and permutation, by simulating a “low power” experiment. The effect is huge (twice as many cells) but the power is low because the sample size is small (<span class="math inline">\(n = 5\)</span>). At this sample size, and for this model of fake data, all tests have low power. The power of the log-transformed response is the largest. A problem is, this is not a test of the means but of the log transformed mean plus 1. The power of the permutation test is about 25% larger than that of the linear model and Mann-Whitney-Wilcoxan test. An advantage of this test is that it is a p-value of the mean. A good complement to this p-value would be bootstraped confidence intervals. Repeat this simulation using <span class="math inline">\(n=40\)</span> do see how the relative power among the three change in a simulation of an experiment with more power.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="model-fitting-and-model-fit-ols.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="part-vi-more-than-one-x-multivariable-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/28-best_practices.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
