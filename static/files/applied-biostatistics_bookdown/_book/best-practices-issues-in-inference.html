<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Best Practices – Issues in Inference | Elementary Statistical Modeling for Applied Biostatistics</title>
  <meta name="description" content="A first course in statistical modeling for biology students" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Best Practices – Issues in Inference | Elementary Statistical Modeling for Applied Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for biology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Best Practices – Issues in Inference | Elementary Statistical Modeling for Applied Biostatistics" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for biology students" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="model-fitting-and-model-fit-ols.html"/>
<link rel="next" href="plotting-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#math"><i class="fa fa-check"></i><b>0.1</b> Math</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#r-and-programming"><i class="fa fa-check"></i><b>0.2</b> R and programming</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-r-fundamentals.html"><a href="part-i-r-fundamentals.html"><i class="fa fa-check"></i>Part I: R fundamentals</a></li>
<li class="chapter" data-level="1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html"><i class="fa fa-check"></i><b>1</b> Organization – R Projects and R Notebooks</a><ul>
<li class="chapter" data-level="1.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#importing-packages"><i class="fa fa-check"></i><b>1.1</b> Importing Packages</a></li>
<li class="chapter" data-level="1.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-studio-project-for-this-class"><i class="fa fa-check"></i><b>1.2</b> Create an R Studio Project for this Class</a></li>
<li class="chapter" data-level="1.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-notebooks"><i class="fa fa-check"></i><b>1.3</b> R Notebooks</a><ul>
<li class="chapter" data-level="1.3.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-notebook-for-this-chapter"><i class="fa fa-check"></i><b>1.3.1</b> Create an R Notebook for this Chapter</a></li>
<li class="chapter" data-level="1.3.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-load-packages-chunk"><i class="fa fa-check"></i><b>1.3.2</b> Create a “load-packages” chunk</a></li>
<li class="chapter" data-level="1.3.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-simple-plot-chunk"><i class="fa fa-check"></i><b>1.3.3</b> Create a “simple plot” chunk</a></li>
<li class="chapter" data-level="1.3.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-more-r-chunks-and-explore-options-and-play-with-r-code"><i class="fa fa-check"></i><b>1.3.4</b> Create more R chunks and explore options and play with R code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html"><i class="fa fa-check"></i><b>2</b> Data – Reading, Writing, and Wrangling</a><ul>
<li class="chapter" data-level="2.1" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#create-new-notebook-for-this-chapter"><i class="fa fa-check"></i><b>2.1</b> Create new notebook for this chapter</a></li>
<li class="chapter" data-level="2.2" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#importing-data"><i class="fa fa-check"></i><b>2.2</b> Importing data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#excel-file"><i class="fa fa-check"></i><b>2.2.1</b> Excel file</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#text-file"><i class="fa fa-check"></i><b>2.2.2</b> Text file</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#data-wrangling"><i class="fa fa-check"></i><b>2.3</b> Data wrangling</a><ul>
<li class="chapter" data-level="2.3.1" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#combining-data"><i class="fa fa-check"></i><b>2.3.1</b> Combining data</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#subsetting-data"><i class="fa fa-check"></i><b>2.3.2</b> Subsetting data</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#missing-data"><i class="fa fa-check"></i><b>2.3.3</b> missing data</a></li>
<li class="chapter" data-level="2.3.4" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#reshaping-data"><i class="fa fa-check"></i><b>2.3.4</b> Reshaping data</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#saving-data"><i class="fa fa-check"></i><b>2.4</b> Saving data</a></li>
<li class="chapter" data-level="2.5" data-path="data-reading-writing-and-wrangling.html"><a href="data-reading-writing-and-wrangling.html#problems"><i class="fa fa-check"></i><b>2.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-some-fundamentals-of-statistical-modeling.html"><a href="part-ii-some-fundamentals-of-statistical-modeling.html"><i class="fa fa-check"></i>Part II: Some Fundamentals of Statistical Modeling</a></li>
<li class="chapter" data-level="3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html"><i class="fa fa-check"></i><b>3</b> An Introduction to Statistical Modeling</a><ul>
<li class="chapter" data-level="3.1" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#two-specifications-of-a-linear-model"><i class="fa fa-check"></i><b>3.1</b> Two specifications of a linear model</a><ul>
<li class="chapter" data-level="3.1.1" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#the-error-draw-specification"><i class="fa fa-check"></i><b>3.1.1</b> The “error draw” specification</a></li>
<li class="chapter" data-level="3.1.2" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#the-conditional-draw-specification"><i class="fa fa-check"></i><b>3.1.2</b> The “conditional draw” specification</a></li>
<li class="chapter" data-level="3.1.3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#comparing-the-two-ways-of-specifying-the-linear-model"><i class="fa fa-check"></i><b>3.1.3</b> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#what-do-we-call-the-x-and-y-variables"><i class="fa fa-check"></i><b>3.2</b> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li class="chapter" data-level="3.3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>3.3</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="3.4" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#modeling-strategy"><i class="fa fa-check"></i><b>3.4</b> Modeling strategy</a></li>
<li class="chapter" data-level="3.5" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#a-mean-is-the-simplest-model"><i class="fa fa-check"></i><b>3.5</b> A mean is the simplest model</a></li>
<li class="chapter" data-level="3.6" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>3.6</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="3.7" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>3.7</b> Specific assumptions for inference with a linear model</a></li>
<li class="chapter" data-level="3.8" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#statistical-model-or-regression-model"><i class="fa fa-check"></i><b>3.8</b> “Statistical model” or “regression model”?</a></li>
<li class="chapter" data-level="3.9" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#glm-vs.glm-vs.gls"><i class="fa fa-check"></i><b>3.9</b> GLM vs. GLM vs. GLS</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><i class="fa fa-check"></i><b>4</b> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="chapter" data-level="4.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#the-sample-standard-deviation-vs.the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#sample-standard-deviation"><i class="fa fa-check"></i><b>4.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="4.1.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>4.2</b> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="4.2.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#steps"><i class="fa fa-check"></i><b>4.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>4.3</b> Using R to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="4.3.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-i"><i class="fa fa-check"></i><b>4.3.1</b> part I</a></li>
<li class="chapter" data-level="4.3.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-ii---means"><i class="fa fa-check"></i><b>4.3.2</b> part II - means</a></li>
<li class="chapter" data-level="4.3.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>4.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="4.3.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>4.3.4</b> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#bootstrapped-standard-errors"><i class="fa fa-check"></i><b>4.4</b> Bootstrapped standard errors</a></li>
<li class="chapter" data-level="4.5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#confidence-interval"><i class="fa fa-check"></i><b>4.5</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html"><i class="fa fa-check"></i><b>5</b> Covariance and Correlation</a></li>
<li class="chapter" data-level="6" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>6</b> P-values</a><ul>
<li class="chapter" data-level="6.1" data-path="p-values.html"><a href="p-values.html#p-values-1"><i class="fa fa-check"></i><b>6.1</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="6.2" data-path="p-values.html"><a href="p-values.html#creating-a-null-distribution."><i class="fa fa-check"></i><b>6.2</b> Creating a null distribution.</a><ul>
<li class="chapter" data-level="6.2.1" data-path="p-values.html"><a href="p-values.html#the-null-distribution"><i class="fa fa-check"></i><b>6.2.1</b> the Null Distribution</a></li>
<li class="chapter" data-level="6.2.2" data-path="p-values.html"><a href="p-values.html#t-tests"><i class="fa fa-check"></i><b>6.2.2</b> t-tests</a></li>
<li class="chapter" data-level="6.2.3" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>6.2.3</b> P-values from the perspective of permutation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="p-values.html"><a href="p-values.html#statistical-modeling-instead-of-hypothesis-testing"><i class="fa fa-check"></i><b>6.3</b> Statistical modeling instead of hypothesis testing</a></li>
<li class="chapter" data-level="6.4" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>6.4</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="6.4.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>6.4.1</b> Background</a></li>
<li class="chapter" data-level="6.4.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>6.4.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <em>p</em>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="6.4.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>6.4.3</b> Two interpretations of the <em>p</em>-value</a></li>
<li class="chapter" data-level="6.4.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>6.4.4</b> NHST</a></li>
<li class="chapter" data-level="6.4.5" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>6.4.5</b> Some major misconceptions of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="6.4.6" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>6.4.6</b> Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="p-values.html"><a href="p-values.html#problems-1"><i class="fa fa-check"></i><b>6.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="creating-fake-data.html"><a href="creating-fake-data.html"><i class="fa fa-check"></i><b>7</b> Creating Fake Data</a><ul>
<li class="chapter" data-level="7.0.1" data-path="creating-fake-data.html"><a href="creating-fake-data.html#continuous-x-fake-observational-data"><i class="fa fa-check"></i><b>7.0.1</b> Continuous X (fake observational data)</a></li>
<li class="chapter" data-level="7.0.2" data-path="creating-fake-data.html"><a href="creating-fake-data.html#categorical-x-fake-experimental-data"><i class="fa fa-check"></i><b>7.0.2</b> Categorical X (fake experimental data)</a></li>
<li class="chapter" data-level="7.0.3" data-path="creating-fake-data.html"><a href="creating-fake-data.html#correlated-x-fake-observational-data"><i class="fa fa-check"></i><b>7.0.3</b> Correlated X (fake observational data)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-introduction-to-linear-models.html"><a href="part-iii-introduction-to-linear-models.html"><i class="fa fa-check"></i>Part III: Introduction to Linear Models</a></li>
<li class="chapter" data-level="8" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html"><i class="fa fa-check"></i><b>8</b> A linear model with a single, continuous <em>X</em></a><ul>
<li class="chapter" data-level="8.1" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><i class="fa fa-check"></i><b>8.1</b> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="8.1.1" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#using-a-linear-model-to-estimate-explanatory-effects"><i class="fa fa-check"></i><b>8.1.1</b> Using a linear model to estimate explanatory effects</a></li>
<li class="chapter" data-level="8.1.2" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#using-a-linear-model-for-prediction"><i class="fa fa-check"></i><b>8.1.2</b> Using a linear model for prediction</a></li>
<li class="chapter" data-level="8.1.3" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#reporting-results"><i class="fa fa-check"></i><b>8.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#working-in-r"><i class="fa fa-check"></i><b>8.2</b> Working in R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#exploring-the-bivariate-relationship-between-y-and-x"><i class="fa fa-check"></i><b>8.2.1</b> Exploring the bivariate relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>8.2.2</b> Fitting the linear model</a></li>
<li class="chapter" data-level="8.2.3" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>8.2.3</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="8.2.4" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#display-an-alternative-to-summary"><i class="fa fa-check"></i><b>8.2.4</b> display: An alternative to summary</a></li>
<li class="chapter" data-level="8.2.5" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#confidence-intervals"><i class="fa fa-check"></i><b>8.2.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="8.2.6" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>8.2.6</b> How good is our model?</a></li>
<li class="chapter" data-level="8.2.7" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#exploring-a-lm-object"><i class="fa fa-check"></i><b>8.2.7</b> exploring a lm object</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#problems-2"><i class="fa fa-check"></i><b>8.3</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>9</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="9.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-estimates-the-effects-of-x-on-the-response."><i class="fa fa-check"></i><b>9.1</b> A linear model with a single, categorical <em>X</em> estimates the effects of <em>X</em> on the response.</a><ul>
<li class="chapter" data-level="9.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#table-of-model-coefficients"><i class="fa fa-check"></i><b>9.1.1</b> Table of model coefficients</a></li>
<li class="chapter" data-level="9.1.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#the-linear-model"><i class="fa fa-check"></i><b>9.1.2</b> The linear model</a></li>
<li class="chapter" data-level="9.1.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#reporting-results-1"><i class="fa fa-check"></i><b>9.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#comparing-the-results-of-a-linear-model-to-classical-hypothesis-tests"><i class="fa fa-check"></i><b>9.2</b> Comparing the results of a linear model to classical hypothesis tests</a><ul>
<li class="chapter" data-level="9.2.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#t-tests-are-special-cases-of-a-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> t-tests are special cases of a linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#anova-is-a-special-case-of-a-linear-model"><i class="fa fa-check"></i><b>9.2.2</b> ANOVA is a special case of a linear model</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#working-in-r-1"><i class="fa fa-check"></i><b>9.3</b> Working in R</a><ul>
<li class="chapter" data-level="9.3.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#fitting-the-model"><i class="fa fa-check"></i><b>9.3.1</b> Fitting the model</a></li>
<li class="chapter" data-level="9.3.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#changing-the-reference-level"><i class="fa fa-check"></i><b>9.3.2</b> Changing the reference level</a></li>
<li class="chapter" data-level="9.3.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#an-introduction-to-contrasts"><i class="fa fa-check"></i><b>9.3.3</b> An introduction to contrasts</a></li>
<li class="chapter" data-level="9.3.4" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#harrell-plot"><i class="fa fa-check"></i><b>9.3.4</b> Harrell plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-checking-1.html"><a href="model-checking-1.html"><i class="fa fa-check"></i><b>10</b> Model Checking</a><ul>
<li class="chapter" data-level="10.1" data-path="model-checking-1.html"><a href="model-checking-1.html#do-coefficients-make-numeric-sense"><i class="fa fa-check"></i><b>10.1</b> Do coefficients make numeric sense?</a></li>
<li class="chapter" data-level="10.2" data-path="model-checking-1.html"><a href="model-checking-1.html#all-statistical-analyses-should-be-followed-by-model-checking"><i class="fa fa-check"></i><b>10.2</b> All statistical analyses should be followed by model checking</a></li>
<li class="chapter" data-level="10.3" data-path="model-checking-1.html"><a href="model-checking-1.html#linear-model-assumptions"><i class="fa fa-check"></i><b>10.3</b> Linear model assumptions</a></li>
<li class="chapter" data-level="10.4" data-path="model-checking-1.html"><a href="model-checking-1.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><i class="fa fa-check"></i><b>10.4</b> Diagnostic plots use the residuals from the model fit</a><ul>
<li class="chapter" data-level="10.4.1" data-path="model-checking-1.html"><a href="model-checking-1.html#residuals"><i class="fa fa-check"></i><b>10.4.1</b> Residuals</a></li>
<li class="chapter" data-level="10.4.2" data-path="model-checking-1.html"><a href="model-checking-1.html#a-normal-q-q-plot-is-used-to-check-normality"><i class="fa fa-check"></i><b>10.4.2</b> A Normal Q-Q plot is used to check normality</a></li>
<li class="chapter" data-level="10.4.3" data-path="model-checking-1.html"><a href="model-checking-1.html#outliers---an-outlier-is-a-point-that-is-highly-unexpected-given-the-modeled-distribution."><i class="fa fa-check"></i><b>10.4.3</b> Outliers - an outlier is a point that is highly unexpected given the modeled distribution.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="model-checking-1.html"><a href="model-checking-1.html#model-checking-homoskedasticity"><i class="fa fa-check"></i><b>10.5</b> Model checking homoskedasticity</a></li>
<li class="chapter" data-level="10.6" data-path="model-checking-1.html"><a href="model-checking-1.html#model-checking-independence---hapiness-adverse-example."><i class="fa fa-check"></i><b>10.6</b> Model checking independence - hapiness adverse example.</a></li>
<li class="chapter" data-level="10.7" data-path="model-checking-1.html"><a href="model-checking-1.html#using-r"><i class="fa fa-check"></i><b>10.7</b> Using R</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html"><i class="fa fa-check"></i><b>11</b> Model Fitting and Model Fit (OLS)</a><ul>
<li class="chapter" data-level="11.1" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#least-squares-estimation-and-the-decomposition-of-variance"><i class="fa fa-check"></i><b>11.1</b> Least Squares Estimation and the Decomposition of Variance</a></li>
<li class="chapter" data-level="11.2" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#ols-regression"><i class="fa fa-check"></i><b>11.2</b> OLS regression</a></li>
<li class="chapter" data-level="11.3" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>11.3</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html"><i class="fa fa-check"></i><b>12</b> Best Practices – Issues in Inference</a><ul>
<li class="chapter" data-level="12.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#power"><i class="fa fa-check"></i><b>12.1</b> Power</a><ul>
<li class="chapter" data-level="12.1.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#types-of-error"><i class="fa fa-check"></i><b>12.1.1</b> “Types” of Error</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing"><i class="fa fa-check"></i><b>12.2</b> multiple testing</a><ul>
<li class="chapter" data-level="12.2.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#some-background"><i class="fa fa-check"></i><b>12.2.1</b> Some background</a></li>
<li class="chapter" data-level="12.2.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing-working-in-r"><i class="fa fa-check"></i><b>12.2.2</b> Multiple testing – working in R</a></li>
<li class="chapter" data-level="12.2.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#false-discovery-rate"><i class="fa fa-check"></i><b>12.2.3</b> False Discovery Rate</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#difference-in-p-is-not-different"><i class="fa fa-check"></i><b>12.3</b> difference in p is not different</a></li>
<li class="chapter" data-level="12.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#inference-when-data-are-not-normal"><i class="fa fa-check"></i><b>12.4</b> Inference when data are not Normal</a><ul>
<li class="chapter" data-level="12.4.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#working-in-r-2"><i class="fa fa-check"></i><b>12.4.1</b> Working in R</a></li>
<li class="chapter" data-level="12.4.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>12.4.2</b> Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="12.4.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#permutation-test"><i class="fa fa-check"></i><b>12.4.3</b> Permutation test</a></li>
<li class="chapter" data-level="12.4.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#non-parametric-tests"><i class="fa fa-check"></i><b>12.4.4</b> Non-parametric tests</a></li>
<li class="chapter" data-level="12.4.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#log-transformations"><i class="fa fa-check"></i><b>12.4.5</b> Log transformations</a></li>
<li class="chapter" data-level="12.4.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#performance-of-parametric-tests-and-alternatives"><i class="fa fa-check"></i><b>12.4.6</b> Performance of parametric tests and alternatives</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#max-vs.mean"><i class="fa fa-check"></i><b>12.5</b> max vs. mean</a></li>
<li class="chapter" data-level="12.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#pre-post-normalization"><i class="fa fa-check"></i><b>12.6</b> pre-post, normalization</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="plotting-models.html"><a href="plotting-models.html"><i class="fa fa-check"></i><b>13</b> Plotting Models</a><ul>
<li class="chapter" data-level="13.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plots-show-the-model-and-the-data"><i class="fa fa-check"></i><b>13.1</b> Pretty good plots show the model and the data</a><ul>
<li class="chapter" data-level="13.1.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-1-modeled-effects-plot"><i class="fa fa-check"></i><b>13.1.1</b> Pretty good plot component 1: Modeled effects plot</a></li>
<li class="chapter" data-level="13.1.2" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot-with-jittered-raw-data"><i class="fa fa-check"></i><b>13.1.2</b> Pretty good plot component 2: Modeled mean and CI plot with jittered raw data</a></li>
<li class="chapter" data-level="13.1.3" data-path="plotting-models.html"><a href="plotting-models.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><i class="fa fa-check"></i><b>13.1.3</b> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="plotting-models.html"><a href="plotting-models.html#some-comments-on-plot-components"><i class="fa fa-check"></i><b>13.2</b> Some comments on plot components</a></li>
<li class="chapter" data-level="13.3" data-path="plotting-models.html"><a href="plotting-models.html#working-in-r-3"><i class="fa fa-check"></i><b>13.3</b> Working in R</a><ul>
<li class="chapter" data-level="13.3.1" data-path="plotting-models.html"><a href="plotting-models.html#unpooled-se-bars-and-confidence-intervals"><i class="fa fa-check"></i><b>13.3.1</b> Unpooled SE bars and confidence intervals</a></li>
<li class="chapter" data-level="13.3.2" data-path="plotting-models.html"><a href="plotting-models.html#adding-bootstrap-intervals"><i class="fa fa-check"></i><b>13.3.2</b> Adding bootstrap intervals</a></li>
<li class="chapter" data-level="13.3.3" data-path="plotting-models.html"><a href="plotting-models.html#adding-modeled-error-intervals"><i class="fa fa-check"></i><b>13.3.3</b> Adding modeled error intervals</a></li>
<li class="chapter" data-level="13.3.4" data-path="plotting-models.html"><a href="plotting-models.html#adding-p-values"><i class="fa fa-check"></i><b>13.3.4</b> Adding p-values</a></li>
<li class="chapter" data-level="13.3.5" data-path="plotting-models.html"><a href="plotting-models.html#adding-custom-p-values"><i class="fa fa-check"></i><b>13.3.5</b> Adding custom p-values</a></li>
<li class="chapter" data-level="13.3.6" data-path="plotting-models.html"><a href="plotting-models.html#plotting-two-factors"><i class="fa fa-check"></i><b>13.3.6</b> Plotting two factors</a></li>
<li class="chapter" data-level="13.3.7" data-path="plotting-models.html"><a href="plotting-models.html#interaction-plot"><i class="fa fa-check"></i><b>13.3.7</b> Interaction plot</a></li>
</ul></li>
</ul></li>
<li><a href="part-iv-more-than-one-x-multivariable-models.html#part-iv-more-than-one-x-multivariable-models">Part IV: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="chapter" data-level="14" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html"><i class="fa fa-check"></i><b>14</b> Adding covariates to a linear model</a><ul>
<li class="chapter" data-level="14.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>14.1</b> Adding covariates can increases the precision of the effect of interest</a></li>
<li class="chapter" data-level="14.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-decrease-prediction-error-in-predictive-models"><i class="fa fa-check"></i><b>14.2</b> Adding covariates can decrease prediction error in predictive models</a></li>
<li class="chapter" data-level="14.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-reduce-bias-due-to-confounding-in-explanatory-models"><i class="fa fa-check"></i><b>14.3</b> Adding covariates can reduce bias due to confounding in explanatory models</a></li>
<li class="chapter" data-level="14.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-1-a-pre-treatment-measure-of-the-response-should-be-a-covariate-and-not-subtracted-from-the-post-treatment-measure-regression-to-the-mean"><i class="fa fa-check"></i><b>14.4</b> Best practices 1: A pre-treatment measure of the response should be a covariate and not subtracted from the post-treatment measure (regression to the mean)</a><ul>
<li class="chapter" data-level="14.4.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-words"><i class="fa fa-check"></i><b>14.4.1</b> Regression to the mean in words</a></li>
<li class="chapter" data-level="14.4.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-pictures"><i class="fa fa-check"></i><b>14.4.2</b> Regression to the mean in pictures</a></li>
<li class="chapter" data-level="14.4.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>14.4.3</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="14.4.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>14.4.4</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-2-use-a-covariate-instead-of-normalizing-a-response"><i class="fa fa-check"></i><b>14.5</b> Best practices 2: Use a covariate instead of normalizing a response</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>15</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="15.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>15.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="15.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>15.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="15.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>15.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="15.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-interpretation-of-the-coefficients-in-a-factorial-model-is-entirely-dependent-on-the-reference"><i class="fa fa-check"></i><b>15.1.3</b> The interpretation of the coefficients in a factorial model is entirely dependent on the reference…</a></li>
<li class="chapter" data-level="15.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#estimated-marginal-means"><i class="fa fa-check"></i><b>15.1.4</b> Estimated marginal means</a></li>
<li class="chapter" data-level="15.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#in-a-factorial-model-there-are-multiple-effects-of-each-factor-simple-effects"><i class="fa fa-check"></i><b>15.1.5</b> In a factorial model, there are multiple effects of each factor (simple effects)</a></li>
<li class="chapter" data-level="15.1.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects"><i class="fa fa-check"></i><b>15.1.6</b> Marginal effects</a></li>
<li class="chapter" data-level="15.1.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>15.1.7</b> The additive model</a></li>
<li class="chapter" data-level="15.1.8" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reduce-models-for-the-right-reason"><i class="fa fa-check"></i><b>15.1.8</b> Reduce models for the right reason</a></li>
<li class="chapter" data-level="15.1.9" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>15.1.9</b> What about models with more than two factors?</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results-2"><i class="fa fa-check"></i><b>15.2</b> Reporting results</a><ul>
<li class="chapter" data-level="15.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>15.2.1</b> Text results</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-4"><i class="fa fa-check"></i><b>15.3</b> Working in R</a><ul>
<li class="chapter" data-level="15.3.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-formula"><i class="fa fa-check"></i><b>15.3.1</b> Model formula</a></li>
<li class="chapter" data-level="15.3.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#modeled-means"><i class="fa fa-check"></i><b>15.3.2</b> Modeled means</a></li>
<li class="chapter" data-level="15.3.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-means"><i class="fa fa-check"></i><b>15.3.3</b> Marginal means</a></li>
<li class="chapter" data-level="15.3.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts"><i class="fa fa-check"></i><b>15.3.4</b> Contrasts</a></li>
<li class="chapter" data-level="15.3.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#simple-effects"><i class="fa fa-check"></i><b>15.3.5</b> Simple effects</a></li>
<li class="chapter" data-level="15.3.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects-1"><i class="fa fa-check"></i><b>15.3.6</b> Marginal effects</a></li>
<li class="chapter" data-level="15.3.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#plotting-results"><i class="fa fa-check"></i><b>15.3.7</b> Plotting results</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-3"><i class="fa fa-check"></i><b>15.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>16</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="16.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>16.1</b> Summary of usage</a></li>
<li class="chapter" data-level="16.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>16.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="16.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>16.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="16.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>16.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="16.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>16.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="16.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>16.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>16.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="16.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="16.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>16.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="16.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>16.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-5"><i class="fa fa-check"></i><b>16.5</b> Working in R</a><ul>
<li class="chapter" data-level="16.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>16.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="16.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="predictive-models.html"><a href="predictive-models.html"><i class="fa fa-check"></i><b>17</b> Predictive Models</a><ul>
<li class="chapter" data-level="17.1" data-path="predictive-models.html"><a href="predictive-models.html#overfitting"><i class="fa fa-check"></i><b>17.1</b> Overfitting</a></li>
<li class="chapter" data-level="17.2" data-path="predictive-models.html"><a href="predictive-models.html#model-building-vs.variable-selection-vs.model-selection"><i class="fa fa-check"></i><b>17.2</b> Model building vs. Variable selection vs. Model selection</a><ul>
<li class="chapter" data-level="17.2.1" data-path="predictive-models.html"><a href="predictive-models.html#stepwise-regression"><i class="fa fa-check"></i><b>17.2.1</b> Stepwise regression</a></li>
<li class="chapter" data-level="17.2.2" data-path="predictive-models.html"><a href="predictive-models.html#cross-validation"><i class="fa fa-check"></i><b>17.2.2</b> Cross-validation</a></li>
<li class="chapter" data-level="17.2.3" data-path="predictive-models.html"><a href="predictive-models.html#penalization"><i class="fa fa-check"></i><b>17.2.3</b> Penalization</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="predictive-models.html"><a href="predictive-models.html#shrinkage"><i class="fa fa-check"></i><b>17.3</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><i class="fa fa-check"></i>Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="chapter" data-level="18" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>18</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="18.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>18.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="18.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>18.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="18.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy-1"><i class="fa fa-check"></i><b>18.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="18.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>18.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="18.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>18.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="18.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>18.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="18.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>18.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="18.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>18.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="18.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>18.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-6"><i class="fa fa-check"></i><b>18.3</b> Working in R</a></li>
<li class="chapter" data-level="18.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-4"><i class="fa fa-check"></i><b>18.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>19</b> Linear mixed models</a><ul>
<li class="chapter" data-level="19.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>19.1</b> Random effects</a></li>
<li class="chapter" data-level="19.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>19.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="19.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>19.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="19.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-block-effects"><i class="fa fa-check"></i><b>19.4</b> Visualizing block effects</a></li>
<li class="chapter" data-level="19.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-can-increase-precision-of-point-estimates"><i class="fa fa-check"></i><b>19.5</b> Linear mixed models can increase precision of point estimates</a></li>
<li class="chapter" data-level="19.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-used-to-avoid-pseudoreplication"><i class="fa fa-check"></i><b>19.6</b> Linear mixed models are used to avoid pseudoreplication</a></li>
<li class="chapter" data-level="19.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>19.7</b> Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="19.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-7"><i class="fa fa-check"></i><b>19.8</b> Working in R</a><ul>
<li class="chapter" data-level="19.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>19.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html"><i class="fa fa-check"></i><b>20</b> Linear models with heterogenous variance</a><ul>
<li class="chapter" data-level="20.1" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html#gls"><i class="fa fa-check"></i><b>20.1</b> gls</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="20.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>20.2</b> Get your computer ready</a><ul>
<li class="chapter" data-level="20.2.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>20.2.1</b> Install R</a></li>
<li class="chapter" data-level="20.2.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>20.2.2</b> Install R Studio</a></li>
<li class="chapter" data-level="20.2.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#resources-for-installing-r-and-r-studio"><i class="fa fa-check"></i><b>20.2.3</b> Resources for installing R and R Studio</a></li>
<li class="chapter" data-level="20.2.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-latex"><i class="fa fa-check"></i><b>20.2.4</b> Install LaTeX</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning"><i class="fa fa-check"></i><b>20.3</b> Start learning</a><ul>
<li class="chapter" data-level="20.3.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-with-data-camp-introduction-to-r"><i class="fa fa-check"></i><b>20.3.1</b> Start with Data Camp Introduction to R</a></li>
<li class="chapter" data-level="20.3.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#then-move-to-introduction-to-r-studio"><i class="fa fa-check"></i><b>20.3.2</b> Then Move to Introduction to R Studio</a></li>
<li class="chapter" data-level="20.3.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#develop-your-project-with-an-r-studio-notebook"><i class="fa fa-check"></i><b>20.3.3</b> Develop your project with an R Studio Notebook</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#getting-data-into-r"><i class="fa fa-check"></i><b>20.4</b> Getting Data into R</a></li>
<li class="chapter" data-level="20.5" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#additional-r-learning-resources"><i class="fa fa-check"></i><b>20.5</b> Additional R learning resources</a></li>
<li class="chapter" data-level="20.6" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#packages-used-extensively-in-this-text"><i class="fa fa-check"></i><b>20.6</b> Packages used extensively in this text</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elementary Statistical Modeling for Applied Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="best-practices-issues-in-inference" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Best Practices – Issues in Inference</h1>
<div id="power" class="section level2">
<h2><span class="header-section-number">12.1</span> Power</h2>
<div id="types-of-error" class="section level3">
<h3><span class="header-section-number">12.1.1</span> “Types” of Error</h3>
<p>I, II, S, M</p>
</div>
</div>
<div id="multiple-testing" class="section level2">
<h2><span class="header-section-number">12.2</span> multiple testing</h2>
<p><strong>Multiple testing</strong> is the practice of adjusting <em>p</em>-values (and less commonly confidence intervals) to account for the expected increase in the frequency of Type I error when there are multiple tests (typically Null Hypothesis Significance Tests). Multiple testing tends to arise in two types of situations:</p>
<ol style="list-style-type: decimal">
<li>Multiple pairwise contrasts among treatment levels (or combinations of levels) are estimated.</li>
<li>The effects of a treatment on multiple responses are estimated. This can arise if
<ol style="list-style-type: lower-alpha">
<li>there are multiple ways of measuring the consequences of something – for example, an injurious treatment on plant health might effect root biomass, shoot biomass, leaf number, leaf area, etc.</li>
<li>one is exploring the consequences of an effect on many, many outcomes – for example, the expression levels of 10,000 genes between normal and obese mice.</li>
</ol></li>
</ol>
<p>Despite the ubiquitous presence of multiple testing in elementary biostatistics textbooks, in the applied biology literature, and in journal guidelines, the practice of adjusting <em>p</em>-values for multiple tests is highly controversial among statisticians. My thoughts:</p>
<ol style="list-style-type: decimal">
<li>In situations like (1) above, I advocate that researchers <strong>do not adjust p-values for multiple tests</strong>. In general, its a best practice to only estimate contrasts for which you care about because of some <em>a priori</em> model of how the system works. If you compare all pairwise contrasts of an experiment with many treatment levels and/or combinations, expect to find some false discoveries.</li>
<li>In situations like (2a) above, I advocate that researchers <strong>do not adjust p-values for multiple tests</strong>.</li>
<li>In situations like (2b) above, adjusting for the <strong>False Discovery Rate</strong> is an interesting approach. But, recognize that tests with small <em>p</em>-values are <em>highly provisional</em> discoveries of a patterns only and not a discovery of the causal sequelae of the treatment. For that, one needs to do the hard work of designing experiments that rigorously probe a working, mechanistic model of the system.</li>
</ol>
<p>Finally, recognize that anytime there are multiple tests, Type M errors will arise due to the vagaries of sampling. This means that in a rank-ordered list of the effects, those at the top have measured effects that are probably bigger than the true effect. An alternative to adjusted <em>p</em>-values is a <strong>penalized regression</strong> model that shrinks effects toward the mean effect.</p>
<div id="some-background" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Some background</h3>
<div id="family-wise-error-rate" class="section level4">
<h4><span class="header-section-number">12.2.1.1</span> Family-wise error rate</h4>
<p>The logic of multiple testing goes something like this: the more tests that a researcher does, the higher the probability that a false positive (Type I error) will occur, therefore a researcher should should adjust <em>p</em>-values so that the Type I error over the set (or “family”) of tests is 5%. This adjusted Type I error rate is the “family-wise error rate”.</p>
<p>If a researcher carries out multiple tests <em>of data in which the null hypothesis is true</em>, what is the probability of finding at least one Type I error? This is easy to compute. If the frequency of Type I error for a single test is <span class="math inline">\(\alpha\)</span>, then the probability of no Type I error is <span class="math inline">\(1 - \alpha\)</span>. For two tests, the probability of no Type I error in either test is the product of the probability for each test, or <span class="math inline">\((1 - \alpha)^2\)</span>. By the same logic, for <span class="math inline">\(m\)</span> tests, the probabilty of no type I error in any of the tests is <span class="math inline">\((1 - \alpha)^m\)</span>. The probability of at least one type one error, across the <span class="math inline">\(m\)</span> tests, then, is <span class="math inline">\(1 - (1 - \alpha)^m\)</span>. A table of these probabilities for different <span class="math inline">\(m\)</span> is given below. If the null is true in all tests, then at least one Type I error is more likely than not if there are 14 tests, and close to certain if there more than 50 tests. Don’t skip over this paragraph – the logic is important even if I don’t advocate adjusting for multiple tests.</p>
<table>
<caption><span id="tab:best-type1-table">Table 12.1: </span>Probability of at least one type I error within the set of multiple tests, for data in which the null hypothesis is true. The Type I error rate for a single test is 0.05. The number of tests is m. The probability is p.</caption>
<thead>
<tr class="header">
<th align="right">m</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0.14</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="right">0.26</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">0.40</td>
</tr>
<tr class="odd">
<td align="right">50</td>
<td align="right">0.92</td>
</tr>
<tr class="even">
<td align="right">100</td>
<td align="right">0.99</td>
</tr>
<tr class="odd">
<td align="right">#### F</td>
<td align="right">alse discovery rate</td>
</tr>
</tbody>
</table>
<p>If a researcher carries out thousands of tests to “discover” new facts, and uses <span class="math inline">\(p &lt; 0.05\)</span> as evidence of discovery, then what is the frequency of <strong>false discoveries</strong>?</p>
</div>
<div id="p-value-filter-i-inflated-effects" class="section level4">
<h4><span class="header-section-number">12.2.1.2</span> p-value filter I – Inflated effects</h4>
<p>If a researcher caries out many tests, and ranks the effects by magnitude or <em>p</em>-value, then the effect sizes of the largest effects will be inflated. Before explaining why, let’s simulate this using an experiment of allelopathic effects of the invasive garlic mustard (<em>Alliaria petiolata</em>) on gene expression in the native American ginseng (<em>Panax quinquefolius</em>). In the treated group, we have ten pots, each with an American ginseng plant grown in a container with a mustard plant. In the control group, we have ten pots, each with an American ginseng plant grown in a container with another American ginseng. I’ve simulated the response of 10,000 genes. The treatment has a true effect in 10% of the 10,000 genes but most effects are very small.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4</span>)
p &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="dv">4</span> <span class="co"># number of genes</span>
pt &lt;-<span class="st"> </span><span class="fl">0.1</span><span class="op">*</span>p <span class="co"># number of genes with true response to treatment</span>
n &lt;-<span class="st"> </span><span class="dv">10</span>

<span class="co"># sample the gene effects from an exponential distribution</span>
theta &lt;-<span class="st"> </span>.<span class="dv">3</span>
beta &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rexp</span>(pt, <span class="dt">rate=</span><span class="dv">1</span><span class="op">/</span>theta),
          <span class="kw">rep</span>(<span class="dv">0</span>, (p<span class="op">-</span>pt))) <span class="co"># the set of 10,000 effects</span>

<span class="co"># sample the variance of the expression level with a gamma, and set a minimum</span>
sigma &lt;-<span class="st"> </span><span class="kw">rgamma</span>(p, <span class="dt">shape=</span><span class="dv">2</span>, <span class="dt">scale=</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.58</span>
<span class="co"># quantile(sigma, c(0.001, 0.1, 0.5, 0.9, 0.999))</span>

Y1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n<span class="op">*</span>p, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="kw">rep</span>(sigma, <span class="dt">each=</span>n)), <span class="dt">nrow=</span>n)
Y2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n<span class="op">*</span>p, <span class="dt">mean=</span><span class="kw">rep</span>(beta, <span class="dt">each=</span>n), <span class="dt">sd=</span><span class="kw">rep</span>(sigma, <span class="dt">each=</span>n)), <span class="dt">nrow=</span>n) <span class="co"># check</span>
<span class="co"># use n &lt;- 10^4 to check</span>
<span class="co"># apply(y2, 2, mean)[1:5]</span>
<span class="co"># b[1:5]</span>
x &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>,<span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)
bhat &lt;-<span class="st"> </span><span class="kw">numeric</span>(p)
p.value &lt;-<span class="st"> </span><span class="kw">numeric</span>(p)
sigma_hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(p)
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>p){
  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">c</span>(Y1[,j], Y2[, j]) <span class="op">~</span><span class="st"> </span>x)
  bhat[j] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(fit))[<span class="st">&quot;xtr&quot;</span>, <span class="st">&quot;Estimate&quot;</span>]
  p.value[j] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(fit))[<span class="st">&quot;xtr&quot;</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]
  sigma_hat[j] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>(fit<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>fit<span class="op">$</span>df.residual)
}</code></pre></div>
<div class="figure"><span id="fig:inflation-histogram"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/inflation-histogram-1.png" alt="A histogram of the distribution of the 10,000 effects" width="576" />
<p class="caption">
Figure 12.1: A histogram of the distribution of the 10,000 effects
</p>
</div>
<table>
<caption><span id="tab:unnamed-chunk-49">Table 12.2: </span>The top 10 genes ranked by p-value. Rank is the rank of the true effect, from large to small.</caption>
<thead>
<tr class="header">
<th align="right">effect</th>
<th align="right">estimate</th>
<th align="right">sigma</th>
<th align="right">sd</th>
<th align="right">p.value</th>
<th align="right">relative true effect</th>
<th align="right">rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2.23</td>
<td align="right">2.67</td>
<td align="right">0.81</td>
<td align="right">0.55</td>
<td align="right">0.0000000</td>
<td align="right">1.00</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">1.59</td>
<td align="right">1.92</td>
<td align="right">0.62</td>
<td align="right">0.57</td>
<td align="right">0.0000005</td>
<td align="right">0.71</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="right">1.46</td>
<td align="right">1.86</td>
<td align="right">0.84</td>
<td align="right">0.71</td>
<td align="right">0.0000159</td>
<td align="right">0.65</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">1.47</td>
<td align="right">1.78</td>
<td align="right">0.83</td>
<td align="right">0.74</td>
<td align="right">0.0000409</td>
<td align="right">0.66</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="right">0.00</td>
<td align="right">1.95</td>
<td align="right">1.10</td>
<td align="right">0.85</td>
<td align="right">0.0000717</td>
<td align="right">0.00</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">0.48</td>
<td align="right">1.26</td>
<td align="right">0.67</td>
<td align="right">0.56</td>
<td align="right">0.0000816</td>
<td align="right">0.21</td>
<td align="right">212</td>
</tr>
<tr class="odd">
<td align="right">0.97</td>
<td align="right">1.32</td>
<td align="right">0.69</td>
<td align="right">0.60</td>
<td align="right">0.0001004</td>
<td align="right">0.43</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="right">0.54</td>
<td align="right">1.68</td>
<td align="right">1.06</td>
<td align="right">0.78</td>
<td align="right">0.0001321</td>
<td align="right">0.24</td>
<td align="right">173</td>
</tr>
<tr class="odd">
<td align="right">0.00</td>
<td align="right">2.05</td>
<td align="right">1.39</td>
<td align="right">0.96</td>
<td align="right">0.0001488</td>
<td align="right">0.00</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="right">0.43</td>
<td align="right">-1.78</td>
<td align="right">1.33</td>
<td align="right">0.84</td>
<td align="right">0.0001733</td>
<td align="right">0.19</td>
<td align="right">244</td>
</tr>
</tbody>
</table>
<p>The table above lists the top 10 genes ranked by <em>p</em>-value, using the logic that the genes with the smallest <em>p</em> values are the genes that we should pursue with further experiments to understand the system. Some points</p>
<ol style="list-style-type: decimal">
<li>Six of the top ten genes with biggest true effects are <em>not</em> on this list. And, in the list are three genes with true effects that have relatively low ranks based on true effect size (column &quot;rank&quot;) <em>and</em> two genes that have no true effect at all. Also in this list is one gene with an estimated effect (-1.78) that is <em>opposite</em> in sign of the true effect (but look at the <em>p</em>-value!)</li>
<li>The estimate of the effect size for all top-ten genes are inflated. The average estimate for these 10 genes is 1.47 while the average true effect for these 10 genes is 0.92 (the estimate ).</li>
<li>The sample standard deviation (sd) for all top-ten genes is less than the true standard deviation (sigma), in some cases substantially.</li>
</ol>
<p>The consequence of an inflated estimate of the effect and a deflated estimate of the variance is a large <em>t</em> (not shown) and small <em>p</em>. What is going on is an individual gene’s estimated effect and standard deviation are functions of 1) the true value and 2) a random sampling component. The random component will be symmetric, some effects will be overestimated and some underestimated. When we rank the genes by the estimate of the effect or <em>t</em> or <em>p</em>, some of the genes that have “risen to the top” will be there because of a large, positive, sampling (random) component of the effect and/or a large, negative, sampling component of the variance. Thus some genes’ high rank is artificial in the sense that it is high because of a random fluke. If the experiment were re-done, these genes at the top because of a large, random component would (probably) fall back to a position closer to their expected rank (regression to the mean again).</p>
<p>In the example here, all genes at the top have inflated estimates of the effect because of the positive, random component. This inflation effect is a function of the signal to noise ratio, which is controled by theta and sigma in the simulation. If theta is increased (try theta=1), or if sigma is decreased, the signal to noise ratio increases (try it and look at the histogram of the new distribution of effects) and both the 1) inflation and the 2) rise to the top phenomenon decrease.</p>
</div>
<div id="p-hacking" class="section level4">
<h4><span class="header-section-number">12.2.1.3</span> p-hacking</h4>
</div>
</div>
<div id="multiple-testing-working-in-r" class="section level3">
<h3><span class="header-section-number">12.2.2</span> Multiple testing – working in R</h3>
<div id="tukey-hsd-adjustment-of-all-pairwise-comparisons" class="section level4">
<h4><span class="header-section-number">12.2.2.1</span> Tukey HSD adjustment of all pairwise comparisons</h4>
<p>The <code>adjust</code> argument in <code>emmeans::contrast()</code> controls the method for <em>p</em>-value adjustment. The default is “tukey”.</p>
<ol style="list-style-type: decimal">
<li>“none” – no adjustment, in general my preference.</li>
<li>“tukey” – Tukey’s HSD, the default</li>
<li>“bonferroni” – the standard bonferroni, which is conservative</li>
<li>“fdr” – the false discovery rate</li>
<li>“mvt” – based on the multivariate <em>t</em> distribution and using covariance structure of the variables</li>
</ol>
<p>The data are those from Fig. 2D of “Data from The enteric nervous system promotes intestinal health by constraining microbiota composition”. There is a single factor with four treatment levels. The response is neutrophil count.</p>
<p>No adjustment:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>donor, <span class="dt">data=</span>exp2d)
m1.emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, <span class="dt">specs=</span><span class="st">&quot;donor&quot;</span>)
m1.pairs.none &lt;-<span class="st"> </span><span class="kw">contrast</span>(m1.emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>, <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>)
<span class="kw">summary</span>(m1.pairs.none, <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>##  contrast       estimate   SE df lower.CL upper.CL t.ratio p.value
##  gf - wt          -1.502 1.48 58    -4.47     1.47 -1.013  0.3153 
##  sox10 - wt        4.679 1.23 58     2.23     7.13  3.817  0.0003 
##  sox10 - gf        6.182 1.45 58     3.29     9.08  4.276  0.0001 
##  iap_mo - wt      -0.384 1.53 58    -3.45     2.68 -0.251  0.8025 
##  iap_mo - gf       1.118 1.71 58    -2.31     4.54  0.654  0.5159 
##  iap_mo - sox10   -5.064 1.49 58    -8.05    -2.07 -3.391  0.0013 
## 
## Confidence level used: 0.95</code></pre>
<p>Tukey HSD:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1.pairs.tukey &lt;-<span class="st"> </span><span class="kw">contrast</span>(m1.emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>, <span class="dt">adjust=</span><span class="st">&quot;tukey&quot;</span>)
<span class="kw">summary</span>(m1.pairs.tukey, <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>##  contrast       estimate   SE df lower.CL upper.CL t.ratio p.value
##  gf - wt          -1.502 1.48 58    -5.43     2.42 -1.013  0.7426 
##  sox10 - wt        4.679 1.23 58     1.44     7.92  3.817  0.0018 
##  sox10 - gf        6.182 1.45 58     2.36    10.01  4.276  0.0004 
##  iap_mo - wt      -0.384 1.53 58    -4.43     3.66 -0.251  0.9944 
##  iap_mo - gf       1.118 1.71 58    -3.41     5.64  0.654  0.9138 
##  iap_mo - sox10   -5.064 1.49 58    -9.01    -1.11 -3.391  0.0067 
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 4 estimates 
## P value adjustment: tukey method for comparing a family of 4 estimates</code></pre>
</div>
</div>
<div id="false-discovery-rate" class="section level3">
<h3><span class="header-section-number">12.2.3</span> False Discovery Rate</h3>
</div>
</div>
<div id="difference-in-p-is-not-different" class="section level2">
<h2><span class="header-section-number">12.3</span> difference in p is not different</h2>
</div>
<div id="inference-when-data-are-not-normal" class="section level2">
<h2><span class="header-section-number">12.4</span> Inference when data are not Normal</h2>
<p>No real data are normal, although many are pretty good approximations of a normal distribution.</p>
<p>I’ll come back to this point, but first, let’s back up. Inference in statistical models (standard errors, confidence intervals, <em>p</em>-values) are a function of the modeled distributions of the parameters (for linear models, this parameter is the conditional (or error) variance <span class="math inline">\(\sigma^2\)</span>); if the data do not approximate the modeled distribution, then inferential statistics might be to liberal (standard errors are too small, confidence intervals are too narrow, Type I error is more than nominal) or to conservative (standard errors are too large, confidence intervals are too wide, Type I error is less than nominal).</p>
<p>Linear models assume that “the data” (specifically, the conditional response, or, equivalently, the residuals from the model) approximate a Normal distribution. Chapter xxx showed how to qualitatively assess how well residuals approximate a Normal distribution using a Q-Q plot. If the researcher concludes that the data poorly approximate a normal distribution because of outliers, the researcher can use robust methods to estimate the parameters. If the approximation is poor because the residuals suggest a skewed distribution or one with heavy or light tails, the researcher can choose among several strategies</p>
<ol style="list-style-type: decimal">
<li>continue to use the linear model; inference can be fairly robust to non-normal data, especially when the sample size is not small.</li>
<li>use a generalized linear model (GLM), which is appropriate if the conditional response approximates any of the distributions that can be modeled using GLM (Chapter xxx)</li>
<li>use bootstrap for confidence intervals and permutation test for <em>p</em>-values</li>
<li>transform the data in a way that makes the conditional response more closely approximate a normal distribution.</li>
<li>use a classic non-parametric test, which are methods that do not assume a particular distribution</li>
</ol>
<p>This list is roughly in the order of how I would advise researchers, although the order of 1-3 is pretty arbitrary. I would rarely advise a researcher to use (4) and never advise (5). Probably the most common strategies in the biology literature are (4) and (5). The first is also common but probably more from lack of recognition of issues or because a “test of normality” failed to reject that the data are “not normal”.</p>
<p>On this last point, do not use the <em>p</em>-value from a “test for normality” (such as a Shapiro-Wilk test) to decide between using the linear model (or t-test or ANOVA) and an alternative such as a generalized linear model (or transformation or non-parametric test). No real data is normal. Tests of normality will tend to “not reject” normality (p &gt; 0.05) when the sample size is small and “reject” normality (p &lt; 0.05) when the sample size is very large. But again, a “not rejected” hypothesis test does not mean the null (in this case, the data are normal) is true. More importantly, where the test for normality tends to fail to reject (encouraging a researcher to use parametric statistics) is where parametric inference performs the worst (because of small <em>n</em>) and where the test for normality tends to reject (encouraging a researcher to use non-parametric statistics) is where the parametric inference performs the best (because of large sample size) (Lumley xxx).</p>
<div id="working-in-r-2" class="section level3">
<h3><span class="header-section-number">12.4.1</span> Working in R</h3>
<p>The data for demonstrating different strategies are from Fig. 4A of “Data from The enteric nervous system promotes intestinal health by constraining microbiota composition”. There is a single factor with two treatment levels. The response is neutrophil count.</p>
<div class="figure"><span id="fig:best-import-non-normal-counts"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/best-import-non-normal-counts-1.png" alt="Distribution of the counts in the wildtype (WT) and sox10 knockout (sox10-) groups. Both groups show a strong right skew, which is common with count data." width="576" />
<p class="caption">
Figure 12.2: Distribution of the counts in the wildtype (WT) and sox10 knockout (sox10-) groups. Both groups show a strong right skew, which is common with count data.
</p>
</div>
<p>A linear model to estimate the treatment effect and 95% confidence interval.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)
m1_emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, <span class="dt">specs=</span><span class="st">&quot;treatment&quot;</span>)
<span class="kw">summary</span>(<span class="kw">contrast</span>(m1_emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>),
        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>##  contrast   estimate   SE  df lower.CL upper.CL t.ratio p.value
##  sox10 - wt     5.16 1.75 174      1.7     8.62 2.947   0.0037 
## 
## Confidence level used: 0.95</code></pre>
</div>
<div id="bootstrap-confidence-intervals" class="section level3">
<h3><span class="header-section-number">12.4.2</span> Bootstrap Confidence Intervals</h3>
<p>A bootstrap confidence interval is computed from the distribution of a statistic from many sets of re-sampled data. The basic algorithm is</p>
<ol style="list-style-type: decimal">
<li>compute the statistic for the observed data, assign this to <span class="math inline">\(\theta_1\)</span></li>
<li>resample <span class="math inline">\(n\)</span> rows of the data, with replacement. “with replacement” means to sample from the entire set of data and not the set that has yet to be sampled. <span class="math inline">\(n\)</span> is the original sample size; by resampling <span class="math inline">\(n\)</span> rows with replacement, some rows will be sampled more than once, and some rows will not be sampled at all.</li>
<li>compute the statistic for the resampled data, assign these to <span class="math inline">\(\theta_{2..m}\)</span></li>
<li>repeat 2 and 3 <span class="math inline">\(m-1\)</span> times</li>
<li>Given the distribution of <span class="math inline">\(m\)</span> estimates, compute the lower interval as the <span class="math inline">\(\frac{\alpha}{2}\)</span>th percentile and the upper interval as the <span class="math inline">\(1 - \frac{\alpha}{2}\)</span>th percentile. For 95% confidence intervals, these are the 2.5th and 97.5th percentiles.</li>
</ol>
<p>Let’s apply this algorithm to the data from fig4A neutrophil count data in the coefficient table above. The focal statistic in these data is the difference in the mean count for the sox10 and wild type groups (the parameter for <span class="math inline">\(treatment\)</span> in the linear model). The script below, which computes the 95% confidence intervals of this difference, resamples within <strong>strata</strong>, that is, within each group; it does this to preserve the original sample size within each group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n_iter &lt;-<span class="st"> </span><span class="dv">5000</span>
b1 &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">5000</span>)
inc &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(fig4a) <span class="co"># the rows for the first iteration are all rows, so this is the observed effect</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_iter){
  <span class="co"># inc creates the index of rows to resample preserving the sample size specific to each group</span>
  b1[i] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a[inc, ]))[<span class="st">&quot;treatmentsox10&quot;</span>]
  inc &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">sample</span>(<span class="kw">which</span>(fig4a[, treatment] <span class="op">==</span><span class="st"> &quot;wt&quot;</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>),
           <span class="kw">sample</span>(<span class="kw">which</span>(fig4a[, treatment] <span class="op">==</span><span class="st"> &quot;sox10&quot;</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>))
}
ci &lt;-<span class="st"> </span><span class="kw">quantile</span>(b1, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))
<span class="kw">c</span>(<span class="dt">contrast =</span> b1[<span class="dv">1</span>], ci[<span class="dv">1</span>], ci[<span class="dv">2</span>])</code></pre></div>
<pre><code>## contrast     2.5%    97.5% 
## 5.163215 2.077892 8.264316</code></pre>
<p>The intervals calculated in step 5 are <strong>percentile intervals</strong>. A histogram of the the re-sampled differences helps to visualize the bootstrap (this is a pedagogical tool, not something you would want to publish).</p>
<div class="figure"><span id="fig:best-bootstrap-histogram"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/best-bootstrap-histogram-1.png" alt="Distribution of the 5000 resampled estimates of the difference in means between the sox10 and wt treatment levels. The dashed lines are located at the 2.5th and 97.5th percentiles of the distribution." width="576" />
<p class="caption">
Figure 12.3: Distribution of the 5000 resampled estimates of the difference in means between the sox10 and wt treatment levels. The dashed lines are located at the 2.5th and 97.5th percentiles of the distribution.
</p>
</div>
<div id="some-r-packages-for-bootstrap-confidence-intervals" class="section level4">
<h4><span class="header-section-number">12.4.2.1</span> Some R packages for bootstrap confidence intervals</h4>
<p>Percentile intervals are known to be biased, meaning the intervals are shifted. The <code>boot</code> package computes a bias-corrected interval in addition to a percentile interval. <code>boot</code> is a very powerful bootstrap package but requires the researcher to write functions to compute the parameter of interest. <code>simpleboot</code> provides functions for common analysis that does this for you (in R speak, we say that <code>simpleboot</code> is a “wrapper” to <code>boot</code>). The function <code>simpleboot::two.boot</code> computes a <code>boot</code>-like object that returns, among other values, the distribution of <span class="math inline">\(m\)</span> statistics. The <code>simpleboot</code> object is then be fed to <code>boot::boot.ci</code> to get bias-corrected intervals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bs_diff &lt;-<span class="st"> </span><span class="kw">two.boot</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count],
                    fig4a[treatment<span class="op">==</span><span class="st">&quot;wt&quot;</span>, count],
                    mean, 
                    <span class="dt">R=</span><span class="dv">5000</span>)
<span class="kw">boot.ci</span>(bs_diff, <span class="dt">type=</span><span class="st">&quot;bca&quot;</span>)</code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 5000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = bs_diff, type = &quot;bca&quot;)
## 
## Intervals : 
## Level       BCa          
## 95%   ( 2.087,  8.410 )  
## Calculations and Intervals on Original Scale</code></pre>
</div>
</div>
<div id="permutation-test" class="section level3">
<h3><span class="header-section-number">12.4.3</span> Permutation test</h3>
<p>A permutation test effectively computes the probability that a random assignment of a response to a particular value of <em>X</em> generates a test statistic as large or larger than the observed statistic. If this probability is small, then this “random assignment” is unlikely. From this we infer that the actual assignment matters, which implies a treatment effect.</p>
<p>The basic algorithm is</p>
<ol style="list-style-type: decimal">
<li>compute the test statistic for the observed data, assign this to <span class="math inline">\(\theta_1\)</span></li>
<li>permute the response</li>
<li>compute the test statistic for the permuted data, assign these to <span class="math inline">\(\theta_{2..m}\)</span></li>
<li>repeat 2 and 3 <span class="math inline">\(m-1\)</span> times</li>
<li>compute <span class="math inline">\(p\)</span> as</li>
</ol>
<span class="math display">\[\begin{equation}
p_{perm} = \frac{N_{\theta_i \ge \theta_{1}}}{m}
\end{equation}\]</span>
<p>This is easily done with a <strong>for loop</strong> in which the observed statistic is the first value in the vector of statistics. If this is done, the minimum value in the numerator for the computation of <span class="math inline">\(p_{perm}\)</span> is 1, which insures that <span class="math inline">\(p_{perm}\)</span> is not zero.</p>
<p>The test statistic depends on the analysis. For the simple comparison of means, a simple test statistic is the difference in means. This is the numerator of the test statistic in a <em>t</em>-test. The test has more power if the test-statistic is scaled (Manley xxx), so a better test statistic would be <em>t</em>, which scales the difference by its standard error.</p>
<p>Here, I implement this algorithm. The test is two-tailed, so the absolute difference is recorded. The first value computed is the observed absolute difference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
n_permutations &lt;-<span class="st"> </span><span class="dv">5000</span>
d &lt;-<span class="st"> </span><span class="kw">numeric</span>(n_permutations)

<span class="co"># create a new column which will contain the permuted response</span>
<span class="co"># for the first iteration, this will be the observed order</span>
fig4a[, count_perm <span class="op">:</span><span class="er">=</span><span class="st"> </span>count]

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_permutations){
  d[i] &lt;-<span class="st"> </span><span class="kw">abs</span>(<span class="kw">t.test</span>(count_perm <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data =</span> fig4a)<span class="op">$</span>statistic)
  
  <span class="co"># permute the count_perm column for the next iteration</span>
  fig4a[, count_perm <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">sample</span>(count)]
}
p &lt;-<span class="st"> </span><span class="kw">sum</span>(d <span class="op">&gt;=</span><span class="st"> </span>d[<span class="dv">1</span>])<span class="op">/</span>n_permutations
p</code></pre></div>
<pre><code>## [1] 0.002</code></pre>
<div id="some-r-packages-with-permutation-tests." class="section level4">
<h4><span class="header-section-number">12.4.3.1</span> Some R packages with permutation tests.</h4>
<p><code>lmPerm::lmp</code> generates permutation p-values for parameters of any kind of linear model. The test statistic is the sum of squares of the term scaled by the residual sum of squares of the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2</span>)
<span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>, 
                 <span class="dt">data=</span>fig4a)))</code></pre></div>
<pre><code>## [1] &quot;Settings:  unique SS &quot;</code></pre>
<pre><code>##              Estimate Iter Pr(Prob)
## (Intercept) 13.694815 5000   0.0042
## treatment1  -2.581608 5000   0.0042</code></pre>
</div>
</div>
<div id="non-parametric-tests" class="section level3">
<h3><span class="header-section-number">12.4.4</span> Non-parametric tests</h3>
<ol style="list-style-type: decimal">
<li>In general, the role of a non-parametric test is a better-behaved <em>p</em>-value, that is, one whose Type I error is well controlled. As such, non-parametric tests are more about Null-Hypothesis Statistical Testing and less (or not at all) about Estimation.</li>
<li>In general, classic non-parametric tests are only available for fairly simple experimental designs. Classic non-parametric tests include
<ul>
<li>Independent sample (Student’s) <em>t</em> test: Mann-Whitney-Wilcoxan</li>
<li>Paired <em>t</em> test: Wilcoxan signed-rank test</li>
</ul></li>
</ol>
<p>One rarely sees non-parametric tests for more complex designs that include covariates, or multiple factors, but for these, one could 1) convert the response to ranks and fit the usual linear model, or 2) implement a permutation test that properly preserves <strong>exchangeability</strong>.</p>
<p>Permutation tests control Type I error and are powerful. That said, I would recommend a permutation test as a supplment to, and not replacement of, inference from a generalized linear model.</p>
<p>A non-parametric (Mann-Whitney-Wilcoxon) test of the fake data generated above</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  count by treatment
## W = 2275, p-value = 0.001495
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="log-transformations" class="section level3">
<h3><span class="header-section-number">12.4.5</span> Log transformations</h3>
<p>Many response variables within biology, including count data, and almost anything that grows, are right skewed and have variances that increase with the mean. A log transform of a response variable with this kind of distribution will tend to make the residuals more approximately normal and the variance less dependent of the mean. At least two issues arise</p>
<ol style="list-style-type: decimal">
<li>if the response is count data, and the data include counts of zero, then a fudge factor has to be added to the response since log(0) doesn’t exist. The typical fudge factor is to add 1 to <em>all</em> values, but this is arbitrary and results do depend on the magnitude of this fudge factor.</li>
<li>the estimates are on a log scale and do not have the units of the response. The estimates can be back-transformed by taking the exponent of a coefficient or contrast but this itself produces problems. For example, the backtransformed mean of the log-transformed response is not the mean on the origianl scale (the arithmetic mean) but the <strong>geometric mean</strong>. Geometric means are smaller than arithmetic means, appreciably so if the data are heavily skewed. Do we want our understanding of a system to be based on geometric means?</li>
</ol>
<div id="working-in-r-log-transformations" class="section level4">
<h4><span class="header-section-number">12.4.5.1</span> Working in R – log transformations</h4>
<p>If we fit a linear model to a log-transformed response then the resulting coefficients and predictions are on the <strong>log scale</strong>. To make interpretation of the analysies easier, we probably want to <strong>back-transform</strong> the coefficients or the predictions to the original scale of the response, which is called the <strong>response scale</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(count <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)
(m2_emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m2,
                  <span class="dt">specs=</span><span class="st">&quot;treatment&quot;</span>,
                  <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))</code></pre></div>
<pre><code>##  treatment response    SE  df lower.CL upper.CL
##  wt            8.22 0.965 174      6.5     10.3
##  sox10        12.59 0.934 174     10.9     14.6
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log(mu + 1) scale</code></pre>
<p>The emmeans package is amazing. Using the argument <code>type = &quot;response&quot;</code> not only backtransforms the means to the response scale but also substracts the 1 that was added to all values in the model.</p>
<p>What about the effect of treatment on count?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">contrast</span>(m2_emm, 
                 <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>,
                 <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),
        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>##  contrast   ratio    SE  df lower.CL upper.CL t.ratio p.value
##  sox10 / wt  1.47 0.185 174     1.15     1.89 3.100   0.0023 
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale 
## Tests are performed on the log scale</code></pre>
<p>It isn’t necessary to backtransform the estimated marginal means prior to computing the contrasts as this can be done in the contrast function itself. Here, the <code>type = &quot;response&quot;</code> argument in the contrast function is redundant since this was done in the computation of the means. But it is transparent so I want it there.</p>
<p><strong>Don’t skip this paragraph</strong> Look at the value in the “contrast” column – it is “sox10 / wt” and not “sox10 - wt”. The backtransformed effect is a ratio instead of a difference. <strong>A difference on the log scale is a ratio on the response scale</strong> because of this equality</p>
<span class="math display">\[\begin{equation}
\mathrm{exp}(\mu_2-\mu_1) = \frac{\mathrm{exp}(\mu_2)}{\mathrm{exp}(\mu_1)})
\end{equation}\]</span>
<p>The interpretation is: If <span class="math inline">\(b^*\)</span> is the backtransformed effect, then, given a one unit increase in <span class="math inline">\(X\)</span>, the expected value of the response increases <span class="math inline">\(b^*\times\)</span>. For a categorical <span class="math inline">\(X\)</span>, this means the backtransformed effect is the ratio of backtransformed means – its what you have to multiply the mean of the reference by to get the mean of the treated group. And, because it is the response that is log-transformed, these means are not arithemetic means but geometric means. Here, this is complicated by the model – the response is not a simple log transformation but log(response + 1). It is easy enough to get the geometric mean of the treated group – multiply the backtransformed intercept by the backtransformed coefficient and then subtract 1 – but because of this subtraction of 1, the interpretation of the backtransformed effect is awkward at best (recall that I told you that a linear model of a log transformed response, and especially the log of the response plus one, leads to difficulty in interpreting the effects).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># backtransformed control mean -- a geometric mean</span>
mu_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">coef</span>(m2)[<span class="dv">1</span>])

<span class="co"># backtransformed effect</span>
b1_star &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">coef</span>(m2)[<span class="dv">2</span>])

<span class="co"># product minus 1</span>
mu_<span class="dv">1</span><span class="op">*</span>b1_star <span class="op">-</span><span class="dv">1</span></code></pre></div>
<pre><code>## (Intercept) 
##    12.59357</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># geometric mean of treatment group</span>
n &lt;-<span class="st"> </span><span class="kw">length</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count])
<span class="kw">exp</span>(<span class="kw">mean</span>(<span class="kw">log</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count<span class="op">+</span><span class="dv">1</span>])))<span class="op">-</span><span class="dv">1</span></code></pre></div>
<pre><code>## [1] 12.59357</code></pre>
<p>Back-transformed effect</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(m2)) </code></pre></div>
<pre><code>##    (Intercept) treatmentsox10 
##       9.219770       1.474394</code></pre>
</div>
</div>
<div id="performance-of-parametric-tests-and-alternatives" class="section level3">
<h3><span class="header-section-number">12.4.6</span> Performance of parametric tests and alternatives</h3>
<div id="type-i-error" class="section level4">
<h4><span class="header-section-number">12.4.6.1</span> Type I error</h4>
<p>If we are going to compute a <span class="math inline">\(p\)</span>-value, we want it to be uniformly distributed “under the null”. A simple way to check this is to compute Type I error. If we set <span class="math inline">\(\alpha = 0.05\)</span>, then we’d expect 5% of tests of an experiment with no effect to have <span class="math inline">\(p &lt; 0.05\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># first create a matrix with a bunch of data sets, each in its own column</span>
n &lt;-<span class="st"> </span><span class="dv">10</span>
n_sets &lt;-<span class="st"> </span><span class="dv">4000</span>
fake_matrix &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n),
                   <span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n))
treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>, <span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)

tests &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>, <span class="st">&quot;log_lm&quot;</span>,<span class="st">&quot;mww&quot;</span>, <span class="st">&quot;perm&quot;</span>)
res_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_sets, <span class="dt">ncol=</span><span class="kw">length</span>(tests))
<span class="kw">colnames</span>(res_matrix) &lt;-<span class="st"> </span>tests
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sets){
  res_matrix[j, <span class="st">&quot;lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment
                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]
  res_matrix[j, <span class="st">&quot;log_lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(fake_matrix[,j] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment
                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]
  res_matrix[j, <span class="st">&quot;mww&quot;</span>] &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,
                                      <span class="dt">exact=</span><span class="ot">FALSE</span>)<span class="op">$</span>p.value
  res_matrix[j, <span class="st">&quot;perm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,
                                 <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>)))[<span class="dv">2</span>, <span class="st">&quot;Pr(Prob)&quot;</span>]
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">apply</span>(res_matrix, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span>)<span class="op">/</span>n_sets)</code></pre></div>
<pre><code>##      lm  log_lm     mww    perm 
## 0.04150 0.05250 0.04350 0.04675</code></pre>
<p>Type I error is computed for the linear model, the linear model with a log transformed responpse, Mann-Whitney-Wilcoxon, and permutation tests. All four tests are slightly conservative for data that look like that modeled. The computed Type I error of the permutation test is closest to the nominal value of 0.05.</p>
</div>
<div id="power-1" class="section level4">
<h4><span class="header-section-number">12.4.6.2</span> Power</h4>
<p>Power is the probability of a test to reject the null hypothesis if the null hypothesis is false (that is, if an effect exists)</p>
<span class="math display">\[\begin{equation}
\mathrm{Power} = \mathrm{Prob}(p &lt; \alpha | mathrm{effect} \neq 0)
\end{equation}\]</span>
<p>If all we care about is a <span class="math inline">\(p-value\)</span> then we want to use a test that is most powerful. But, while power is defined using <span class="math inline">\(\alpha\)</span>, we <em>can</em> care about power even if we don’t consider <span class="math inline">\(\alpha\)</span> to be a very useful concept because increased power also increases the precision of an estimate (that is, narrows confidence intervals).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># first create a matrix with a bunch of data sets, each in its own column</span>
n &lt;-<span class="st"> </span><span class="dv">5</span>
n_sets &lt;-<span class="st"> </span><span class="dv">4000</span>
fake_matrix &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n),
                   <span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">20</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n))
treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>, <span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)

tests &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>, <span class="st">&quot;log_lm&quot;</span>,<span class="st">&quot;mww&quot;</span>, <span class="st">&quot;perm&quot;</span>)
res_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_sets, <span class="dt">ncol=</span><span class="kw">length</span>(tests))
<span class="kw">colnames</span>(res_matrix) &lt;-<span class="st"> </span>tests
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sets){
  res_matrix[j, <span class="st">&quot;lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment
                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]
  res_matrix[j, <span class="st">&quot;log_lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(fake_matrix[,j] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment
                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]
  res_matrix[j, <span class="st">&quot;mww&quot;</span>] &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,
                                      <span class="dt">exact=</span><span class="ot">FALSE</span>)<span class="op">$</span>p.value
  res_matrix[j, <span class="st">&quot;perm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,
                                 <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>)))[<span class="dv">2</span>, <span class="st">&quot;Pr(Prob)&quot;</span>]
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">apply</span>(res_matrix, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span>)<span class="op">/</span>n_sets)</code></pre></div>
<pre><code>##      lm  log_lm     mww    perm 
## 0.09200 0.12525 0.08375 0.10600</code></pre>
<p>As above, Power is computed for the linear model, linear model with a log-transformed response, Mann-Whitney-Wilcoxan, and permutation, by simulating a “low power” experiment. The effect is huge (twice as many cells) but the power is low because the sample size is small (<span class="math inline">\(n = 5\)</span>). At this sample size, and for this model of fake data, all tests have low power. The power of the log-transformed response is the largest. A problem is, this is not a test of the means but of the log transformed mean plus 1. The power of the permutation test is about 25% larger than that of the linear model and Mann-Whitney-Wilcoxan test. An advantage of this test is that it is a p-value of the mean. A good complement to this p-value would be bootstraped confidence intervals. Repeat this simulation using <span class="math inline">\(n=40\)</span> do see how the relative power among the three change in a simulation of an experiment with more power.</p>
</div>
</div>
</div>
<div id="max-vs.mean" class="section level2">
<h2><span class="header-section-number">12.5</span> max vs. mean</h2>
</div>
<div id="pre-post-normalization" class="section level2">
<h2><span class="header-section-number">12.6</span> pre-post, normalization</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="model-fitting-and-model-fit-ols.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="plotting-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/28-best_practices.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
