<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 3 An Introduction to Statistical Modeling | Elementary Statistical Modeling for Applied Biostatistics</title>
  <meta name="description" content="A first course in statistical modeling for biology students">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 3 An Introduction to Statistical Modeling | Elementary Statistical Modeling for Applied Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for biology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 An Introduction to Statistical Modeling | Elementary Statistical Modeling for Applied Biostatistics" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for biology students" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="part-ii-some-fundamentals-of-statistical-modeling.html">
<link rel="next" href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#math"><i class="fa fa-check"></i><b>0.1</b> Math</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#r-and-programming"><i class="fa fa-check"></i><b>0.2</b> R and programming</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-r-fundamentals.html"><a href="part-i-r-fundamentals.html"><i class="fa fa-check"></i>Part I: R fundamentals</a></li>
<li class="chapter" data-level="1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html"><i class="fa fa-check"></i><b>1</b> Organization – R Projects and R Notebooks</a><ul>
<li class="chapter" data-level="1.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#importing-packages"><i class="fa fa-check"></i><b>1.1</b> Importing Packages</a></li>
<li class="chapter" data-level="1.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-studio-project-for-this-class"><i class="fa fa-check"></i><b>1.2</b> Create an R Studio Project for this Class</a></li>
<li class="chapter" data-level="1.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-notebooks"><i class="fa fa-check"></i><b>1.3</b> R Notebooks</a><ul>
<li class="chapter" data-level="1.3.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-notebook-for-this-chapter"><i class="fa fa-check"></i><b>1.3.1</b> Create an R Notebook for this Chapter</a></li>
<li class="chapter" data-level="1.3.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-load-packages-chunk"><i class="fa fa-check"></i><b>1.3.2</b> Create a “load-packages” chunk</a></li>
<li class="chapter" data-level="1.3.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-simple-plot-chunk"><i class="fa fa-check"></i><b>1.3.3</b> Create a “simple plot” chunk</a></li>
<li class="chapter" data-level="1.3.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-more-r-chunks-and-explore-options-and-play-with-r-code"><i class="fa fa-check"></i><b>1.3.4</b> Create more R chunks and explore options and play with R code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html"><i class="fa fa-check"></i><b>2</b> Data – Importing and Saving Data</a><ul>
<li class="chapter" data-level="2.1" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html#create-new-notebook-for-this-chapter"><i class="fa fa-check"></i><b>2.1</b> Create new notebook for this chapter</a></li>
<li class="chapter" data-level="2.2" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html#importing-data"><i class="fa fa-check"></i><b>2.2</b> Importing Data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html#excel-file"><i class="fa fa-check"></i><b>2.2.1</b> Excel File</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html#text-file"><i class="fa fa-check"></i><b>2.2.2</b> Text File</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html#saving-data"><i class="fa fa-check"></i><b>2.3</b> Saving Data</a></li>
<li class="chapter" data-level="2.4" data-path="data-importing-and-saving-data.html"><a href="data-importing-and-saving-data.html#problems"><i class="fa fa-check"></i><b>2.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-some-fundamentals-of-statistical-modeling.html"><a href="part-ii-some-fundamentals-of-statistical-modeling.html"><i class="fa fa-check"></i>Part II: Some Fundamentals of Statistical Modeling</a></li>
<li class="chapter" data-level="3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html"><i class="fa fa-check"></i><b>3</b> An Introduction to Statistical Modeling</a><ul>
<li class="chapter" data-level="3.1" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#two-specifications-of-a-linear-model"><i class="fa fa-check"></i><b>3.1</b> Two specifications of a linear model</a><ul>
<li class="chapter" data-level="3.1.1" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#the-error-draw-specification"><i class="fa fa-check"></i><b>3.1.1</b> The “error draw” specification</a></li>
<li class="chapter" data-level="3.1.2" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#the-conditional-draw-specification"><i class="fa fa-check"></i><b>3.1.2</b> The “conditional draw” specification</a></li>
<li class="chapter" data-level="3.1.3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#comparing-the-two-ways-of-specifying-the-linear-model"><i class="fa fa-check"></i><b>3.1.3</b> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#what-do-we-call-the-x-and-y-variables"><i class="fa fa-check"></i><b>3.2</b> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li class="chapter" data-level="3.3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>3.3</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="3.4" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#modeling-strategy"><i class="fa fa-check"></i><b>3.4</b> Modeling strategy</a></li>
<li class="chapter" data-level="3.5" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#a-mean-is-the-simplest-model"><i class="fa fa-check"></i><b>3.5</b> A mean is the simplest model</a></li>
<li class="chapter" data-level="3.6" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>3.6</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="3.7" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>3.7</b> Specific assumptions for inference with a linear model</a></li>
<li class="chapter" data-level="3.8" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#statistical-model-or-regression-model"><i class="fa fa-check"></i><b>3.8</b> “Statistical model” or “regression model”?</a></li>
<li class="chapter" data-level="3.9" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#glm-vs.glm-vs.gls"><i class="fa fa-check"></i><b>3.9</b> GLM vs. GLM vs. GLS</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><i class="fa fa-check"></i><b>4</b> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="chapter" data-level="4.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#the-sample-standard-deviation-vs.the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#sample-standard-deviation"><i class="fa fa-check"></i><b>4.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="4.1.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>4.2</b> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="4.2.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#steps"><i class="fa fa-check"></i><b>4.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>4.3</b> Using R to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="4.3.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-i"><i class="fa fa-check"></i><b>4.3.1</b> part I</a></li>
<li class="chapter" data-level="4.3.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-ii---means"><i class="fa fa-check"></i><b>4.3.2</b> part II - means</a></li>
<li class="chapter" data-level="4.3.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>4.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="4.3.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>4.3.4</b> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#bootstrapped-standard-errors"><i class="fa fa-check"></i><b>4.4</b> Bootstrapped standard errors</a></li>
<li class="chapter" data-level="4.5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#confidence-interval"><i class="fa fa-check"></i><b>4.5</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="covariance-and-correlation.html"><a href="covariance-and-correlation.html"><i class="fa fa-check"></i><b>5</b> Covariance and Correlation</a></li>
<li class="chapter" data-level="6" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>6</b> P-values</a><ul>
<li class="chapter" data-level="6.1" data-path="p-values.html"><a href="p-values.html#p-values-1"><i class="fa fa-check"></i><b>6.1</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="6.2" data-path="p-values.html"><a href="p-values.html#creating-a-null-distribution."><i class="fa fa-check"></i><b>6.2</b> Creating a null distribution.</a><ul>
<li class="chapter" data-level="6.2.1" data-path="p-values.html"><a href="p-values.html#the-null-distribution"><i class="fa fa-check"></i><b>6.2.1</b> the Null Distribution</a></li>
<li class="chapter" data-level="6.2.2" data-path="p-values.html"><a href="p-values.html#t-tests"><i class="fa fa-check"></i><b>6.2.2</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="6.2.3" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>6.2.3</b> P-values from the perspective of permutation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="p-values.html"><a href="p-values.html#statistical-modeling-instead-of-hypothesis-testing"><i class="fa fa-check"></i><b>6.3</b> Statistical modeling instead of hypothesis testing</a></li>
<li class="chapter" data-level="6.4" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>6.4</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="6.4.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>6.4.1</b> Background</a></li>
<li class="chapter" data-level="6.4.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>6.4.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <em>p</em>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="6.4.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>6.4.3</b> Two interpretations of the <em>p</em>-value</a></li>
<li class="chapter" data-level="6.4.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>6.4.4</b> NHST</a></li>
<li class="chapter" data-level="6.4.5" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>6.4.5</b> Some major misconceptions of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="6.4.6" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>6.4.6</b> Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="p-values.html"><a href="p-values.html#problems-1"><i class="fa fa-check"></i><b>6.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="creating-fake-data.html"><a href="creating-fake-data.html"><i class="fa fa-check"></i><b>7</b> Creating Fake Data</a><ul>
<li class="chapter" data-level="7.0.1" data-path="creating-fake-data.html"><a href="creating-fake-data.html#continuous-x-fake-observational-data"><i class="fa fa-check"></i><b>7.0.1</b> Continuous X (fake observational data)</a></li>
<li class="chapter" data-level="7.0.2" data-path="creating-fake-data.html"><a href="creating-fake-data.html#categorical-x-fake-experimental-data"><i class="fa fa-check"></i><b>7.0.2</b> Categorical X (fake experimental data)</a></li>
<li class="chapter" data-level="7.0.3" data-path="creating-fake-data.html"><a href="creating-fake-data.html#correlated-x-fake-observational-data"><i class="fa fa-check"></i><b>7.0.3</b> Correlated X (fake observational data)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-introduction-to-linear-models.html"><a href="part-iii-introduction-to-linear-models.html"><i class="fa fa-check"></i>Part III: Introduction to Linear Models</a></li>
<li class="chapter" data-level="8" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html"><i class="fa fa-check"></i><b>8</b> A linear model with a single, continuous <em>X</em></a><ul>
<li class="chapter" data-level="8.1" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><i class="fa fa-check"></i><b>8.1</b> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="8.1.1" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#using-a-linear-model-to-estimate-explanatory-effects"><i class="fa fa-check"></i><b>8.1.1</b> Using a linear model to estimate explanatory effects</a></li>
<li class="chapter" data-level="8.1.2" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#using-a-linear-model-for-prediction"><i class="fa fa-check"></i><b>8.1.2</b> Using a linear model for prediction</a></li>
<li class="chapter" data-level="8.1.3" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#reporting-results"><i class="fa fa-check"></i><b>8.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#working-in-r"><i class="fa fa-check"></i><b>8.2</b> Working in R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#exploring-the-bivariate-relationship-between-y-and-x"><i class="fa fa-check"></i><b>8.2.1</b> Exploring the bivariate relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>8.2.2</b> Fitting the linear model</a></li>
<li class="chapter" data-level="8.2.3" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>8.2.3</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="8.2.4" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#display-an-alternative-to-summary"><i class="fa fa-check"></i><b>8.2.4</b> display: An alternative to summary</a></li>
<li class="chapter" data-level="8.2.5" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#confidence-intervals"><i class="fa fa-check"></i><b>8.2.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="8.2.6" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>8.2.6</b> How good is our model?</a></li>
<li class="chapter" data-level="8.2.7" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#exploring-a-lm-object"><i class="fa fa-check"></i><b>8.2.7</b> exploring a lm object</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="a-linear-model-with-a-single-continuous-x.html"><a href="a-linear-model-with-a-single-continuous-x.html#problems-2"><i class="fa fa-check"></i><b>8.3</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>9</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="9.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-is-the-engine-behind-a-single-factor-one-way-anova-and-a-t-test-is-a-special-case-of-this-model."><i class="fa fa-check"></i><b>9.1</b> A linear model with a single, categorical <em>X</em> is the engine behind a single factor (one-way) ANOVA and a t-test is a special case of this model.</a><ul>
<li class="chapter" data-level="9.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#table-of-model-coefficients"><i class="fa fa-check"></i><b>9.1.1</b> Table of model coefficients</a></li>
<li class="chapter" data-level="9.1.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#the-linear-model"><i class="fa fa-check"></i><b>9.1.2</b> The linear model</a></li>
<li class="chapter" data-level="9.1.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#reporting-results-1"><i class="fa fa-check"></i><b>9.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#working-in-r-1"><i class="fa fa-check"></i><b>9.2</b> Working in R</a><ul>
<li class="chapter" data-level="9.2.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#exploring-the-relationship-between-y-and-x"><i class="fa fa-check"></i><b>9.2.1</b> Exploring the relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="9.2.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#fitting-the-model"><i class="fa fa-check"></i><b>9.2.2</b> Fitting the model</a></li>
<li class="chapter" data-level="9.2.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#an-introduction-to-contrasts"><i class="fa fa-check"></i><b>9.2.3</b> An introduction to contrasts</a></li>
<li class="chapter" data-level="9.2.4" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#harrell-plot"><i class="fa fa-check"></i><b>9.2.4</b> Harrell plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-checking-1.html"><a href="model-checking-1.html"><i class="fa fa-check"></i><b>10</b> Model Checking</a><ul>
<li class="chapter" data-level="10.1" data-path="model-checking-1.html"><a href="model-checking-1.html#do-coefficients-make-numeric-sense"><i class="fa fa-check"></i><b>10.1</b> Do coefficients make numeric sense?</a></li>
<li class="chapter" data-level="10.2" data-path="model-checking-1.html"><a href="model-checking-1.html#all-statistical-analyses-should-be-followed-by-model-checking"><i class="fa fa-check"></i><b>10.2</b> All statistical analyses should be followed by model checking</a></li>
<li class="chapter" data-level="10.3" data-path="model-checking-1.html"><a href="model-checking-1.html#linear-model-assumptions"><i class="fa fa-check"></i><b>10.3</b> Linear model assumptions</a></li>
<li class="chapter" data-level="10.4" data-path="model-checking-1.html"><a href="model-checking-1.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><i class="fa fa-check"></i><b>10.4</b> Diagnostic plots use the residuals from the model fit</a><ul>
<li class="chapter" data-level="10.4.1" data-path="model-checking-1.html"><a href="model-checking-1.html#residuals"><i class="fa fa-check"></i><b>10.4.1</b> Residuals</a></li>
<li class="chapter" data-level="10.4.2" data-path="model-checking-1.html"><a href="model-checking-1.html#a-normal-q-q-plot-is-used-to-check-normality"><i class="fa fa-check"></i><b>10.4.2</b> A Normal Q-Q plot is used to check normality</a></li>
<li class="chapter" data-level="10.4.3" data-path="model-checking-1.html"><a href="model-checking-1.html#outliers---an-outlier-is-a-point-that-is-highly-unexpected-given-the-modeled-distribution."><i class="fa fa-check"></i><b>10.4.3</b> Outliers - an outlier is a point that is highly unexpected given the modeled distribution.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="model-checking-1.html"><a href="model-checking-1.html#model-checking-homoskedasticity"><i class="fa fa-check"></i><b>10.5</b> Model checking homoskedasticity</a></li>
<li class="chapter" data-level="10.6" data-path="model-checking-1.html"><a href="model-checking-1.html#model-checking-independence---hapiness-adverse-example."><i class="fa fa-check"></i><b>10.6</b> Model checking independence - hapiness adverse example.</a></li>
<li class="chapter" data-level="10.7" data-path="model-checking-1.html"><a href="model-checking-1.html#using-r"><i class="fa fa-check"></i><b>10.7</b> Using R</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html"><i class="fa fa-check"></i><b>11</b> Model Fitting and Model Fit (OLS)</a><ul>
<li class="chapter" data-level="11.1" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#least-squares-estimation-and-the-decomposition-of-variance"><i class="fa fa-check"></i><b>11.1</b> Least Squares Estimation and the Decomposition of Variance</a></li>
<li class="chapter" data-level="11.2" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#ols-regression"><i class="fa fa-check"></i><b>11.2</b> OLS regression</a></li>
<li class="chapter" data-level="11.3" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>11.3</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="plotting-models.html"><a href="plotting-models.html"><i class="fa fa-check"></i><b>12</b> Plotting Models</a><ul>
<li class="chapter" data-level="12.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plots-show-the-model-and-the-data"><i class="fa fa-check"></i><b>12.1</b> Pretty good plots show the model and the data</a><ul>
<li class="chapter" data-level="12.1.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-1-modeled-effects-plot"><i class="fa fa-check"></i><b>12.1.1</b> Pretty good plot component 1: Modeled effects plot</a></li>
<li class="chapter" data-level="12.1.2" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot-with-jittered-raw-data"><i class="fa fa-check"></i><b>12.1.2</b> Pretty good plot component 2: Modeled mean and CI plot with jittered raw data</a></li>
<li class="chapter" data-level="12.1.3" data-path="plotting-models.html"><a href="plotting-models.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><i class="fa fa-check"></i><b>12.1.3</b> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="plotting-models.html"><a href="plotting-models.html#some-comments-on-plot-components"><i class="fa fa-check"></i><b>12.2</b> Some comments on plot components</a></li>
<li class="chapter" data-level="12.3" data-path="plotting-models.html"><a href="plotting-models.html#working-in-r-2"><i class="fa fa-check"></i><b>12.3</b> Working in R</a><ul>
<li class="chapter" data-level="12.3.1" data-path="plotting-models.html"><a href="plotting-models.html#unpooled-se-bars-and-confidence-intervals"><i class="fa fa-check"></i><b>12.3.1</b> Unpooled SE bars and confidence intervals</a></li>
<li class="chapter" data-level="12.3.2" data-path="plotting-models.html"><a href="plotting-models.html#adding-bootstrap-intervals"><i class="fa fa-check"></i><b>12.3.2</b> Adding bootstrap intervals</a></li>
<li class="chapter" data-level="12.3.3" data-path="plotting-models.html"><a href="plotting-models.html#adding-modeled-error-intervals"><i class="fa fa-check"></i><b>12.3.3</b> Adding modeled error intervals</a></li>
<li class="chapter" data-level="12.3.4" data-path="plotting-models.html"><a href="plotting-models.html#adding-p-values"><i class="fa fa-check"></i><b>12.3.4</b> Adding p-values</a></li>
<li class="chapter" data-level="12.3.5" data-path="plotting-models.html"><a href="plotting-models.html#adding-custom-p-values"><i class="fa fa-check"></i><b>12.3.5</b> Adding custom p-values</a></li>
<li class="chapter" data-level="12.3.6" data-path="plotting-models.html"><a href="plotting-models.html#plotting-two-factors"><i class="fa fa-check"></i><b>12.3.6</b> Plotting two factors</a></li>
</ul></li>
</ul></li>
<li><a href="part-iv-more-than-one-x-multivariable-models.html#part-iv-more-than-one-x-multivariable-models">Part IV: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="chapter" data-level="13" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html"><i class="fa fa-check"></i><b>13</b> Adding covariates to a linear model</a><ul>
<li class="chapter" data-level="13.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>13.1</b> Adding covariates can increases the precision of the effect of interest</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#interaction-effects-with-covariates"><i class="fa fa-check"></i><b>13.1.1</b> Interaction effects with covariates</a></li>
<li class="chapter" data-level="13.1.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#add-only-covariates-that-were-measured-before-peaking-at-the-data"><i class="fa fa-check"></i><b>13.1.2</b> Add only covariates that were measured before peaking at the data</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean"><i class="fa fa-check"></i><b>13.2</b> Regression to the mean</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>13.2.1</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="13.2.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>13.2.2</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>14</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="14.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>14.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="14.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>14.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="14.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>14.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="14.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>14.1.3</b> What about models with more than two factors?</a></li>
<li class="chapter" data-level="14.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>14.1.4</b> The additive model</a></li>
<li class="chapter" data-level="14.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts-simple-vs.main-effects"><i class="fa fa-check"></i><b>14.1.5</b> Contrasts – simple vs. main effects</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results-2"><i class="fa fa-check"></i><b>14.2</b> Reporting results</a><ul>
<li class="chapter" data-level="14.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>14.2.1</b> Text results</a></li>
<li class="chapter" data-level="14.2.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#harrellplot"><i class="fa fa-check"></i><b>14.2.2</b> Harrellplot</a></li>
<li class="chapter" data-level="14.2.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#interaction-plots"><i class="fa fa-check"></i><b>14.2.3</b> Interaction plots</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#recommendations-1"><i class="fa fa-check"></i><b>14.3</b> Recommendations</a></li>
<li class="chapter" data-level="14.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-3"><i class="fa fa-check"></i><b>14.4</b> Working in R</a></li>
<li class="chapter" data-level="14.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-3"><i class="fa fa-check"></i><b>14.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>15</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="15.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>15.1</b> Summary of usage</a></li>
<li class="chapter" data-level="15.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>15.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="15.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>15.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="15.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>15.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="15.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>15.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="15.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>15.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>15.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="15.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>15.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="15.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>15.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="15.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>15.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-4"><i class="fa fa-check"></i><b>15.5</b> Working in R</a><ul>
<li class="chapter" data-level="15.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>15.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="15.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>15.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="predictive-models.html"><a href="predictive-models.html"><i class="fa fa-check"></i><b>16</b> Predictive Models</a><ul>
<li class="chapter" data-level="16.1" data-path="predictive-models.html"><a href="predictive-models.html#overfitting"><i class="fa fa-check"></i><b>16.1</b> Overfitting</a></li>
<li class="chapter" data-level="16.2" data-path="predictive-models.html"><a href="predictive-models.html#model-building-vs.variable-selection-vs.model-selection"><i class="fa fa-check"></i><b>16.2</b> Model building vs. Variable selection vs. Model selection</a><ul>
<li class="chapter" data-level="16.2.1" data-path="predictive-models.html"><a href="predictive-models.html#stepwise-regression"><i class="fa fa-check"></i><b>16.2.1</b> Stepwise regression</a></li>
<li class="chapter" data-level="16.2.2" data-path="predictive-models.html"><a href="predictive-models.html#cross-validation"><i class="fa fa-check"></i><b>16.2.2</b> Cross-validation</a></li>
<li class="chapter" data-level="16.2.3" data-path="predictive-models.html"><a href="predictive-models.html#penalization"><i class="fa fa-check"></i><b>16.2.3</b> Penalization</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="predictive-models.html"><a href="predictive-models.html#shrinkage"><i class="fa fa-check"></i><b>16.3</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><i class="fa fa-check"></i>Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="chapter" data-level="17" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>17</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="17.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>17.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="17.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>17.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="17.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy-1"><i class="fa fa-check"></i><b>17.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="17.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>17.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="17.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>17.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="17.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>17.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="17.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>17.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="17.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>17.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="17.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>17.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-5"><i class="fa fa-check"></i><b>17.3</b> Working in R</a></li>
<li class="chapter" data-level="17.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-4"><i class="fa fa-check"></i><b>17.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>18</b> Linear mixed models</a><ul>
<li class="chapter" data-level="18.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>18.1</b> Random effects</a></li>
<li class="chapter" data-level="18.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>18.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="18.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>18.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="18.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-block-effects"><i class="fa fa-check"></i><b>18.4</b> Visualizing block effects</a></li>
<li class="chapter" data-level="18.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-can-increase-precision-of-point-estimates"><i class="fa fa-check"></i><b>18.5</b> Linear mixed models can increase precision of point estimates</a></li>
<li class="chapter" data-level="18.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-used-to-avoid-pseudoreplication"><i class="fa fa-check"></i><b>18.6</b> Linear mixed models are used to avoid pseudoreplication</a></li>
<li class="chapter" data-level="18.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>18.7</b> Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="18.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-6"><i class="fa fa-check"></i><b>18.8</b> Working in R</a><ul>
<li class="chapter" data-level="18.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>18.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="18.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>18.9</b> Get your computer ready</a><ul>
<li class="chapter" data-level="18.9.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>18.9.1</b> Install R</a></li>
<li class="chapter" data-level="18.9.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>18.9.2</b> Install R Studio</a></li>
<li class="chapter" data-level="18.9.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#resources-for-installing-r-and-r-studio"><i class="fa fa-check"></i><b>18.9.3</b> Resources for installing R and R Studio</a></li>
<li class="chapter" data-level="18.9.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-latex"><i class="fa fa-check"></i><b>18.9.4</b> Install LaTeX</a></li>
</ul></li>
<li class="chapter" data-level="18.10" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning"><i class="fa fa-check"></i><b>18.10</b> Start learning</a><ul>
<li class="chapter" data-level="18.10.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-with-data-camp-introduction-to-r"><i class="fa fa-check"></i><b>18.10.1</b> Start with Data Camp Introduction to R</a></li>
<li class="chapter" data-level="18.10.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#then-move-to-introduction-to-r-studio"><i class="fa fa-check"></i><b>18.10.2</b> Then Move to Introduction to R Studio</a></li>
<li class="chapter" data-level="18.10.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#develop-your-project-with-an-r-studio-notebook"><i class="fa fa-check"></i><b>18.10.3</b> Develop your project with an R Studio Notebook</a></li>
</ul></li>
<li class="chapter" data-level="18.11" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#getting-data-into-r"><i class="fa fa-check"></i><b>18.11</b> Getting Data into R</a></li>
<li class="chapter" data-level="18.12" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#additional-r-learning-resources"><i class="fa fa-check"></i><b>18.12</b> Additional R learning resources</a></li>
<li class="chapter" data-level="18.13" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#packages-used-extensively-in-this-text"><i class="fa fa-check"></i><b>18.13</b> Packages used extensively in this text</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elementary Statistical Modeling for Applied Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="an-introduction-to-statistical-modeling" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> An Introduction to Statistical Modeling</h1>
<p>This chapter introduces statistical modeling using the <strong>linear model</strong>. All students are familiar with the idea of a linear model from learning the equation of a line, which is</p>
<span class="math display" id="eq:line">\[\begin{equation}
Y = mX + b
\tag{3.1}
\end{equation}\]</span>
<p>where <span class="math inline">\(m\)</span> is the slope of the line and <span class="math inline">\(b\)</span> is the <span class="math inline">\(Y\)</span>-intercept. It is useful to think of equation <a href="an-introduction-to-statistical-modeling.html#eq:line">(3.1)</a> as a function that maps values of <span class="math inline">\(X\)</span> to values of <span class="math inline">\(Y\)</span>. Using this function, if we input some value of <span class="math inline">\(X\)</span>, we always get the same value of Y as the output.</p>
<p>A linear model is a function, like that in equation <a href="an-introduction-to-statistical-modeling.html#eq:line">(3.1)</a>, that is fit to a set of data, often to model a process that generated the data or something like the data. The line in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">3.1</a>A is just that, a line, but the line in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">3.1</a>B is a linear model fit to the data in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">3.1</a>B.</p>
<div class="figure"><span id="fig:line"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/line-1.png" alt="A line vs. a linear model. (A) the line $y=-3.48X + 105.7$ is drawn. (B) A linear model fit to the data. The model coefficients are numerically equal to the slope and intercept of the line in A." width="576" />
<p class="caption">
Figure 3.1: A line vs. a linear model. (A) the line <span class="math inline">\(y=-3.48X + 105.7\)</span> is drawn. (B) A linear model fit to the data. The model coefficients are numerically equal to the slope and intercept of the line in A.
</p>
</div>
<div id="two-specifications-of-a-linear-model" class="section level2">
<h2><span class="header-section-number">3.1</span> Two specifications of a linear model</h2>
<div id="the-error-draw-specification" class="section level3">
<h3><span class="header-section-number">3.1.1</span> The “error draw” specification</h3>
<p>A linear model is commonly specified using</p>
<span class="math display" id="eq:lm">\[\begin{align}
Y &amp;= \beta_0 + \beta_1 X + \varepsilon\\
\tag{3.2}
\end{align}\]</span>
<p>This specification of a linear model has two parts: the <strong>linear predictor</strong> <span class="math inline">\(Y = \beta_0 + \beta_1 X\)</span> and the <strong>error</strong> <span class="math inline">\(\varepsilon\)</span>. The linear predictor part looks like the equation for a line except that 1) <span class="math inline">\(\beta_0\)</span> is used for the intercept and <span class="math inline">\(\beta_1\)</span> for the slope and 2) the intercept term precedes the slope term. This re-labeling and re-arrangement make the notation for a linear model more flexible for more complicated linear models. For example <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \varepsilon\)</span> is a model where <span class="math inline">\(Y\)</span> is a function of two <span class="math inline">\(X\)</span> variables.</p>
<p>As with the equation for a line, the linear predictor part of a linear model is a function that maps a specific value of <span class="math inline">\(X\)</span> to a value of <span class="math inline">\(Y\)</span>. This mapped value is the <strong>expected value</strong> given a specific input value of <span class="math inline">\(X\)</span>. This is often written as <span class="math inline">\(\mathrm{E}[Y|X]\)</span>, which is read as “the expected value of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>”, where “given X” means a specific value of X. Importantly, <span class="math inline">\(\mathrm{E}[Y|X]\)</span> is the <strong>conditional mean</strong>, which is the <em>modeled</em> value of <span class="math inline">\(Y\)</span> for all observations in which <span class="math inline">\(X\)</span> takes some specific value <span class="math inline">\(x\)</span>.</p>
Introductory textbooks almost always introduce linear models using equation <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a> above. The key part of the model that is missing from the specification above is a second line
<span class="math display">\[\begin{equation}
\varepsilon \sim N(0, \sigma^2)
\end{equation}\]</span>
<p>which is read as “epsilon is distributed as Normal with mean zero and variance sigma squared”. This line explicitly specifies the distribution of the error part. The error part of a linear model is a random “draw” from a normal distribution with mean zero and variance <span class="math inline">\(\sigma^2\)</span>. Think of this as adding some random value to the expected value.</p>
</div>
<div id="the-conditional-draw-specification" class="section level3">
<h3><span class="header-section-number">3.1.2</span> The “conditional draw” specification</h3>
<p>A second way of specifying a linear model is</p>
<span class="math display" id="eq:lm-spec2">\[\begin{align}
y_i &amp;\sim N(\mu_i, \sigma^2)\\
\mathrm{E}(Y|X) &amp;= \mu\\
\mu_i &amp;= \beta_0 + \beta_1 x_i
\tag{3.3}
\end{align}\]</span>
<p>The first line states that the response variable <span class="math inline">\(Y\)</span> is a random variable independently drawn from a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. This first line is the <strong>stochastic</strong> part of the statistical model. The second line simply states that <span class="math inline">\(\mu\)</span> (the greek letter “mu”) from the first line is the conditional mean or conditional expectation. The third line states how <span class="math inline">\(\mu_i\)</span> is generated given that <span class="math inline">\(X=x_i\)</span>. This is the linear predictor, which is the <strong>systematic</strong> (or deterministic) part of the statistical model. It is systematic because the same value of <span class="math inline">\(x_i\)</span> will always generate the same <span class="math inline">\(\mu_i\)</span>.</p>
</div>
<div id="comparing-the-two-ways-of-specifying-the-linear-model" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Comparing the two ways of specifying the linear model</h3>
<p>These two ways of specifying the model encourage slightly different ways of thinking about how the data (the response varible <span class="math inline">\(Y\)</span>) were generated. The error draw specification “generates” data by randomly drawing some error <span class="math inline">\(\varepsilon_i\)</span> from the specified distribution and adding this to <span class="math inline">\(x_i\)</span>. The conditional draw specification “generates” data by constructing what <span class="math inline">\(y_i\)</span> “should be” given <span class="math inline">\(x_i\)</span> (the conditional expection), and then drawing a random variable from a distribution with this expectation. This random draw is <span class="math inline">\(y_i\)</span> and not the “error”. For the error draw generation, we need only one hat of random numbers, but for the conditional draw generation, we need a hat for each value of <span class="math inline">\(x_i\)</span>.</p>
<p>The conditional draw specification explicitly defines all parameters, including the parameters of the linear predictor (<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>), the conditional mean <span class="math inline">\(\mu\)</span> and the variance <span class="math inline">\(\sigma^2\)</span>. The error draw specification only defines the parameters of the linear predictor, and often these are referrred to as “the parameters” in the sense that there are not other parameters. The error draw specification is most useful for thinking about model checking a fit linear model. The random draw specification is more generally useful in that it is easily generalized to more complex models, including hierarchical models, generalized linear models, and Bayesian models. In fact, <em>thinking about a model as a predictor plus error can lead to the misconception that in a generalized linear models, the error has the distribution (binomial, poisson, etc.) modeled</em>.</p>
<p>Although a linear model (or statistical model more generally) is a model of a data-generating process, linear models are not typically used to actually generate any data. Instead, when we use a linear model to understand something about a real dataset, we think of our data as one realization of a process that generates data like ours. A linear model is a model of that process. That said, it is incredibly useful to use linear models to create fake datasets for at least two reasons: to probe our understanding of statistical modeling generally and, more specifically, to check that a model actually creates data like that in the real dataset that we are analyzing.</p>
</div>
</div>
<div id="what-do-we-call-the-x-and-y-variables" class="section level2">
<h2><span class="header-section-number">3.2</span> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</h2>
<p>The inputs to a linear model (the <span class="math inline">\(X\)</span> variables) have many names including “independent variables,” “predictor variables,”, “explanatory variables,” “treatment variables,” and “covariates”. The output of a linear model (the <span class="math inline">\(Y\)</span> variable or variables if the model is multivariate) is the “dependent variable,” “response,” or “outcome.” The <span class="math inline">\(\beta\)</span> in the linear model are model <strong>parameters</strong> and if a parameter is multiplied by an <span class="math inline">\(X\)</span> variable then it is also a <strong>coefficient</strong> (for example, <span class="math inline">\(\beta_1\)</span> in model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a> is a coefficient). The coefficients of the <span class="math inline">\(X\)</span> in a linear model (<span class="math inline">\(\beta_1\)</span> in model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a>) are often called “the effects” (so <span class="math inline">\(\beta_1\)</span> is the effect of <span class="math inline">\(X_1\)</span>).</p>
</div>
<div id="statistical-models-are-used-for-prediction-explanation-and-description" class="section level2">
<h2><span class="header-section-number">3.3</span> Statistical models are used for prediction, explanation, and description</h2>
<p>Researchers typically use statistical models to understand relationships between one or more <span class="math inline">\(Y\)</span> variables and one or more <span class="math inline">\(X\)</span> variables. These relationships include</p>
<ol style="list-style-type: decimal">
<li><p>Descriptive modeling. Sometimes a researcher merely wants to describe the relationship between <span class="math inline">\(Y\)</span> and a set of <span class="math inline">\(X\)</span> variables, perhaps to discover patterns. For example, the arrival of a spring migrant bird (<span class="math inline">\(Y\)</span>) as a function of sex (<span class="math inline">\(X_1\)</span>) and age (<span class="math inline">\(X_2\)</span>) might show that males and younger individuals arrive earlier. Importantly, if another <span class="math inline">\(X\)</span> variable is added to the model (or one dropped), the coefficients, and therefore, the precise description, will change. That is, the interpretation of a coefficient as a descriptor is <em>conditional</em> on the other covariates (<span class="math inline">\(X\)</span> variables) in the model. In a descriptive model, there is no implication of causal effects and the goal is not prediction. Nevertheless, it is very hard for humans to discuss a descriptive model without using causal language, which probably means that it is hard for us to think of these models as <em>mere description</em>. Like natural history, descriptive models are useful as patterns in want of an explanation, using more explicit causal models including experiments.</p></li>
<li><p>Predictive modeling. Predictive modeling is very common in applied research. For example, fisheries researchers might model the relationship between population density and habitat variables to predict which subset of ponds in a region are most suitable for brook trout (<em>Salvelinus fontinalis</em>) reintroduction. The goal is to build a model with minimal prediction error, which is the error between predicted and actual values for a future sample. In predictive modeling, the <span class="math inline">\(X\)</span> (“predictor”) variables are largely instrumental – how these are related to <span class="math inline">\(Y\)</span> is not a goal of the modeling, although sometimes an investigator may be interested in the relative importance among the <span class="math inline">\(X\)</span> for predicting <span class="math inline">\(Y\)</span> (for example, collecting the data may be time consuming, or expensive, or enviromentally destructive, so know which subset of <span class="math inline">\(X\)</span> are most important for predicting <span class="math inline">\(Y\)</span> is a useful strategy).</p></li>
<li><p>Explanatory (causal) modeling. Very often, researchers are explicitly interested in <em>how</em> the <span class="math inline">\(X\)</span> variables are causally related to <span class="math inline">\(Y\)</span>. The fisheries researchers that want to reintroduce trout may want to develop and manage a set of ponds to maintain healthy trout populations. This active management requires intervention to change habitat traits in a direction, and with a magnitude, to cause the desired response. This model is predictive – a specific change in <span class="math inline">\(X\)</span> predicts a specific response in <span class="math inline">\(Y\)</span> – because the coefficients of the model provide knowledge on how the system functions – how changes in the inputs <em>cause</em> change in the output. Causal interpretation of model coefficients requires a set of strong assumptions about the <span class="math inline">\(X\)</span> variables in the model. These assumptions are typically met in <strong>experimental designs</strong> but not <strong>observational designs</strong>.</p></li>
</ol>
<p>With observational designs, biologists are often not very explicit about which of these is the goal of the modeling and use a combination of descriptive, predictive, and causal language to describe and discuss results. Many papers read as if the researchers intend explanatory inference but because of norms within the biology community, mask this intention with “predictive” language. Here, I advocate embracing explicit, explanatory modeling by being very transparent about the model’s goal and assumptions.</p>
</div>
<div id="modeling-strategy" class="section level2">
<h2><span class="header-section-number">3.4</span> Modeling strategy</h2>
<ol style="list-style-type: decimal">
<li><p><strong>choose a model</strong>. Statistical modeling includes a diverse array of models, yet almost all methods used by researchers in biology, and all models in this book, are generalizations of the linear model specified in <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(3.3)</a>.</p></li>
<li><p><strong>fit the model</strong>, in order to estimate the model parameters and the uncertainty in these estimates.</p></li>
<li><p><strong>check the model</strong>, which means to use a series of diagnostic plots and computations of model output to check that the data reasonably approximate the chosen model.</p></li>
<li><p><strong>inference from the model</strong>, which means to use the fit parameters to learn, with uncertainty, about the system, or to predict future observations, with uncertainty.</p></li>
<li><p><strong>plot the model</strong>, which means to plot the estimated parameters (or other results dervived from the estimates) with their uncertainty.</p></li>
</ol>
<p>In order to use a statistical model to describe, predict, or explain, we need to fit a model to data in order to estimate the parameters. A linear model fit to some data is</p>
<span class="math display" id="eq:yhat">\[\begin{align}
\hat{y}_i &amp;= b_0 + b_1 x_i + e_i\\
\tag{3.4}
\end{align}\]</span>
<p><span class="math inline">\(\hat{y}_i\)</span> (“y hat”) is the <strong>predicted value</strong> of individual <span class="math inline">\(i\)</span>, <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are the coefficients of the model fit (though technically <span class="math inline">\(b_0\)</span> is not a coefficient), and <span class="math inline">\(e_i\)</span> is the residual. Sometimes <span class="math inline">\(\hat{y}_i\)</span> is simply called “the prediction”.</p>
<p>If our goal is inference – to infer something about the “population” from the sample using the fit model, then <span class="math inline">\(\hat{y}_i\)</span> is the <strong>point estimate</strong> of the parameter <span class="math inline">\(\mu_i\)</span>, the coefficients <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are point estimates of the parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, and the standard deviation of the <span class="math inline">\(e_i\)</span> is an estimate of <span class="math inline">\(\sigma\)</span>. “Population” is in quotes because it is a very abstract concept. Throughout this book, Greek letters refer to a theoretical parameter and Roman letters refer to point estimates.</p>
<p>Throughout this text, I recommend reporting and interpreting <strong>interval estimates</strong> of the point estimate. A <strong>confidence interval</strong> is a type of interval estimate. A confidence interval of a parameter is a measure of the uncertainty in the estimate. A 95% confidence interval has a 95% probability (in the sense of long-run frequency) of containing the parameter This probability is a property of the population of intervals that could be computed using the same sampling and measuring procedure. It is not correct, without further assumptions, to state that there is a 95% probability that the parameter lies within the interval. Perhaps a more useful interpretation is that the interval is a <strong>compatability interval</strong> in that it contains the range of estimates that are compatible with the data, in the sense that a <span class="math inline">\(t\)</span>-test would not reject the null hypothesis of a difference between the estimate and any value within the interval (this interpretation does not imply anything about the true value).</p>
<div class="figure"><span id="fig:coldVoles"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/coldVoles-1.png" alt="HarrellPlot of vole data." width="576" />
<p class="caption">
Figure 3.2: HarrellPlot of vole data.
</p>
</div>
<p>For the model fit to the data in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">3.1</a>B, the coefficient of <span class="math inline">\(X\)</span> is the slope of the line. Perhaps surprisingly, we can fit a model like equation <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a> to data in which the <span class="math inline">\(X\)</span> variable is categorical. A simple example is the experiment of antioxidants (vitamins C and E) on lifespan in Voles (Fig. <a href="an-introduction-to-statistical-modeling.html#fig:coldVoles">3.2</a>). In this experiment, the <span class="math inline">\(X\)</span> variable is categorical, with three <strong>levels</strong>: “Control”, “Vitamin_E” and “Vitamin_C”. Categorical <span class="math inline">\(X\)</span> variables are often called <strong>factors</strong>. The trick to using a statistical model with categorical <span class="math inline">\(X\)</span> is to recode the factor levels into numbers – how this is done is explained in Chapter xxx. When the <span class="math inline">\(X\)</span> variable is categorical, the coefficients of the <span class="math inline">\(X\)</span> are <em>differences in group means</em>. The linear model fit to the vole data has two coefficients, one for Vitamin E and one for vitamin C. The estimate and uncertainty of the these two coefficients are shown in the top part of Figure <a href="an-introduction-to-statistical-modeling.html#fig:coldVoles">3.2</a>. The bottom part shows the raw data, as well as the group (factor level) means and the uncertainty in the estimate of these means.</p>
</div>
<div id="a-mean-is-the-simplest-model" class="section level2">
<h2><span class="header-section-number">3.5</span> A mean is the simplest model</h2>
<p>The simplest possible model that can be fit to the data is</p>
<span class="math display" id="eq:unconditional">\[\begin{equation}
\mathrm{E}[Y] = b_0
\tag{3.5}
\end{equation}\]</span>
<p>which is simply the mean of <span class="math inline">\(Y\)</span>, or, more specifically, the <strong>unconditional mean</strong> of <span class="math inline">\(Y\)</span>, since its value is not conditional on any value of <span class="math inline">\(X\)</span>.</p>
</div>
<div id="assumptions-for-inference-with-a-statistical-model" class="section level2">
<h2><span class="header-section-number">3.6</span> Assumptions for inference with a statistical model</h2>
<p><strong>Inference</strong> refers to using the fit model to generalize from the sample to the population, which assumes that the response is drawn from some specified probability distribution (Normal, or Poisson, or Bernouli, etc.). Throughout this text, I emphasize reporting and interpreting point estimates and confidence intervals. Another kind of inference is a <strong>significance test</strong>, which is the computation of the probability of “seeing the data” or something more extreme than the data, given a specified null hypothesis. A significance test results in a <strong>p-value</strong>, which can be reported with the point estimate and confidence interval. Somewhat related to a significance test is a hypothesis test, or what is now often perjoratively called a <strong>Null-Hypothesis Signficance Test</strong> (NHST), in which the <span class="math inline">\(p\)</span>-value from a significance test is compared to a pre-specified error rate called <span class="math inline">\(\alpha\)</span>. NHST may be useful for some very limited kinds of science but, in general, is not useful for most biological research and, instead, leads to large misconceptions. A general rule of thumb is, do not compare a reported <span class="math inline">\(p\)</span>-value to <span class="math inline">\(\alpha\)</span>.</p>
<ol style="list-style-type: decimal">
<li>The data were generated by a process that is “linear in the parameters”, which means that the different components of the model are added together. This additive part of the model containing the parameters is the linear predictor in specifications <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a> and <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(3.3)</a> above. For example, a cubic polynomial model</li>
</ol>
<span class="math display">\[\begin{equation}
\mathrm{E}(Y|X) = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3
\end{equation}\]</span>
<p>is a linear model, even though the function is non-linear, because the different components are added. Because a linear predictor is additive, it can be compactly defined using matrix algebra</p>
<span class="math display">\[\begin{equation}
\mathrm{E}(Y|X) = \mathbf{X}\boldsymbol{\beta}
\end{equation}\]</span>
<p>where <span class="math inline">\(mathbf{X}\)</span> is the <strong>model matrix</strong> and <span class="math inline">\(\boldsymbol{\beta}\)</span> is the vector of parameters. We discuss these more in chapter xxx.</p>
<p>A <strong>Generalized Linear Model</strong> (GLM) has the form <span class="math inline">\(g(\mu_i) = \eta_i\)</span> where <span class="math inline">\(\eta\)</span> (the Greek letter “eta”) is the linear predictor</p>
<span class="math display">\[\begin{equation}
\eta = \mathbf{X}\boldsymbol{\beta} 
\end{equation}\]</span>
<p>GLMs are extensions of linear models. There are non-linear models that are not linear in the parameters, that is, the predictor is not a simple dot product of the model matrix and a vector of parameters. For example, the Michaelis-Menten model is a non-linear model</p>
<span class="math display">\[\begin{equation}
\mathrm{E}(Y|X)  = \frac{\beta_1 X}{\beta_2 + X}
\end{equation}\]</span>
<p>that is non-linear in the parameters because the parts are not added together. This text covers linear models and generalized linear models, but not non-linear models that are also non-linear in the parameters.</p>
<ol start="2" style="list-style-type: decimal">
<li>The draws from the probability distribution are <strong>independent</strong>. Independence implies <strong>uncorrelated</strong> observations (the <span class="math inline">\(Y\)</span>), that is, for any two observations with the same value of <span class="math inline">\(X\)</span>, we cannot predict the value of one given the value of the other. For example, in the vole data above, uncorrelated implies that we cannot predict the lifespan of one vole within the Vitamin E treatment given the lifespan of another vole in the Vitamin E treatment. For linear models, this assumption is often stated as “independent errors” (the <span class="math inline">\(\varepsilon\)</span> in model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a>) instead of independent observations.</li>
</ol>
<p>There are lots of reasons that observations might be correlated. In the vole example, perhaps the voles were housed in batches of 5 individuals, and slight differences in the environment among the housing containers, caused all the voles in some containers to have shorter lifespans than expected given their treatment assigment and all voles in other containers to have longer lifespans than expected given their treatment assigment. More generally, if there are measures both within and among experimental units (field sites or humans or rats) then we’d expect the measures within the same unit to err from the model in the same direction. Multiple measures within experimental units (a site or individual) creates “clustered” observations. Lack of independence or clustered observations can be modeled using models with <strong>random effects</strong>. These models go by many names including linear mixed models (common in Ecology), hierarchical models, multilevel models, and random effects models. A linear mixed model is a variation of model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a>. This text introduces linear mixed models in chapter xxx.</p>
<p>Measures that are taken from sites that are closer together or measures taken closer in time or measures from more closely related biological species will tend to have more similar values than measures taken from sites that are further apart or from times that are further apart or from species that are less closely related. Space and time and phylogeny create <strong>spatial and temporal and phylogenetic autocorrelation</strong>. Correlated error due to space or time or phylogeny can be modeled with <strong>Generalized Least Squares</strong> (GLS) models. A GLS model is a variation of model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a>.</p>
</div>
<div id="specific-assumptions-for-inference-with-a-linear-model" class="section level2">
<h2><span class="header-section-number">3.7</span> Specific assumptions for inference with a linear model</h2>
<ol style="list-style-type: decimal">
<li><strong>Constant variance</strong> or <strong>homoskedasticity</strong>. The most common way of thinking about this is the error term <span class="math inline">\(\varepsilon\)</span> has constant variance, which is a short way of saying that random draws of <span class="math inline">\(\varepsilon\)</span> in model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a> are all from the same (or <strong>identical</strong>) distribution. This is explicitly stated in the second line of model specification <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a>. If we were to think about this using model specification <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(3.3)</a>, then homoskedasticity means that <span class="math inline">\(\sigma\)</span> in <span class="math inline">\(N(\mu, \sigma)\)</span> is constant for all observations (or that the <em>conditional</em> probability distributions are identical, where <em>conditional</em> would mean adjusted for <span class="math inline">\(\mu\)</span>)</li>
</ol>
<p>Many biological processes generate data in which the error is a function of the mean. For example, measures of biological variables that grow, such as lengths of body parts or population size, have variances that “grow” with the mean. Or, measures of counts, such as the number of cells damaged by toxin, the number of eggs in a nest, or the number of mRNA transcripts per cell have variances that are a function of the mean. Heteroskedastic error can be modeled with <strong>Generalized Least Squares</strong>, a generalization of the linear model, and with <strong>Generalized Linear Models</strong> (GLM), which are “extensions” of the classical linear model.</p>
<ol start="2" style="list-style-type: decimal">
<li>Normal or <strong>Gaussian</strong> probability distribution. As above, the most common way of thinking about this is the error term <span class="math inline">\(\varepsilon\)</span> is Normal. Using model specification <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(3.3)</a>, we’d say the conditional probablity distribution of the response is normal. A normal probability distribution implies that 1) the response is continuous and 2) the conditional probability is symmetric around <span class="math inline">\(mu_i\)</span>. If the conditional probability distribution has a long left or right tail it is <strong>skewed</strong> left or right. Counts (number of cells, number of eggs, number of mRNA transcripts) and binary responses (sucessful escape or sucessful infestation of host) are not continuous and often often have asymmetric probablity distributions that are skewed to the right and while sometimes both can be reasonably modeled using a linear model they are more often modeled using generalized linear models, which, again, is an extension of the linear model in equation <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(3.3)</a>.</li>
</ol>
<p>A common misconception is that inference from a linear model assumes that the <em>response</em> (<span class="math inline">\(Y\)</span>) is normally distributed. Both the “linear model” and “statistical model” ways of specifying the model show precisely why this conception is wrong. Model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(3.2)</a> states explicitly that it is the error that has the normal distribution – the distribution of <span class="math inline">\(Y\)</span> is a mix of the distribution of <span class="math inline">\(X\)</span> and the error. Model <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(3.3)</a> states that the conditional outcome has a normal distribution, that is, the distribution after adjusting for variation in <span class="math inline">\(X\)</span>.</p>
</div>
<div id="statistical-model-or-regression-model" class="section level2">
<h2><span class="header-section-number">3.8</span> “Statistical model” or “regression model”?</h2>
<p>Statistical modeling terminology can be confusing. The <span class="math inline">\(X\)</span> variables in a statistical model may be quantitative (continuous or integers) or categorical (names or qualitative amounts) or some mix of the two. Linear models with all quantitative independent variables are often called “regression models.” Linear models with all categorical independent variables are often called “ANOVA models.” Linear models with a mix of quantitative and categorical variables are often called “ANCOVA models” if the focus is on one of the categorical <span class="math inline">\(X\)</span> or “regression models” if there tend to be many independent variables. Other patterns occur. For example “ANCOVA models” often include interaction effects but “regression models” rarely do. To avoid thinking of statistical analysis as “regression vs. ANOVA” (the type of thinking encouraged by many textbooks in biostatistics), I will most often use the term “statistical model” for general usage, and use a more specific term only to emphasize something about the model in that particluar context.</p>
</div>
<div id="glm-vs.glm-vs.gls" class="section level2">
<h2><span class="header-section-number">3.9</span> GLM vs. GLM vs. GLS</h2>
<p>Linear models are sometimes called “general linear models” with the abbreviation GLM. This is unfortunate because the abbreviation GLM usually refers to <strong>generalized linear models</strong>. Regardless, don’t confuse either version of GLM with GLS, which is the abbreviation of <strong>generalized least squares</strong>. GLS generalizes the linear model to allow for heteroskedastic and/or correlated error (using the “linear model” way of thinking about model specification)</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="part-ii-some-fundamentals-of-statistical-modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/12-introduction-to-statistical-modeling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
