<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 An Introduction to Statistical Modeling | Elements of Statistical Modeling for Experimental Biology</title>
  <meta name="description" content="A first course in statistical modeling for experimental biology researchers" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 An Introduction to Statistical Modeling | Elements of Statistical Modeling for Experimental Biology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for experimental biology researchers" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 An Introduction to Statistical Modeling | Elements of Statistical Modeling for Experimental Biology" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for experimental biology researchers" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="part-iii-introduction-to-linear-models.html"/>
<link rel="next" href="models-with-a-single-continuous-x.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#math"><i class="fa fa-check"></i><b>0.1</b> Math</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#r-and-programming"><i class="fa fa-check"></i><b>0.2</b> R and programming</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="a-completed-r-markdown-document.html"><a href="a-completed-r-markdown-document.html"><i class="fa fa-check"></i>A completed R Markdown document</a></li>
<li class="chapter" data-level="1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><i class="fa fa-check"></i><b>1</b> Analysis for Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a><ul>
<li class="chapter" data-level="1.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#useful-functions"><i class="fa fa-check"></i><b>1.1</b> useful functions</a></li>
<li class="chapter" data-level="1.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-effect-of-ask1-ko-on-growth-body-weight"><i class="fa fa-check"></i><b>1.2</b> figure 2b – effect of ASK1 KO on growth (body weight)</a><ul>
<li class="chapter" data-level="1.2.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-import"><i class="fa fa-check"></i><b>1.2.1</b> figure 2b – import</a></li>
<li class="chapter" data-level="1.2.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-exploratory-plots"><i class="fa fa-check"></i><b>1.2.2</b> figure 2b – exploratory plots</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-effect-of-ask1-ko-on-final-body-weight"><i class="fa fa-check"></i><b>1.3</b> Figure 2c – Effect of ASK1 KO on final body weight</a><ul>
<li class="chapter" data-level="1.3.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-import"><i class="fa fa-check"></i><b>1.3.1</b> Figure 2c – import</a></li>
<li class="chapter" data-level="1.3.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-own-computation-of-weight-change-v-imported-value"><i class="fa fa-check"></i><b>1.3.2</b> Figure 2c – check own computation of weight change v imported value</a></li>
<li class="chapter" data-level="1.3.3" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-exploratory-plots"><i class="fa fa-check"></i><b>1.3.3</b> Figure 2c – exploratory plots</a></li>
<li class="chapter" data-level="1.3.4" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-fit-the-model-m1-lm"><i class="fa fa-check"></i><b>1.3.4</b> Figure 2c – fit the model: m1 (lm)</a></li>
<li class="chapter" data-level="1.3.5" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-the-model-m1"><i class="fa fa-check"></i><b>1.3.5</b> Figure 2c – check the model: m1</a></li>
<li class="chapter" data-level="1.3.6" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-fit-the-model-m2-gamma-glm"><i class="fa fa-check"></i><b>1.3.6</b> Figure 2c – fit the model: m2 (gamma glm)</a></li>
<li class="chapter" data-level="1.3.7" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-the-model-m2"><i class="fa fa-check"></i><b>1.3.7</b> Figure 2c – check the model, m2</a></li>
<li class="chapter" data-level="1.3.8" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-inference-from-the-model"><i class="fa fa-check"></i><b>1.3.8</b> Figure 2c – inference from the model</a></li>
<li class="chapter" data-level="1.3.9" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-plot-the-model"><i class="fa fa-check"></i><b>1.3.9</b> Figure 2c – plot the model</a></li>
<li class="chapter" data-level="1.3.10" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-report"><i class="fa fa-check"></i><b>1.3.10</b> Figure 2c – report</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve"><i class="fa fa-check"></i><b>1.4</b> Figure 2d – Effect of ASK1 KO on glucose tolerance (whole curve)</a><ul>
<li class="chapter" data-level="1.4.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-import"><i class="fa fa-check"></i><b>1.4.1</b> Figure 2d – Import</a></li>
<li class="chapter" data-level="1.4.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-exploratory-plots"><i class="fa fa-check"></i><b>1.4.2</b> Figure 2d – exploratory plots</a></li>
<li class="chapter" data-level="1.4.3" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-fit-the-model"><i class="fa fa-check"></i><b>1.4.3</b> Figure 2d – fit the model</a></li>
<li class="chapter" data-level="1.4.4" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-check-the-model"><i class="fa fa-check"></i><b>1.4.4</b> Figure 2d – check the model</a></li>
<li class="chapter" data-level="1.4.5" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-inference"><i class="fa fa-check"></i><b>1.4.5</b> Figure 2d – inference</a></li>
<li class="chapter" data-level="1.4.6" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-plot-the-model"><i class="fa fa-check"></i><b>1.4.6</b> Figure 2d – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-effect-of-ask1-ko-on-glucose-tolerance-summary-measure"><i class="fa fa-check"></i><b>1.5</b> Figure 2e – Effect of ASK1 KO on glucose tolerance (summary measure)</a><ul>
<li class="chapter" data-level="1.5.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-message-the-data"><i class="fa fa-check"></i><b>1.5.1</b> Figure 2e – message the data</a></li>
<li class="chapter" data-level="1.5.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-exploratory-plots"><i class="fa fa-check"></i><b>1.5.2</b> Figure 2e – exploratory plots</a></li>
<li class="chapter" data-level="1.5.3" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-fit-the-model"><i class="fa fa-check"></i><b>1.5.3</b> Figure 2e – fit the model</a></li>
<li class="chapter" data-level="1.5.4" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-check-the-model"><i class="fa fa-check"></i><b>1.5.4</b> Figure 2e – check the model</a></li>
<li class="chapter" data-level="1.5.5" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-inference-from-the-model"><i class="fa fa-check"></i><b>1.5.5</b> Figure 2e – inference from the model</a></li>
<li class="chapter" data-level="1.5.6" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-plot-the-model"><i class="fa fa-check"></i><b>1.5.6</b> Figure 2e – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-effect-of-ask1-on-glucose-infusion-rate"><i class="fa fa-check"></i><b>1.6</b> Figure 2f – Effect of ASK1 on glucose infusion rate</a><ul>
<li class="chapter" data-level="1.6.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-import"><i class="fa fa-check"></i><b>1.6.1</b> Figure 2f – import</a></li>
<li class="chapter" data-level="1.6.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-exploratory-plots"><i class="fa fa-check"></i><b>1.6.2</b> Figure 2f – exploratory plots</a></li>
<li class="chapter" data-level="1.6.3" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-fit-the-model"><i class="fa fa-check"></i><b>1.6.3</b> Figure 2f – fit the model</a></li>
<li class="chapter" data-level="1.6.4" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-check-the-model"><i class="fa fa-check"></i><b>1.6.4</b> Figure 2f – check the model</a></li>
<li class="chapter" data-level="1.6.5" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-inference"><i class="fa fa-check"></i><b>1.6.5</b> Figure 2f – inference</a></li>
<li class="chapter" data-level="1.6.6" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-plot-the-model"><i class="fa fa-check"></i><b>1.6.6</b> Figure 2f – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g"><i class="fa fa-check"></i><b>1.7</b> Figure 2g</a><ul>
<li class="chapter" data-level="1.7.1" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-import"><i class="fa fa-check"></i><b>1.7.1</b> Figure 2g – import</a></li>
<li class="chapter" data-level="1.7.2" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-exploratory-plots"><i class="fa fa-check"></i><b>1.7.2</b> Figure 2g – exploratory plots</a></li>
<li class="chapter" data-level="1.7.3" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-fit-the-model"><i class="fa fa-check"></i><b>1.7.3</b> Figure 2g – fit the model</a></li>
<li class="chapter" data-level="1.7.4" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-check-the-model"><i class="fa fa-check"></i><b>1.7.4</b> Figure 2g – check the model</a></li>
<li class="chapter" data-level="1.7.5" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-inference"><i class="fa fa-check"></i><b>1.7.5</b> Figure 2g – inference</a></li>
<li class="chapter" data-level="1.7.6" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-plot-the-model"><i class="fa fa-check"></i><b>1.7.6</b> Figure 2g – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2h"><i class="fa fa-check"></i><b>1.8</b> Figure 2h</a></li>
<li class="chapter" data-level="1.9" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i"><i class="fa fa-check"></i><b>1.9</b> Figure 2i</a></li>
<li class="chapter" data-level="1.10" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2j"><i class="fa fa-check"></i><b>1.10</b> Figure 2j</a></li>
<li class="chapter" data-level="1.11" data-path="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analysis-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#exercises"><i class="fa fa-check"></i><b>1.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-r-fundamentals.html"><a href="part-i-r-fundamentals.html"><i class="fa fa-check"></i>Part I: R fundamentals</a></li>
<li class="chapter" data-level="2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html"><i class="fa fa-check"></i><b>2</b> Organization – R Projects and R Notebooks</a><ul>
<li class="chapter" data-level="2.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-vs-r-studio"><i class="fa fa-check"></i><b>2.1</b> R vs R Studio</a></li>
<li class="chapter" data-level="2.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-notebook-vs.-r-markdown"><i class="fa fa-check"></i><b>2.2</b> R Notebook vs. R Markdown</a></li>
<li class="chapter" data-level="2.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#importing-packages"><i class="fa fa-check"></i><b>2.3</b> Importing Packages</a></li>
<li class="chapter" data-level="2.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-studio-project-for-this-textbook"><i class="fa fa-check"></i><b>2.4</b> Create an R Studio Project for this textbook</a><ul>
<li class="chapter" data-level="2.4.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-markdown-file-for-this-chapter"><i class="fa fa-check"></i><b>2.4.1</b> Create an R Markdown file for this Chapter</a></li>
<li class="chapter" data-level="2.4.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-fake-data-chunk"><i class="fa fa-check"></i><b>2.4.2</b> Create a “fake-data” chunk</a></li>
<li class="chapter" data-level="2.4.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-plot-chunk"><i class="fa fa-check"></i><b>2.4.3</b> Create a “plot” chunk</a></li>
<li class="chapter" data-level="2.4.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#knit"><i class="fa fa-check"></i><b>2.4.4</b> Knit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html"><i class="fa fa-check"></i><b>3</b> Data – Reading, Wrangling, and Writing</a><ul>
<li class="chapter" data-level="3.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#learning-from-this-chapter"><i class="fa fa-check"></i><b>3.1</b> Learning from this chapter</a></li>
<li class="chapter" data-level="3.2" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#data-working-in-r"><i class="fa fa-check"></i><b>3.2</b> Working in R</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#importing-data"><i class="fa fa-check"></i><b>3.2.1</b> Importing data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#data-wrangling"><i class="fa fa-check"></i><b>3.3</b> Data wrangling</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#reshaping-data-wide-to-long"><i class="fa fa-check"></i><b>3.3.1</b> Reshaping data – Wide to long</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#reshaping-data-transpose-turning-the-columns-into-rows"><i class="fa fa-check"></i><b>3.3.2</b> Reshaping data – Transpose (turning the columns into rows)</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#combining-data"><i class="fa fa-check"></i><b>3.3.3</b> Combining data</a></li>
<li class="chapter" data-level="3.3.4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#subsetting-data"><i class="fa fa-check"></i><b>3.3.4</b> Subsetting data</a></li>
<li class="chapter" data-level="3.3.5" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#wrangling-columns"><i class="fa fa-check"></i><b>3.3.5</b> Wrangling columns</a></li>
<li class="chapter" data-level="3.3.6" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#missing-data"><i class="fa fa-check"></i><b>3.3.6</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#saving-data"><i class="fa fa-check"></i><b>3.4</b> Saving data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plotting-models.html"><a href="plotting-models.html"><i class="fa fa-check"></i><b>4</b> Plotting Models</a><ul>
<li class="chapter" data-level="4.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plots-show-the-model-and-the-data"><i class="fa fa-check"></i><b>4.1</b> Pretty good plots show the model and the data</a><ul>
<li class="chapter" data-level="4.1.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-1-modeled-effects-plot"><i class="fa fa-check"></i><b>4.1.1</b> Pretty good plot component 1: Modeled effects plot</a></li>
<li class="chapter" data-level="4.1.2" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot"><i class="fa fa-check"></i><b>4.1.2</b> Pretty good plot component 2: Modeled mean and CI plot</a></li>
<li class="chapter" data-level="4.1.3" data-path="plotting-models.html"><a href="plotting-models.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><i class="fa fa-check"></i><b>4.1.3</b> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="plotting-models.html"><a href="plotting-models.html#some-comments-on-plot-components"><i class="fa fa-check"></i><b>4.2</b> Some comments on plot components</a></li>
<li class="chapter" data-level="4.3" data-path="plotting-models.html"><a href="plotting-models.html#working-in-r"><i class="fa fa-check"></i><b>4.3</b> Working in R</a><ul>
<li class="chapter" data-level="4.3.1" data-path="plotting-models.html"><a href="plotting-models.html#unpooled-se-bars-and-confidence-intervals"><i class="fa fa-check"></i><b>4.3.1</b> Unpooled SE bars and confidence intervals</a></li>
<li class="chapter" data-level="4.3.2" data-path="plotting-models.html"><a href="plotting-models.html#adding-bootstrap-intervals"><i class="fa fa-check"></i><b>4.3.2</b> Adding bootstrap intervals</a></li>
<li class="chapter" data-level="4.3.3" data-path="plotting-models.html"><a href="plotting-models.html#adding-modeled-means-and-error-intervals"><i class="fa fa-check"></i><b>4.3.3</b> Adding modeled means and error intervals</a></li>
<li class="chapter" data-level="4.3.4" data-path="plotting-models.html"><a href="plotting-models.html#adding-p-values"><i class="fa fa-check"></i><b>4.3.4</b> Adding p-values</a></li>
<li class="chapter" data-level="4.3.5" data-path="plotting-models.html"><a href="plotting-models.html#adding-custom-p-values"><i class="fa fa-check"></i><b>4.3.5</b> Adding custom p-values</a></li>
<li class="chapter" data-level="4.3.6" data-path="plotting-models.html"><a href="plotting-models.html#plotting-two-factors"><i class="fa fa-check"></i><b>4.3.6</b> Plotting two factors</a></li>
<li class="chapter" data-level="4.3.7" data-path="plotting-models.html"><a href="plotting-models.html#interaction-plot"><i class="fa fa-check"></i><b>4.3.7</b> Interaction plot</a></li>
<li class="chapter" data-level="4.3.8" data-path="plotting-models.html"><a href="plotting-models.html#plot-components"><i class="fa fa-check"></i><b>4.3.8</b> Plot components</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-some-fundamentals-of-statistical-modeling.html"><a href="part-ii-some-fundamentals-of-statistical-modeling.html"><i class="fa fa-check"></i>Part II: Some Fundamentals of Statistical Modeling</a></li>
<li class="chapter" data-level="5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="chapter" data-level="5.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#the-sample-standard-deviation-vs.-the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>5.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="5.1.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#sample-standard-deviation"><i class="fa fa-check"></i><b>5.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="5.1.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>5.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>5.2</b> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="5.2.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#steps"><i class="fa fa-check"></i><b>5.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>5.3</b> Using R to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="5.3.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-i"><i class="fa fa-check"></i><b>5.3.1</b> part I</a></li>
<li class="chapter" data-level="5.3.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-ii---means"><i class="fa fa-check"></i><b>5.3.2</b> part II - means</a></li>
<li class="chapter" data-level="5.3.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>5.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="5.3.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>5.3.4</b> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#bootstrap"><i class="fa fa-check"></i><b>5.4</b> Bootstrapped standard errors</a><ul>
<li class="chapter" data-level="5.4.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#an-example-of-bootstrapped-standard-errors-using-vole-data"><i class="fa fa-check"></i><b>5.4.1</b> An example of bootstrapped standard errors using vole data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#confidence-interval"><i class="fa fa-check"></i><b>5.5</b> Confidence Interval</a><ul>
<li class="chapter" data-level="5.5.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#interpretation-of-a-confidence-interval"><i class="fa fa-check"></i><b>5.5.1</b> Interpretation of a confidence interval</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-introduction-to-linear-models.html"><a href="part-iii-introduction-to-linear-models.html"><i class="fa fa-check"></i>Part III: Introduction to Linear Models</a></li>
<li class="chapter" data-level="6" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html"><i class="fa fa-check"></i><b>6</b> An Introduction to Statistical Modeling</a><ul>
<li class="chapter" data-level="6.1" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#two-specifications-of-a-linear-model"><i class="fa fa-check"></i><b>6.1</b> Two specifications of a linear model</a><ul>
<li class="chapter" data-level="6.1.1" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#the-error-draw-specification"><i class="fa fa-check"></i><b>6.1.1</b> The “error draw” specification</a></li>
<li class="chapter" data-level="6.1.2" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#the-conditional-draw-specification"><i class="fa fa-check"></i><b>6.1.2</b> The “conditional draw” specification</a></li>
<li class="chapter" data-level="6.1.3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#comparing-the-two-ways-of-specifying-the-linear-model"><i class="fa fa-check"></i><b>6.1.3</b> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>6.2</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="6.3" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#what-do-we-call-the-x-and-y-variables"><i class="fa fa-check"></i><b>6.3</b> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li class="chapter" data-level="6.4" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#modeling-strategy"><i class="fa fa-check"></i><b>6.4</b> Modeling strategy</a></li>
<li class="chapter" data-level="6.5" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#fitting-the-model"><i class="fa fa-check"></i><b>6.5</b> Fitting the model</a></li>
<li class="chapter" data-level="6.6" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#models-fit-to-data-in-which-the-x-are-treatment-variables-are-regression-models"><i class="fa fa-check"></i><b>6.6</b> Models fit to data in which the <span class="math inline">\(X\)</span> are treatment variables are regression models</a></li>
<li class="chapter" data-level="6.7" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>6.7</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="6.8" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>6.8</b> Specific assumptions for inference with a linear model</a></li>
<li class="chapter" data-level="6.9" data-path="an-introduction-to-statistical-modeling.html"><a href="an-introduction-to-statistical-modeling.html#linear-modelregression-model-orstatistical-model"><i class="fa fa-check"></i><b>6.9</b> “linear model,”regression model“, or”statistical model"?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html"><i class="fa fa-check"></i><b>7</b> Models with a single, continuous <em>X</em></a><ul>
<li class="chapter" data-level="7.1" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><i class="fa fa-check"></i><b>7.1</b> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="7.1.1" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#analysis-of-green-down-data"><i class="fa fa-check"></i><b>7.1.1</b> Analysis of “green-down” data</a></li>
<li class="chapter" data-level="7.1.2" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#learning-from-the-green-down-example"><i class="fa fa-check"></i><b>7.1.2</b> Learning from the green-down example</a></li>
<li class="chapter" data-level="7.1.3" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#what-a-regression-coefficient-means"><i class="fa fa-check"></i><b>7.1.3</b> What a regression coefficient means</a></li>
<li class="chapter" data-level="7.1.4" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#using-the-linear-model-for-prediction-prediction-models"><i class="fa fa-check"></i><b>7.1.4</b> Using the linear model for prediction – prediction models</a></li>
<li class="chapter" data-level="7.1.5" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#using-a-linear-model-for-explanation-causal-models"><i class="fa fa-check"></i><b>7.1.5</b> Using a linear model for “explanation” – causal models</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#working-in-r-1"><i class="fa fa-check"></i><b>7.2</b> Working in R</a><ul>
<li class="chapter" data-level="7.2.1" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>7.2.1</b> Fitting the linear model</a></li>
<li class="chapter" data-level="7.2.2" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>7.2.2</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="7.2.3" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#inference-the-coefficient-table-and-confidence-intervals"><i class="fa fa-check"></i><b>7.2.3</b> Inference – the coefficient table and Confidence intervals</a></li>
<li class="chapter" data-level="7.2.4" data-path="models-with-a-single-continuous-x.html"><a href="models-with-a-single-continuous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>7.2.4</b> How good is our model?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>8</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="8.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-estimates-the-effects-of-x-on-the-response."><i class="fa fa-check"></i><b>8.1</b> A linear model with a single, categorical <em>X</em> estimates the effects of <em>X</em> on the response.</a><ul>
<li class="chapter" data-level="8.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#table-of-model-coefficients"><i class="fa fa-check"></i><b>8.1.1</b> Table of model coefficients</a></li>
<li class="chapter" data-level="8.1.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#the-linear-model"><i class="fa fa-check"></i><b>8.1.2</b> The linear model</a></li>
<li class="chapter" data-level="8.1.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#reporting-results"><i class="fa fa-check"></i><b>8.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#comparing-the-results-of-a-linear-model-to-classical-hypothesis-tests"><i class="fa fa-check"></i><b>8.2</b> Comparing the results of a linear model to classical hypothesis tests</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#t-tests-are-special-cases-of-a-linear-model"><i class="fa fa-check"></i><b>8.2.1</b> t-tests are special cases of a linear model</a></li>
<li class="chapter" data-level="8.2.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#anova-is-a-special-case-of-a-linear-model"><i class="fa fa-check"></i><b>8.2.2</b> ANOVA is a special case of a linear model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#working-in-r-2"><i class="fa fa-check"></i><b>8.3</b> Working in R</a><ul>
<li class="chapter" data-level="8.3.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#fitting-the-model-1"><i class="fa fa-check"></i><b>8.3.1</b> Fitting the model</a></li>
<li class="chapter" data-level="8.3.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#changing-the-reference-level"><i class="fa fa-check"></i><b>8.3.2</b> Changing the reference level</a></li>
<li class="chapter" data-level="8.3.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#an-introduction-to-contrasts"><i class="fa fa-check"></i><b>8.3.3</b> An introduction to contrasts</a></li>
<li class="chapter" data-level="8.3.4" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#harrell-plot"><i class="fa fa-check"></i><b>8.3.4</b> Harrell plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>9</b> Model Checking</a><ul>
<li class="chapter" data-level="9.1" data-path="model-checking.html"><a href="model-checking.html#do-coefficients-make-numeric-sense"><i class="fa fa-check"></i><b>9.1</b> Do coefficients make numeric sense?</a></li>
<li class="chapter" data-level="9.2" data-path="model-checking.html"><a href="model-checking.html#all-statistical-analyses-should-be-followed-by-model-checking"><i class="fa fa-check"></i><b>9.2</b> All statistical analyses should be followed by model checking</a></li>
<li class="chapter" data-level="9.3" data-path="model-checking.html"><a href="model-checking.html#linear-model-assumptions"><i class="fa fa-check"></i><b>9.3</b> Linear model assumptions</a></li>
<li class="chapter" data-level="9.4" data-path="model-checking.html"><a href="model-checking.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><i class="fa fa-check"></i><b>9.4</b> Diagnostic plots use the residuals from the model fit</a><ul>
<li class="chapter" data-level="9.4.1" data-path="model-checking.html"><a href="model-checking.html#residuals"><i class="fa fa-check"></i><b>9.4.1</b> Residuals</a></li>
<li class="chapter" data-level="9.4.2" data-path="model-checking.html"><a href="model-checking.html#a-normal-q-q-plot-is-used-to-check-normality"><i class="fa fa-check"></i><b>9.4.2</b> A Normal Q-Q plot is used to check normality</a></li>
<li class="chapter" data-level="9.4.3" data-path="model-checking.html"><a href="model-checking.html#outliers---an-outlier-is-a-point-that-is-highly-unexpected-given-the-modeled-distribution."><i class="fa fa-check"></i><b>9.4.3</b> Outliers - an outlier is a point that is highly unexpected given the modeled distribution.</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="model-checking.html"><a href="model-checking.html#model-checking-homoskedasticity"><i class="fa fa-check"></i><b>9.5</b> Model checking homoskedasticity</a></li>
<li class="chapter" data-level="9.6" data-path="model-checking.html"><a href="model-checking.html#model-checking-independence---hapiness-adverse-example."><i class="fa fa-check"></i><b>9.6</b> Model checking independence - hapiness adverse example.</a></li>
<li class="chapter" data-level="9.7" data-path="model-checking.html"><a href="model-checking.html#using-r"><i class="fa fa-check"></i><b>9.7</b> Using R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html"><i class="fa fa-check"></i><b>10</b> Model Fitting and Model Fit (OLS)</a><ul>
<li class="chapter" data-level="10.1" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#least-squares-estimation-and-the-decomposition-of-variance"><i class="fa fa-check"></i><b>10.1</b> Least Squares Estimation and the Decomposition of Variance</a></li>
<li class="chapter" data-level="10.2" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#ols-regression"><i class="fa fa-check"></i><b>10.2</b> OLS regression</a></li>
<li class="chapter" data-level="10.3" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>10.3</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html"><i class="fa fa-check"></i><b>11</b> Best Practices – Issues in Inference</a><ul>
<li class="chapter" data-level="11.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#power"><i class="fa fa-check"></i><b>11.1</b> Power</a><ul>
<li class="chapter" data-level="11.1.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#types-of-error"><i class="fa fa-check"></i><b>11.1.1</b> “Types” of Error</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing"><i class="fa fa-check"></i><b>11.2</b> multiple testing</a><ul>
<li class="chapter" data-level="11.2.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#some-background"><i class="fa fa-check"></i><b>11.2.1</b> Some background</a></li>
<li class="chapter" data-level="11.2.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing-working-in-r"><i class="fa fa-check"></i><b>11.2.2</b> Multiple testing – working in R</a></li>
<li class="chapter" data-level="11.2.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#false-discovery-rate"><i class="fa fa-check"></i><b>11.2.3</b> False Discovery Rate</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#difference-in-p-is-not-different"><i class="fa fa-check"></i><b>11.3</b> difference in p is not different</a></li>
<li class="chapter" data-level="11.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#inference-when-data-are-not-normal"><i class="fa fa-check"></i><b>11.4</b> Inference when data are not Normal</a><ul>
<li class="chapter" data-level="11.4.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#working-in-r-3"><i class="fa fa-check"></i><b>11.4.1</b> Working in R</a></li>
<li class="chapter" data-level="11.4.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>11.4.2</b> Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="11.4.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#permutation-test"><i class="fa fa-check"></i><b>11.4.3</b> Permutation test</a></li>
<li class="chapter" data-level="11.4.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#non-parametric-tests"><i class="fa fa-check"></i><b>11.4.4</b> Non-parametric tests</a></li>
<li class="chapter" data-level="11.4.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#log-transformations"><i class="fa fa-check"></i><b>11.4.5</b> Log transformations</a></li>
<li class="chapter" data-level="11.4.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#performance-of-parametric-tests-and-alternatives"><i class="fa fa-check"></i><b>11.4.6</b> Performance of parametric tests and alternatives</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#max-vs.-mean"><i class="fa fa-check"></i><b>11.5</b> max vs. mean</a></li>
<li class="chapter" data-level="11.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#pre-post-normalization"><i class="fa fa-check"></i><b>11.6</b> pre-post, normalization</a></li>
</ul></li>
<li><a href="part-iv-more-than-one-x-multivariable-models.html#part-iv-more-than-one-x-multivariable-models">Part IV: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="chapter" data-level="12" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html"><i class="fa fa-check"></i><b>12</b> Adding covariates to a linear model</a><ul>
<li class="chapter" data-level="12.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>12.1</b> Adding covariates can increases the precision of the effect of interest</a></li>
<li class="chapter" data-level="12.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-decrease-prediction-error-in-predictive-models"><i class="fa fa-check"></i><b>12.2</b> Adding covariates can decrease prediction error in predictive models</a></li>
<li class="chapter" data-level="12.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-reduce-bias-due-to-confounding-in-explanatory-models"><i class="fa fa-check"></i><b>12.3</b> Adding covariates can reduce bias due to confounding in explanatory models</a></li>
<li class="chapter" data-level="12.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-1-a-pre-treatment-measure-of-the-response-should-be-a-covariate-and-not-subtracted-from-the-post-treatment-measure-regression-to-the-mean"><i class="fa fa-check"></i><b>12.4</b> Best practices 1: A pre-treatment measure of the response should be a covariate and not subtracted from the post-treatment measure (regression to the mean)</a><ul>
<li class="chapter" data-level="12.4.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-words"><i class="fa fa-check"></i><b>12.4.1</b> Regression to the mean in words</a></li>
<li class="chapter" data-level="12.4.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-pictures"><i class="fa fa-check"></i><b>12.4.2</b> Regression to the mean in pictures</a></li>
<li class="chapter" data-level="12.4.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>12.4.3</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="12.4.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>12.4.4</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-2-use-a-covariate-instead-of-normalizing-a-response"><i class="fa fa-check"></i><b>12.5</b> Best practices 2: Use a covariate instead of normalizing a response</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>13</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="13.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>13.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="13.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>13.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="13.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>13.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="13.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-interpretation-of-the-coefficients-in-a-factorial-model-is-entirely-dependent-on-the-reference"><i class="fa fa-check"></i><b>13.1.3</b> The interpretation of the coefficients in a factorial model is entirely dependent on the reference…</a></li>
<li class="chapter" data-level="13.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#estimated-marginal-means"><i class="fa fa-check"></i><b>13.1.4</b> Estimated marginal means</a></li>
<li class="chapter" data-level="13.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#in-a-factorial-model-there-are-multiple-effects-of-each-factor-simple-effects"><i class="fa fa-check"></i><b>13.1.5</b> In a factorial model, there are multiple effects of each factor (simple effects)</a></li>
<li class="chapter" data-level="13.1.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects"><i class="fa fa-check"></i><b>13.1.6</b> Marginal effects</a></li>
<li class="chapter" data-level="13.1.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>13.1.7</b> The additive model</a></li>
<li class="chapter" data-level="13.1.8" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reduce-models-for-the-right-reason"><i class="fa fa-check"></i><b>13.1.8</b> Reduce models for the right reason</a></li>
<li class="chapter" data-level="13.1.9" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>13.1.9</b> What about models with more than two factors?</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results-1"><i class="fa fa-check"></i><b>13.2</b> Reporting results</a><ul>
<li class="chapter" data-level="13.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>13.2.1</b> Text results</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-4"><i class="fa fa-check"></i><b>13.3</b> Working in R</a><ul>
<li class="chapter" data-level="13.3.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-formula"><i class="fa fa-check"></i><b>13.3.1</b> Model formula</a></li>
<li class="chapter" data-level="13.3.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#modeled-means"><i class="fa fa-check"></i><b>13.3.2</b> Modeled means</a></li>
<li class="chapter" data-level="13.3.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-means"><i class="fa fa-check"></i><b>13.3.3</b> Marginal means</a></li>
<li class="chapter" data-level="13.3.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts"><i class="fa fa-check"></i><b>13.3.4</b> Contrasts</a></li>
<li class="chapter" data-level="13.3.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#simple-effects"><i class="fa fa-check"></i><b>13.3.5</b> Simple effects</a></li>
<li class="chapter" data-level="13.3.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects-1"><i class="fa fa-check"></i><b>13.3.6</b> Marginal effects</a></li>
<li class="chapter" data-level="13.3.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#plotting-results"><i class="fa fa-check"></i><b>13.3.7</b> Plotting results</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems"><i class="fa fa-check"></i><b>13.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>14</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="14.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>14.1</b> Summary of usage</a></li>
<li class="chapter" data-level="14.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>14.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="14.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>14.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="14.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>14.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="14.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>14.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="14.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>14.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>14.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="14.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>14.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="14.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>14.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="14.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>14.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-5"><i class="fa fa-check"></i><b>14.5</b> Working in R</a><ul>
<li class="chapter" data-level="14.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>14.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="14.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>14.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="predictive-models.html"><a href="predictive-models.html"><i class="fa fa-check"></i><b>15</b> Predictive Models</a><ul>
<li class="chapter" data-level="15.1" data-path="predictive-models.html"><a href="predictive-models.html#overfitting"><i class="fa fa-check"></i><b>15.1</b> Overfitting</a></li>
<li class="chapter" data-level="15.2" data-path="predictive-models.html"><a href="predictive-models.html#model-building-vs.-variable-selection-vs.-model-selection"><i class="fa fa-check"></i><b>15.2</b> Model building vs. Variable selection vs. Model selection</a><ul>
<li class="chapter" data-level="15.2.1" data-path="predictive-models.html"><a href="predictive-models.html#stepwise-regression"><i class="fa fa-check"></i><b>15.2.1</b> Stepwise regression</a></li>
<li class="chapter" data-level="15.2.2" data-path="predictive-models.html"><a href="predictive-models.html#cross-validation"><i class="fa fa-check"></i><b>15.2.2</b> Cross-validation</a></li>
<li class="chapter" data-level="15.2.3" data-path="predictive-models.html"><a href="predictive-models.html#penalization"><i class="fa fa-check"></i><b>15.2.3</b> Penalization</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="predictive-models.html"><a href="predictive-models.html#shrinkage"><i class="fa fa-check"></i><b>15.3</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="additional-tools-and-information.html"><a href="additional-tools-and-information.html"><i class="fa fa-check"></i>Additional tools and information</a></li>
<li class="chapter" data-level="16" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>16</b> Linear mixed models</a><ul>
<li class="chapter" data-level="16.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>16.1</b> Random effects</a></li>
<li class="chapter" data-level="16.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>16.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="16.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>16.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="16.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#blocking"><i class="fa fa-check"></i><b>16.4</b> Blocking</a><ul>
<li class="chapter" data-level="16.4.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualing-variation-due-to-blocks"><i class="fa fa-check"></i><b>16.4.1</b> Visualing variation due to blocks</a></li>
<li class="chapter" data-level="16.4.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#blocking-increases-precision-of-point-estimates"><i class="fa fa-check"></i><b>16.4.2</b> Blocking increases precision of point estimates</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#pseudoreplication"><i class="fa fa-check"></i><b>16.5</b> Pseudoreplication</a><ul>
<li class="chapter" data-level="16.5.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-pseduoreplication"><i class="fa fa-check"></i><b>16.5.1</b> Visualizing pseduoreplication</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model"><i class="fa fa-check"></i><b>16.6</b> Mapping NHST to estimation: A paired t-test is a special case of a linear mixed model</a></li>
<li class="chapter" data-level="16.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>16.7</b> Advanced topic – Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="16.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-6"><i class="fa fa-check"></i><b>16.8</b> Working in R</a><ul>
<li class="chapter" data-level="16.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>16.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>17</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="17.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>17.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="17.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>17.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="17.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy-1"><i class="fa fa-check"></i><b>17.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="17.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>17.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="17.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>17.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="17.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>17.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="17.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>17.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="17.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>17.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="17.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>17.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-7"><i class="fa fa-check"></i><b>17.3</b> Working in R</a><ul>
<li class="chapter" data-level="17.3.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-to-count-data"><i class="fa fa-check"></i><b>17.3.1</b> Fitting a GLM to count data</a></li>
<li class="chapter" data-level="17.3.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-generalized-linear-mixed-model-glmm-to-count-data"><i class="fa fa-check"></i><b>17.3.2</b> Fitting a generalized linear mixed model (GLMM) to count data</a></li>
<li class="chapter" data-level="17.3.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-generalized-linear-model-to-continouus-data"><i class="fa fa-check"></i><b>17.3.3</b> Fitting a generalized linear model to continouus data</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-1"><i class="fa fa-check"></i><b>17.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html"><i class="fa fa-check"></i><b>18</b> Linear models with heterogenous variance</a><ul>
<li class="chapter" data-level="18.1" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html#gls"><i class="fa fa-check"></i><b>18.1</b> gls</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><i class="fa fa-check"></i>Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="chapter" data-level="19" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html"><i class="fa fa-check"></i><b>19</b> Plotting functions (#ggplotsci)</a><ul>
<li class="chapter" data-level="19.1" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#odd-even"><i class="fa fa-check"></i><b>19.1</b> odd-even</a></li>
<li class="chapter" data-level="19.2" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#estimate-response-and-effects-with-emmeans"><i class="fa fa-check"></i><b>19.2</b> estimate response and effects with emmeans</a></li>
<li class="chapter" data-level="19.3" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#emm_table"><i class="fa fa-check"></i><b>19.3</b> emm_table</a></li>
<li class="chapter" data-level="19.4" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#pairs_table"><i class="fa fa-check"></i><b>19.4</b> pairs_table</a></li>
<li class="chapter" data-level="19.5" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_mean_error"><i class="fa fa-check"></i><b>19.5</b> gg_mean_error</a></li>
<li class="chapter" data-level="19.6" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_ancova"><i class="fa fa-check"></i><b>19.6</b> gg_ancova</a></li>
<li class="chapter" data-level="19.7" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_mean_ci_ancova"><i class="fa fa-check"></i><b>19.7</b> gg_mean_ci_ancova</a></li>
<li class="chapter" data-level="19.8" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_effects"><i class="fa fa-check"></i><b>19.8</b> gg_effects</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="19.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>19.9</b> Get your computer ready</a><ul>
<li class="chapter" data-level="19.9.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-here"><i class="fa fa-check"></i><b>19.9.1</b> Start here</a></li>
<li class="chapter" data-level="19.9.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>19.9.2</b> Install R</a></li>
<li class="chapter" data-level="19.9.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>19.9.3</b> Install R Studio</a></li>
<li class="chapter" data-level="19.9.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-markdown"><i class="fa fa-check"></i><b>19.9.4</b> Install R Markdown</a></li>
<li class="chapter" data-level="19.9.5" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#optional-alternative-latex-installations"><i class="fa fa-check"></i><b>19.9.5</b> (optional) Alternative LaTeX installations</a></li>
</ul></li>
<li class="chapter" data-level="19.10" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning-r-studio"><i class="fa fa-check"></i><b>19.10</b> Start learning R Studio</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="chapter" data-level="" data-path="appendix-3-fake-data-simulations.html"><a href="appendix-3-fake-data-simulations.html"><i class="fa fa-check"></i>Appendix 3: Fake Data Simulations</a><ul>
<li class="chapter" data-level="19.11" data-path="appendix-3-fake-data-simulations.html"><a href="appendix-3-fake-data-simulations.html#performance-of-blocking-relative-to-a-linear-model"><i class="fa fa-check"></i><b>19.11</b> Performance of Blocking relative to a linear model</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elements of Statistical Modeling for Experimental Biology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="an-introduction-to-statistical-modeling" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> An Introduction to Statistical Modeling</h1>
<p>This chapter introduces statistical modeling using the <strong>linear model</strong>. All students are familiar with the idea of a linear model from learning the equation of a line, which is</p>
<p><span class="math display" id="eq:line">\[\begin{equation}
Y = mX + b
\tag{6.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(m\)</span> is the slope of the line and <span class="math inline">\(b\)</span> is the <span class="math inline">\(Y\)</span>-intercept. It is useful to think of equation <a href="an-introduction-to-statistical-modeling.html#eq:line">(6.1)</a> as a function that maps values of <span class="math inline">\(X\)</span> to values of <span class="math inline">\(Y\)</span>. Using this function, if we input some value of <span class="math inline">\(X\)</span>, we always get the same value of Y as the output.</p>
<p>A linear model is a function, like that in equation <a href="an-introduction-to-statistical-modeling.html#eq:line">(6.1)</a>, that is fit to a set of data, often to model a process that generated the data or something like the data. The line in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">6.1</a>A is just that, a line, but the line in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">6.1</a>B is a linear model fit to the data in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">6.1</a>B.</p>
<div class="figure"><span id="fig:line"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/line-1.png" alt="A line vs. a linear model. (A) the line $y=-3.48X + 105.7$ is drawn. (B) A linear model fit to the data. The model coefficients are numerically equal to the slope and intercept of the line in A." width="576" />
<p class="caption">
Figure 6.1: A line vs. a linear model. (A) the line <span class="math inline">\(y=-3.48X + 105.7\)</span> is drawn. (B) A linear model fit to the data. The model coefficients are numerically equal to the slope and intercept of the line in A.
</p>
</div>
<div id="two-specifications-of-a-linear-model" class="section level2">
<h2><span class="header-section-number">6.1</span> Two specifications of a linear model</h2>
<div id="the-error-draw-specification" class="section level3">
<h3><span class="header-section-number">6.1.1</span> The “error draw” specification</h3>
<p>A linear model is commonly specified using</p>
<p><span class="math display" id="eq:lm">\[\begin{align}
Y &amp;= \beta_0 + \beta_1 X + \varepsilon\\
\tag{6.2}
\end{align}\]</span></p>
<p>This specification of a linear model has two parts: the <strong>linear predictor</strong> <span class="math inline">\(Y = \beta_0 + \beta_1 X\)</span> and the <strong>error</strong> <span class="math inline">\(\varepsilon\)</span>. The linear predictor part looks like the equation for a line except that 1) <span class="math inline">\(\beta_0\)</span> is used for the intercept and <span class="math inline">\(\beta_1\)</span> for the slope and 2) the intercept term precedes the slope term. This re-labeling and re-arrangement make the notation for a linear model more flexible for more complicated linear models. For example <span class="math inline">\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \varepsilon\)</span> is a model where <span class="math inline">\(Y\)</span> is a function of two <span class="math inline">\(X\)</span> variables.</p>
<p>As with the equation for a line, the linear predictor part of a linear model is a function that maps a specific value of <span class="math inline">\(X\)</span> to a value of <span class="math inline">\(Y\)</span>. This mapped value is the <strong>expected value</strong>, or expectation, given a specific input value of <span class="math inline">\(X\)</span>. This is often written as <span class="math inline">\(\mathrm{E}[Y|X]\)</span>, which is read as “the expected value of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>”, where “given X” means a specific value of X. This text will often use the word <strong>conditional</strong> in place of “given”. It is important to recognize that <span class="math inline">\(\mathrm{E}[Y|X]\)</span> is a <strong>conditional mean</strong> – it is the mean value of <span class="math inline">\(Y\)</span> when we observe that <span class="math inline">\(X\)</span> has some specific value <span class="math inline">\(x\)</span>.</p>
<p>Introductory textbooks almost always introduce linear models using equation <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a> above. The key part of the model that is missing from the specification above is a second line
<span class="math display">\[\begin{equation}
\varepsilon \sim N(0, \sigma^2)
\end{equation}\]</span></p>
<p>which is read as “epsilon is distributed as Normal with mean zero and variance sigma squared”. This line explicitly specifies the distribution of the error part. The error part of a linear model is a random “draw” from a normal distribution with mean zero and variance <span class="math inline">\(\sigma^2\)</span>. Using the error-draw specification, we can think of any measurement of <span class="math inline">\(Y\)</span> as an expected value plus some random value sampled from a specific distribution.</p>
</div>
<div id="the-conditional-draw-specification" class="section level3">
<h3><span class="header-section-number">6.1.2</span> The “conditional draw” specification</h3>
<p>A second way of specifying a linear model is</p>
<p><span class="math display" id="eq:lm-spec2">\[\begin{align}
y_i &amp;\sim N(\mu_i, \sigma^2)\\
\mathrm{E}(Y|X) &amp;= \mu\\
\mu_i &amp;= \beta_0 + \beta_1 x_i
\tag{6.3}
\end{align}\]</span></p>
<p>The first line states that the response variable <span class="math inline">\(Y\)</span> is a random variable independently drawn from a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. This first line is the <strong>stochastic</strong> part of the statistical model. The second line simply states that <span class="math inline">\(\mu\)</span> (the greek letter “mu”) from the first line is the conditional mean or conditional expectation. The third line states how <span class="math inline">\(\mu_i\)</span> is generated given that <span class="math inline">\(X=x_i\)</span>. This is the linear predictor, which is the <strong>systematic</strong> (or deterministic) part of the statistical model. It is systematic because the same value of <span class="math inline">\(x_i\)</span> will always generate the same <span class="math inline">\(\mu_i\)</span>.</p>
</div>
<div id="comparing-the-two-ways-of-specifying-the-linear-model" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Comparing the two ways of specifying the linear model</h3>
<p>These two ways of specifying the model encourage slightly different ways of thinking about how the data (the response varible <span class="math inline">\(Y\)</span>) were generated. The error-draw specification “generates” data by 1) constructing what <span class="math inline">\(y_i\)</span> “should be” given <span class="math inline">\(x_i\)</span> (this is the conditional expection), then 2) adding some error <span class="math inline">\(e_i\)</span> drawn from a normal distribution with mean zero and some specified variance. The conditional-draw specification “generates” data by 1) constructing what <span class="math inline">\(y_i\)</span> “should be” given <span class="math inline">\(x_i\)</span>, then 2) drawing a random variable from some specified distribution <em>whose mean is this expectation</em>. This random draw is not “error” but the measured value <span class="math inline">\(y_i\)</span>. For the error draw generation, we need only one hat of random numbers, but for the conditional draw generation, we need a hat for each value of <span class="math inline">\(x_i\)</span>.</p>
<p>Here is a short script that generates data by implementing both the error-draw and condition-draw specifications.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="an-introduction-to-statistical-modeling.html#cb211-1"></a>n &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb211-2"><a href="an-introduction-to-statistical-modeling.html#cb211-2"></a>b_<span class="dv">0</span> &lt;-<span class="st"> </span><span class="fl">10.0</span></span>
<span id="cb211-3"><a href="an-introduction-to-statistical-modeling.html#cb211-3"></a>b_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="fl">1.2</span></span>
<span id="cb211-4"><a href="an-introduction-to-statistical-modeling.html#cb211-4"></a>sigma &lt;-<span class="st"> </span><span class="fl">0.4</span></span>
<span id="cb211-5"><a href="an-introduction-to-statistical-modeling.html#cb211-5"></a>x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>n</span>
<span id="cb211-6"><a href="an-introduction-to-statistical-modeling.html#cb211-6"></a>y_expected &lt;-<span class="st"> </span>b_<span class="dv">0</span> <span class="op">+</span><span class="st"> </span>b_<span class="dv">1</span><span class="op">*</span>x</span>
<span id="cb211-7"><a href="an-introduction-to-statistical-modeling.html#cb211-7"></a></span>
<span id="cb211-8"><a href="an-introduction-to-statistical-modeling.html#cb211-8"></a><span class="co"># error-draw. Note that the n draws are all from the same distribution</span></span>
<span id="cb211-9"><a href="an-introduction-to-statistical-modeling.html#cb211-9"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb211-10"><a href="an-introduction-to-statistical-modeling.html#cb211-10"></a>y_error_draw &lt;-<span class="st"> </span>y_expected <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> sigma)</span>
<span id="cb211-11"><a href="an-introduction-to-statistical-modeling.html#cb211-11"></a></span>
<span id="cb211-12"><a href="an-introduction-to-statistical-modeling.html#cb211-12"></a><span class="co"># conditional-draw. Note that the n draws are each from a different</span></span>
<span id="cb211-13"><a href="an-introduction-to-statistical-modeling.html#cb211-13"></a><span class="co"># distribution because each has a different mean.</span></span>
<span id="cb211-14"><a href="an-introduction-to-statistical-modeling.html#cb211-14"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb211-15"><a href="an-introduction-to-statistical-modeling.html#cb211-15"></a>y_conditional_draw &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean =</span> y_expected, <span class="dt">sd =</span> sigma)</span>
<span id="cb211-16"><a href="an-introduction-to-statistical-modeling.html#cb211-16"></a></span>
<span id="cb211-17"><a href="an-introduction-to-statistical-modeling.html#cb211-17"></a><span class="kw">data.table</span>(<span class="dt">X =</span> x,</span>
<span id="cb211-18"><a href="an-introduction-to-statistical-modeling.html#cb211-18"></a>           <span class="st">&quot;Y (error draw)&quot;</span> =<span class="st"> </span>y_error_draw,</span>
<span id="cb211-19"><a href="an-introduction-to-statistical-modeling.html#cb211-19"></a>           <span class="st">&quot;Y (conditional draw)&quot;</span> =<span class="st"> </span>y_conditional_draw)</span></code></pre></div>
<pre><code>##    X Y (error draw) Y (conditional draw)
## 1: 1       10.94942             10.94942
## 2: 2       12.47346             12.47346
## 3: 3       13.26575             13.26575
## 4: 4       15.43811             15.43811
## 5: 5       16.13180             16.13180</code></pre>
<p>The error-draw specification is not useful for thinking about data generation for data analyzed by generalized linear models, which are models that allow one to specify distribution families other than Normal (such as the binomial, Poisson, and Gamma families). In fact, thinking about a model as a predictor plus error can lead to the misconception that in a generalized linear model, the error (or residuals from the fit) has a distribution from the non-Normal distribution modeled. This cannot be true because the distributions modeled using generalized linear models (other than the Normal) do not have negative values (some residuals must have negative values since the mean of the residuals is zero). Introductory biostatistics textbooks typically only introduce the error-draw specification because introductory textbooks recommend data transformation or non-parametric tests if the data are not approximately normal. This is unfortunate because generalized linear models are extremely useful for real biological data.</p>
<p>Although a linear model (or statistical model more generally) is a model of a data-generating process, linear models are not typically used to actually generate any data. Instead, when we use a linear model to understand something about a real dataset, we think of our data as one realization of a process that generates data like ours. A linear model is a model of that process. That said, it is incredibly useful to use linear models to create fake datasets for at least two reasons: to probe our understanding of statistical modeling generally and, more specifically, to check that a model actually creates data like that in the real dataset that we are analyzing.</p>
</div>
</div>
<div id="statistical-models-are-used-for-prediction-explanation-and-description" class="section level2">
<h2><span class="header-section-number">6.2</span> Statistical models are used for prediction, explanation, and description</h2>
<p>Researchers typically use statistical models to understand relationships between one or more <span class="math inline">\(Y\)</span> variables and one or more <span class="math inline">\(X\)</span> variables. These relationships include</p>
<ol style="list-style-type: decimal">
<li><p>Descriptive modeling. Sometimes a researcher merely wants to describe the relationship between <span class="math inline">\(Y\)</span> and a set of <span class="math inline">\(X\)</span> variables, perhaps to discover patterns. For example, the arrival of a spring migrant bird (<span class="math inline">\(Y\)</span>) as a function of sex (<span class="math inline">\(X_1\)</span>) and age (<span class="math inline">\(X_2\)</span>) might show that males and younger individuals arrive earlier. Importantly, if another <span class="math inline">\(X\)</span> variable is added to the model (or one dropped), the coefficients, and therefore, the precise description, will change. That is, the interpretation of a coefficient as a descriptor is <em>conditional</em> on the other covariates (<span class="math inline">\(X\)</span> variables) in the model. In a descriptive model, there is no implication of causal effects and the goal is not prediction. Nevertheless, it is very hard for humans to discuss a descriptive model without using causal language, which probably means that it is hard for us to think of these models as <em>mere description</em>. Like natural history, descriptive models are useful as patterns in want of an explanation, using more explicit causal models including experiments.</p></li>
<li><p>Predictive modeling. Predictive modeling is very common in applied research. For example, fisheries researchers might model the relationship between population density and habitat variables to predict which subset of ponds in a region are most suitable for brook trout (<em>Salvelinus fontinalis</em>) reintroduction. The goal is to build a model with minimal prediction error, which is the error between predicted and actual values for a future sample. In predictive modeling, the <span class="math inline">\(X\)</span> (“predictor”) variables are largely instrumental – how these are related to <span class="math inline">\(Y\)</span> is not a goal of the modeling, although sometimes an investigator may be interested in the relative importance among the <span class="math inline">\(X\)</span> for predicting <span class="math inline">\(Y\)</span> (for example, collecting the data may be time consuming, or expensive, or enviromentally destructive, so know which subset of <span class="math inline">\(X\)</span> are most important for predicting <span class="math inline">\(Y\)</span> is a useful strategy).</p></li>
<li><p>Explanatory (causal) modeling. Very often, researchers are explicitly interested in <em>how</em> the <span class="math inline">\(X\)</span> variables are causally related to <span class="math inline">\(Y\)</span>. The fisheries researchers that want to reintroduce trout may want to develop and manage a set of ponds to maintain healthy trout populations. This active management requires intervention to change habitat traits in a direction, and with a magnitude, to cause the desired response. This model is predictive – a specific change in <span class="math inline">\(X\)</span> predicts a specific response in <span class="math inline">\(Y\)</span> – because the coefficients of the model provide knowledge on how the system functions – how changes in the inputs <em>cause</em> change in the output. Causal interpretation of model coefficients requires a set of strong assumptions about the <span class="math inline">\(X\)</span> variables in the model. These assumptions are typically met in <strong>experimental designs</strong> but not <strong>observational designs</strong>.</p></li>
</ol>
<p>With observational designs, biologists are often not very explicit about which of these is the goal of the modeling and use a combination of descriptive, predictive, and causal language to describe and discuss results. Many papers read as if the researchers intend explanatory inference but because of norms within the biology community, mask this intention with “predictive” language. Here, I advocate embracing explicit, explanatory modeling by being very transparent about the model’s goal and assumptions.</p>
</div>
<div id="what-do-we-call-the-x-and-y-variables" class="section level2">
<h2><span class="header-section-number">6.3</span> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</h2>
<p>The inputs to a linear model (the <span class="math inline">\(X\)</span> variables) have many names. In this text, the <span class="math inline">\(X\)</span> variables are typically
* <strong>treatment variables</strong> – this term makes sense only for variables that are a <strong>factor</strong> containing the treatment assignment (for example “control” and “treated”)
* <strong>covariates</strong> – this term is usually used for the non-focal <span class="math inline">\(X\)</span> variables in a statistical model.</p>
<p>A linear model is a regression model and in regression modeling, the <span class="math inline">\(X\)</span> variables are typically called</p>
<ul>
<li><strong>independent variables</strong> (often shortened to IV) – “independent” in the sense that in a statistical model at least, the <span class="math inline">\(X\)</span> are not a function of <span class="math inline">\(Y\)</span>.</li>
<li><strong>predictor variables</strong> (or simply, “predictors”) – this makes the most sense in prediction models.</li>
<li><strong>explanatory variables</strong> – this makes sense in causal models and is usually applied in observational designs.</li>
</ul>
<p>In this text, the output of a linear model (the <span class="math inline">\(Y\)</span> variable or variables if the model is multivariate) will most often be calle either of</p>
<ul>
<li><strong>response variable</strong> (or simply, “response”)</li>
<li><strong>outcome variable</strong> (or simply, “outcome”)</li>
</ul>
<p>These terms have a causal connotation in everyday english. These terms are often used in regression modeling with observational data, even if the model is not explicitly causal. On other term, common in introductory textbooks, is</p>
<ul>
<li><strong>dependent variable</strong> – “dependent” in the sense that in a statistical model at least, the <span class="math inline">\(Y\)</span> is a function of the <span class="math inline">\(X\)</span>.</li>
</ul>
</div>
<div id="modeling-strategy" class="section level2">
<h2><span class="header-section-number">6.4</span> Modeling strategy</h2>
<ol style="list-style-type: decimal">
<li><strong>exploratory plots</strong> is <em>not</em> data mining, or exploring the data for patterns to test. Instead, initial plots are used to</li>
</ol>
<ul>
<li>examine individual points and identify outliers that are likely due to data transcription errors or measurement blunders (not simply odd, but biologically plausible measures).</li>
<li>provide useful information for initial model filtering (narrowing the list of potential models that are relevant to the question and data). Statistical modeling includes a diverse array of models, yet almost all methods used by researchers in biology, and all models in this book, are generalizations of the linear model specified in <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(6.3)</a>. For some experiments, there may be multiple models that are relevant to the question and data. Model checking (step 3) can help decide which model to ultimately use.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>fit the model</strong>, in order to estimate the model parameters and the uncertainty in these estimates.</li>
<li><strong>check the model</strong>, which means to use a series of diagnostic plots and computations of model output to check that the fit model reasonably approximates the data.</li>
<li><strong>inference from the model</strong>, which means to use the fit parameters to learn, with uncertainty, about the system, or to predict future observations, with uncertainty.</li>
<li><strong>plot the model</strong>, which means to plot the data, which may be adjusted, and the estimated parameters (or other results dervived from the estimates) with their uncertainty.</li>
</ol>
</div>
<div id="fitting-the-model" class="section level2">
<h2><span class="header-section-number">6.5</span> Fitting the model</h2>
<p>If we fit the model</p>
<p><span class="math display">\[\begin{align}
Y &amp;= \beta_0 + \beta_1 X + \varepsilon\\
\varepsilon &amp;\sim N(0, \sigma^2)
\end{align}\]</span></p>
<p>we get coefficients that estimate the <span class="math inline">\(\beta\)</span> parameters, residuals that estimate <span class="math inline">\(\varepsilon\)</span>, and model error that estimates <span class="math inline">\(\sigma\)</span>. The coefficients and residuals can be used to recover the data</p>
<p><span class="math display">\[\begin{equation}
y_i = b_0 + b_1 x_i + e_i
\end{equation}\]</span></p>
<p>The coefficients without the residuals are used to calculate the expected values. For experiments where the focus is on the effect of a treatment on some resopnse, these expected values are the same for all the members of a treatment group and this value is the <strong>estimated marginal mean</strong> of the group. For a prediction model, these expected values are the <strong>predicted values</strong> or simply, <strong>prediction</strong>, which is often denoted <span class="math inline">\(\hat{y}\)</span>.</p>
<p><span class="math display">\[\begin{equation}
\hat{y}_i = b_0 + b_1 x_i
\end{equation}\]</span></p>
<p>where <span class="math inline">\(i\)</span> stands for (or “indexes”) the <em>i</em>th case or individual.</p>
<p>If our goal is inference – to infer something about the “population” from the sample using the fit model, then <span class="math inline">\(\hat{y}_i\)</span> is the <strong>point estimate</strong> of the parameter <span class="math inline">\(\mu_i\)</span> (the true mean conditional on <span class="math inline">\(X\)</span>), the coefficients <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are point estimates of the parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, and the standard deviation of the <span class="math inline">\(e_i\)</span> is an estimate of <span class="math inline">\(\sigma\)</span>. “Population” is in quotes because it is a very abstract concept. Throughout this book, Greek letters refer to a theoretical parameter and Roman letters refer to point estimates.</p>
<p>Throughout this text, I recommend reporting and interpreting <strong>interval estimates</strong> of the point estimate. A <strong>confidence interval</strong> is a type of interval estimate. A confidence interval of a parameter is a measure of the uncertainty in the estimate. A 95% confidence interval has a 95% probability (in the sense of long-run frequency) of containing the parameter This probability is a property of the population of intervals that could be computed using the same sampling and measuring procedure. It is not correct, without further assumptions, to state that there is a 95% probability that the parameter lies within the interval. Perhaps a more useful interpretation is that the interval is a <strong>compatability interval</strong> in that it contains the range of estimates that are compatible with the data, in the sense that a <span class="math inline">\(t\)</span>-test would not reject the null hypothesis of a difference between the estimate and any value within the interval (this interpretation does not imply anything about the true value).</p>
</div>
<div id="models-fit-to-data-in-which-the-x-are-treatment-variables-are-regression-models" class="section level2">
<h2><span class="header-section-number">6.6</span> Models fit to data in which the <span class="math inline">\(X\)</span> are treatment variables are regression models</h2>
<div class="figure"><span id="fig:coldVoles"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/coldVoles-1.png" alt="HarrellPlot of vole data." width="576" />
<p class="caption">
Figure 6.2: HarrellPlot of vole data.
</p>
</div>
<p>For the model fit to the data in Figure <a href="an-introduction-to-statistical-modeling.html#fig:line">6.1</a>B, the coefficient of <span class="math inline">\(X\)</span> is the slope of the line. Perhaps surprisingly, we can fit a model like equation <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a> to data in which the <span class="math inline">\(X\)</span> variable is categorical. A simple example is an experiment of the effect of antioxidants (vitamins C and E) on lifespan in Voles (Fig. <a href="an-introduction-to-statistical-modeling.html#fig:coldVoles">6.2</a>). In this experiment, the <span class="math inline">\(X\)</span> variable is a categorical, factor variable with three <strong>levels</strong>: “Control”, “Vitamin_E” and “Vitamin_C”. The trick to using a statistical model with categorical <span class="math inline">\(X\)</span> (factor variables) is to recode the factor levels into numbers – how this is done is explained in the chapter on Models with a single Categorical X. When the <span class="math inline">\(X\)</span> variable is categorical, the coefficients are <em>differences in group means</em>. The linear model fit to the vole data has two coefficients, one for Vitamin E and one for vitamin C. The estimate and uncertainty of the these two coefficients are shown in the top part of Figure <a href="an-introduction-to-statistical-modeling.html#fig:coldVoles">6.2</a>. The bottom part shows the raw data, as well as the estimated marginal means and the uncertainty in the estimate of these means.</p>
</div>
<div id="assumptions-for-inference-with-a-statistical-model" class="section level2">
<h2><span class="header-section-number">6.7</span> Assumptions for inference with a statistical model</h2>
<p><strong>Inference</strong> refers to using the fit model to generalize from the sample to the population, which assumes that the response is drawn from some specified probability distribution (Normal, or Poisson, or Bernouli, etc.). Throughout this text, I emphasize reporting and interpreting point estimates and confidence intervals. Another kind of inference is a <strong>significance test</strong>, which is the computation of the probability of “seeing the data” or something more extreme than the data, given a specified null hypothesis. A significance test results in a <strong>p-value</strong>, which can be reported with the point estimate and confidence interval. Somewhat related to a significance test is a hypothesis test, or a <strong>Null-Hypothesis Signficance Test</strong> (NHST), in which the <span class="math inline">\(p\)</span>-value from a significance test is compared to a pre-specified error rate called <span class="math inline">\(\alpha\)</span>. Hypothesis testing was developed as a formal means of decision making but this is rarely the use of NHST in modern biology. For almost all applications of <em>p</em>-values that I see in the literature that I read in ecology, evolution, phyiology, and wet-bench biology, comparing a <span class="math inline">\(p\)</span>-value to <span class="math inline">\(\alpha\)</span> adds no value.</p>
<ol style="list-style-type: decimal">
<li>The data were generated by a process that is “linear in the parameters”, which means that the different components of the model are added together. This additive part of the model containing the parameters is the linear predictor in specifications <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a> and <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(6.3)</a> above. For example, a cubic polynomial model</li>
</ol>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y|X) = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3
\end{equation}\]</span></p>
<p>is a linear model, even though the function is non-linear, because the different components are added. Because a linear predictor is additive, it can be compactly defined using matrix algebra</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y|X) = \mathbf{X}\boldsymbol{\beta}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(mathbf{X}\)</span> is the <strong>model matrix</strong> and <span class="math inline">\(\boldsymbol{\beta}\)</span> is the vector of parameters. We discuss these more in chapter xxx.</p>
<p>A <strong>Generalized Linear Model</strong> (GLM) has the form <span class="math inline">\(g(\mu_i) = \eta_i\)</span> where <span class="math inline">\(\eta\)</span> (the Greek letter “eta”) is the linear predictor</p>
<p><span class="math display">\[\begin{equation}
\eta = \mathbf{X}\boldsymbol{\beta} 
\end{equation}\]</span></p>
<p>GLMs are extensions of linear models. There are non-linear models that are not linear in the parameters, that is, the predictor is not a simple dot product of the model matrix and a vector of parameters. For example, the Michaelis-Menten model is a non-linear model</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y|X)  = \frac{\beta_1 X}{\beta_2 + X}
\end{equation}\]</span></p>
<p>that is non-linear in the parameters because the parts are not added together. This text covers linear models and generalized linear models, but not non-linear models that are also non-linear in the parameters.</p>
<ol start="2" style="list-style-type: decimal">
<li>The draws from the probability distribution are <strong>independent</strong>. Independence implies <strong>uncorrelated</strong> <span class="math inline">\(Y\)</span> conditional on the <span class="math inline">\(X\)</span>, that is, for any two <span class="math inline">\(Y\)</span> with the same value of <span class="math inline">\(X\)</span>, we cannot predict the value of one given the value of the other. For example, in the vole data above, uncorrelated implies that we cannot predict the lifespan of one vole within the Vitamin E treatment given the lifespan of another vole in the Vitamin E treatment. For linear models, this assumption is often stated as “independent errors” (the <span class="math inline">\(\varepsilon\)</span> in model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a>) instead of independent observations.</li>
</ol>
<p>There are lots of reasons that conditional responses might be correlated. In the vole example, perhaps the voles were housed in batches of 5 individuals, and slight differences in the environment among the housing containers, caused all the voles in some containers to have shorter lifespans than expected given their treatment assigment and all voles in other containers to have longer lifespans than expected given their treatment assigment. More generally, if there are measures both within and among experimental units (field sites or humans or rats) then we’d expect the measures within the same unit to err from the model in the same direction. Multiple measures within experimental units (a site or individual) creates “clustered” observations. Lack of independence or clustered observations can be modeled using models with <strong>random effects</strong>. These models go by many names including linear mixed models (common in Ecology), hierarchical models, multilevel models, and random effects models. A linear mixed model is a variation of model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a>. This text introduces linear mixed models in chapter xxx.</p>
<p>Measures that are taken from sites that are closer together or measures taken closer in time or measures from more closely related biological species will tend to have more similar values than measures taken from sites that are further apart or from times that are further apart or from species that are less closely related. Space and time and phylogeny create <strong>spatial and temporal and phylogenetic autocorrelation</strong>. Correlated error due to space or time or phylogeny can be modeled with <strong>Generalized Least Squares</strong> (GLS) models. A GLS model is a variation of model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a>.</p>
</div>
<div id="specific-assumptions-for-inference-with-a-linear-model" class="section level2">
<h2><span class="header-section-number">6.8</span> Specific assumptions for inference with a linear model</h2>
<ol style="list-style-type: decimal">
<li><strong>Constant variance</strong> or <strong>homoskedasticity</strong>. The most common way of thinking about this is the error term <span class="math inline">\(\varepsilon\)</span> has constant variance, which is a short way of saying that random draws of <span class="math inline">\(\varepsilon\)</span> in model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a> are all from the same (or <strong>identical</strong>) distribution. This is explicitly stated in the second line of model specification <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a>. If we were to think about this using model specification <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(6.3)</a>, then homoskedasticity means that <span class="math inline">\(\sigma\)</span> in <span class="math inline">\(N(\mu, \sigma)\)</span> is constant for all observations (or that the <em>conditional</em> probability distributions are identical, where <em>conditional</em> would mean adjusted for <span class="math inline">\(\mu\)</span>)</li>
</ol>
<p>Many biological processes generate data in which the error is a function of the mean. For example, measures of biological variables that grow, such as lengths of body parts or population size, have variances that “grow” with the mean. Or, measures of counts, such as the number of cells damaged by toxin, the number of eggs in a nest, or the number of mRNA transcripts per cell have variances that are a function of the mean. Heteroskedastic error can be modeled with <strong>Generalized Least Squares</strong>, a generalization of the linear model, and with <strong>Generalized Linear Models</strong> (GLM), which are “extensions” of the classical linear model.</p>
<ol start="2" style="list-style-type: decimal">
<li>Normal or <strong>Gaussian</strong> probability distribution. As above, the most common way of thinking about this is the error term <span class="math inline">\(\varepsilon\)</span> is Normal. Using model specification <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(6.3)</a>, we’d say the conditional probablity distribution of the response is normal. A normal probability distribution implies that 1) the response is continuous and 2) the conditional probability is symmetric around <span class="math inline">\(mu_i\)</span>. If the conditional probability distribution has a long left or right tail it is <strong>skewed</strong> left or right. Counts (number of cells, number of eggs, number of mRNA transcripts) and binary responses (sucessful escape or sucessful infestation of host) are not continuous and often often have asymmetric probablity distributions that are skewed to the right and while sometimes both can be reasonably modeled using a linear model they are more often modeled using generalized linear models, which, again, is an extension of the linear model in equation <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(6.3)</a>. A classical linear model is a specific case of a GLM.</li>
</ol>
<p>A common misconception is that inference from a linear model assumes that the <em>unconditional response</em> (this is just the response variable) is normally distributed. Both the error-draw and conditional-draw specifications of a linear model show precisely why this conception is wrong. Model <a href="an-introduction-to-statistical-modeling.html#eq:lm">(6.2)</a> states explicitly that it is the error that has the normal distribution – the distribution of <span class="math inline">\(Y\)</span> is a mix of the distribution of <span class="math inline">\(X\)</span> and the error. Model <a href="an-introduction-to-statistical-modeling.html#eq:lm-spec2">(6.3)</a> states that the conditional outcome has a normal distribution, that is, the distribution after adjusting for variation in <span class="math inline">\(X\)</span>.</p>
</div>
<div id="linear-modelregression-model-orstatistical-model" class="section level2">
<h2><span class="header-section-number">6.9</span> “linear model,”regression model“, or”statistical model"?</h2>
<p>Statistical modeling terminology can be confusing. The <span class="math inline">\(X\)</span> variables in a statistical model may be quantitative (continuous or integers) or categorical (names or qualitative amounts) or some mix of the two. Linear models with all quantitative independent variables are often called “regression models.” Linear models with all categorical independent variables are often called “ANOVA models.” Linear models with a mix of quantitative and categorical variables are often called “ANCOVA models” if the focus is on one of the categorical <span class="math inline">\(X\)</span> or “regression models” if there tend to be many independent variables.</p>
<p>This confusion partly results from the history of the development of regression for the analysis of observational data and ANOVA for the analysis of experimental data. The math underneath classical regression (without categorical variables) is the linear model. The math underneath classical ANOVA is the computation of sums of squared deviations from a group mean, or “sums of squares”. The basic output from a regression is a table of coefficients with standard errors. The basic ouput from ANOVA is an ANOVA table, containing the sums of squares along with mean-squares, <em>F</em>-ratios, and <em>p</em>-values. Because of these historical differences in usage, underlying math, and output, many textbooks in biostatistics are organized around regression “vs.” ANOVA, presenting regression as if it is “for” observational studies and ANOVA as if it is “for” experiments.</p>
<p>It has been recognized for many decades that experiments can be analyzed using the technique of classical regression if the categorical variables are coded as numbers (again, this will be explained later) and that both regression and ANOVA are variations of a more general, linear model. Despite this, the “regression vs. ANOVA” way-of-thinking dominates the teaching of biostatistics.</p>
<p>To avoid misconceptions that arise from thinking of statistical analysis as “regression vs. ANOVA”, I will use the term “linear model” as the general, umbrella term to cover everything in this book. By linear model, I mean any model that is linear in the parameters, including classical regression models, marginal models, linear mixed models, and generalized linear models. To avoid repetition, I’ll also use “statistical model”.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="part-iii-introduction-to-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="models-with-a-single-continuous-x.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/12-introduction-to-statistical-modeling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
