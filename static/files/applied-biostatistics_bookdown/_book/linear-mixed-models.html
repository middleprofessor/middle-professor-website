<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Elementary Statistical Modeling for Applied Biostatistics</title>
  <meta name="description" content="A first course in statistical modeling for biology students">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Elementary Statistical Modeling for Applied Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for biology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Elementary Statistical Modeling for Applied Biostatistics" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for biology students" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="generalized-linear-models-i-count-data.html">
<link rel="next" href="appendix-1-getting-started-with-r.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#math"><i class="fa fa-check"></i><b>0.1</b> Math</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#r-and-programming"><i class="fa fa-check"></i><b>0.2</b> R and programming</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html"><i class="fa fa-check"></i><b>1</b> Linear models as statistical models</a><ul>
<li class="chapter" data-level="1.1" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#two-specifications-of-a-linear-model-i-the-random-error-specification"><i class="fa fa-check"></i><b>1.1</b> Two specifications of a linear model I: the “random error” specification</a></li>
<li class="chapter" data-level="1.2" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#two-specifications-of-a-linear-model-ii-the-random-draw-specification"><i class="fa fa-check"></i><b>1.2</b> Two specifications of a linear model II: the “random draw” specification</a></li>
<li class="chapter" data-level="1.3" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>1.3</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="1.4" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#modeling-strategy"><i class="fa fa-check"></i><b>1.4</b> Modeling strategy</a></li>
<li class="chapter" data-level="1.5" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#model-fitting"><i class="fa fa-check"></i><b>1.5</b> Model fitting</a></li>
<li class="chapter" data-level="1.6" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#a-mean-is-the-simplest-model"><i class="fa fa-check"></i><b>1.6</b> A mean is the simplest model</a></li>
<li class="chapter" data-level="1.7" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>1.7</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="1.8" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>1.8</b> Specific assumptions for inference with a linear model</a></li>
<li class="chapter" data-level="1.9" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#statistical-model-or-regression-model"><i class="fa fa-check"></i><b>1.9</b> “Statistical model” or “regression model”?</a></li>
<li class="chapter" data-level="1.10" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#glm-vs.glm-vs.gls"><i class="fa fa-check"></i><b>1.10</b> GLM vs. GLM vs. GLS</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html"><i class="fa fa-check"></i><b>2</b> Organization – R Projects and R Notebooks</a><ul>
<li class="chapter" data-level="2.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#importing-packages"><i class="fa fa-check"></i><b>2.1</b> Importing Packages</a></li>
<li class="chapter" data-level="2.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-studio-project-for-this-class"><i class="fa fa-check"></i><b>2.2</b> Create an R Studio Project for this Class</a></li>
<li class="chapter" data-level="2.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-notebooks"><i class="fa fa-check"></i><b>2.3</b> R Notebooks</a><ul>
<li class="chapter" data-level="2.3.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-notebook-for-this-chapter"><i class="fa fa-check"></i><b>2.3.1</b> Create an R Notebook for this Chapter</a></li>
<li class="chapter" data-level="2.3.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-setup-chunk"><i class="fa fa-check"></i><b>2.3.2</b> Create a “setup” chunk</a></li>
<li class="chapter" data-level="2.3.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-simple-plot-chunk"><i class="fa fa-check"></i><b>2.3.3</b> Create a “simple plot” chunk</a></li>
<li class="chapter" data-level="2.3.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-more-r-chunks-and-explore-options-and-play-with-r-code"><i class="fa fa-check"></i><b>2.3.4</b> Create more R chunks and explore options and play with R code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html"><i class="fa fa-check"></i><b>3</b> Data – Reading, Writing, and Fake</a><ul>
<li class="chapter" data-level="3.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#create-new-notebook-for-this-chapter"><i class="fa fa-check"></i><b>3.1</b> Create new notebook for this chapter</a></li>
<li class="chapter" data-level="3.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#importing-data"><i class="fa fa-check"></i><b>3.2</b> Importing Data</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#excel-file"><i class="fa fa-check"></i><b>3.2.1</b> Excel File</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#text-file"><i class="fa fa-check"></i><b>3.2.2</b> Text File</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#creating-fake-data"><i class="fa fa-check"></i><b>3.3</b> Creating Fake Data</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#continuous-x-fake-observational-data"><i class="fa fa-check"></i><b>3.3.1</b> Continuous X (fake observational data)</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#categorical-x-fake-experimental-data"><i class="fa fa-check"></i><b>3.3.2</b> Categorical X (fake experimental data)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#saving-data"><i class="fa fa-check"></i><b>3.4</b> Saving Data</a></li>
<li class="chapter" data-level="3.5" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#problems"><i class="fa fa-check"></i><b>3.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><i class="fa fa-check"></i><b>4</b> Variability and Uncertainty (Standard Deviations and Standard Errors)</a><ul>
<li class="chapter" data-level="4.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#the-sample-standard-deviation-vs.the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#sample-standard-deviation"><i class="fa fa-check"></i><b>4.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="4.1.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#using-google-sheets-to-generate-fake-data-to-explore-uncertainty"><i class="fa fa-check"></i><b>4.2</b> Using Google Sheets to generate fake data to explore uncertainty</a><ul>
<li class="chapter" data-level="4.2.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#steps"><i class="fa fa-check"></i><b>4.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#using-r-to-generate-fake-data-to-explore-uncertainty"><i class="fa fa-check"></i><b>4.3</b> Using R to generate fake data to explore uncertainty</a><ul>
<li class="chapter" data-level="4.3.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-i"><i class="fa fa-check"></i><b>4.3.1</b> part I</a></li>
<li class="chapter" data-level="4.3.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-ii---means"><i class="fa fa-check"></i><b>4.3.2</b> part II - means</a></li>
<li class="chapter" data-level="4.3.3" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>4.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="4.3.4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>4.3.4</b> Part IV – Generating fake data with “for loops”</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#bootstrapped-standard-errors"><i class="fa fa-check"></i><b>4.4</b> Bootstrapped standard errors</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>5</b> Plotting</a><ul>
<li class="chapter" data-level="5.1" data-path="plotting.html"><a href="plotting.html#plots-should-be-the-center-of-your-papers-universe"><i class="fa fa-check"></i><b>5.1</b> Plots should be the center of your paper’s universe</a></li>
<li class="chapter" data-level="5.2" data-path="plotting.html"><a href="plotting.html#pretty-good-plots-show-the-data"><i class="fa fa-check"></i><b>5.2</b> Pretty good plots show the data</a></li>
<li class="chapter" data-level="5.3" data-path="plotting.html"><a href="plotting.html#even-better-plots"><i class="fa fa-check"></i><b>5.3</b> Even better plots…</a><ul>
<li class="chapter" data-level="5.3.1" data-path="plotting.html"><a href="plotting.html#let-interaction-plots-be-interaction-plots"><i class="fa fa-check"></i><b>5.3.1</b> Let interaction plots be interaction plots</a></li>
<li class="chapter" data-level="5.3.2" data-path="plotting.html"><a href="plotting.html#even-better-plots-continuedshow-the-model"><i class="fa fa-check"></i><b>5.3.2</b> Even better plots (continued)…Show the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html"><i class="fa fa-check"></i><b>6</b> A linear model with a single, continous <em>X</em></a><ul>
<li class="chapter" data-level="6.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#a-linear-model-with-a-single-continous-x-is-classical-regression"><i class="fa fa-check"></i><b>6.1</b> A linear model with a single, continous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="6.1.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#using-a-linear-model-to-estimate-explanatory-effects"><i class="fa fa-check"></i><b>6.1.1</b> Using a linear model to estimate explanatory effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#using-a-linear-model-for-prediction"><i class="fa fa-check"></i><b>6.1.2</b> Using a linear model for prediction</a></li>
<li class="chapter" data-level="6.1.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#reporting-results"><i class="fa fa-check"></i><b>6.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#working-in-r"><i class="fa fa-check"></i><b>6.2</b> Working in R</a><ul>
<li class="chapter" data-level="6.2.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#exploring-the-bivariate-relationship-between-y-and-x"><i class="fa fa-check"></i><b>6.2.1</b> Exploring the bivariate relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="6.2.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>6.2.2</b> Fitting the linear model</a></li>
<li class="chapter" data-level="6.2.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>6.2.3</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="6.2.4" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#display-an-alternative-to-summary"><i class="fa fa-check"></i><b>6.2.4</b> display: An alternative to summary</a></li>
<li class="chapter" data-level="6.2.5" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#confidence-intervals"><i class="fa fa-check"></i><b>6.2.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="6.2.6" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>6.2.6</b> How good is our model?</a></li>
<li class="chapter" data-level="6.2.7" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#exploring-a-lm-object"><i class="fa fa-check"></i><b>6.2.7</b> exploring a lm object</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#problems-1"><i class="fa fa-check"></i><b>6.3</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html"><i class="fa fa-check"></i><b>7</b> Least Squares Estimation and the Decomposition of Variance</a><ul>
<li class="chapter" data-level="7.1" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html#ols-regression"><i class="fa fa-check"></i><b>7.1</b> OLS regression</a></li>
<li class="chapter" data-level="7.2" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>7.2</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>8</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="8.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-is-the-engine-behind-a-single-factor-one-way-anova-and-a-t-test-is-a-special-case-of-this-model."><i class="fa fa-check"></i><b>8.1</b> A linear model with a single, categorical <em>X</em> is the engine behind a single factor (one-way) ANOVA and a t-test is a special case of this model.</a><ul>
<li class="chapter" data-level="8.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#table-of-model-coefficients"><i class="fa fa-check"></i><b>8.1.1</b> Table of model coefficients</a></li>
<li class="chapter" data-level="8.1.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#the-linear-model"><i class="fa fa-check"></i><b>8.1.2</b> The linear model</a></li>
<li class="chapter" data-level="8.1.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#reporting-results-1"><i class="fa fa-check"></i><b>8.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#working-in-r-1"><i class="fa fa-check"></i><b>8.2</b> Working in R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#exploring-the-relationship-between-y-and-x"><i class="fa fa-check"></i><b>8.2.1</b> Exploring the relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#fitting-the-model"><i class="fa fa-check"></i><b>8.2.2</b> Fitting the model</a></li>
<li class="chapter" data-level="8.2.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#an-introduction-to-contrasts"><i class="fa fa-check"></i><b>8.2.3</b> An introduction to contrasts</a></li>
<li class="chapter" data-level="8.2.4" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#harrell-plot"><i class="fa fa-check"></i><b>8.2.4</b> Harrell plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>9</b> P-values</a><ul>
<li class="chapter" data-level="9.1" data-path="p-values.html"><a href="p-values.html#p-values"><i class="fa fa-check"></i><b>9.1</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="9.2" data-path="p-values.html"><a href="p-values.html#creating-a-null-distribution."><i class="fa fa-check"></i><b>9.2</b> Creating a null distribution.</a><ul>
<li class="chapter" data-level="9.2.1" data-path="p-values.html"><a href="p-values.html#the-null-distribution"><i class="fa fa-check"></i><b>9.2.1</b> the Null Distribution</a></li>
<li class="chapter" data-level="9.2.2" data-path="p-values.html"><a href="p-values.html#t-tests"><i class="fa fa-check"></i><b>9.2.2</b> <span class="math inline">\(t\)</span>-tests</a></li>
<li class="chapter" data-level="9.2.3" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>9.2.3</b> P-values from the perspective of permutation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="p-values.html"><a href="p-values.html#statistical-modeling-instead-of-hypothesis-testing"><i class="fa fa-check"></i><b>9.3</b> Statistical modeling instead of hypothesis testing</a></li>
<li class="chapter" data-level="9.4" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>9.4</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="9.4.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>9.4.1</b> Background</a></li>
<li class="chapter" data-level="9.4.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>9.4.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <span class="math inline">\(p\)</span>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="9.4.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>9.4.3</b> Two interpretations of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="9.4.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>9.4.4</b> NHST</a></li>
<li class="chapter" data-level="9.4.5" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>9.4.5</b> Some major misconceptions of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="9.4.6" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>9.4.6</b> Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="p-values.html"><a href="p-values.html#problems-2"><i class="fa fa-check"></i><b>9.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>10</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="10.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>10.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="10.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>10.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="10.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>10.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="10.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>10.1.3</b> What about models with more than two factors?</a></li>
<li class="chapter" data-level="10.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>10.1.4</b> The additive model</a></li>
<li class="chapter" data-level="10.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts-simple-vs.main-effects"><i class="fa fa-check"></i><b>10.1.5</b> Contrasts – simple vs. main effects</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results-2"><i class="fa fa-check"></i><b>10.2</b> Reporting results</a><ul>
<li class="chapter" data-level="10.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>10.2.1</b> Text results</a></li>
<li class="chapter" data-level="10.2.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#harrellplot"><i class="fa fa-check"></i><b>10.2.2</b> Harrellplot</a></li>
<li class="chapter" data-level="10.2.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#interaction-plots"><i class="fa fa-check"></i><b>10.2.3</b> Interaction plots</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#recommendations-1"><i class="fa fa-check"></i><b>10.3</b> Recommendations</a></li>
<li class="chapter" data-level="10.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-2"><i class="fa fa-check"></i><b>10.4</b> Working in R</a></li>
<li class="chapter" data-level="10.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-3"><i class="fa fa-check"></i><b>10.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>11</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="11.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>11.1</b> Summary of usage</a></li>
<li class="chapter" data-level="11.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>11.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="11.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>11.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="11.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>11.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="11.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>11.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="11.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>11.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>11.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="11.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>11.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="11.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>11.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="11.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>11.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-3"><i class="fa fa-check"></i><b>11.5</b> Working in R</a><ul>
<li class="chapter" data-level="11.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>11.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="11.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>11.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html"><i class="fa fa-check"></i><b>12</b> Adding covariates to a linear model I: ANCOVA</a><ul>
<li class="chapter" data-level="12.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>12.1</b> Adding covariates can increases the precision of the effect of interest</a><ul>
<li class="chapter" data-level="12.1.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#interaction-effects-with-covariates"><i class="fa fa-check"></i><b>12.1.1</b> Interaction effects with covariates</a></li>
<li class="chapter" data-level="12.1.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#add-only-covariates-that-were-measured-before-peaking-at-the-data"><i class="fa fa-check"></i><b>12.1.2</b> Add only covariates that were measured before peaking at the data</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#regression-to-the-mean"><i class="fa fa-check"></i><b>12.2</b> Regression to the mean</a><ul>
<li class="chapter" data-level="12.2.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>12.2.1</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="12.2.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>12.2.2</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>13</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="13.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>13.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="13.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>13.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="13.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy-1"><i class="fa fa-check"></i><b>13.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="13.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>13.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="13.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>13.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="13.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>13.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="13.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>13.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="13.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>13.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="13.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>13.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-4"><i class="fa fa-check"></i><b>13.3</b> Working in R</a></li>
<li class="chapter" data-level="13.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-4"><i class="fa fa-check"></i><b>13.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>14</b> Linear mixed models</a><ul>
<li class="chapter" data-level="14.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>14.1</b> Random effects</a></li>
<li class="chapter" data-level="14.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>14.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="14.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>14.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="14.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-block-effects"><i class="fa fa-check"></i><b>14.4</b> Visualizing block effects</a></li>
<li class="chapter" data-level="14.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-can-increase-precision-of-point-estimates"><i class="fa fa-check"></i><b>14.5</b> Linear mixed models can increase precision of point estimates</a></li>
<li class="chapter" data-level="14.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-used-to-avoid-pseudoreplication"><i class="fa fa-check"></i><b>14.6</b> Linear mixed models are used to avoid pseudoreplication</a></li>
<li class="chapter" data-level="14.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>14.7</b> Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="14.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-5"><i class="fa fa-check"></i><b>14.8</b> Working in R</a><ul>
<li class="chapter" data-level="14.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>14.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="14.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>14.9</b> Get your computer ready</a><ul>
<li class="chapter" data-level="14.9.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>14.9.1</b> Install R</a></li>
<li class="chapter" data-level="14.9.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>14.9.2</b> Install R Studio</a></li>
<li class="chapter" data-level="14.9.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#resources-for-installing-r-and-r-studio"><i class="fa fa-check"></i><b>14.9.3</b> Resources for installing R and R Studio</a></li>
<li class="chapter" data-level="14.9.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-latex"><i class="fa fa-check"></i><b>14.9.4</b> Install LaTeX</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning"><i class="fa fa-check"></i><b>14.10</b> Start learning</a><ul>
<li class="chapter" data-level="14.10.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-with-data-camp-introduction-to-r"><i class="fa fa-check"></i><b>14.10.1</b> Start with Data Camp Introduction to R</a></li>
<li class="chapter" data-level="14.10.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#then-move-to-introduction-to-r-studio"><i class="fa fa-check"></i><b>14.10.2</b> Then Move to Introduction to R Studio</a></li>
<li class="chapter" data-level="14.10.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#develop-your-project-with-an-r-studio-notebook"><i class="fa fa-check"></i><b>14.10.3</b> Develop your project with an R Studio Notebook</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#getting-data-into-r"><i class="fa fa-check"></i><b>14.11</b> Getting Data into R</a></li>
<li class="chapter" data-level="14.12" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#additional-r-learning-resources"><i class="fa fa-check"></i><b>14.12</b> Additional R learning resources</a></li>
<li class="chapter" data-level="14.13" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#packages-used-extensively-in-this-text"><i class="fa fa-check"></i><b>14.13</b> Packages used extensively in this text</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-linear-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-linear-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Linear Modeling in R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elementary Statistical Modeling for Applied Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-mixed-models" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Linear mixed models</h1>
<div id="random-effects" class="section level2">
<h2><span class="header-section-number">14.1</span> Random effects</h2>
<p>Researchers often collect data in batches, for example</p>
<ol style="list-style-type: decimal">
<li>Researchers interested in the effects of insectivorous birds on tree seedling performance in a forest stake out ten 1 m<span class="math inline">\(^2\)</span> plots and use a wire-mesh cage to cover half of each plot.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> The cage allows insect herbivores into the seedlings inside but excludes insectivorous birds that eat the insects from the seedlings. In every plot, five seedlings are planted within the exclosure and five outside of the exclosure. At the end of the experiment, the total leaf mass is measured on all seedlings. Small, uncontrolled, environmental factors (including soil factors and density of insectivorous birds) will differ between plots but will be common to all seedlings within a plot and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the ten measures of leaf mass within a plot are not independent.</li>
<li>A nutrition researcher wants to compare the effect of glucose vs. fructose on glucose metabolism in humans. Ten individuals are recruited. Each individual has blood insulin measured 60 minutes after a noon meal over six successive days. The meal alternates between high glucose and high fructose on each day. Each individual has three measures under high glucose treatment and three measures under high fructose treatment. Small, uncontrolled, environmental factors (including metabolic variation, other meals, activity levels) will differ between the individuals but be common within an individual and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the six measures of insulin within an individual are not independent.</li>
<li>A researcher is using a mouse model to compare growth of a wildtype and engineered mutant strain of <em>Staphylococcus</em>. A small spot on both right and left forelimbs of ten mice is shaved and abraded. The two strains are randomly assigned to a side (so each mouse is infected with each strain). Small, uncontrolled, environmental factors (including immune responses) will differ between the mice but be common between the two limbs within a mouse and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the two measures of growth within a mouse are not independent.</li>
<li>An ecologist wants to measure the effect of an invasive plant on the reproduction of a native plant. They stake-out ten 2 m<span class="math inline">\(^2\)</span> plots in a forest and divide each plot into four quadrants, with each quadrant assigned a different treatment: control, activated carbon (a procedural control), extract from the invasive plant’s leaves, and both activated carbon and extract from the invasive plant’s leaves. The response is seedling count. Small, uncontrolled, environmental factors (including soil, drainage, and light) will differ between plots but will will be common to all four quadrants within a plot and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the four sets of counts within a plot are not independent.</li>
<li>An ecologist wants to measure the effect of habitat on chick growth in a bird. Five individuals nest in artifical nest boxes built on the boundary between the forest and a large, agricultural field. Five other individuals nest in boxes built deep in the interior of the forest. Chicks in each nest are weighed 13 days after hatching. Small, uncontrolled, environmental factors (including parenting, food availablity, temperature, etc.) will differ between the nests but be common within the nests and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the measures of weight within a nest are not independent.</li>
<li>A physiologists has skeletal muscle cells growing in 5 control cultures, and 5 treated cultures. The <span class="math inline">\(Y\)</span> variable is cell diameter, which is measured in 10 cells per culture. Small, uncontrolled, environmental factors (including chemical) will differ between cultures but will be common to all cells within a culture and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the ten measures of diameter within a culture are not independent.</li>
<li>A behavioral biologist wants to measure the effect of a predator fish on the preferred feeding location (open water or vegetation) of a prey fish. Ten tanks are set up with equal amounts of vegetated and unvegetated area. One-third of each tank is screened off to house a predator fish, which are added to five of the tanks. Ten prey fish are added to each tank. The response is minutes spent foraging in the open water as a fraction of total time foraging, which is measured in each fish in each tank. Small, uncontrolled, environmental factors (including temperature, water chemistry, light, and fish behavior) will differ between the tanks but be common within tanks and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the ten measures of foraging of each fish within a tank are not independent.</li>
</ol>
<p>The batches – plots in experiment 1, individuals in experiment 2, mice in experiment 3, plots in experiment 4, nests in experiment 5, cultures in experiment 6, and tanks in experiment 7 – are often referred to as <strong>blocks</strong> or <strong>clusters</strong>. I’ll generally use the term “block” in this book. The blocks are the experimental units, meaning that it is at this level that the experimenter is controlling the conditions. There is systematic variation at two levels: among treatments due to treatment effects and among blocks due to <strong>block effects</strong>. This among-block variation is the <strong>random effect</strong>. An assumption of modeling random effects is that the blocks (plots/individuals/mice/nests/cultures/tanks) are a random sample of the blocks that could have been sampled. This is often not strictly true as blocks are often <strong>convenience samples</strong>.</p>
<p>The multiple measures within a block are often called <strong>repeated measures</strong>, especially if the block is an experimental animal such as a mouse or human. If multiple measures within a treatment level within a block (that is, within a <span class="math inline">\(block \times treatment\)</span> combination) are taken over time, the data are <strong>longitudinal</strong>. Sometimes in cell biology, the subsamples within a treatment within a block are called “replicates”, as they are replicates of this <span class="math inline">\(block \times treatment\)</span> combination, but this can be confusing because the treatments are replicated at the level of the block and not at the level of the subsamples within a treatment by block combination. The blocks are the independent experimental units. Instead the multiple measures of the response within a <span class="math inline">\(block \times treatment\)</span> combination are <strong>subsamples</strong>.</p>
<p>Experiments 1 and 2 are examples of a <strong>complete randomized block with subsampling</strong> design. “Complete” means that each block has all treatment levels or combinations of levels if there is more than one factor. Experiments 3 and 4 are examples of a <strong>complete randomized block</strong> design. The blocks are complete but there is only one measure of the response per treatment. Experiments 5, 6, and 7 are examples of an <strong>incomplete randomized blocks</strong> design. The blocks are incomplete because they do not contain less than all treatment levels and combinations. In these examples, each block contains only one treatment level.</p>
</div>
<div id="random-effects-in-statistical-models" class="section level2">
<h2><span class="header-section-number">14.2</span> Random effects in statistical models</h2>
<p>In all of the above examples, the researcher is interested in the treatment effect but not the variation due to differences among the blocks. The blocks are nuissance factors that add additional variance to the response, with the consequence that estimates of treatment effects are less precise, unless the varriance due to the blocks is explicitly modeled. Including block structure in the design and in the statistical model is known as <strong>blocking</strong>. A natural way to think about the block factor is as a <strong>random effect</strong>, meaning that plots in experiment 1 or the mice in experiment 3 are simply random samples from a population of plots or mice. Modeling this using the residual-error specification looks like</p>
<span class="math display" id="eq:lmm-spec1">\[\begin{equation}
y_{ij} = (\beta_{0} + \beta_{0j}) + (\beta_{1} + \beta_{1j}) x_i + \varepsilon_i 
\tag{14.1}
\end{equation}\]</span>
<p>where <span class="math inline">\(i\)</span> indexes the observation and <span class="math inline">\(j\)</span> indexes the block (culture, plot, mouse, etc). The intercept parameter <span class="math inline">\(\beta_{0j}\)</span> is a <strong>random intercept</strong> and the slope parameter <span class="math inline">\(\beta_{1j}\)</span> is a <strong>random slope</strong>. The random intercept has a <strong>fixed</strong> component (<span class="math inline">\(\beta_0\)</span>) that is common to all observations and a random component (<span class="math inline">\(\beta_{0j}\)</span>) that is common within a block but differs among blocks (see table below). In the above equation, I’ve used parentheses to show how these combine into the random intercept that is unique for each block. Similarly, the random slope (treatment effect) has a fixed part (<span class="math inline">\(\beta_1\)</span>) that is common to all observations and a random component (<span class="math inline">\(\beta_{1j}\)</span>) that is common within a block but differs among blocks (see table below). Again, these are collected within a pair of parentheses in the equation above.</p>
<table>
<caption><span id="tab:lmm-table">Table 14.1: </span>The linear mixed model specified above estimates a fixed intercept and fixed slope (treatment effect) that are common to all observations and a random intercept and random slope for each block, each of which is common among observations within a block but differ among observations in different blocks.</caption>
<thead>
<tr class="header">
<th align="right">block</th>
<th align="left"><span class="math inline">\(b_0\)</span></th>
<th align="left"><span class="math inline">\(b_{0j}\)</span></th>
<th align="left"><span class="math inline">\(b_1\)</span></th>
<th align="left"><span class="math inline">\(b_{1j}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_{0,j=1}\)</span></td>
<td align="left"><span class="math inline">\(b_1\)</span></td>
<td align="left"><span class="math inline">\(b_{1,j=1}\)</span></td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_{0,j=2}\)</span></td>
<td align="left"><span class="math inline">\(b_1\)</span></td>
<td align="left"><span class="math inline">\(b_{1,j=2}\)</span></td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_{0,j=3}\)</span></td>
<td align="left"><span class="math inline">\(b_1\)</span></td>
<td align="left"><span class="math inline">\(b_{1,j=3}\)</span></td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_{0,j=4}\)</span></td>
<td align="left"><span class="math inline">\(b_1\)</span></td>
<td align="left"><span class="math inline">\(b_{1,j=4}\)</span></td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_{0,j=5}\)</span></td>
<td align="left"><span class="math inline">\(b_1\)</span></td>
<td align="left"><span class="math inline">\(b_{1,j=5}\)</span></td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_{0,j=6}\)</span></td>
<td align="left"><span class="math inline">\(b_1\)</span></td>
<td align="left"><span class="math inline">\(b_{1,j=6}\)</span></td>
</tr>
</tbody>
</table>
<p>Linear mixed models are called “mixed models” because they are a mix of fixed and random components. Another useful way to specify this model is to think about it hierarchically, using</p>
<span class="math display" id="eq:lmm-spec2">\[\begin{align}
y_{ij} &amp;= \beta_{0j} + \beta_{1j}x_i + \varepsilon_i \\
\varepsilon_i &amp;\sim N(0, \sigma) \\
\beta_{0j} &amp;= \beta_{0} + N(0, \sigma_{0}) \\
\beta_{1j} &amp;= \beta_{1} + N(0, \sigma_{1})
\tag{14.2}
\end{align}\]</span>
<p>The first line states that the response is a function of a block-specific intercept and a block specific slope plus some error that is unique to each observation. The third and fourth lines state that these block-specific effects are themselves a function of a common effect and a random term that is unique to each block. That is, we have a hierarchical or multi-level structure to the model. Line 1 is the top level and the effects that are specified in line 1 are a function of effects at a second, lower level, which are specified in lines 3 and 4. Because of this structure, linear mixed models are sometimes called hierarchical or multi-level models.</p>
<p>Finally, it’s useful to think how to specify a linear mixed model using the random-draw specification, as this leads naturally to generalized linear mixed models, or GLMMs.</p>
<span class="math display" id="eq:lmm-spec3">\[\begin{align}
y_{ij} &amp;\sim N(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;=\beta_{0j} + \beta_{1j}x_i \\
\beta_{0j} &amp;\sim N(\beta_0, \sigma_0) \\
\beta_{1j} &amp;\sim N(\beta_1, \sigma_1)
\tag{14.3}
\end{align}\]</span>
</div>
<div id="linear-mixed-models-are-flexible" class="section level2">
<h2><span class="header-section-number">14.3</span> Linear mixed models are flexible</h2>
<p>The linear mixed model in Equation <a href="linear-mixed-models.html#eq:lmm-spec1">(14.1)</a> specifies both a random intercept and a random slope but a researcher might limit the random effect to the intercept only, or less commonly, the slope only. Excluding the random slope from Equation <a href="linear-mixed-models.html#eq:lmm-spec1">(14.1)</a> results in the model</p>
<span class="math display" id="eq:lmm-spec1b">\[\begin{equation}
y_{ij} = (\beta_{0} + \beta_{0j}) + \beta_{1}x_i + \varepsilon_i 
\tag{14.4}
\end{equation}\]</span>
<p>We might use a random-intercept-only model if we think that features of the block would effect the mean response among blocks but not effect the difference in treatment level (or treatment effect) among blocks. For example, differences in the immune systems among the individual mice in experiment 3 might effect growth in both the wild-type and engineered strains of staph but won’t effect the difference in growth between wild-type and engineered strains from one mouse to another.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>Not more than you should know</strong> – For more complex mixed models, matrix algebra makes the specification of the model much more manageable than the scalar algebra in <a href="#lmm-spec1b"><strong>??</strong></a>.</p>
<span class="math display">\[\begin{equation}
\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \mathbf{Zu} + \boldsymbol{\varepsilon}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{y}\)</span> is the vector of the response, <span class="math inline">\(\mathbf{X}\boldsymbol{\beta}\)</span> is the linear predictor of fixed effects and <span class="math inline">\(\mathbf{Zu}\)</span> is the linear predictor of random effects. <span class="math inline">\(\mathbf{X}\)</span> is the model matrix for the fixed effects and <span class="math inline">\(\boldsymbol{\beta}\)</span> is the vector of fixed-effect terms (the fixed part of the intercept (<span class="math inline">\(\beta_0\)</span>), including the fixed-effect coefficients for each of the</p>
</div>
</div>
<div id="visualizing-block-effects" class="section level2">
<h2><span class="header-section-number">14.4</span> Visualizing block effects</h2>
<p>To visualize random effects due to block, Let’s create fake data that look something like experiments 1 or 2, with a single factor with two treatment levels, <span class="math inline">\(k=10\)</span> blocks, and <span class="math inline">\(n=3\)</span> measures for each treatment level within each block. This is a randomized complete block design with subsampling and has a total of <span class="math inline">\(N=2 \times k \times n\)</span> measures of <span class="math inline">\(Y\)</span> (and rows of the data.table).</p>
<div class="figure"><span id="fig:lmm1-sim1"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/lmm1-sim1-1.png" alt="Visualizing random effects. A) The response in the two treatment levels. B) The same data but separated by block. The blue line is at the control mean and the yellow line is at the treated mean. The black dots are the mean response within a block." width="576" />
<p class="caption">
Figure 14.1: Visualizing random effects. A) The response in the two treatment levels. B) The same data but separated by block. The blue line is at the control mean and the yellow line is at the treated mean. The black dots are the mean response within a block.
</p>
</div>
<p>Figure <a href="linear-mixed-models.html#fig:lmm1-sim1">14.1</a>A shows the response as a function of treatment. The responses are nicely symmetric around the treatment means (the blue and yellow lines). A linear model (and generalized linear models, more generally) assumes that a response, conditional on the <span class="math inline">\(X\)</span>, are independent. Figure <a href="linear-mixed-models.html#fig:lmm1-sim1">14.1</a>B shows how this assumption is violated for the simulated data. That pattern of residuals within a block around the treatment means does not look at all random. Instead, there is a distinct pattern within a block for the points to cluster either below the treatment means or above the treatment means. In blocks a, b, c, g, and h, all or most of the responses are below their treatment mean (for example in block a, all the blue points are below the blue line and 2 of 3 yellow points are below the yellow line). In blocks, e, f, i, and j, all or most of the responses are above their treatment mean (for example, in block i, all three yellow points are above the yellow line and 2 of 3 blue points are above the blue line). In other words, the responses within a block covary together. For a linear model, this is known as <strong>correlated error</strong>.</p>
</div>
<div id="linear-mixed-models-can-increase-precision-of-point-estimates" class="section level2">
<h2><span class="header-section-number">14.5</span> Linear mixed models can increase precision of point estimates</h2>
<p>Block effects are differences in expected mean response among blocks due to unmeasured factors that are shared within blocks but not among blocks. A classical linear model fails to model this component of the total variance in the response, and as a consquence, this block-specific variance becomes part of the error variance. One way to visualize this is by moving the random intercept and random slope components of equation <a href="linear-mixed-models.html#eq:lmm-spec1">(14.1)</a> to the right and combining it with the observation-specific error</p>
<span class="math display" id="eq:lmm-spec1b">\[\begin{equation}
y_{ij} = \beta_{0} + \beta_{1} x_i + (\beta_{0j} + \beta_{1j} + \varepsilon_i)
\tag{14.4}
\end{equation}\]</span>
<p>% which shows that the random effects <span class="math inline">\(\beta_{0j}\)</span> and <span class="math inline">\(\beta_{1j}\)</span> are modeled as error in a linear model. As a consequence, the residual variance is larger and, therefore, the standard errors of point estimates, including means, coefficients of the model, and contrasts from the model, are larger. Here is the table of model coefficients of the data in Figure <a href="linear-mixed-models.html#fig:lmm1-sim1">14.1</a> fitted using a classical linear model</p>
<pre><code>##               Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept) 10.0235749  0.2439544 41.08791 1.393185e-44
## TreatmentT+  0.6884787  0.3450036  1.99557 5.068466e-02</code></pre>
<p>and a linear mixed model</p>
<pre><code>##               Estimate Std. Error       df   t value     Pr(&gt;|t|)
## (Intercept) 10.0235749  0.3954692 9.000000 25.346031 1.114196e-09
## TreatmentT+  0.6884787  0.2700725 8.999999  2.549237 3.123383e-02</code></pre>
<p>The linear mixed model has increased precision (a smaller SE of the estimates) because it estimates the value of <span class="math inline">\(\beta_{0j}\)</span> and <span class="math inline">\(\beta_{1j}\)</span> for each block. The linear model does not estimate these parameters and the variance in these parameters is swept into the residual variance.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>NHST blues</strong> – A <strong>paired t-test</strong> is equivalent to the special case of a linear mixed model with a single factor with two treatment levels, <span class="math inline">\(k\)</span> blocks, and a single measure of each treatment level within each block. A good example is the wild type vs. engineered staph count in mice in experiment 3 above. A linear mixed model is much more flexible than a paired <em>t</em>-test because it allows a researcher to add treatment levels, additional factors, and covariates to the model. In addition, a linear mixed model can handle missing data.</p>
<p>Here is fake data similar in design to experiment 3 with a single factor with two treatment levels and both levels applied to the same experimental unit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2</span>)
n &lt;-<span class="st"> </span><span class="dv">10</span> <span class="co"># number of mice (blocks)</span>
x &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;WT&quot;</span>,<span class="st">&quot;T+&quot;</span>), <span class="dt">each=</span>n) <span class="co"># treatments</span>
id &lt;-<span class="st"> </span><span class="kw">rep</span>(letters[<span class="dv">1</span><span class="op">:</span>n], <span class="dv">2</span>) <span class="co"># block id</span>
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">10</span>), <span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">11</span>))
fake_data &lt;-<span class="st"> </span><span class="kw">data.table</span>(<span class="dt">Y=</span>y, <span class="dt">X=</span>x, <span class="dt">ID=</span>id)</code></pre></div>
<p>The <em>t</em>-test <em>p</em>-value is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(Y<span class="op">~</span>X, <span class="dt">data=</span>fake_data, <span class="dt">paired=</span><span class="ot">TRUE</span>)<span class="op">$</span>p.value</code></pre></div>
<pre><code>## [1] 0.05336815</code></pre>
<p>and the coefficient table of the fixed effect in the linear mixed model is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lme</span>(Y<span class="op">~</span>X, <span class="dt">random =</span> <span class="op">~</span><span class="dv">1</span><span class="op">|</span>ID, <span class="dt">correlation=</span><span class="kw">corCompSymm</span>(<span class="dt">form=</span><span class="op">~</span><span class="dv">1</span><span class="op">|</span>ID), <span class="dt">data=</span>fake_data)))</code></pre></div>
<pre><code>##                  Value Std.Error DF   t-value      p-value
## (Intercept) 11.1797704 0.3438775  9 32.510914 1.212113e-10
## XWT         -0.9686188 0.4358740  9 -2.222245 5.336815e-02</code></pre>
</div>
</div>
<div id="linear-mixed-models-are-used-to-avoid-pseudoreplication" class="section level2">
<h2><span class="header-section-number">14.6</span> Linear mixed models are used to avoid pseudoreplication</h2>
</div>
<div id="linear-mixed-models-shrink-coefficients-by-partial-pooling" class="section level2">
<h2><span class="header-section-number">14.7</span> Linear mixed models shrink coefficients by partial pooling</h2>
<p>In experiment 1 above, there are 10 sites (maybe different woodlots). In each plot, five seedlings are planted inside a cage and five outside the cage. The cage excludes insectivorous birds but not herbivorous insects. The researchers are investigating how birds affect plant growth indirectly – by eating insects that feed on the plants. The response is total leaf area in each seedling.</p>
<p>Let’s say we want to know the treatment effect in each of these sites. There are several ways of estimating this.</p>
<ol style="list-style-type: decimal">
<li><p>Fit <span class="math inline">\(k\)</span> separate models, one for each site. The intercept (control mean) and slope (treatment effect) parameters for each site are estimated independently from all other sites. Conequently, the model parameters are computed using <strong>no pooling</strong>. For the estimation of the <span class="math inline">\(\beta\)</span> terms, this is equivalent to a single, factorial linear model with <span class="math inline">\(Site\)</span> modeled as a <strong>fixed effect</strong> (this is not true for the estimate of the standard errors of these terms since these are computed from the residual sum of squares of the model. For balanced data, all of the “intercept” or “slope” terms will have the same SE in the factorial analysis but differ among the <span class="math inline">\(k\)</span> independent analyses).</p></li>
<li><p>Fit a linear model to all the data combined as if these were from a single site, and assign the intercept and treatment effect paramters to all sites. The model parameters are computed using <strong>complete pooling</strong>.</p></li>
<li><p>Fit a linear mixed model to all the data, using site as a random factor to estimate both random intercepts and slopes. Similar to the no-pooling analysis, there will be different intercept (control mean) and slope (treatment effect) estimates for each site, but unlike the no-pooling analysis, these estimates are computed by combining information from the other sites. The information used to estimate parameters in a linear mixed model is somewhere in between no pooling and complete pooling and is sometimes called <strong>partial pooling</strong>.</p></li>
</ol>
<p>The consequence of partial pooling in a linear mixed model is that site intercepts (control means) are pulled toward the single intercept in the complete-pooling analysis and the site slopes (treatment effects) are pulled toward the single slope in the complete-pooling analysis. This has the consequence that the <strong>differences</strong> in parameter estimates among sites are shrunk toward zero. A consequence of this shrinkage is that the variance of the intercept estimates or of the slope estimates is smaller than that in the no-pooling analysis. Figure <a href="#fig:lmm-partialpoolin"><strong>??</strong></a> shows this shrinkage effect using fake data simulating the seedling experiment.</p>
<div class="figure"><span id="fig:lmm-partialpooling"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/lmm-partialpooling-1.png" alt="Shrinkage estimates of the treatment effect in a linear mixed model. The grey line is the estimate using complete pooling (so there is only one estimate which is assigned to each site). In general, the partial-pooling (linear mixed model) estimates (yellow) are generally closer to the complete pooling estimate than the no-pooling (separate linear models) estimates (blue). More specifically, if the no-pooling estimate is far from the complete pooling estimate, the partial pooling estimate is *much* closer to the complete pooling estimate. The consequence of partial pooling is that the differences among the estimates are shrunk toward zero." width="576" />
<p class="caption">
Figure 14.2: Shrinkage estimates of the treatment effect in a linear mixed model. The grey line is the estimate using complete pooling (so there is only one estimate which is assigned to each site). In general, the partial-pooling (linear mixed model) estimates (yellow) are generally closer to the complete pooling estimate than the no-pooling (separate linear models) estimates (blue). More specifically, if the no-pooling estimate is far from the complete pooling estimate, the partial pooling estimate is <em>much</em> closer to the complete pooling estimate. The consequence of partial pooling is that the differences among the estimates are shrunk toward zero.
</p>
</div>
<p>The linear mixed model estimates of the treatment effects for each site are a type of <strong>shrinkage estimate</strong> and a linear mixed model is one kind of <strong>shrinkage estimator</strong>. Shrinkage estimates have fascinating properties:</p>
<ol style="list-style-type: decimal">
<li>the variance of shrinkage estimates is less than that of ordinary least squares estimates (no-pooling, or using the block as a fixed factor)</li>
<li>shrinkage estimates are <strong>biased</strong> but the OLS estimates are not. This means that the expected value of a coefficient from the linear mixed model <em>does not equal</em> the true (parameter) value! Or, more formally, <span class="math inline">\(\mathrm{E}(b_j) \ne \beta_j\)</span>.</li>
<li>the <strong>mean square error</strong> of shrinkage estimates will be smaller than that for OLS estimates.</li>
</ol>
<p>The first property was discussed above and shown in Figure <a href="linear-mixed-models.html#fig:lmm-partialpooling">14.2</a>. The second property raises the question, if we want to estimate the treatment effects within each site, why would we ever want to use <span class="math inline">\(Site\)</span> as a random instead of fixed effect? The answer is the third property, which can be summarized as, “if we were to replicate the experiment many times, the shrinkage estimates will be, on average, less wrong (or closer to the true value) than the OLS estimates, where”wrong&quot; is the absolute deviation from the true value.&quot;</p>
<p>When shrinkage estimators were first discovered, the third property surprised stasticians. The third property has profound consequences. Consider a scenario where researchers want to compare the performance of a new expression vector to that of an existing expression vector on protein production using <em>E. coli</em>. The researchers have ten different <em>E. coli</em> strains and are interested in strain-specific effects because they will choose the three strains with the largest effects for further testing. The researchers measure the response of each strain five times.</p>
<table>
<caption><span id="tab:lmm-fish-passage">Table 14.2: </span>Effect of new expression vector on protein production in ten strains of <em>E. coli</em> using a fixed effect factorial model and linear mixed model.</caption>
<thead>
<tr class="header">
<th align="left">Strain</th>
<th align="right"><span class="math inline">\(\beta_{1j}\)</span></th>
<th align="right">fixed <span class="math inline">\(b_{1j}\)</span></th>
<th align="right">random <span class="math inline">\(b_{1j}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a</td>
<td align="right">0.91</td>
<td align="right">1.07</td>
<td align="right">0.98</td>
</tr>
<tr class="even">
<td align="left">b</td>
<td align="right">0.87</td>
<td align="right">0.94</td>
<td align="right">0.85</td>
</tr>
<tr class="odd">
<td align="left">c</td>
<td align="right">0.90</td>
<td align="right">-1.03</td>
<td align="right">0.30</td>
</tr>
<tr class="even">
<td align="left">d</td>
<td align="right">0.81</td>
<td align="right">0.64</td>
<td align="right">0.63</td>
</tr>
<tr class="odd">
<td align="left">e</td>
<td align="right">1.09</td>
<td align="right">1.00</td>
<td align="right">1.07</td>
</tr>
<tr class="even">
<td align="left">f</td>
<td align="right">0.62</td>
<td align="right">0.91</td>
<td align="right">1.14</td>
</tr>
<tr class="odd">
<td align="left">g</td>
<td align="right">1.33</td>
<td align="right">2.26</td>
<td align="right">1.36</td>
</tr>
<tr class="even">
<td align="left">h</td>
<td align="right">1.27</td>
<td align="right">1.48</td>
<td align="right">0.96</td>
</tr>
<tr class="odd">
<td align="left">i</td>
<td align="right">1.61</td>
<td align="right">0.57</td>
<td align="right">1.13</td>
</tr>
<tr class="even">
<td align="left">j</td>
<td align="right">0.89</td>
<td align="right">1.50</td>
<td align="right">0.93</td>
</tr>
</tbody>
</table>
<p>The table above shows the true strain-specific effect and both the fixed (OLS) and random (LMM) effect estimates. The largest OLS estimate is 70% larger than the true effect and the strain with the largest true effect is not among the top three biggest OLS estimates (its ranking is 9/10). By contrast, the LMM estimates are closer to the true effects and the top strain is among the three largest LMM estimates.</p>
<p>These results are specific to these fake data but more generally, 1) the largest OLS estimates are inflated (larger error from the true effect), relative to the largest LMM estimates 2) overall, the LMM estimates will be closer than the OLS estimates to the true effects</p>
<p>To understand this, rank order the treatment effects for each strain. An individual strain’s position in this rank is the sum of the true effect for that strain and some random error. Because OLS, relative to shrinkage estimates, have greater variance in the estimate (that is, the random error component is bigger), the biggest effects estimated by OLS are more likely to be big because of the error component, compared to shrinkage estimates.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>Not more than you want to know</strong> – Shrinkage estimators are not only useful when we are interested in block-specific effects but are also useful for estimating effects when there are <strong>multiple responses</strong>. For example, consider a researcher interested in measuring the effects of some exercise treatment on gene expression in adipose cells. The researcher measures expression levels in 10,000 genes. Given the typical content in undergraduate biostatics courses, a researcher would probably model these responses using 10,000 <em>t</em>-tests, or equivalently, 10,000 separate linear models. If the tests were ranked by <span class="math inline">\(p\)</span>-value or absolute effect size, many of the genes with largest absolute effect would be there because of a large error component and many of the largest effects would be massively overinflated. Re-imagining the design as a single, linear mixed model with each gene modeled as a block would lead to a rank order in which the biggest measured effects more closely approximate the true effects.</p>
</div>
</div>
<div id="working-in-r-5" class="section level2">
<h2><span class="header-section-number">14.8</span> Working in R</h2>
<p>The major function for working with linear mixed models is <code>lmer()</code> from the lme4 package. An older, and still sometimes used and useful function is <code>lme()</code> from the nlme package. The authors of the lme4 package argue that the df in a linear mixed model are too approximate for a useful <span class="math inline">\(p\)</span>-value and, consequently, the <code>lme</code> function does not return a <span class="math inline">\(p\)</span>-value. Many biological researchers want a <span class="math inline">\(p\)</span>-value and typically use the <code>lmerTest</code> package to get this.</p>
<div id="coral-data" class="section level3">
<h3><span class="header-section-number">14.8.1</span> coral data</h3>
<p><strong>Source</strong> Zill, J. A., Gil, M. A., &amp; Osenberg, C. W. (2017). When environmental factors become stressors: interactive effects of vermetid gastropods and sedimentation on corals. Biology letters, 13(3), 20160957.</p>
<p><strong>Dryad source</strong> <a href="https://datadryad.org/resource/doi:10.5061/dryad.p59n8" class="uri">https://datadryad.org/resource/doi:10.5061/dryad.p59n8</a></p>
<p><strong>file name</strong> “VermetidSedimentData_ZillGilOsenberg_DRYAD.xlsx”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">folder &lt;-<span class="st"> &quot;Data from When environmental factors become stressors- interactive effects of vermetid gastropods and sedimentation on corals&quot;</span>
fn &lt;-<span class="st"> &quot;VermetidSedimentData_ZillGilOsenberg_DRYAD.xlsx&quot;</span>
sheet_i &lt;-<span class="st"> &quot;Coral Growth Rate Data&quot;</span>
file_path &lt;-<span class="st"> </span><span class="kw">paste</span>(data_path, folder, fn, <span class="dt">sep=</span><span class="st">&quot;/&quot;</span>)
coral &lt;-<span class="st"> </span><span class="kw">data.table</span>(<span class="kw">read_excel</span>(file_path, <span class="dt">sheet=</span>sheet_i))
<span class="kw">setnames</span>(coral, <span class="dt">old=</span><span class="kw">colnames</span>(coral), <span class="dt">new=</span><span class="kw">clean_label</span>(<span class="kw">colnames</span>(coral)))
coral[, Vermetids<span class="op">:</span><span class="er">=</span><span class="kw">factor</span>(Vermetids)]
coral[, Sediment<span class="op">:</span><span class="er">=</span><span class="kw">factor</span>(Sediment)]</code></pre></div>
<p><code>lmer</code> adds the random component to the formula. <code>lme</code> adds the random component as a separate argument</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># to reproduce the results</span>
<span class="co"># observation 2 should be excluded from the analysis</span>
inc &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span><span class="op">:</span><span class="kw">nrow</span>(coral))

<span class="co"># specification using lmer</span>
<span class="co"># random intercept only</span>
fit.lmer1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(GrowthRate <span class="op">~</span><span class="st"> </span>Vermetids<span class="op">*</span>Sediment <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>Block), <span class="dt">data=</span>coral[inc])
<span class="co"># random intercept and slope</span>
fit.lmer2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(GrowthRate <span class="op">~</span><span class="st"> </span>Vermetids<span class="op">*</span>Sediment <span class="op">+</span><span class="st"> </span>(Vermetids<span class="op">|</span>Block) <span class="op">+</span><span class="st"> </span>(Sediment<span class="op">|</span>Block), <span class="dt">data=</span>coral[inc])
<span class="co"># random intercept and slope</span>
fit.lmer3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(GrowthRate <span class="op">~</span><span class="st"> </span>Vermetids<span class="op">*</span>Sediment <span class="op">+</span><span class="st"> </span>(Vermetids<span class="op">|</span>Block) <span class="op">+</span><span class="st"> </span>(Sediment<span class="op">|</span>Block), <span class="dt">data=</span>coral[inc])
<span class="co"># to include the interaction as a random effect we&#39;d need subsampling within each factorial treatment combination</span>

<span class="co"># specification using lme</span>
fit.lme &lt;-<span class="st"> </span><span class="kw">lme</span>(GrowthRate <span class="op">~</span><span class="st"> </span>Vermetids<span class="op">*</span>Sediment, <span class="dt">random=</span> <span class="op">~</span><span class="dv">1</span><span class="op">|</span>Block, <span class="dt">data=</span>coral[inc])

<span class="co"># results using lmer fit</span>
<span class="kw">coefficients</span>(fit.lmer1)</code></pre></div>
<pre><code>## $Block
##    (Intercept)  Vermetids1 Sediment1 Vermetids1:Sediment1
## 1     1.205030 0.004655556 0.2852037           -0.7735482
## 2     1.336057 0.004655556 0.2852037           -0.7735482
## 3     1.213975 0.004655556 0.2852037           -0.7735482
## 4     1.262806 0.004655556 0.2852037           -0.7735482
## 6     1.320778 0.004655556 0.2852037           -0.7735482
## 7     1.201253 0.004655556 0.2852037           -0.7735482
## 8     1.314433 0.004655556 0.2852037           -0.7735482
## 9     1.199842 0.004655556 0.2852037           -0.7735482
## 10    1.361526 0.004655556 0.2852037           -0.7735482
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coefficients</span>(<span class="kw">summary</span>(fit.lmer1))</code></pre></div>
<pre><code>##                          Estimate Std. Error       df     t value
## (Intercept)           1.268411111  0.1541678 30.42810  8.22747196
## Vermetids1            0.004655556  0.2091414 22.94176  0.02226033
## Sediment1             0.285203739  0.2160141 23.53066  1.32030164
## Vermetids1:Sediment1 -0.773548184  0.3006696 23.24572 -2.57275179
##                          Pr(&gt;|t|)
## (Intercept)          3.129452e-09
## Vermetids1           9.824328e-01
## Sediment1            1.994339e-01
## Vermetids1:Sediment1 1.693478e-02</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit.emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(fit.lmer1, <span class="dt">specs=</span><span class="kw">c</span>(<span class="st">&quot;Vermetids&quot;</span>, <span class="st">&quot;Sediment&quot;</span>))
<span class="kw">summary</span>(<span class="kw">contrast</span>(fit.emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>, <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>), <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>##  contrast      estimate        SE    df   lower.CL    upper.CL t.ratio
##  1,0 - 0,0  0.004655556 0.2091414 23.04 -0.4279489  0.43725999   0.022
##  0,1 - 0,0  0.285203739 0.2167702 23.62 -0.1625690  0.73297646   1.316
##  0,1 - 1,0  0.280548184 0.2167702 23.62 -0.1672245  0.72832090   1.294
##  1,1 - 0,0 -0.483688889 0.2091414 23.04 -0.9162933 -0.05108446  -2.313
##  1,1 - 1,0 -0.488344444 0.2091414 23.04 -0.9209489 -0.05574001  -2.335
##  1,1 - 0,1 -0.768892628 0.2167702 23.62 -1.2166653 -0.32111991  -3.547
##  p.value
##   0.9824
##   0.2009
##   0.2081
##   0.0300
##   0.0286
##   0.0017
## 
## Confidence level used: 0.95</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit.lmer1.ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(GrowthRate <span class="op">~</span><span class="st"> </span>Vermetids<span class="op">*</span>Sediment <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>Block), <span class="dt">data=</span>coral[inc], <span class="dt">REML=</span><span class="ot">FALSE</span>)
<span class="co"># random intercept and slope</span>
fit.lmer3.ml &lt;-<span class="st"> </span><span class="kw">lmer</span>(GrowthRate <span class="op">~</span><span class="st"> </span>Vermetids<span class="op">*</span>Sediment <span class="op">+</span><span class="st"> </span>(Vermetids<span class="op">|</span>Block) <span class="op">+</span><span class="st"> </span>(Sediment<span class="op">|</span>Block), <span class="dt">data=</span>coral[inc], <span class="dt">REML=</span><span class="ot">FALSE</span>)

<span class="kw">AIC</span>(fit.lmer1.ml)</code></pre></div>
<pre><code>## [1] 52.80349</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(fit.lmer3.ml)</code></pre></div>
<pre><code>## [1] 61.04197</code></pre>
<p>The formula for <code>lmer</code></p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Giffard, B., Corcket, E., Barbaro, L., &amp; Jactel, H. (2012). Bird predation enhances tree seedling resistance to insect herbivores in contrasting forest habitats. Oecologia, 168(2), 415-424<a href="linear-mixed-models.html#fnref6">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models-i-count-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendix-1-getting-started-with-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/45-lmm01-blocking.Rmd",
"text": "Edit"
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
