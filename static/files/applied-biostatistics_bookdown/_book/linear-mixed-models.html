<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 18 Linear mixed models | Elements of Statistical Modeling for Experimental Biology</title>
  <meta name="description" content="A first course in statistical modeling for experimental biology researchers" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 18 Linear mixed models | Elements of Statistical Modeling for Experimental Biology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for experimental biology researchers" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 18 Linear mixed models | Elements of Statistical Modeling for Experimental Biology" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for experimental biology researchers" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="part-vii-expanding-the-linear-model.html"/>
<link rel="next" href="generalized-linear-models-i-count-data.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#math"><i class="fa fa-check"></i><b>0.1</b> Math</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#r-and-programming"><i class="fa fa-check"></i><b>0.2</b> R and programming</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-getting-started.html"><a href="part-i-getting-started.html"><i class="fa fa-check"></i>Part I: Getting Started</a></li>
<li class="chapter" data-level="1" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html"><i class="fa fa-check"></i><b>1</b> Getting Started – R Projects and R Markdown</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#r-vs-r-studio"><i class="fa fa-check"></i><b>1.1</b> R vs R Studio</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#download-and-install-r-and-r-studio"><i class="fa fa-check"></i><b>1.2</b> Download and install R and R studio</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#install-r-markdown"><i class="fa fa-check"></i><b>1.3</b> Install R Markdown</a></li>
<li class="chapter" data-level="1.4" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#importing-packages"><i class="fa fa-check"></i><b>1.4</b> Importing Packages</a></li>
<li class="chapter" data-level="1.5" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-an-r-studio-project-for-this-textbook"><i class="fa fa-check"></i><b>1.5</b> Create an R Studio Project for this textbook</a><ul>
<li class="chapter" data-level="1.5.1" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-an-r-markdown-file-for-this-chapter"><i class="fa fa-check"></i><b>1.5.1</b> Create an R Markdown file for this Chapter</a></li>
<li class="chapter" data-level="1.5.2" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-a-fake-data-chunk"><i class="fa fa-check"></i><b>1.5.2</b> Create a “fake-data” chunk</a></li>
<li class="chapter" data-level="1.5.3" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#create-a-plot-chunk"><i class="fa fa-check"></i><b>1.5.3</b> Create a “plot” chunk</a></li>
<li class="chapter" data-level="1.5.4" data-path="getting-started-r-projects-and-r-markdown.html"><a href="getting-started-r-projects-and-r-markdown.html#knit"><i class="fa fa-check"></i><b>1.5.4</b> Knit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model.html"><a href="part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model.html"><i class="fa fa-check"></i>Part II: An introduction to the analysis of experimental data with a linear model</a></li>
<li class="chapter" data-level="2" data-path="analyzing-experimental-data-with-a-linear-model.html"><a href="analyzing-experimental-data-with-a-linear-model.html"><i class="fa fa-check"></i><b>2</b> Analyzing experimental data with a linear model</a><ul>
<li class="chapter" data-level="2.1" data-path="analyzing-experimental-data-with-a-linear-model.html"><a href="analyzing-experimental-data-with-a-linear-model.html#this-text-is-about-the-estimation-of-treatment-effects-and-the-uncertainty-in-our-estimates-using-linear-models.-this-raises-the-question-what-is-an-effect"><i class="fa fa-check"></i><b>2.1</b> This text is about the estimation of treatment effects and the uncertainty in our estimates using linear models. This, raises the question, what is “an effect”?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><i class="fa fa-check"></i>Background physiology to the experiments in Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a></li>
<li class="chapter" data-level="" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><i class="fa fa-check"></i>Analyses for Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a><ul>
<li class="chapter" data-level="2.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#setup"><i class="fa fa-check"></i><b>2.2</b> Setup</a></li>
<li class="chapter" data-level="2.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#data-source"><i class="fa fa-check"></i><b>2.3</b> Data source</a></li>
<li class="chapter" data-level="2.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#control-the-color-palette"><i class="fa fa-check"></i><b>2.4</b> control the color palette</a></li>
<li class="chapter" data-level="2.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#useful-functions"><i class="fa fa-check"></i><b>2.5</b> useful functions</a></li>
<li class="chapter" data-level="2.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-effect-of-ask1-deletion-on-growth-body-weight"><i class="fa fa-check"></i><b>2.6</b> figure 2b – effect of ASK1 deletion on growth (body weight)</a><ul>
<li class="chapter" data-level="2.6.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-import"><i class="fa fa-check"></i><b>2.6.1</b> figure 2b – import</a></li>
<li class="chapter" data-level="2.6.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2b-exploratory-plots"><i class="fa fa-check"></i><b>2.6.2</b> figure 2b – exploratory plots</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-effect-of-ask1-deletion-on-final-body-weight"><i class="fa fa-check"></i><b>2.7</b> Figure 2c – Effect of ASK1 deletion on final body weight</a><ul>
<li class="chapter" data-level="2.7.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-import"><i class="fa fa-check"></i><b>2.7.1</b> Figure 2c – import</a></li>
<li class="chapter" data-level="2.7.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-own-computation-of-weight-change-v-imported-value"><i class="fa fa-check"></i><b>2.7.2</b> Figure 2c – check own computation of weight change v imported value</a></li>
<li class="chapter" data-level="2.7.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-exploratory-plots"><i class="fa fa-check"></i><b>2.7.3</b> Figure 2c – exploratory plots</a></li>
<li class="chapter" data-level="2.7.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-fit-the-model-m1-lm"><i class="fa fa-check"></i><b>2.7.4</b> Figure 2c – fit the model: m1 (lm)</a></li>
<li class="chapter" data-level="2.7.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-the-model-m1"><i class="fa fa-check"></i><b>2.7.5</b> Figure 2c – check the model: m1</a></li>
<li class="chapter" data-level="2.7.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-fit-the-model-m2-gamma-glm"><i class="fa fa-check"></i><b>2.7.6</b> Figure 2c – fit the model: m2 (gamma glm)</a></li>
<li class="chapter" data-level="2.7.7" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-check-the-model-m2"><i class="fa fa-check"></i><b>2.7.7</b> Figure 2c – check the model, m2</a></li>
<li class="chapter" data-level="2.7.8" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-inference-from-the-model"><i class="fa fa-check"></i><b>2.7.8</b> Figure 2c – inference from the model</a></li>
<li class="chapter" data-level="2.7.9" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-plot-the-model"><i class="fa fa-check"></i><b>2.7.9</b> Figure 2c – plot the model</a></li>
<li class="chapter" data-level="2.7.10" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2c-report"><i class="fa fa-check"></i><b>2.7.10</b> Figure 2c – report</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve"><i class="fa fa-check"></i><b>2.8</b> Figure 2d – Effect of ASK1 KO on glucose tolerance (whole curve)</a><ul>
<li class="chapter" data-level="2.8.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-import"><i class="fa fa-check"></i><b>2.8.1</b> Figure 2d – Import</a></li>
<li class="chapter" data-level="2.8.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-exploratory-plots"><i class="fa fa-check"></i><b>2.8.2</b> Figure 2d – exploratory plots</a></li>
<li class="chapter" data-level="2.8.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-fit-the-model"><i class="fa fa-check"></i><b>2.8.3</b> Figure 2d – fit the model</a></li>
<li class="chapter" data-level="2.8.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-check-the-model"><i class="fa fa-check"></i><b>2.8.4</b> Figure 2d – check the model</a></li>
<li class="chapter" data-level="2.8.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-inference"><i class="fa fa-check"></i><b>2.8.5</b> Figure 2d – inference</a></li>
<li class="chapter" data-level="2.8.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2d-plot-the-model"><i class="fa fa-check"></i><b>2.8.6</b> Figure 2d – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure"><i class="fa fa-check"></i><b>2.9</b> Figure 2e – Effect of ASK1 deletion on glucose tolerance (summary measure)</a><ul>
<li class="chapter" data-level="2.9.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-message-the-data"><i class="fa fa-check"></i><b>2.9.1</b> Figure 2e – message the data</a></li>
<li class="chapter" data-level="2.9.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-exploratory-plots"><i class="fa fa-check"></i><b>2.9.2</b> Figure 2e – exploratory plots</a></li>
<li class="chapter" data-level="2.9.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-fit-the-model"><i class="fa fa-check"></i><b>2.9.3</b> Figure 2e – fit the model</a></li>
<li class="chapter" data-level="2.9.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-check-the-model"><i class="fa fa-check"></i><b>2.9.4</b> Figure 2e – check the model</a></li>
<li class="chapter" data-level="2.9.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-inference-from-the-model"><i class="fa fa-check"></i><b>2.9.5</b> Figure 2e – inference from the model</a></li>
<li class="chapter" data-level="2.9.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2e-plot-the-model"><i class="fa fa-check"></i><b>2.9.6</b> Figure 2e – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate"><i class="fa fa-check"></i><b>2.10</b> Figure 2f – Effect of ASK1 deletion on glucose infusion rate</a><ul>
<li class="chapter" data-level="2.10.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-import"><i class="fa fa-check"></i><b>2.10.1</b> Figure 2f – import</a></li>
<li class="chapter" data-level="2.10.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-exploratory-plots"><i class="fa fa-check"></i><b>2.10.2</b> Figure 2f – exploratory plots</a></li>
<li class="chapter" data-level="2.10.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-fit-the-model"><i class="fa fa-check"></i><b>2.10.3</b> Figure 2f – fit the model</a></li>
<li class="chapter" data-level="2.10.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-check-the-model"><i class="fa fa-check"></i><b>2.10.4</b> Figure 2f – check the model</a></li>
<li class="chapter" data-level="2.10.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-inference"><i class="fa fa-check"></i><b>2.10.5</b> Figure 2f – inference</a></li>
<li class="chapter" data-level="2.10.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2f-plot-the-model"><i class="fa fa-check"></i><b>2.10.6</b> Figure 2f – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake"><i class="fa fa-check"></i><b>2.11</b> Figure 2g – Effect of ASK1 deletion on tissue-specific glucose uptake</a><ul>
<li class="chapter" data-level="2.11.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-import"><i class="fa fa-check"></i><b>2.11.1</b> Figure 2g – import</a></li>
<li class="chapter" data-level="2.11.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-exploratory-plots"><i class="fa fa-check"></i><b>2.11.2</b> Figure 2g – exploratory plots</a></li>
<li class="chapter" data-level="2.11.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-fit-the-model"><i class="fa fa-check"></i><b>2.11.3</b> Figure 2g – fit the model</a></li>
<li class="chapter" data-level="2.11.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-check-the-model"><i class="fa fa-check"></i><b>2.11.4</b> Figure 2g – check the model</a></li>
<li class="chapter" data-level="2.11.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-inference"><i class="fa fa-check"></i><b>2.11.5</b> Figure 2g – inference</a></li>
<li class="chapter" data-level="2.11.6" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2g-plot-the-model"><i class="fa fa-check"></i><b>2.11.6</b> Figure 2g – plot the model</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2h"><i class="fa fa-check"></i><b>2.12</b> Figure 2h</a></li>
<li class="chapter" data-level="2.13" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-effect-of-ask1-deletion-on-liver-tg"><i class="fa fa-check"></i><b>2.13</b> Figure 2i – Effect of ASK1 deletion on liver TG</a><ul>
<li class="chapter" data-level="2.13.1" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-fit-the-model"><i class="fa fa-check"></i><b>2.13.1</b> Figure 2i – fit the model</a></li>
<li class="chapter" data-level="2.13.2" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-check-the-model"><i class="fa fa-check"></i><b>2.13.2</b> Figure 2i – check the model</a></li>
<li class="chapter" data-level="2.13.3" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-inference"><i class="fa fa-check"></i><b>2.13.3</b> Figure 2i – inference</a></li>
<li class="chapter" data-level="2.13.4" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-plot-the-model"><i class="fa fa-check"></i><b>2.13.4</b> Figure 2i – plot the model</a></li>
<li class="chapter" data-level="2.13.5" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2i-report-the-model"><i class="fa fa-check"></i><b>2.13.5</b> Figure 2i – report the model</a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#figure-2j"><i class="fa fa-check"></i><b>2.14</b> Figure 2j</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html"><i class="fa fa-check"></i><b>3</b> An introduction to linear models</a><ul>
<li class="chapter" data-level="3.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#two-specifications-of-a-linear-model"><i class="fa fa-check"></i><b>3.1</b> Two specifications of a linear model</a><ul>
<li class="chapter" data-level="3.1.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#the-error-draw-specification"><i class="fa fa-check"></i><b>3.1.1</b> The “error draw” specification</a></li>
<li class="chapter" data-level="3.1.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#the-conditional-draw-specification"><i class="fa fa-check"></i><b>3.1.2</b> The “conditional draw” specification</a></li>
<li class="chapter" data-level="3.1.3" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#comparing-the-two-ways-of-specifying-the-linear-model"><i class="fa fa-check"></i><b>3.1.3</b> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables"><i class="fa fa-check"></i><b>3.2</b> A linear model can be fit to data with continuous, discrete, or categorical <span class="math inline">\(X\)</span> variables</a><ul>
<li class="chapter" data-level="3.2.1" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-continuous-or-discrete"><i class="fa fa-check"></i><b>3.2.1</b> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is continuous or discrete</a></li>
<li class="chapter" data-level="3.2.2" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-categorical"><i class="fa fa-check"></i><b>3.2.2</b> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is categorical</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>3.3</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="3.4" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#what-do-we-call-the-x-and-y-variables"><i class="fa fa-check"></i><b>3.4</b> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li class="chapter" data-level="3.5" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#modeling-strategy"><i class="fa fa-check"></i><b>3.5</b> Modeling strategy</a></li>
<li class="chapter" data-level="3.6" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#predictions-from-the-model"><i class="fa fa-check"></i><b>3.6</b> Predictions from the model</a></li>
<li class="chapter" data-level="3.7" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#inference-from-the-model"><i class="fa fa-check"></i><b>3.7</b> Inference from the model</a></li>
<li class="chapter" data-level="3.8" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>3.8</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="3.9" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>3.9</b> Specific assumptions for inference with a linear model</a></li>
<li class="chapter" data-level="3.10" data-path="an-introduction-to-linear-models.html"><a href="an-introduction-to-linear-models.html#linear-modelregression-model-orstatistical-model"><i class="fa fa-check"></i><b>3.10</b> “linear model,”regression model“, or”statistical model"?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-r-fundamentals.html"><a href="part-iii-r-fundamentals.html"><i class="fa fa-check"></i>Part III: R fundamentals</a></li>
<li class="chapter" data-level="4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html"><i class="fa fa-check"></i><b>4</b> Data – Reading, Wrangling, and Writing</a><ul>
<li class="chapter" data-level="4.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#learning-from-this-chapter"><i class="fa fa-check"></i><b>4.1</b> Learning from this chapter</a></li>
<li class="chapter" data-level="4.2" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#data-working-in-r"><i class="fa fa-check"></i><b>4.2</b> Working in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#importing-data"><i class="fa fa-check"></i><b>4.2.1</b> Importing data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#data-wrangling"><i class="fa fa-check"></i><b>4.3</b> Data wrangling</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#reshaping-data-wide-to-long"><i class="fa fa-check"></i><b>4.3.1</b> Reshaping data – Wide to long</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#reshaping-data-transpose-turning-the-columns-into-rows"><i class="fa fa-check"></i><b>4.3.2</b> Reshaping data – Transpose (turning the columns into rows)</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#combining-data"><i class="fa fa-check"></i><b>4.3.3</b> Combining data</a></li>
<li class="chapter" data-level="4.3.4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#subsetting-data"><i class="fa fa-check"></i><b>4.3.4</b> Subsetting data</a></li>
<li class="chapter" data-level="4.3.5" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#wrangling-columns"><i class="fa fa-check"></i><b>4.3.5</b> Wrangling columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#missing-data"><i class="fa fa-check"></i><b>4.3.6</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#saving-data"><i class="fa fa-check"></i><b>4.4</b> Saving data</a></li>
<li class="chapter" data-level="4.5" data-path="data-reading-wrangling-and-writing.html"><a href="data-reading-wrangling-and-writing.html#exercises"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="plotting-models.html"><a href="plotting-models.html"><i class="fa fa-check"></i><b>5</b> Plotting Models</a><ul>
<li class="chapter" data-level="5.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plots-show-the-model-and-the-data"><i class="fa fa-check"></i><b>5.1</b> Pretty good plots show the model and the data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-1-modeled-effects-plot"><i class="fa fa-check"></i><b>5.1.1</b> Pretty good plot component 1: Modeled effects plot</a></li>
<li class="chapter" data-level="5.1.2" data-path="plotting-models.html"><a href="plotting-models.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot"><i class="fa fa-check"></i><b>5.1.2</b> Pretty good plot component 2: Modeled mean and CI plot</a></li>
<li class="chapter" data-level="5.1.3" data-path="plotting-models.html"><a href="plotting-models.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><i class="fa fa-check"></i><b>5.1.3</b> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="plotting-models.html"><a href="plotting-models.html#some-comments-on-plot-components"><i class="fa fa-check"></i><b>5.2</b> Some comments on plot components</a></li>
<li class="chapter" data-level="5.3" data-path="plotting-models.html"><a href="plotting-models.html#working-in-r"><i class="fa fa-check"></i><b>5.3</b> Working in R</a><ul>
<li class="chapter" data-level="5.3.1" data-path="plotting-models.html"><a href="plotting-models.html#unpooled-se-bars-and-confidence-intervals"><i class="fa fa-check"></i><b>5.3.1</b> Unpooled SE bars and confidence intervals</a></li>
<li class="chapter" data-level="5.3.2" data-path="plotting-models.html"><a href="plotting-models.html#adding-bootstrap-intervals"><i class="fa fa-check"></i><b>5.3.2</b> Adding bootstrap intervals</a></li>
<li class="chapter" data-level="5.3.3" data-path="plotting-models.html"><a href="plotting-models.html#adding-modeled-means-and-error-intervals"><i class="fa fa-check"></i><b>5.3.3</b> Adding modeled means and error intervals</a></li>
<li class="chapter" data-level="5.3.4" data-path="plotting-models.html"><a href="plotting-models.html#adding-p-values"><i class="fa fa-check"></i><b>5.3.4</b> Adding p-values</a></li>
<li class="chapter" data-level="5.3.5" data-path="plotting-models.html"><a href="plotting-models.html#adding-custom-p-values"><i class="fa fa-check"></i><b>5.3.5</b> Adding custom p-values</a></li>
<li class="chapter" data-level="5.3.6" data-path="plotting-models.html"><a href="plotting-models.html#plotting-two-factors"><i class="fa fa-check"></i><b>5.3.6</b> Plotting two factors</a></li>
<li class="chapter" data-level="5.3.7" data-path="plotting-models.html"><a href="plotting-models.html#interaction-plot"><i class="fa fa-check"></i><b>5.3.7</b> Interaction plot</a></li>
<li class="chapter" data-level="5.3.8" data-path="plotting-models.html"><a href="plotting-models.html#plot-components"><i class="fa fa-check"></i><b>5.3.8</b> Plot components</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iv-some-fundamentals-of-statistical-modeling.html"><a href="part-iv-some-fundamentals-of-statistical-modeling.html"><i class="fa fa-check"></i>Part IV: Some Fundamentals of Statistical Modeling</a></li>
<li class="chapter" data-level="6" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><i class="fa fa-check"></i><b>6</b> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="chapter" data-level="6.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#the-sample-standard-deviation-vs.-the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>6.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="6.1.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#sample-standard-deviation"><i class="fa fa-check"></i><b>6.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="6.1.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>6.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>6.2</b> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="6.2.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#steps"><i class="fa fa-check"></i><b>6.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><i class="fa fa-check"></i><b>6.3</b> Using R to generate fake data to explore the standard error</a><ul>
<li class="chapter" data-level="6.3.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-i"><i class="fa fa-check"></i><b>6.3.1</b> part I</a></li>
<li class="chapter" data-level="6.3.2" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-ii---means"><i class="fa fa-check"></i><b>6.3.2</b> part II - means</a></li>
<li class="chapter" data-level="6.3.3" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>6.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="6.3.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>6.3.4</b> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#bootstrap"><i class="fa fa-check"></i><b>6.4</b> Bootstrapped standard errors</a><ul>
<li class="chapter" data-level="6.4.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#an-example-of-bootstrapped-standard-errors-using-vole-data"><i class="fa fa-check"></i><b>6.4.1</b> An example of bootstrapped standard errors using vole data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#confidence-interval"><i class="fa fa-check"></i><b>6.5</b> Confidence Interval</a><ul>
<li class="chapter" data-level="6.5.1" data-path="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html"><a href="variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#interpretation-of-a-confidence-interval"><i class="fa fa-check"></i><b>6.5.1</b> Interpretation of a confidence interval</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>7</b> P-values</a><ul>
<li class="chapter" data-level="7.1" data-path="p-values.html"><a href="p-values.html#a-p-value-is-the-probability-of-sampling-a-value-as-or-more-extreme-than-the-test-statistic-if-sampling-from-a-null-distribution"><i class="fa fa-check"></i><b>7.1</b> A <em>p</em>-value is the probability of sampling a value as or more extreme than the test statistic if sampling from a null distribution</a></li>
<li class="chapter" data-level="7.2" data-path="p-values.html"><a href="p-values.html#pump-your-intuition-creating-a-null-distribution"><i class="fa fa-check"></i><b>7.2</b> Pump your intuition – Creating a null distribution</a></li>
<li class="chapter" data-level="7.3" data-path="p-values.html"><a href="p-values.html#a-null-distribution-of-t-values-the-t-distribution"><i class="fa fa-check"></i><b>7.3</b> A null distribution of <em>t</em>-values – the <em>t</em> distribution</a></li>
<li class="chapter" data-level="7.4" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>7.4</b> P-values from the perspective of permutation</a></li>
<li class="chapter" data-level="7.5" data-path="p-values.html"><a href="p-values.html#parametric-vs.-non-parametric-statistics"><i class="fa fa-check"></i><b>7.5</b> Parametric vs. non-parametric statistics</a></li>
<li class="chapter" data-level="7.6" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>7.6</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="7.6.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>7.6.1</b> Background</a></li>
<li class="chapter" data-level="7.6.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>7.6.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <em>p</em>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="7.6.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>7.6.3</b> Two interpretations of the <em>p</em>-value</a></li>
<li class="chapter" data-level="7.6.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>7.6.4</b> NHST</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>7.7</b> Some major misconceptions of the <em>p</em>-value</a><ul>
<li class="chapter" data-level="7.7.1" data-path="p-values.html"><a href="p-values.html#misconception-p-is-the-probability-that-the-null-is-true-and-1-p-is-probability-that-the-alternative-is-true"><i class="fa fa-check"></i><b>7.7.1</b> Misconception: <em>p</em> is the probability that the null is true <em>and</em> <span class="math inline">\(1-p\)</span> is probability that the alternative is true</a></li>
<li class="chapter" data-level="7.7.2" data-path="p-values.html"><a href="p-values.html#misconception-a-p-value-is-repeatable"><i class="fa fa-check"></i><b>7.7.2</b> Misconception: a <em>p</em>-value is repeatable</a></li>
<li class="chapter" data-level="7.7.3" data-path="p-values.html"><a href="p-values.html#misconception-0.05-is-the-lifetime-rate-of-false-discoveries"><i class="fa fa-check"></i><b>7.7.3</b> Misconception: 0.05 is the lifetime rate of false discoveries</a></li>
<li class="chapter" data-level="7.7.4" data-path="p-values.html"><a href="p-values.html#misconception-a-low-p-value-indicates-an-important-effect"><i class="fa fa-check"></i><b>7.7.4</b> Misconception: a low <em>p</em>-value indicates an important effect</a></li>
<li class="chapter" data-level="7.7.5" data-path="p-values.html"><a href="p-values.html#misconception-a-low-p-value-indicates-high-model-fit-or-high-predictive-capacity"><i class="fa fa-check"></i><b>7.7.5</b> Misconception: a low <em>p</em>-value indicates high model fit or high predictive capacity</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="p-values.html"><a href="p-values.html#what-the-p-value-does-not-mean"><i class="fa fa-check"></i><b>7.8</b> What the <em>p</em>-value does not mean</a></li>
<li class="chapter" data-level="7.9" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>7.9</b> Recommendations</a><ul>
<li class="chapter" data-level="7.9.1" data-path="p-values.html"><a href="p-values.html#primary-sources-for-recommendations"><i class="fa fa-check"></i><b>7.9.1</b> Primary sources for recommendations</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="p-values.html"><a href="p-values.html#problems"><i class="fa fa-check"></i><b>7.10</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="errors-in-inference.html"><a href="errors-in-inference.html"><i class="fa fa-check"></i><b>8</b> Errors in inference</a><ul>
<li class="chapter" data-level="8.1" data-path="errors-in-inference.html"><a href="errors-in-inference.html#classical-nhst-concepts-of-wrong"><i class="fa fa-check"></i><b>8.1</b> Classical NHST concepts of wrong</a><ul>
<li class="chapter" data-level="8.1.1" data-path="errors-in-inference.html"><a href="errors-in-inference.html#type-i-error"><i class="fa fa-check"></i><b>8.1.1</b> Type I error</a></li>
<li class="chapter" data-level="8.1.2" data-path="errors-in-inference.html"><a href="errors-in-inference.html#power"><i class="fa fa-check"></i><b>8.1.2</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="errors-in-inference.html"><a href="errors-in-inference.html#a-non-neyman-pearson-concept-of-power"><i class="fa fa-check"></i><b>8.2</b> A non-Neyman-Pearson concept of power</a><ul>
<li class="chapter" data-level="8.2.1" data-path="errors-in-inference.html"><a href="errors-in-inference.html#estimation-error"><i class="fa fa-check"></i><b>8.2.1</b> Estimation error</a></li>
<li class="chapter" data-level="8.2.2" data-path="errors-in-inference.html"><a href="errors-in-inference.html#coverage"><i class="fa fa-check"></i><b>8.2.2</b> Coverage</a></li>
<li class="chapter" data-level="8.2.3" data-path="errors-in-inference.html"><a href="errors-in-inference.html#type-s-error"><i class="fa fa-check"></i><b>8.2.3</b> Type S error</a></li>
<li class="chapter" data-level="8.2.4" data-path="errors-in-inference.html"><a href="errors-in-inference.html#type-m-error"><i class="fa fa-check"></i><b>8.2.4</b> Type M error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-introduction-to-linear-models.html"><a href="part-v-introduction-to-linear-models.html"><i class="fa fa-check"></i>Part V: Introduction to Linear Models</a></li>
<li class="chapter" data-level="9" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html"><i class="fa fa-check"></i><b>9</b> Linear models with a single, continuous <em>X</em></a><ul>
<li class="chapter" data-level="9.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><i class="fa fa-check"></i><b>9.1</b> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="9.1.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#analysis-of-green-down-data"><i class="fa fa-check"></i><b>9.1.1</b> Analysis of “green-down” data</a></li>
<li class="chapter" data-level="9.1.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#learning-from-the-green-down-example"><i class="fa fa-check"></i><b>9.1.2</b> Learning from the green-down example</a></li>
<li class="chapter" data-level="9.1.3" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#using-a-linear-model-for-prediction-prediction-models"><i class="fa fa-check"></i><b>9.1.3</b> Using a linear model for prediction – prediction models</a></li>
<li class="chapter" data-level="9.1.4" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#using-a-linear-model-for-explanation-causal-models"><i class="fa fa-check"></i><b>9.1.4</b> Using a linear model for “explanation” – causal models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#working-in-r-1"><i class="fa fa-check"></i><b>9.2</b> Working in R</a><ul>
<li class="chapter" data-level="9.2.1" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> Fitting the linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>9.2.2</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="9.2.3" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#inference-the-coefficient-table-and-confidence-intervals"><i class="fa fa-check"></i><b>9.2.3</b> Inference – the coefficient table and Confidence intervals</a></li>
<li class="chapter" data-level="9.2.4" data-path="linear-models-with-a-single-continuous-x.html"><a href="linear-models-with-a-single-continuous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>9.2.4</b> How good is our model?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>10</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="10.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-variable-estimates-the-effect-of-x-on-the-response."><i class="fa fa-check"></i><b>10.1</b> A linear model with a single, categorical <em>X</em> variable estimates the effect of <em>X</em> on the response.</a><ul>
<li class="chapter" data-level="10.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#example-1-two-treatment-levels-groups"><i class="fa fa-check"></i><b>10.1.1</b> Example 1 – two treatment levels (“groups”)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>11</b> Model Checking</a><ul>
<li class="chapter" data-level="11.1" data-path="model-checking.html"><a href="model-checking.html#do-coefficients-make-numeric-sense"><i class="fa fa-check"></i><b>11.1</b> Do coefficients make numeric sense?</a></li>
<li class="chapter" data-level="11.2" data-path="model-checking.html"><a href="model-checking.html#all-statistical-analyses-should-be-followed-by-model-checking"><i class="fa fa-check"></i><b>11.2</b> All statistical analyses should be followed by model checking</a></li>
<li class="chapter" data-level="11.3" data-path="model-checking.html"><a href="model-checking.html#linear-model-assumptions"><i class="fa fa-check"></i><b>11.3</b> Linear model assumptions</a></li>
<li class="chapter" data-level="11.4" data-path="model-checking.html"><a href="model-checking.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><i class="fa fa-check"></i><b>11.4</b> Diagnostic plots use the residuals from the model fit</a><ul>
<li class="chapter" data-level="11.4.1" data-path="model-checking.html"><a href="model-checking.html#residuals"><i class="fa fa-check"></i><b>11.4.1</b> Residuals</a></li>
<li class="chapter" data-level="11.4.2" data-path="model-checking.html"><a href="model-checking.html#a-normal-q-q-plot-is-used-to-check-normality"><i class="fa fa-check"></i><b>11.4.2</b> A Normal Q-Q plot is used to check normality</a></li>
<li class="chapter" data-level="11.4.3" data-path="model-checking.html"><a href="model-checking.html#outliers---an-outlier-is-a-point-that-is-highly-unexpected-given-the-modeled-distribution."><i class="fa fa-check"></i><b>11.4.3</b> Outliers - an outlier is a point that is highly unexpected given the modeled distribution.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="model-checking.html"><a href="model-checking.html#model-checking-homoskedasticity"><i class="fa fa-check"></i><b>11.5</b> Model checking homoskedasticity</a></li>
<li class="chapter" data-level="11.6" data-path="model-checking.html"><a href="model-checking.html#model-checking-independence---hapiness-adverse-example."><i class="fa fa-check"></i><b>11.6</b> Model checking independence - hapiness adverse example.</a></li>
<li class="chapter" data-level="11.7" data-path="model-checking.html"><a href="model-checking.html#using-r"><i class="fa fa-check"></i><b>11.7</b> Using R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html"><i class="fa fa-check"></i><b>12</b> Model Fitting and Model Fit (OLS)</a><ul>
<li class="chapter" data-level="12.1" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#least-squares-estimation-and-the-decomposition-of-variance"><i class="fa fa-check"></i><b>12.1</b> Least Squares Estimation and the Decomposition of Variance</a></li>
<li class="chapter" data-level="12.2" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#ols-regression"><i class="fa fa-check"></i><b>12.2</b> OLS regression</a></li>
<li class="chapter" data-level="12.3" data-path="model-fitting-and-model-fit-ols.html"><a href="model-fitting-and-model-fit-ols.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>12.3</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html"><i class="fa fa-check"></i><b>13</b> Best Practices – Issues in Inference</a><ul>
<li class="chapter" data-level="13.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#power-1"><i class="fa fa-check"></i><b>13.1</b> Power</a><ul>
<li class="chapter" data-level="13.1.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#types-of-error"><i class="fa fa-check"></i><b>13.1.1</b> “Types” of Error</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing"><i class="fa fa-check"></i><b>13.2</b> multiple testing</a><ul>
<li class="chapter" data-level="13.2.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#some-background"><i class="fa fa-check"></i><b>13.2.1</b> Some background</a></li>
<li class="chapter" data-level="13.2.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#multiple-testing-working-in-r"><i class="fa fa-check"></i><b>13.2.2</b> Multiple testing – working in R</a></li>
<li class="chapter" data-level="13.2.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#false-discovery-rate"><i class="fa fa-check"></i><b>13.2.3</b> False Discovery Rate</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#difference-in-p-is-not-different"><i class="fa fa-check"></i><b>13.3</b> difference in p is not different</a></li>
<li class="chapter" data-level="13.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#inference-when-data-are-not-normal"><i class="fa fa-check"></i><b>13.4</b> Inference when data are not Normal</a><ul>
<li class="chapter" data-level="13.4.1" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#working-in-r-2"><i class="fa fa-check"></i><b>13.4.1</b> Working in R</a></li>
<li class="chapter" data-level="13.4.2" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>13.4.2</b> Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="13.4.3" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#permutation-test"><i class="fa fa-check"></i><b>13.4.3</b> Permutation test</a></li>
<li class="chapter" data-level="13.4.4" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#non-parametric-tests"><i class="fa fa-check"></i><b>13.4.4</b> Non-parametric tests</a></li>
<li class="chapter" data-level="13.4.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#log-transformations"><i class="fa fa-check"></i><b>13.4.5</b> Log transformations</a></li>
<li class="chapter" data-level="13.4.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#performance-of-parametric-tests-and-alternatives"><i class="fa fa-check"></i><b>13.4.6</b> Performance of parametric tests and alternatives</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#max-vs.-mean"><i class="fa fa-check"></i><b>13.5</b> max vs. mean</a></li>
<li class="chapter" data-level="13.6" data-path="best-practices-issues-in-inference.html"><a href="best-practices-issues-in-inference.html#pre-post-normalization"><i class="fa fa-check"></i><b>13.6</b> pre-post, normalization</a></li>
</ul></li>
<li><a href="part-vi-more-than-one-x-multivariable-models.html#part-vi-more-than-one-x-multivariable-models">Part VI: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="chapter" data-level="14" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html"><i class="fa fa-check"></i><b>14</b> Adding covariates to a linear model</a><ul>
<li class="chapter" data-level="14.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>14.1</b> Adding covariates can increases the precision of the effect of interest</a></li>
<li class="chapter" data-level="14.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-decrease-prediction-error-in-predictive-models"><i class="fa fa-check"></i><b>14.2</b> Adding covariates can decrease prediction error in predictive models</a></li>
<li class="chapter" data-level="14.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#adding-covariates-can-reduce-bias-due-to-confounding-in-explanatory-models"><i class="fa fa-check"></i><b>14.3</b> Adding covariates can reduce bias due to confounding in explanatory models</a></li>
<li class="chapter" data-level="14.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-1-a-pre-treatment-measure-of-the-response-should-be-a-covariate-and-not-subtracted-from-the-post-treatment-measure-regression-to-the-mean"><i class="fa fa-check"></i><b>14.4</b> Best practices 1: A pre-treatment measure of the response should be a covariate and not subtracted from the post-treatment measure (regression to the mean)</a><ul>
<li class="chapter" data-level="14.4.1" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-words"><i class="fa fa-check"></i><b>14.4.1</b> Regression to the mean in words</a></li>
<li class="chapter" data-level="14.4.2" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#regression-to-the-mean-in-pictures"><i class="fa fa-check"></i><b>14.4.2</b> Regression to the mean in pictures</a></li>
<li class="chapter" data-level="14.4.3" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>14.4.3</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="14.4.4" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>14.4.4</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="adding-covariates-to-a-linear-model.html"><a href="adding-covariates-to-a-linear-model.html#best-practices-2-use-a-covariate-instead-of-normalizing-a-response"><i class="fa fa-check"></i><b>14.5</b> Best practices 2: Use a covariate instead of normalizing a response</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>15</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="15.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>15.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="15.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>15.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="15.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>15.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="15.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-interpretation-of-the-coefficients-in-a-factorial-model-is-entirely-dependent-on-the-reference"><i class="fa fa-check"></i><b>15.1.3</b> The interpretation of the coefficients in a factorial model is entirely dependent on the reference…</a></li>
<li class="chapter" data-level="15.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#estimated-marginal-means"><i class="fa fa-check"></i><b>15.1.4</b> Estimated marginal means</a></li>
<li class="chapter" data-level="15.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#in-a-factorial-model-there-are-multiple-effects-of-each-factor-simple-effects"><i class="fa fa-check"></i><b>15.1.5</b> In a factorial model, there are multiple effects of each factor (simple effects)</a></li>
<li class="chapter" data-level="15.1.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects"><i class="fa fa-check"></i><b>15.1.6</b> Marginal effects</a></li>
<li class="chapter" data-level="15.1.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>15.1.7</b> The additive model</a></li>
<li class="chapter" data-level="15.1.8" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reduce-models-for-the-right-reason"><i class="fa fa-check"></i><b>15.1.8</b> Reduce models for the right reason</a></li>
<li class="chapter" data-level="15.1.9" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>15.1.9</b> What about models with more than two factors?</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results"><i class="fa fa-check"></i><b>15.2</b> Reporting results</a><ul>
<li class="chapter" data-level="15.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>15.2.1</b> Text results</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-3"><i class="fa fa-check"></i><b>15.3</b> Working in R</a><ul>
<li class="chapter" data-level="15.3.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-formula"><i class="fa fa-check"></i><b>15.3.1</b> Model formula</a></li>
<li class="chapter" data-level="15.3.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#modeled-means"><i class="fa fa-check"></i><b>15.3.2</b> Modeled means</a></li>
<li class="chapter" data-level="15.3.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-means"><i class="fa fa-check"></i><b>15.3.3</b> Marginal means</a></li>
<li class="chapter" data-level="15.3.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts"><i class="fa fa-check"></i><b>15.3.4</b> Contrasts</a></li>
<li class="chapter" data-level="15.3.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#simple-effects"><i class="fa fa-check"></i><b>15.3.5</b> Simple effects</a></li>
<li class="chapter" data-level="15.3.6" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#marginal-effects-1"><i class="fa fa-check"></i><b>15.3.6</b> Marginal effects</a></li>
<li class="chapter" data-level="15.3.7" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#plotting-results"><i class="fa fa-check"></i><b>15.3.7</b> Plotting results</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-1"><i class="fa fa-check"></i><b>15.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>16</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="16.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>16.1</b> Summary of usage</a></li>
<li class="chapter" data-level="16.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>16.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="16.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>16.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="16.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>16.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="16.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>16.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="16.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>16.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>16.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="16.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="16.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>16.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="16.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>16.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-4"><i class="fa fa-check"></i><b>16.5</b> Working in R</a><ul>
<li class="chapter" data-level="16.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>16.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="16.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="predictive-models.html"><a href="predictive-models.html"><i class="fa fa-check"></i><b>17</b> Predictive Models</a><ul>
<li class="chapter" data-level="17.1" data-path="predictive-models.html"><a href="predictive-models.html#overfitting"><i class="fa fa-check"></i><b>17.1</b> Overfitting</a></li>
<li class="chapter" data-level="17.2" data-path="predictive-models.html"><a href="predictive-models.html#model-building-vs.-variable-selection-vs.-model-selection"><i class="fa fa-check"></i><b>17.2</b> Model building vs. Variable selection vs. Model selection</a><ul>
<li class="chapter" data-level="17.2.1" data-path="predictive-models.html"><a href="predictive-models.html#stepwise-regression"><i class="fa fa-check"></i><b>17.2.1</b> Stepwise regression</a></li>
<li class="chapter" data-level="17.2.2" data-path="predictive-models.html"><a href="predictive-models.html#cross-validation"><i class="fa fa-check"></i><b>17.2.2</b> Cross-validation</a></li>
<li class="chapter" data-level="17.2.3" data-path="predictive-models.html"><a href="predictive-models.html#penalization"><i class="fa fa-check"></i><b>17.2.3</b> Penalization</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="predictive-models.html"><a href="predictive-models.html#shrinkage"><i class="fa fa-check"></i><b>17.3</b> Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-vii-expanding-the-linear-model.html"><a href="part-vii-expanding-the-linear-model.html"><i class="fa fa-check"></i>Part VII – Expanding the Linear Model</a></li>
<li class="chapter" data-level="18" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>18</b> Linear mixed models</a><ul>
<li class="chapter" data-level="18.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>18.1</b> Random effects</a></li>
<li class="chapter" data-level="18.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>18.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="18.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>18.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="18.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#blocking"><i class="fa fa-check"></i><b>18.4</b> Blocking</a><ul>
<li class="chapter" data-level="18.4.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualing-variation-due-to-blocks"><i class="fa fa-check"></i><b>18.4.1</b> Visualing variation due to blocks</a></li>
<li class="chapter" data-level="18.4.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#blocking-increases-precision-of-point-estimates"><i class="fa fa-check"></i><b>18.4.2</b> Blocking increases precision of point estimates</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#pseudoreplication"><i class="fa fa-check"></i><b>18.5</b> Pseudoreplication</a><ul>
<li class="chapter" data-level="18.5.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-pseduoreplication"><i class="fa fa-check"></i><b>18.5.1</b> Visualizing pseduoreplication</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model"><i class="fa fa-check"></i><b>18.6</b> Mapping NHST to estimation: A paired t-test is a special case of a linear mixed model</a></li>
<li class="chapter" data-level="18.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>18.7</b> Advanced topic – Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="18.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-5"><i class="fa fa-check"></i><b>18.8</b> Working in R</a><ul>
<li class="chapter" data-level="18.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>18.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>19</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="19.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>19.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="19.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>19.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="19.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy-1"><i class="fa fa-check"></i><b>19.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="19.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>19.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="19.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>19.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="19.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>19.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="19.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>19.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="19.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>19.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="19.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>19.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-6"><i class="fa fa-check"></i><b>19.3</b> Working in R</a><ul>
<li class="chapter" data-level="19.3.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-to-count-data"><i class="fa fa-check"></i><b>19.3.1</b> Fitting a GLM to count data</a></li>
<li class="chapter" data-level="19.3.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-generalized-linear-mixed-model-glmm-to-count-data"><i class="fa fa-check"></i><b>19.3.2</b> Fitting a generalized linear mixed model (GLMM) to count data</a></li>
<li class="chapter" data-level="19.3.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-generalized-linear-model-to-continouus-data"><i class="fa fa-check"></i><b>19.3.3</b> Fitting a generalized linear model to continouus data</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-2"><i class="fa fa-check"></i><b>19.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html"><i class="fa fa-check"></i><b>20</b> Linear models with heterogenous variance</a><ul>
<li class="chapter" data-level="20.1" data-path="linear-models-with-heterogenous-variance.html"><a href="linear-models-with-heterogenous-variance.html#gls"><i class="fa fa-check"></i><b>20.1</b> gls</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html"><i class="fa fa-check"></i>Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="chapter" data-level="21" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html"><i class="fa fa-check"></i><b>21</b> Plotting functions (#ggplotsci)</a><ul>
<li class="chapter" data-level="21.1" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#odd-even"><i class="fa fa-check"></i><b>21.1</b> odd-even</a></li>
<li class="chapter" data-level="21.2" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#estimate-response-and-effects-with-emmeans"><i class="fa fa-check"></i><b>21.2</b> estimate response and effects with emmeans</a></li>
<li class="chapter" data-level="21.3" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#emm_table"><i class="fa fa-check"></i><b>21.3</b> emm_table</a></li>
<li class="chapter" data-level="21.4" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#pairs_table"><i class="fa fa-check"></i><b>21.4</b> pairs_table</a></li>
<li class="chapter" data-level="21.5" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_mean_error"><i class="fa fa-check"></i><b>21.5</b> gg_mean_error</a></li>
<li class="chapter" data-level="21.6" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_ancova"><i class="fa fa-check"></i><b>21.6</b> gg_ancova</a></li>
<li class="chapter" data-level="21.7" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_mean_ci_ancova"><i class="fa fa-check"></i><b>21.7</b> gg_mean_ci_ancova</a></li>
<li class="chapter" data-level="21.8" data-path="plotting-functions-ggplotsci.html"><a href="plotting-functions-ggplotsci.html#gg_effects"><i class="fa fa-check"></i><b>21.8</b> gg_effects</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="21.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>21.9</b> Get your computer ready</a><ul>
<li class="chapter" data-level="21.9.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-here"><i class="fa fa-check"></i><b>21.9.1</b> Start here</a></li>
<li class="chapter" data-level="21.9.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>21.9.2</b> Install R</a></li>
<li class="chapter" data-level="21.9.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>21.9.3</b> Install R Studio</a></li>
<li class="chapter" data-level="21.9.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-markdown-1"><i class="fa fa-check"></i><b>21.9.4</b> Install R Markdown</a></li>
<li class="chapter" data-level="21.9.5" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#optional-alternative-latex-installations"><i class="fa fa-check"></i><b>21.9.5</b> (optional) Alternative LaTeX installations</a></li>
</ul></li>
<li class="chapter" data-level="21.10" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning-r-studio"><i class="fa fa-check"></i><b>21.10</b> Start learning R Studio</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="chapter" data-level="" data-path="appendix-3-fake-data-simulations.html"><a href="appendix-3-fake-data-simulations.html"><i class="fa fa-check"></i>Appendix 3: Fake Data Simulations</a><ul>
<li class="chapter" data-level="21.11" data-path="appendix-3-fake-data-simulations.html"><a href="appendix-3-fake-data-simulations.html#performance-of-blocking-relative-to-a-linear-model"><i class="fa fa-check"></i><b>21.11</b> Performance of Blocking relative to a linear model</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elements of Statistical Modeling for Experimental Biology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-mixed-models" class="section level1">
<h1><span class="header-section-number">Chapter 18</span> Linear mixed models</h1>
<div id="random-effects" class="section level2">
<h2><span class="header-section-number">18.1</span> Random effects</h2>
<p>Researchers often collect data in batches, for example</p>
<ol style="list-style-type: decimal">
<li>An ecologist interested in the effects of insectivorous birds on tree seedling performance in a forest stake out ten 1 m<span class="math inline">\(^2\)</span> plots and use a wire-mesh cage to cover half of each plot.<a href="appendix-3-fake-data-simulations.html#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> The cage allows insect herbivores into the seedlings inside but excludes insectivorous birds that eat the insects from the seedlings. In every plot, five seedlings are planted within the exclosure and five outside of the exclosure. At the end of the experiment, the total leaf mass is measured on each seedling. Small, uncontrolled, environmental factors (including soil factors and density of insectivorous birds) will differ between plots but will be common to all seedlings within a plot and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the ten measures of leaf mass within a plot are not independent.</li>
<li>A nutrition researcher wants to compare the effect of glucose vs. fructose on glucose metabolism in humans. Ten individuals are recruited. Each individual has blood insulin measured 60 minutes after a noon meal over six successive days. The meal alternates between high glucose and high fructose on each day. Each individual has three measures under high glucose treatment and three measures under high fructose treatment. Small, uncontrolled, environmental factors (including metabolic variation, other meals, activity levels) will differ between the individuals but be common within an individual and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the six measures of insulin within an individual are not independent.</li>
<li>An ecologist wants to measure the effect of an invasive plant on the reproduction of a native plant. They stake-out ten, 2 m<span class="math inline">\(^2\)</span> plots in a forest and divide each plot into four quadrants, with each quadrant assigned a different treatment: control, activated carbon (a procedural control), extract from the invasive plant’s leaves, and both activated carbon and extract from the invasive plant’s leaves. The response is seedling count. Small, uncontrolled, environmental factors (including soil, drainage, and light) will differ between plots but will be common to all four quadrants within a plot and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the four sets of counts within a plot are not independent.</li>
<li>A physiologist has skeletal muscle cells growing in 5 control cultures, and 5 treated cultures. The <span class="math inline">\(Y\)</span> variable is cell diameter, which is measured in 10 cells per culture. Small, uncontrolled, environmental factors (including chemical) will differ between cultures but will be common to all cells within a culture and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the ten measures of diameter within a culture are not independent.</li>
<li>A behavioral biologist wants to measure the effect of a predator fish on the preferred feeding location (open water or vegetation) of a prey fish. Ten tanks are set up with equal amounts of vegetated and unvegetated area. One-third of each tank is screened off to house a predator fish, which are added to five of the tanks. Ten prey fish are added to each tank. The response is minutes spent foraging in the open water as a fraction of total time foraging, which is measured in each fish in each tank. Small, uncontrolled, environmental factors (including temperature, water chemistry, light, and fish behavior) will differ between the tanks but be common within tanks and we would expect a common response to this uncontrolled variation on top of the differential response to each treatment. As a consequence, the ten measures of foraging of each fish within a tank are not independent.</li>
<li>A microbiologist wants to measure the effect of the microbiome on autism-spectrum-disorder(ASD)-like behavior in mice<a href="appendix-3-fake-data-simulations.html#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. Intestinal microbobial communities from five humans with ASD and five humans without ASD are transferred to germ-free mice via fecal transplant. Each human donor is used to colonize three mice. The response is time socializing in a direct social interaction. Uncontrolled features of each microbial community (species composition and proportions) will differ among human donors but will be the same within human donors and we would expect a common response to this uncontrolled variation in addition to any differential response to ASD-associated microbiota. As a consequence, the measures of behavior in the three mice within a donor group are not independent.</li>
</ol>
<p>The batches – plots in experiment 1, individuals in experiment 2, plots in experiment 3, cultures in experiment 4, tanks in experiment 5, and mice in experiment 6 – are the experimental units, meaning that it is at this level that the experimenter is controlling the conditions. In each of these studies, there is systematic variation at two levels: among treatments due to treatment effects and among batches due to <strong>batch effects</strong>. This among-batch variation is the <strong>random effect</strong>. An assumption of modeling random effects is that the batches (plots/individuals/cultures/tanks/donor) are a random sample of the batches that could have been sampled. This is often not strictly true as batches are often <strong>convenience samples</strong>.</p>
<p>The multiple measures within a batch are <strong>subsamples</strong> but are often called <strong>repeated measures</strong> if the batch is an individual (experiment 2 is an example). If multiple measures within a treatment level within a batch (that is, within a <span class="math inline">\(batch \times treatment\)</span> combination) are taken over time, the data are <strong>longitudinal</strong>. Not infrequently, subsamples within a treatment within a batch are called “replicates”, but this can be confusing because the treatments are replicated at the level of the batch and not at the level of the subsamples within a treatment by batch combination. The batches are the independent experimental units. The subsamples within a batch are not replicates.</p>
<p>The variation among batches/lack of independence within batches has different consequences on the uncertainty of the estimate of a treatment effect. The batches in experiments 1-3 are similar in that each contains all treatment levels. In these, the researcher is interested in the treatment effect but not the variation due to differences among the batches. The batches are nuissance factors that add additional variance to the response, with the consequence that estimates of treatment effects are less precise, unless the variance due to the batches is explicitly modeled. In experiments like 1-3, the batches are known as <strong>blocks</strong>. Including block structure in the design is known as <strong>blocking</strong>. Adding a blocking factor to a statistical mode is used to increase the precision of an estimated treatment effect.</p>
<p>Experiments 1 and 2 are examples of a <strong>randomized complete block with subsampling</strong> design. “Complete” means that each block has all treatment levels or combinations of levels if there is more than one factor. <em>The subsampling is not replication</em>. The replicates are the blocks, because <em>it was at this level that treatment assignment was randomized</em>. Experiment 3 is an example of a <strong>randomized complete block</strong> design. The blocks are complete but there is only one measure of the response per treatment.</p>
<p>The batches in experiments 4-6 are similar in that treatment is randomized <em>to</em> batch, so each batch contains only a single treatment level. In these <strong>segregated</strong> experimental designs, the variation among batches that arises from non-treatment related differences among batches <strong>confounds</strong> the variation among batches due to a true treatment effect. An extreme example of this would be experiment 4 (muscle cell cultures) with only a single culture with control conditions and a single culture with treatment conditions. Imagine 1) the true effect of the treatment is zero and 2) an unmeasured growth factor that happens to be more concentrated in the treatment culture at the beginning of the experiment. At the end of the experiment the cells in the treatment culture have an average diameter twice that of that in the control culture. The researcher is fooled into thinking that the treatment caused the increased growth. Again, the replicates are at the level of the cultures, because it was at this level that treatment assignment was randomized. This means the researcher has a single replicate (or, <span class="math inline">\(n=1\)</span>) in each treatment level, regardless of the number of cells that are measured within each culture. A statistical analysis that uses the subsampling within a replicate as the sample size is an example of <strong>pseudoreplication</strong> (Hurlbert 1984 xxx).</p>
</div>
<div id="random-effects-in-statistical-models" class="section level2">
<h2><span class="header-section-number">18.2</span> Random effects in statistical models</h2>
<p>In all of the above examples, the researcher is interested in the treatment effect but not the variation due to differences among the blocks. The blocks are nuissance factors that add additional variance to the response, with the consequence that estimates of treatment effects are less precise, unless the variance due to the blocks is explicitly modeled. Including block structure in the design and in the statistical model is known as <strong>blocking</strong>. A natural way to think about the block factor is as a <strong>random effect</strong>, meaning that plots in experiment 1 or the mice in experiment 3 are simply random samples from a population of plots or mice. Modeling this using the residual-error specification looks like</p>
<p><span class="math display" id="eq:lmm-spec1">\[\begin{equation}
y_{ij} = (\beta_{0} + \beta_{0j}) + (\beta_{1} + \beta_{1j}) x_i + \varepsilon_i 
\tag{18.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(i\)</span> indexes the observation and <span class="math inline">\(j\)</span> indexes the block (culture, plot, mouse, etc). The intercept parameter <span class="math inline">\(\beta_{0j}\)</span> is a <strong>random intercept</strong> and the slope parameter <span class="math inline">\(\beta_{1j}\)</span> is a <strong>random slope</strong>. The intercept for observation <em>i</em> (that is, its expected value when <span class="math inline">\(X=0\)</span>) has a <strong>fixed</strong> component (<span class="math inline">\(\beta_0\)</span>) that is common to all observations and a random component (<span class="math inline">\(\beta_{0j}\)</span>) that is common within a block but differs among blocks (see table below). In the above equation, I’ve used parentheses to show how these combine into the random intercept that is unique for each block. Similarly, the random slope (treatment effect) has a fixed part (<span class="math inline">\(\beta_1\)</span>) that is common to all observations and a random component (<span class="math inline">\(\beta_{1j}\)</span>) that is common within a block but differs among blocks (see table below). Again, these are collected within a pair of parentheses in the equation above.</p>
<table>
<caption>
<span id="tab:lmm-table">Table 18.1: </span>The linear mixed model specified above estimates a fixed intercept and fixed slope (treatment effect) that are common to all observations and a random intercept and random slope for each block, each of which is common among observations within a block but differ among observations in different blocks.
</caption>
<thead>
<tr>
<th style="text-align:right;">
block
</th>
<th style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(b_{0j}\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(b_{1j}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{0,j=1}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{1,j=1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{0,j=2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{1,j=2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{0,j=3}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{1,j=3}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{0,j=4}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{1,j=4}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{0,j=5}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{1,j=5}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
<span class="math inline">\(b_0\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{0,j=6}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(b_{1,j=6}\)</span>
</td>
</tr>
</tbody>
</table>
<p>Linear mixed models are called “mixed models” because they are a mix of fixed and random factors. Another useful way to specify this model is to think about it hierarchically, using</p>
<p><span class="math display" id="eq:lmm-spec2">\[\begin{align}
y_{ij} &amp;= \beta_{0j} + \beta_{1j}x_i + \varepsilon_i \\
\varepsilon_i &amp;\sim N(0, \sigma) \\
\beta_{0j} &amp;= \beta_{0} + N(0, \sigma_{0}) \\
\beta_{1j} &amp;= \beta_{1} + N(0, \sigma_{1})
\tag{18.2}
\end{align}\]</span></p>
<p>The first line states that the response is a function of a block-specific intercept and a block specific slope plus some error that is unique to each observation. The third and fourth lines state that these block-specific effects are themselves a function of a common effect and a random term that is unique to each block. That is, we have a hierarchical or multi-level structure to the model. Line 1 is the top level and the effects that are specified in line 1 are a function of effects at a second, lower level, which are specified in lines 3 and 4. Because of this structure, linear mixed models are sometimes called hierarchical or multi-level models.</p>
<p>Finally, it’s useful to think how to specify a linear mixed model using the random-draw specification, as this leads naturally to generalized linear mixed models, or GLMMs.</p>
<p><span class="math display" id="eq:lmm-spec3">\[\begin{align}
y_{ij} &amp;\sim N(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;=\beta_{0j} + \beta_{1j}x_i \\
\beta_{0j} &amp;\sim N(\beta_0, \sigma_0) \\
\beta_{1j} &amp;\sim N(\beta_1, \sigma_1)
\tag{18.3}
\end{align}\]</span></p>
</div>
<div id="linear-mixed-models-are-flexible" class="section level2">
<h2><span class="header-section-number">18.3</span> Linear mixed models are flexible</h2>
<p>The linear mixed model in Equation <a href="linear-mixed-models.html#eq:lmm-spec1">(18.1)</a> specifies both a random intercept and a random slope but a researcher might limit the random effect to the intercept only, or less commonly, the slope only. Excluding the random slope from Equation <a href="linear-mixed-models.html#eq:lmm-spec1">(18.1)</a> results in the model</p>
<p><span class="math display" id="eq:lmm-spec1b">\[\begin{equation}
y_{ij} = (\beta_{0} + \beta_{0j}) + \beta_{1}x_i + \varepsilon_i 
\tag{18.4}
\end{equation}\]</span></p>
<p>We might use a random-intercept-only model if we think that features of the block would effect the mean response among blocks but not effect the difference in treatment level (or treatment effect) among blocks. For example, differences in the immune systems among the individual mice in experiment 3 might effect growth in both the wild-type and engineered strains of staph but won’t effect the difference in growth between wild-type and engineered strains from one mouse to another.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>Not more than you should know</strong> – For more complex mixed models, matrix algebra makes the specification of the model much more manageable than the scalar algebra in <a href="#lmm-spec1b"><strong>??</strong></a>.</p>
<p><span class="math display">\[\begin{equation}
\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \mathbf{Zu} + \boldsymbol{\varepsilon}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathbf{y}\)</span> is the vector of the response, <span class="math inline">\(\mathbf{X}\boldsymbol{\beta}\)</span> is the linear predictor of fixed effects and <span class="math inline">\(\mathbf{Zu}\)</span> is the linear predictor of random effects. <span class="math inline">\(\mathbf{X}\)</span> is the model matrix for the fixed effects and <span class="math inline">\(\boldsymbol{\beta}\)</span> is the vector of fixed-effect terms (the fixed part of the intercept (<span class="math inline">\(\beta_0\)</span>), including the fixed-effect coefficients for each of the</p>
</div>
</div>
<div id="blocking" class="section level2">
<h2><span class="header-section-number">18.4</span> Blocking</h2>
<div id="visualing-variation-due-to-blocks" class="section level3">
<h3><span class="header-section-number">18.4.1</span> Visualing variation due to blocks</h3>
<p>To visualize random effects due to block, Let’s create fake data that look something like experiment 1, with a single factor with two treatment levels, <span class="math inline">\(k=10\)</span> blocks, and <span class="math inline">\(n=3\)</span> measures for each treatment level within each block. This is a randomized complete block design with subsampling and has a total of <span class="math inline">\(N=2 \times k \times n\)</span> measures of <span class="math inline">\(Y\)</span> (and rows of the data.table).</p>
<div class="figure"><span id="fig:lmm1-blocking-fig"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/lmm1-blocking-fig-1.png" alt="Visualizing random effects. A) The response in the two treatment levels. B) The same data but separated by block. The blue line is at the control mean and the yellow line is at the treated mean. The black dots are the mean response within a block." width="576" />
<p class="caption">
Figure 18.1: Visualizing random effects. A) The response in the two treatment levels. B) The same data but separated by block. The blue line is at the control mean and the yellow line is at the treated mean. The black dots are the mean response within a block.
</p>
</div>
<p>Figure <a href="linear-mixed-models.html#fig:lmm1-blocking-fig">18.1</a>A shows the response as a function of treatment. The responses are nicely symmetric around the treatment means (the blue and yellow lines). A linear model (and generalized linear models, more generally) assumes that a response, conditional on the <span class="math inline">\(X\)</span>, are independent. Figure <a href="linear-mixed-models.html#fig:lmm1-blocking-fig">18.1</a>B shows how this assumption is violated for the simulated data. That pattern of residuals within a block around the treatment means does not look at all random. Instead, there is a distinct pattern within a block for the points to cluster either below the treatment means or above the treatment means. In blocks a, b, g, and i, all or most of the responses are below their treatment mean (for example in block b, all the yellow points are below the yellow line and two of three blue points are below the blue line). In blocks d, e, f, and j, all or most of the responses are above their treatment mean (for example, in block e, all three yellow points are above the yellow line and all three blue points are above the blue line). In other words, the responses within a block covary together. For a linear model, this is known as <strong>correlated error</strong>.</p>
</div>
<div id="blocking-increases-precision-of-point-estimates" class="section level3">
<h3><span class="header-section-number">18.4.2</span> Blocking increases precision of point estimates</h3>
<p>Block effects are differences in expected mean response among blocks due to unmeasured factors that are shared within blocks but not among blocks. A classical linear model fails to model this component of the total variance in the response, and as a consequence, this block-specific variance is part of the error variance. One way to think about this is by moving the random intercept and random slope components of equation <a href="linear-mixed-models.html#eq:lmm-spec1">(18.1)</a> to the right and combining it with the observation-specific (or “conditional”) error (<span class="math inline">\(\varepsilon_i\)</span>)</p>
<p><span class="math display" id="eq:lmm-spec1b">\[\begin{equation}
y_{ij} = \beta_{0} + \beta_{1} x_i + (\beta_{0j} + \beta_{1j} + \varepsilon_i)
\tag{18.4}
\end{equation}\]</span></p>
<p>A linear mixed model estimates the random effects parameters, so the residual from observation <span class="math inline">\(i\)</span> is <span class="math inline">\(\varepsilon_i\)</span>. A linear model does not estimate the random effects parameters, so the residual of observation <span class="math inline">\(i\)</span> from a linear model is <span class="math inline">\(\beta_{0j} + \beta_{1j} + \varepsilon_i\)</span>. Consequently, the error variance from a linear model is larger than the error variance from a linear mixed model fit to the same data. The consequence of this on inference depends on the variance of the random effects relative to the variance of the observation-specific error and on the subsample size. If the variance due to random effects is relatively big and subsample size is relatively small, then a linear mixed model estimates treatment effects with much more precision (and <em>p</em>-values will be smaller).</p>
<p>This increased precision is seen in the coefficient table of three models fit to the fake data in Figure <a href="linear-mixed-models.html#fig:lmm1-blocking-fig">18.1</a>.</p>
A linear model fit to all data
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.62441
</td>
<td style="text-align:right;">
0.3566
</td>
<td style="text-align:right;">
1.75
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
-0.089
</td>
<td style="text-align:right;">
1.338
</td>
</tr>
</tbody>
</table>
A linear model fit to the means of each treatment level with each block
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.62441
</td>
<td style="text-align:right;">
0.54713
</td>
<td style="text-align:right;">
1.14
</td>
<td style="text-align:right;">
0.269
</td>
<td style="text-align:right;">
-0.525
</td>
<td style="text-align:right;">
1.774
</td>
</tr>
</tbody>
</table>
A linear mixed model with both a random intercept and random slope fit to all data
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.62441
</td>
<td style="text-align:right;">
0.26995
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
1.154
</td>
</tr>
</tbody>
</table>
<p>Note that the estimates of treatment effect do not differ among models. What does differ is the estimated standard error of the treatment effect, which is 24% smaller in the linear mixed model relative to that in the linear model, and 51% smaller in the linear mixed model relative to that in the linear model fit to the block means. This difference in SE propogates to the confidence intervals and <em>p</em>-values.</p>
<p>Let’s explore this a wee bit more systematically using a simple, Monte Carlo simulation experiment. 5000 fake data sets were generated. Each data set simulated an experiment with a single treatment factor with two levels (“control” and “treatment”). The design is a randomized complete block with subsampling. There are 8 blocks and 3 subsamples in each treatment level per block. The treatment effect (<span class="math inline">\(\beta_1\)</span>) is 1. The observation-specific (or “within-block”) variance (<span class="math inline">\(\sigma^2_{varepsilon}\)</span>) is 1. The (“among-block”) variance of the random intercept (<span class="math inline">\(\sigma^2_{\beta_0j}\)</span>) is 1 – the same as the the within-block variance. The variance variance of the random slope (<span class="math inline">\(\sigma^2_{\beta_1j}\)</span>), which is due to a variable response of the treatment among blocks, is <span class="math inline">\(0.1^2\)</span>).</p>
<p>The following three models were fit to all 5000 data sets</p>
<ol style="list-style-type: decimal">
<li>a linear model fit to all data, ignoring blocks (violating the independence assumption)</li>
<li>a linear model fit to the treatment means of the blocks (valid, but throwing out data)</li>
<li>a linear mixed model that models the random intercept<a href="appendix-3-fake-data-simulations.html#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>.</li>
</ol>
<p>From each fit, I saved the 95% confidence interval of the treatment effect and the <em>p</em>-value. The median width of the confidence interval and the power, which is the relative frequency of <em>p</em>-values less than 0.05. The simulation was re-run using the same parameters except setting the treatment effect (<span class="math inline">\(\beta_1\)</span>) to 0. In this new simulation, the relative frequency of <em>p</em>-values less than 0.05 is the Type I error.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
CI width
</th>
<th style="text-align:right;">
Power
</th>
<th style="text-align:right;">
Type I
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<ol style="list-style-type: decimal">
<li>lm
</td>
<td style="text-align:right;">
1.58
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.012
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="2" style="list-style-type: decimal">
<li>lm of means
</td>
<td style="text-align:right;">
2.39
</td>
<td style="text-align:right;">
0.31
</td>
<td style="text-align:right;">
0.002
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="3" style="list-style-type: decimal">
<li>lmm b0j
</td>
<td style="text-align:right;">
1.16
</td>
<td style="text-align:right;">
0.92
</td>
<td style="text-align:right;">
0.051
</td>
</tr>
</tbody>
</table></li>
</ol></li>
</ol></li>
</ol>
<p>For data similar to that simulated, the linear mixed model using a blocking factor has much more power than the linear model ignoring block (and ignoring the lack of independence) or the linear model comparing the treatment level means of the blocks. This lost power in the two linear models is due to the conservative Type I error rate (extreme in the case of the linear model of the group means). One take-home lesson here is, don’t throw away perfectly good data if the design of the experiment includes a blocking factor!</p>
</div>
</div>
<div id="pseudoreplication" class="section level2">
<h2><span class="header-section-number">18.5</span> Pseudoreplication</h2>
<div id="visualizing-pseduoreplication" class="section level3">
<h3><span class="header-section-number">18.5.1</span> Visualizing pseduoreplication</h3>
<p>Subsamples from batches are not replicates. Inference from a model fit to subsampled observations without modeling the batches is called pseudoreplication, a term famously coined by Hurlbert (1984). For data from a randomized complete block design, ignoring the batches in the model will typically result in larger standard errors, wider confidence intervals, and too conservative <em>p</em>-values. In a segregated experiment, with only a single treatment level per batch (like that in experiments 4-6 above), ignoring the lack of independence in the model has the opposite effect. Standard errors are too small. Confidence intervals are too narrow. <em>P</em>-values are too liberal. Type I error is inflated. Let’s visualize a pseudoreplicated data set like this.</p>
<div class="figure"><span id="fig:lmm1-pseudoreplication-fig"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/lmm1-pseudoreplication-fig-1.png" alt="A data set in which treatment and batch are confounded because there is only one treatment level per batch." width="576" />
<p class="caption">
Figure 18.2: A data set in which treatment and batch are confounded because there is only one treatment level per batch.
</p>
</div>
<p>This consequence of pseudoreplication when batch and treatment are confounded is seen in the coefficient table of four models fit to the fake data in Figure <a href="linear-mixed-models.html#fig:lmm1-pseudoreplication-fig">18.2</a>.</p>
<strong>A linear model fit to all data (pseudoreplication).</strong>
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.7175
</td>
<td style="text-align:right;">
0.31278
</td>
<td style="text-align:right;">
2.29
</td>
<td style="text-align:right;">
0.025
</td>
<td style="text-align:right;">
0.091
</td>
<td style="text-align:right;">
1.344
</td>
</tr>
</tbody>
</table>
<strong>A linear model fit the batch means.</strong>
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.7175
</td>
<td style="text-align:right;">
0.51803
</td>
<td style="text-align:right;">
1.39
</td>
<td style="text-align:right;">
0.238
</td>
<td style="text-align:right;">
-0.721
</td>
<td style="text-align:right;">
2.156
</td>
</tr>
</tbody>
</table>
<strong>A linear mixed model with both random intercept and random slope.</strong>
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.7175
</td>
<td style="text-align:right;">
0.51797
</td>
<td style="text-align:right;">
1.39
</td>
<td style="text-align:right;">
3.32
</td>
<td style="text-align:right;">
0.252
</td>
<td style="text-align:right;">
-0.298
</td>
<td style="text-align:right;">
1.733
</td>
</tr>
</tbody>
</table>
<strong>A linear mixed model with random intercept.</strong>
<table>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
TreatmentTr
</td>
<td style="text-align:right;">
0.7175
</td>
<td style="text-align:right;">
0.51803
</td>
<td style="text-align:right;">
1.39
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.238
</td>
<td style="text-align:right;">
-0.298
</td>
<td style="text-align:right;">
1.733
</td>
</tr>
</tbody>
</table>
<p>As with the blocked design, all models compute the same estimate of the treatment effect. But in contrast to the blocked design, in this confounded design, the standard error of the treatment effect is smaller in the linear model of all data than that of the linear mixed models. This increased precision is an illusion because the model fails to account for the lack of independence within the batches.</p>
<p>One interesting result to note is the equivalence of the standard error, test statistic, <em>p</em>-value, and confidence intervals of the linear model on the batch means and the linear mixed model with a random intercept (but no random slope) only. The two are equivalent. Murtaugh (xxx) has argued that with this kind of design, it is much simpler to the analyst, and to your audience, to simply use the linear model on the batch means. This raises the question, why bother with subsampling within batch? One answer is, subsampling increases the precision of the batch mean, and therefore, the precision of the treatment effect. That said, <em>the precision of a treatment effect is increased more efficiently by adding more replicates (more batches), not more subsamples</em>.</p>
<p>Let’s explore the consequence of pseudoreplication with a confounded with a Monte Carlo simulation experiment. 5000 fake data sets were generated. Each data set simulated an experiment with a single treatment factor with two levels (“control” and “treatment”). The design is treatment level randomized to batch (only one treatment level per batch). There are 8 batches and 3 subsamples in each batch. The treatment effect (<span class="math inline">\(\beta_1\)</span>) is zero. The observation-specific (or “within-block”) variance (<span class="math inline">\(\sigma^2_{varepsilon}\)</span>) is 1. The (“among-block”) variance of the random intercept (<span class="math inline">\(\sigma^2_{\beta_0j}\)</span>) is 1 – the same as the the within-block variance. The variance variance of the random slope (<span class="math inline">\(\sigma^2_{\beta_1j}\)</span>), which is due to a variable response of the treatment among blocks, is <span class="math inline">\(0.1^2\)</span>).</p>
<p>Because the effect is zero, the frequency of <em>p</em>-values less than 0.05 is the type I error. The same three models fit to the simulated blocked data are fit to these data. I don’t simulate an effect in order to compute power (at that effect size) because the increased power in the linear model of all data is, again, an illusion. It only comes at the cost of strongly elevated Type I error.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
CI width
</th>
<th style="text-align:right;">
Type I
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<ol style="list-style-type: decimal">
<li>lm
</td>
<td style="text-align:right;">
2.22
</td>
<td style="text-align:right;">
0.18
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="2" style="list-style-type: decimal">
<li>lm of means
</td>
<td style="text-align:right;">
3.80
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
<tr>
<td style="text-align:left;">
<ol start="3" style="list-style-type: decimal">
<li>lmm b0j
</td>
<td style="text-align:right;">
3.80
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
</tbody>
</table></li>
</ol></li>
</ol></li>
</ol>
<p>When treatment level is randomized <em>to</em> batch, the type I error rate of a linear model fit to all data (and ignoring the lack of independence) is highly inflated. Don’t do this.</p>
</div>
</div>
<div id="mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model" class="section level2">
<h2><span class="header-section-number">18.6</span> Mapping NHST to estimation: A paired t-test is a special case of a linear mixed model</h2>
<p>Specifically, a <strong>paired t-test</strong> is equivalent to a linear mixed model with a single factor with two treatment levels, <span class="math inline">\(k\)</span> blocks, and a single measure of each treatment level within each block. A good example is the wild type vs. engineered staph count in mice in experiment 3 above. A linear mixed model is much more flexible than a paired <em>t</em>-test because it allows a researcher to add treatment levels, additional factors, and covariates to the model. In addition, a linear mixed model can handle missing data.</p>
<p>Here is fake data similar in design to experiment 3 with a single factor with two treatment levels and both levels applied to the same experimental unit.</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="linear-mixed-models.html#cb343-1"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb343-2"><a href="linear-mixed-models.html#cb343-2"></a>n &lt;-<span class="st"> </span><span class="dv">10</span> <span class="co"># number of mice (blocks)</span></span>
<span id="cb343-3"><a href="linear-mixed-models.html#cb343-3"></a>x &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;WT&quot;</span>,<span class="st">&quot;Tr&quot;</span>), <span class="dt">each=</span>n) <span class="co"># treatments</span></span>
<span id="cb343-4"><a href="linear-mixed-models.html#cb343-4"></a>id &lt;-<span class="st"> </span><span class="kw">rep</span>(letters[<span class="dv">1</span><span class="op">:</span>n], <span class="dv">2</span>) <span class="co"># block id</span></span>
<span id="cb343-5"><a href="linear-mixed-models.html#cb343-5"></a>y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">10</span>), <span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">11</span>))</span>
<span id="cb343-6"><a href="linear-mixed-models.html#cb343-6"></a>fake_data &lt;-<span class="st"> </span><span class="kw">data.table</span>(<span class="dt">Y=</span>y, <span class="dt">X=</span>x, <span class="dt">ID=</span>id)</span></code></pre></div>
<p>The <em>t</em>-test <em>p</em>-value is</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="linear-mixed-models.html#cb344-1"></a><span class="kw">t.test</span>(Y<span class="op">~</span>X, <span class="dt">data=</span>fake_data, <span class="dt">paired=</span><span class="ot">TRUE</span>)<span class="op">$</span>p.value</span></code></pre></div>
<pre><code>## [1] 0.05336815</code></pre>
<p>and the coefficient table of the fixed effect in the linear mixed model is</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="linear-mixed-models.html#cb346-1"></a><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lme</span>(Y<span class="op">~</span>X, <span class="dt">random =</span> <span class="op">~</span><span class="dv">1</span><span class="op">|</span>ID, <span class="dt">correlation=</span><span class="kw">corCompSymm</span>(<span class="dt">form=</span><span class="op">~</span><span class="dv">1</span><span class="op">|</span>ID), <span class="dt">data=</span>fake_data)))</span></code></pre></div>
<pre><code>##                  Value Std.Error DF   t-value      p-value
## (Intercept) 11.1797704 0.3438775  9 32.510914 1.212113e-10
## XWT         -0.9686188 0.4358740  9 -2.222245 5.336815e-02</code></pre>
</div>
<div id="advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling" class="section level2">
<h2><span class="header-section-number">18.7</span> Advanced topic – Linear mixed models shrink coefficients by partial pooling</h2>
<p>In experiment 1 above, there are 10 sites (maybe different woodlots). In each plot, five seedlings are planted inside a cage and five outside the cage. The cage excludes insectivorous birds but not herbivorous insects. The researchers are investigating how birds affect plant growth indirectly – by eating insects that feed on the plants. The response is total leaf area in each seedling.</p>
<p>Let’s say we want to know the treatment effect in each of these sites. There are several ways of estimating this.</p>
<ol style="list-style-type: decimal">
<li><p>Fit <span class="math inline">\(k\)</span> separate models, one for each site. The intercept (control mean) and slope (treatment effect) parameters for each site are estimated independently from all other sites. Consequently, the model parameters are computed using <strong>no pooling</strong>. For the estimation of the <span class="math inline">\(\beta\)</span> terms, this is equivalent to a single, factorial linear model with <span class="math inline">\(Site\)</span> modeled as a <strong>fixed effect</strong> (this is not true for the estimate of the standard errors of these terms since these are computed from the residual sum of squares of the model. For balanced data, all of the “intercept” or “slope” terms will have the same SE in the factorial analysis but differ among the <span class="math inline">\(k\)</span> independent analyses).</p></li>
<li><p>Fit a linear model to all the data combined as if these were from a single site, and assign the intercept and treatment effect paramters to all sites. The model parameters are computed using <strong>complete pooling</strong>.</p></li>
<li><p>Fit a linear mixed model to all the data, using site as a random factor to estimate both random intercepts and slopes. Similar to the no-pooling analysis, there will be different intercept (control mean) and slope (treatment effect) estimates for each site, but unlike the no-pooling analysis, these estimates are computed by combining information from the other sites. The information used to estimate parameters in a linear mixed model is somewhere in between no pooling and complete pooling and is sometimes called <strong>partial pooling</strong>.</p></li>
</ol>
<p>The consequence of partial pooling in a linear mixed model is that site intercepts (control means) are pulled toward the single intercept in the complete-pooling analysis and the site slopes (treatment effects) are pulled toward the single slope in the complete-pooling analysis. This has the consequence that the <strong>differences</strong> in parameter estimates among sites are shrunk toward zero. A consequence of this shrinkage is that the variance of the intercept estimates or of the slope estimates is smaller than that in the no-pooling analysis. Figure <a href="linear-mixed-models.html#fig:lmm-partialpooling">18.3</a> shows this shrinkage effect using fake data simulating the seedling experiment.</p>
<div class="figure"><span id="fig:lmm-partialpooling"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/lmm-partialpooling-1.png" alt="Shrinkage estimates of the treatment effect in a linear mixed model. The grey line is the estimate using complete pooling (so there is only one estimate which is assigned to each site). In general, the partial-pooling (linear mixed model) estimates (yellow) are generally closer to the complete pooling estimate than the no-pooling (separate linear models) estimates (blue). More specifically, if the no-pooling estimate is far from the complete pooling estimate, the partial pooling estimate is *much* closer to the complete pooling estimate. The consequence of partial pooling is that the differences among the estimates are shrunk toward zero." width="576" />
<p class="caption">
Figure 18.3: Shrinkage estimates of the treatment effect in a linear mixed model. The grey line is the estimate using complete pooling (so there is only one estimate which is assigned to each site). In general, the partial-pooling (linear mixed model) estimates (yellow) are generally closer to the complete pooling estimate than the no-pooling (separate linear models) estimates (blue). More specifically, if the no-pooling estimate is far from the complete pooling estimate, the partial pooling estimate is <em>much</em> closer to the complete pooling estimate. The consequence of partial pooling is that the differences among the estimates are shrunk toward zero.
</p>
</div>
<p>The linear mixed model estimates of the treatment effects for each site are a type of <strong>shrinkage estimate</strong> and a linear mixed model is one kind of <strong>shrinkage estimator</strong>. Shrinkage estimates have fascinating properties:</p>
<ol style="list-style-type: decimal">
<li>the variance of shrinkage estimates is less than that of ordinary least squares estimates (no-pooling, or using the block as a fixed factor)</li>
<li>shrinkage estimates are <strong>biased</strong> but the OLS estimates are not. This means that the expected value of a coefficient from the linear mixed model <em>does not equal</em> the true (parameter) value! Or, more formally, <span class="math inline">\(\mathrm{E}(b_j) \ne \beta_j\)</span>.</li>
<li>the <strong>mean square error</strong> of shrinkage estimates will be smaller than that for OLS estimates.</li>
</ol>
<p>The first property was discussed above and shown in Figure <a href="linear-mixed-models.html#fig:lmm-partialpooling">18.3</a>. The second property raises the question, if we want to estimate the treatment effects within each site, why would we ever want to use <span class="math inline">\(Site\)</span> as a random instead of fixed effect? The answer is the third property, which can be summarized as, “if we were to replicate the experiment many times, the shrinkage estimates will be, on average, less wrong (or closer to the true value) than the OLS estimates, where”wrong" is the absolute deviation from the true value."</p>
<p>When shrinkage estimators were first discovered, the third property surprised stasticians. The third property has profound consequences. Consider a scenario where researchers want to compare the performance of a new expression vector to that of an existing expression vector on protein production using <em>E. coli</em>. The researchers have ten different <em>E. coli</em> strains and are interested in strain-specific effects because they will choose the three strains with the largest effects for further testing. The researchers measure the response of each strain five times.</p>
<table>
<caption>
<span id="tab:lmm-fish-passage">Table 18.2: </span>Effect of new expression vector on protein production in ten strains of <em>E. coli</em> using a fixed effect factorial model and linear mixed model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Strain
</th>
<th style="text-align:right;">
<span class="math inline">\(\beta_{1j}\)</span>
</th>
<th style="text-align:right;">
fixed <span class="math inline">\(b_{1j}\)</span>
</th>
<th style="text-align:right;">
random <span class="math inline">\(b_{1j}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
a
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
1.07
</td>
<td style="text-align:right;">
0.98
</td>
</tr>
<tr>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.87
</td>
<td style="text-align:right;">
0.94
</td>
<td style="text-align:right;">
0.85
</td>
</tr>
<tr>
<td style="text-align:left;">
c
</td>
<td style="text-align:right;">
0.90
</td>
<td style="text-align:right;">
-1.03
</td>
<td style="text-align:right;">
0.30
</td>
</tr>
<tr>
<td style="text-align:left;">
d
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.64
</td>
<td style="text-align:right;">
0.63
</td>
</tr>
<tr>
<td style="text-align:left;">
e
</td>
<td style="text-align:right;">
1.09
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
1.07
</td>
</tr>
<tr>
<td style="text-align:left;">
f
</td>
<td style="text-align:right;">
0.62
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
1.14
</td>
</tr>
<tr>
<td style="text-align:left;">
g
</td>
<td style="text-align:right;">
1.33
</td>
<td style="text-align:right;">
2.26
</td>
<td style="text-align:right;">
1.36
</td>
</tr>
<tr>
<td style="text-align:left;">
h
</td>
<td style="text-align:right;">
1.27
</td>
<td style="text-align:right;">
1.48
</td>
<td style="text-align:right;">
0.96
</td>
</tr>
<tr>
<td style="text-align:left;">
i
</td>
<td style="text-align:right;">
1.61
</td>
<td style="text-align:right;">
0.57
</td>
<td style="text-align:right;">
1.13
</td>
</tr>
<tr>
<td style="text-align:left;">
j
</td>
<td style="text-align:right;">
0.89
</td>
<td style="text-align:right;">
1.50
</td>
<td style="text-align:right;">
0.93
</td>
</tr>
</tbody>
</table>
<p>The table above shows the true strain-specific effect and both the fixed (OLS) and random (LMM) effect estimates. The largest OLS estimate is 70% larger than the true effect and the strain with the largest true effect is not among the top three biggest OLS estimates (its ranking is 9/10). By contrast, the LMM estimates are closer to the true effects and the top strain is among the three largest LMM estimates.</p>
<p>These results are specific to these fake data but more generally,
1) the largest OLS estimates are inflated (larger error from the true effect), relative to the largest LMM estimates
2) overall, the LMM estimates will be closer than the OLS estimates to the true effects</p>
<p>To understand this, rank order the treatment effects for each strain. An individual strain’s position in this rank is the sum of the true effect for that strain and some random error. Because OLS, relative to shrinkage estimates, have greater variance in the estimate (that is, the random error component is bigger), the biggest effects estimated by OLS are more likely to be big because of the error component, compared to shrinkage estimates.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>Not more than you want to know</strong> – Shrinkage estimators are not only useful when we are interested in block-specific effects but are also useful for estimating effects when there are <strong>multiple responses</strong>. For example, consider a researcher interested in measuring the effects of some exercise treatment on gene expression in adipose cells. The researcher measures expression levels in 10,000 genes. Given the typical content in undergraduate biostatics courses, a researcher would probably model these responses using 10,000 <em>t</em>-tests, or equivalently, 10,000 separate linear models. If the tests were ranked by <span class="math inline">\(p\)</span>-value or absolute effect size, many of the genes with largest absolute effect would be there because of a large error component and many of the largest effects would be massively overinflated. Re-imagining the design as a single, linear mixed model with each gene modeled as a block would lead to a rank order in which the biggest measured effects more closely approximate the true effects.</p>
</div>
</div>
<div id="working-in-r-5" class="section level2">
<h2><span class="header-section-number">18.8</span> Working in R</h2>
<p>The major function for working with linear mixed models is <code>lmer()</code> from the lme4 package. An older, and still sometimes used and useful function is <code>lme()</code> from the nlme package. The authors of the lme4 package argue that the df in a linear mixed model are too approximate for a useful <span class="math inline">\(p\)</span>-value and, consequently, the <code>lme</code> function does not return a <span class="math inline">\(p\)</span>-value. Many biological researchers want a <span class="math inline">\(p\)</span>-value and typically use the <code>lmerTest</code> package to get this.</p>
<p><strong>Specifying a linear mixed model using <code>lme</code></strong>. The random factor is in the column “block”. To conform to some packages that use lme4 objects, any variable used to model a random effect should be converted to type <code>factor</code>.</p>
<ol style="list-style-type: decimal">
<li>add a random intercept using <code>y ~ treatment + (1|block)</code>. This adds a random intercept for each level of treatment.</li>
<li>add a random slope and intercept using <code>y ~ treatment + (treatment|block)</code>. This adds a random intercept for each level of treatment and a random slope for each level of treatment.</li>
</ol>
<p>A message that might appear is “boundary (singular) fit: see ?isSingular”. This does not mean there is a problem with the fit model.</p>
<p>A warning that “Model failed to converge with 1 negative eigenvalue” does mean there is a problem. A solution is to simplify the model by, for example, removing a random slope.</p>
<div id="coral-data" class="section level3">
<h3><span class="header-section-number">18.8.1</span> coral data</h3>
<p><strong>Source</strong> Zill, J. A., Gil, M. A., &amp; Osenberg, C. W. (2017). When environmental factors become stressors: interactive effects of vermetid gastropods and sedimentation on corals. Biology letters, 13(3), 20160957.</p>
<p><strong>Dryad source</strong> <a href="https://datadryad.org/resource/doi:10.5061/dryad.p59n8" class="uri">https://datadryad.org/resource/doi:10.5061/dryad.p59n8</a></p>
<p><strong>file name</strong> “VermetidSedimentData_ZillGilOsenberg_DRYAD.xlsx”</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="linear-mixed-models.html#cb348-1"></a>folder &lt;-<span class="st"> &quot;Data from When environmental factors become stressors- interactive effects of vermetid gastropods and sedimentation on corals&quot;</span></span>
<span id="cb348-2"><a href="linear-mixed-models.html#cb348-2"></a>fn &lt;-<span class="st"> &quot;VermetidSedimentData_ZillGilOsenberg_DRYAD.xlsx&quot;</span></span>
<span id="cb348-3"><a href="linear-mixed-models.html#cb348-3"></a>sheet_i &lt;-<span class="st"> &quot;Coral Growth Rate Data&quot;</span></span>
<span id="cb348-4"><a href="linear-mixed-models.html#cb348-4"></a>file_path &lt;-<span class="st"> </span><span class="kw">here</span>(data_path, folder, fn)</span>
<span id="cb348-5"><a href="linear-mixed-models.html#cb348-5"></a>coral &lt;-<span class="st"> </span><span class="kw">read_excel</span>(file_path, <span class="dt">sheet=</span>sheet_i) <span class="op">%&gt;%</span></span>
<span id="cb348-6"><a href="linear-mixed-models.html#cb348-6"></a><span class="st">  </span><span class="kw">clean_names</span>() <span class="op">%&gt;%</span></span>
<span id="cb348-7"><a href="linear-mixed-models.html#cb348-7"></a><span class="st">  </span><span class="kw">data.table</span>()</span>
<span id="cb348-8"><a href="linear-mixed-models.html#cb348-8"></a>coral[, vermetids<span class="op">:</span><span class="er">=</span><span class="kw">factor</span>(vermetids)]</span>
<span id="cb348-9"><a href="linear-mixed-models.html#cb348-9"></a>coral[, sediment<span class="op">:</span><span class="er">=</span><span class="kw">factor</span>(sediment)]</span>
<span id="cb348-10"><a href="linear-mixed-models.html#cb348-10"></a></span>
<span id="cb348-11"><a href="linear-mixed-models.html#cb348-11"></a><span class="co"># recode levels of factors since 0 and 1</span></span>
<span id="cb348-12"><a href="linear-mixed-models.html#cb348-12"></a>coral[, vermetids <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">fct_recode</span>(vermetids,</span>
<span id="cb348-13"><a href="linear-mixed-models.html#cb348-13"></a>                                <span class="dt">absent =</span> <span class="st">&quot;0&quot;</span>,</span>
<span id="cb348-14"><a href="linear-mixed-models.html#cb348-14"></a>                                <span class="dt">present =</span> <span class="st">&quot;1&quot;</span>)]</span>
<span id="cb348-15"><a href="linear-mixed-models.html#cb348-15"></a>coral[, sediment <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">fct_recode</span>(sediment,</span>
<span id="cb348-16"><a href="linear-mixed-models.html#cb348-16"></a>                                <span class="dt">control =</span> <span class="st">&quot;0&quot;</span>,</span>
<span id="cb348-17"><a href="linear-mixed-models.html#cb348-17"></a>                                <span class="dt">addition =</span> <span class="st">&quot;1&quot;</span>)]</span></code></pre></div>
<div id="fitting-models" class="section level4">
<h4><span class="header-section-number">18.8.1.1</span> Fitting models</h4>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="linear-mixed-models.html#cb349-1"></a><span class="co"># to reproduce the results</span></span>
<span id="cb349-2"><a href="linear-mixed-models.html#cb349-2"></a><span class="co"># observation 2 should be excluded from the analysis</span></span>
<span id="cb349-3"><a href="linear-mixed-models.html#cb349-3"></a>inc &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span><span class="op">:</span><span class="kw">nrow</span>(coral))</span>
<span id="cb349-4"><a href="linear-mixed-models.html#cb349-4"></a></span>
<span id="cb349-5"><a href="linear-mixed-models.html#cb349-5"></a><span class="co"># random intercept only</span></span>
<span id="cb349-6"><a href="linear-mixed-models.html#cb349-6"></a>m1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(growth_rate <span class="op">~</span><span class="st"> </span>vermetids<span class="op">*</span>sediment <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>block), <span class="dt">data=</span>coral[inc])</span>
<span id="cb349-7"><a href="linear-mixed-models.html#cb349-7"></a><span class="co"># random intercept and slope</span></span>
<span id="cb349-8"><a href="linear-mixed-models.html#cb349-8"></a>m2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(growth_rate <span class="op">~</span><span class="st"> </span>vermetids<span class="op">*</span>sediment <span class="op">+</span><span class="st"> </span>(vermetids<span class="op">|</span>block) <span class="op">+</span><span class="st"> </span>(sediment<span class="op">|</span>block), <span class="dt">data=</span>coral[inc])</span>
<span id="cb349-9"><a href="linear-mixed-models.html#cb349-9"></a><span class="co"># to include the interaction as a random effect we&#39;d need subsampling within each factorial treatment combination</span></span></code></pre></div>
<p>The conditional effects of m1 are</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="linear-mixed-models.html#cb350-1"></a><span class="co"># results using lmer fit</span></span>
<span id="cb350-2"><a href="linear-mixed-models.html#cb350-2"></a>fit.emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, <span class="dt">specs=</span><span class="kw">c</span>(<span class="st">&quot;vermetids&quot;</span>, <span class="st">&quot;sediment&quot;</span>))</span>
<span id="cb350-3"><a href="linear-mixed-models.html#cb350-3"></a><span class="kw">summary</span>(<span class="kw">contrast</span>(fit.emm, </span>
<span id="cb350-4"><a href="linear-mixed-models.html#cb350-4"></a>                 <span class="dt">method =</span> <span class="st">&quot;revpairwise&quot;</span>, </span>
<span id="cb350-5"><a href="linear-mixed-models.html#cb350-5"></a>                 <span class="dt">simple =</span> <span class="st">&quot;each&quot;</span>,</span>
<span id="cb350-6"><a href="linear-mixed-models.html#cb350-6"></a>                 <span class="dt">combine =</span> <span class="ot">TRUE</span>,</span>
<span id="cb350-7"><a href="linear-mixed-models.html#cb350-7"></a>                 <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>),</span>
<span id="cb350-8"><a href="linear-mixed-models.html#cb350-8"></a>        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  sediment vermetids contrast           estimate    SE   df lower.CL
##  control  .         present - absent    0.00466 0.209 23.0   -0.428
##  addition .         present - absent   -0.76889 0.217 23.6   -1.217
##  .        absent    addition - control  0.28520 0.217 23.6   -0.163
##  .        present   addition - control -0.48834 0.209 23.0   -0.921
##  upper.CL t.ratio p.value
##    0.4373  0.022  0.9824 
##   -0.3211 -3.547  0.0017 
##    0.7330  1.316  0.2009 
##   -0.0557 -2.335  0.0286 
## 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95</code></pre>
<p>There is no “correct” way to compute the degrees of freedom for inferential statistics (SE, CIs, <em>p</em>-values). Two common choices are “Kenward-Roger” and “Satterthwaite”. There is little empirical reason to vastly prefer one over the other (they each seem to perform a wee bit bitter under different conditions).</p>
<p>In <code>emmeans</code>, the Kenward-Roger degrees of freedom are the default. For Satterthwaite, use the <code>lmer.df</code> argument:</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="linear-mixed-models.html#cb352-1"></a>fit.emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, </span>
<span id="cb352-2"><a href="linear-mixed-models.html#cb352-2"></a>                   <span class="dt">specs=</span><span class="kw">c</span>(<span class="st">&quot;vermetids&quot;</span>, <span class="st">&quot;sediment&quot;</span>),</span>
<span id="cb352-3"><a href="linear-mixed-models.html#cb352-3"></a>                   <span class="dt">lmer.df =</span> <span class="st">&quot;satterthwaite&quot;</span>)</span>
<span id="cb352-4"><a href="linear-mixed-models.html#cb352-4"></a><span class="kw">summary</span>(<span class="kw">contrast</span>(fit.emm, </span>
<span id="cb352-5"><a href="linear-mixed-models.html#cb352-5"></a>                 <span class="dt">method =</span> <span class="st">&quot;revpairwise&quot;</span>, </span>
<span id="cb352-6"><a href="linear-mixed-models.html#cb352-6"></a>                 <span class="dt">simple =</span> <span class="st">&quot;each&quot;</span>,</span>
<span id="cb352-7"><a href="linear-mixed-models.html#cb352-7"></a>                 <span class="dt">combine =</span> <span class="ot">TRUE</span>,</span>
<span id="cb352-8"><a href="linear-mixed-models.html#cb352-8"></a>                 <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>),</span>
<span id="cb352-9"><a href="linear-mixed-models.html#cb352-9"></a>        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  sediment vermetids contrast           estimate    SE   df lower.CL
##  control  .         present - absent    0.00466 0.209 22.9   -0.428
##  addition .         present - absent   -0.76889 0.216 23.5   -1.215
##  .        absent    addition - control  0.28520 0.216 23.5   -0.161
##  .        present   addition - control -0.48834 0.209 22.9   -0.921
##  upper.CL t.ratio p.value
##    0.4374  0.022  0.9824 
##   -0.3226 -3.559  0.0016 
##    0.7315  1.320  0.1994 
##   -0.0556 -2.335  0.0287 
## 
## Degrees-of-freedom method: satterthwaite 
## Confidence level used: 0.95</code></pre>
<p>If you want to compute the coefficient table or an ANOVA, lmer does not output test statistics. To get test statistics, you have to load the library “lmerTest” (which automatically loads “lme4”). With <code>lmerTest</code>, the Satterthwaite degrees of freedom are the default. For Kenward-Roger, use the <code>ddf</code> argument in either <code>summary()</code> (for the coefficients) or <code>anova()</code> (for ANOVA).</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="linear-mixed-models.html#cb354-1"></a><span class="kw">coef</span>(<span class="kw">summary</span>(m1)) <span class="co"># default is Satterthwaite</span></span></code></pre></div>
<pre><code>##                                       Estimate Std. Error       df
## (Intercept)                        1.268411111  0.1541680 30.42768
## vermetidspresent                   0.004655556  0.2091398 22.94243
## sedimentaddition                   0.285202305  0.2160126 23.53130
## vermetidspresent:sedimentaddition -0.773546750  0.3006674 23.24638
##                                       t value     Pr(&gt;|t|)
## (Intercept)                        8.22745788 3.129900e-09
## vermetidspresent                   0.02226049 9.824326e-01
## sedimentaddition                   1.32030428 1.994327e-01
## vermetidspresent:sedimentaddition -2.57276556 1.693404e-02</code></pre>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="linear-mixed-models.html#cb356-1"></a><span class="kw">coef</span>(<span class="kw">summary</span>(m1, <span class="dt">ddf=</span><span class="st">&quot;Kenward-Roger&quot;</span>))</span></code></pre></div>
<pre><code>##                                       Estimate Std. Error       df
## (Intercept)                        1.268411111  0.1541680 30.43671
## vermetidspresent                   0.004655556  0.2091398 23.03604
## sedimentaddition                   0.285202305  0.2167687 23.62024
## vermetidspresent:sedimentaddition -0.773546750  0.3012111 23.33762
##                                       t value     Pr(&gt;|t|)
## (Intercept)                        8.22745788 3.122797e-09
## vermetidspresent                   0.02226049 9.824319e-01
## sedimentaddition                   1.31569876 2.009032e-01
## vermetidspresent:sedimentaddition -2.56812158 1.708128e-02</code></pre>
<p>Compare the output from emmeans and <code>coef(summary())</code> using the different methods for computing the df.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="part-vii-expanding-the-linear-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="generalized-linear-models-i-count-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/55-lmm01-blocking.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
