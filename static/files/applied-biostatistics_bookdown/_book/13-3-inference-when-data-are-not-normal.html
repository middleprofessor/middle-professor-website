<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="13.3 Inference when data are not Normal | Elements of Statistical Modeling for Experimental Biology" />
<meta property="og:type" content="book" />


<meta property="og:description" content="A first course in statistical modeling for experimental biology researchers" />


<meta name="author" content="Copyright 2018 Jeffrey A. Walker" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A first course in statistical modeling for experimental biology researchers">

<title>13.3 Inference when data are not Normal | Elements of Statistical Modeling for Experimental Biology</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a><ul>
<li><a href="0-1-math.html#math"><span class="toc-section-number">0.1</span> Math</a></li>
<li><a href="0-2-r-and-programming.html#r-and-programming"><span class="toc-section-number">0.2</span> R and programming</a></li>
</ul></li>
<li><a href="part-i-getting-started.html#part-i-getting-started">Part I: Getting Started</a></li>
<li class="has-sub"><a href="1-getting-started-r-projects-and-r-markdown.html#getting-started-r-projects-and-r-markdown"><span class="toc-section-number">1</span> Getting Started – R Projects and R Markdown</a><ul>
<li><a href="1-1-r-vs-r-studio.html#r-vs-r-studio"><span class="toc-section-number">1.1</span> R vs R Studio</a></li>
<li><a href="1-2-download-and-install-r-and-r-studio.html#download-and-install-r-and-r-studio"><span class="toc-section-number">1.2</span> Download and install R and R studio</a></li>
<li><a href="1-3-install-r-markdown.html#install-r-markdown"><span class="toc-section-number">1.3</span> Install R Markdown</a></li>
<li><a href="1-4-importing-packages.html#importing-packages"><span class="toc-section-number">1.4</span> Importing Packages</a></li>
<li class="has-sub"><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-an-r-studio-project-for-this-textbook"><span class="toc-section-number">1.5</span> Create an R Studio Project for this textbook</a><ul>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-an-r-markdown-file-for-this-chapter"><span class="toc-section-number">1.5.1</span> Create an R Markdown file for this Chapter</a></li>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-a-fake-data-chunk"><span class="toc-section-number">1.5.2</span> Create a “fake-data” chunk</a></li>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-a-plot-chunk"><span class="toc-section-number">1.5.3</span> Create a “plot” chunk</a></li>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#knit"><span class="toc-section-number">1.5.4</span> Knit</a></li>
</ul></li>
</ul></li>
<li><a href="part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model.html#part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model">Part II: An introduction to the analysis of experimental data with a linear model</a></li>
<li class="has-sub"><a href="2-analyzing-experimental-data-with-a-linear-model.html#analyzing-experimental-data-with-a-linear-model"><span class="toc-section-number">2</span> Analyzing experimental data with a linear model</a><ul>
<li><a href="2-1-this-text-is-about-the-estimation-of-treatment-effects-and-the-uncertainty-in-our-estimates-using-linear-models-this-raises-the-question-what-is-an-effect.html#this-text-is-about-the-estimation-of-treatment-effects-and-the-uncertainty-in-our-estimates-using-linear-models.-this-raises-the-question-what-is-an-effect"><span class="toc-section-number">2.1</span> This text is about the estimation of treatment effects and the uncertainty in our estimates using linear models. This, raises the question, what is “an effect”?</a></li>
</ul></li>
<li><a href="background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity">Background physiology to the experiments in Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a></li>
<li class="has-sub"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity">Analyses for Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a><ul>
<li><a href="2-2-setup.html#setup"><span class="toc-section-number">2.2</span> Setup</a></li>
<li><a href="2-3-data-source.html#data-source"><span class="toc-section-number">2.3</span> Data source</a></li>
<li><a href="2-4-control-the-color-palette.html#control-the-color-palette"><span class="toc-section-number">2.4</span> control the color palette</a></li>
<li><a href="2-5-useful-functions.html#useful-functions"><span class="toc-section-number">2.5</span> useful functions</a></li>
<li class="has-sub"><a href="2-6-figure-2b-effect-of-ask1-deletion-on-growth-body-weight.html#figure-2b-effect-of-ask1-deletion-on-growth-body-weight"><span class="toc-section-number">2.6</span> figure 2b – effect of ASK1 deletion on growth (body weight)</a><ul>
<li><a href="2-6-figure-2b-effect-of-ask1-deletion-on-growth-body-weight.html#figure-2b-import"><span class="toc-section-number">2.6.1</span> figure 2b – import</a></li>
<li><a href="2-6-figure-2b-effect-of-ask1-deletion-on-growth-body-weight.html#figure-2b-exploratory-plots"><span class="toc-section-number">2.6.2</span> figure 2b – exploratory plots</a></li>
</ul></li>
<li class="has-sub"><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-effect-of-ask1-deletion-on-final-body-weight"><span class="toc-section-number">2.7</span> Figure 2c – Effect of ASK1 deletion on final body weight</a><ul>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-import"><span class="toc-section-number">2.7.1</span> Figure 2c – import</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-check-own-computation-of-weight-change-v-imported-value"><span class="toc-section-number">2.7.2</span> Figure 2c – check own computation of weight change v imported value</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-exploratory-plots"><span class="toc-section-number">2.7.3</span> Figure 2c – exploratory plots</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-fit-the-model-m1-lm"><span class="toc-section-number">2.7.4</span> Figure 2c – fit the model: m1 (lm)</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-check-the-model-m1"><span class="toc-section-number">2.7.5</span> Figure 2c – check the model: m1</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-fit-the-model-m2-gamma-glm"><span class="toc-section-number">2.7.6</span> Figure 2c – fit the model: m2 (gamma glm)</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-check-the-model-m2"><span class="toc-section-number">2.7.7</span> Figure 2c – check the model, m2</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-inference-from-the-model"><span class="toc-section-number">2.7.8</span> Figure 2c – inference from the model</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-plot-the-model"><span class="toc-section-number">2.7.9</span> Figure 2c – plot the model</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-report"><span class="toc-section-number">2.7.10</span> Figure 2c – report</a></li>
</ul></li>
<li class="has-sub"><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve"><span class="toc-section-number">2.8</span> Figure 2d – Effect of ASK1 KO on glucose tolerance (whole curve)</a><ul>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-import"><span class="toc-section-number">2.8.1</span> Figure 2d – Import</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-exploratory-plots"><span class="toc-section-number">2.8.2</span> Figure 2d – exploratory plots</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-fit-the-model"><span class="toc-section-number">2.8.3</span> Figure 2d – fit the model</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-check-the-model"><span class="toc-section-number">2.8.4</span> Figure 2d – check the model</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-inference"><span class="toc-section-number">2.8.5</span> Figure 2d – inference</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-plot-the-model"><span class="toc-section-number">2.8.6</span> Figure 2d – plot the model</a></li>
</ul></li>
<li class="has-sub"><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure"><span class="toc-section-number">2.9</span> Figure 2e – Effect of ASK1 deletion on glucose tolerance (summary measure)</a><ul>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-message-the-data"><span class="toc-section-number">2.9.1</span> Figure 2e – message the data</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-exploratory-plots"><span class="toc-section-number">2.9.2</span> Figure 2e – exploratory plots</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-fit-the-model"><span class="toc-section-number">2.9.3</span> Figure 2e – fit the model</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-check-the-model"><span class="toc-section-number">2.9.4</span> Figure 2e – check the model</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-inference-from-the-model"><span class="toc-section-number">2.9.5</span> Figure 2e – inference from the model</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-plot-the-model"><span class="toc-section-number">2.9.6</span> Figure 2e – plot the model</a></li>
</ul></li>
<li class="has-sub"><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate"><span class="toc-section-number">2.10</span> Figure 2f – Effect of ASK1 deletion on glucose infusion rate</a><ul>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-import"><span class="toc-section-number">2.10.1</span> Figure 2f – import</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-exploratory-plots"><span class="toc-section-number">2.10.2</span> Figure 2f – exploratory plots</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-fit-the-model"><span class="toc-section-number">2.10.3</span> Figure 2f – fit the model</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-check-the-model"><span class="toc-section-number">2.10.4</span> Figure 2f – check the model</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-inference"><span class="toc-section-number">2.10.5</span> Figure 2f – inference</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-plot-the-model"><span class="toc-section-number">2.10.6</span> Figure 2f – plot the model</a></li>
</ul></li>
<li class="has-sub"><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake"><span class="toc-section-number">2.11</span> Figure 2g – Effect of ASK1 deletion on tissue-specific glucose uptake</a><ul>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-import"><span class="toc-section-number">2.11.1</span> Figure 2g – import</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-exploratory-plots"><span class="toc-section-number">2.11.2</span> Figure 2g – exploratory plots</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-fit-the-model"><span class="toc-section-number">2.11.3</span> Figure 2g – fit the model</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-check-the-model"><span class="toc-section-number">2.11.4</span> Figure 2g – check the model</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-inference"><span class="toc-section-number">2.11.5</span> Figure 2g – inference</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-plot-the-model"><span class="toc-section-number">2.11.6</span> Figure 2g – plot the model</a></li>
</ul></li>
<li><a href="2-12-figure-2h.html#figure-2h"><span class="toc-section-number">2.12</span> Figure 2h</a></li>
<li class="has-sub"><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-effect-of-ask1-deletion-on-liver-tg"><span class="toc-section-number">2.13</span> Figure 2i – Effect of ASK1 deletion on liver TG</a><ul>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-fit-the-model"><span class="toc-section-number">2.13.1</span> Figure 2i – fit the model</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-check-the-model"><span class="toc-section-number">2.13.2</span> Figure 2i – check the model</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-inference"><span class="toc-section-number">2.13.3</span> Figure 2i – inference</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-plot-the-model"><span class="toc-section-number">2.13.4</span> Figure 2i – plot the model</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-report-the-model"><span class="toc-section-number">2.13.5</span> Figure 2i – report the model</a></li>
</ul></li>
<li><a href="2-14-figure-2j.html#figure-2j"><span class="toc-section-number">2.14</span> Figure 2j</a></li>
</ul></li>
<li><a href="part-iii-r-fundamentals.html#part-iii-r-fundamentals">Part III: R fundamentals</a></li>
<li class="has-sub"><a href="3-data-reading-wrangling-and-writing.html#data-reading-wrangling-and-writing"><span class="toc-section-number">3</span> Data – Reading, Wrangling, and Writing</a><ul>
<li><a href="3-1-learning-from-this-chapter.html#learning-from-this-chapter"><span class="toc-section-number">3.1</span> Learning from this chapter</a></li>
<li class="has-sub"><a href="3-2-data-working-in-r.html#data-working-in-r"><span class="toc-section-number">3.2</span> Working in R</a><ul>
<li><a href="3-2-data-working-in-r.html#importing-data"><span class="toc-section-number">3.2.1</span> Importing data</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-data-wrangling.html#data-wrangling"><span class="toc-section-number">3.3</span> Data wrangling</a><ul>
<li><a href="3-3-data-wrangling.html#reshaping-data-wide-to-long"><span class="toc-section-number">3.3.1</span> Reshaping data – Wide to long</a></li>
<li><a href="3-3-data-wrangling.html#reshaping-data-transpose-turning-the-columns-into-rows"><span class="toc-section-number">3.3.2</span> Reshaping data – Transpose (turning the columns into rows)</a></li>
<li><a href="3-3-data-wrangling.html#combining-data"><span class="toc-section-number">3.3.3</span> Combining data</a></li>
<li><a href="3-3-data-wrangling.html#subsetting-data"><span class="toc-section-number">3.3.4</span> Subsetting data</a></li>
<li><a href="3-3-data-wrangling.html#wrangling-columns"><span class="toc-section-number">3.3.5</span> Wrangling columns</a></li>
<li><a href="3-3-data-wrangling.html#missing-data"><span class="toc-section-number">3.3.6</span> Missing data</a></li>
</ul></li>
<li><a href="3-4-saving-data.html#saving-data"><span class="toc-section-number">3.4</span> Saving data</a></li>
<li><a href="3-5-exercises.html#exercises"><span class="toc-section-number">3.5</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="4-plotting-models.html#plotting-models"><span class="toc-section-number">4</span> Plotting Models</a><ul>
<li class="has-sub"><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#pretty-good-plots-show-the-model-and-the-data"><span class="toc-section-number">4.1</span> Pretty good plots show the model and the data</a><ul>
<li><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#pretty-good-plot-component-1-modeled-effects-plot"><span class="toc-section-number">4.1.1</span> Pretty good plot component 1: Modeled effects plot</a></li>
<li><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot"><span class="toc-section-number">4.1.2</span> Pretty good plot component 2: Modeled mean and CI plot</a></li>
<li><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><span class="toc-section-number">4.1.3</span> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li><a href="4-2-some-comments-on-plot-components.html#some-comments-on-plot-components"><span class="toc-section-number">4.2</span> Some comments on plot components</a></li>
<li class="has-sub"><a href="4-3-working-in-r.html#working-in-r"><span class="toc-section-number">4.3</span> Working in R</a><ul>
<li><a href="4-3-working-in-r.html#unpooled-se-bars-and-confidence-intervals"><span class="toc-section-number">4.3.1</span> Unpooled SE bars and confidence intervals</a></li>
<li><a href="4-3-working-in-r.html#adding-bootstrap-intervals"><span class="toc-section-number">4.3.2</span> Adding bootstrap intervals</a></li>
<li><a href="4-3-working-in-r.html#adding-modeled-means-and-error-intervals"><span class="toc-section-number">4.3.3</span> Adding modeled means and error intervals</a></li>
<li><a href="4-3-working-in-r.html#adding-p-values"><span class="toc-section-number">4.3.4</span> Adding p-values</a></li>
<li><a href="4-3-working-in-r.html#adding-custom-p-values"><span class="toc-section-number">4.3.5</span> Adding custom p-values</a></li>
<li><a href="4-3-working-in-r.html#plotting-two-factors"><span class="toc-section-number">4.3.6</span> Plotting two factors</a></li>
<li><a href="4-3-working-in-r.html#interaction-plot"><span class="toc-section-number">4.3.7</span> Interaction plot</a></li>
<li><a href="4-3-working-in-r.html#plot-components"><span class="toc-section-number">4.3.8</span> Plot components</a></li>
</ul></li>
</ul></li>
<li><a href="part-iv-some-fundamentals-of-statistical-modeling.html#part-iv-some-fundamentals-of-statistical-modeling">Part IV: Some Fundamentals of Statistical Modeling</a></li>
<li class="has-sub"><a href="5-variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals"><span class="toc-section-number">5</span> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="has-sub"><a href="5-1-the-sample-standard-deviation-vs-the-standard-error-of-the-mean.html#the-sample-standard-deviation-vs.-the-standard-error-of-the-mean"><span class="toc-section-number">5.1</span> The sample standard deviation vs. the standard error of the mean</a><ul>
<li><a href="5-1-the-sample-standard-deviation-vs-the-standard-error-of-the-mean.html#sample-standard-deviation"><span class="toc-section-number">5.1.1</span> Sample standard deviation</a></li>
<li><a href="5-1-the-sample-standard-deviation-vs-the-standard-error-of-the-mean.html#standard-error-of-the-mean"><span class="toc-section-number">5.1.2</span> Standard error of the mean</a></li>
</ul></li>
<li class="has-sub"><a href="5-2-using-google-sheets-to-generate-fake-data-to-explore-the-standard-error.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><span class="toc-section-number">5.2</span> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li><a href="5-2-using-google-sheets-to-generate-fake-data-to-explore-the-standard-error.html#steps"><span class="toc-section-number">5.2.1</span> Steps</a></li>
</ul></li>
<li class="has-sub"><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><span class="toc-section-number">5.3</span> Using R to generate fake data to explore the standard error</a><ul>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-i"><span class="toc-section-number">5.3.1</span> part I</a></li>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-ii---means"><span class="toc-section-number">5.3.2</span> part II - means</a></li>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><span class="toc-section-number">5.3.3</span> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-iv-generating-fake-data-with-for-loops"><span class="toc-section-number">5.3.4</span> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="has-sub"><a href="5-4-bootstrap.html#bootstrap"><span class="toc-section-number">5.4</span> Bootstrapped standard errors</a><ul>
<li><a href="5-4-bootstrap.html#an-example-of-bootstrapped-standard-errors-using-vole-data"><span class="toc-section-number">5.4.1</span> An example of bootstrapped standard errors using vole data</a></li>
</ul></li>
<li class="has-sub"><a href="5-5-confidence-interval.html#confidence-interval"><span class="toc-section-number">5.5</span> Confidence Interval</a><ul>
<li><a href="5-5-confidence-interval.html#interpretation-of-a-confidence-interval"><span class="toc-section-number">5.5.1</span> Interpretation of a confidence interval</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="6-p-values.html#p-values"><span class="toc-section-number">6</span> P-values</a><ul>
<li><a href="6-1-a-p-value-is-the-probability-of-sampling-a-value-as-or-more-extreme-than-the-test-statistic-if-sampling-from-a-null-distribution.html#a-p-value-is-the-probability-of-sampling-a-value-as-or-more-extreme-than-the-test-statistic-if-sampling-from-a-null-distribution"><span class="toc-section-number">6.1</span> A <em>p</em>-value is the probability of sampling a value as or more extreme than the test statistic if sampling from a null distribution</a></li>
<li><a href="6-2-pump-your-intuition-creating-a-null-distribution.html#pump-your-intuition-creating-a-null-distribution"><span class="toc-section-number">6.2</span> Pump your intuition – Creating a null distribution</a></li>
<li><a href="6-3-a-null-distribution-of-t-values-the-t-distribution.html#a-null-distribution-of-t-values-the-t-distribution"><span class="toc-section-number">6.3</span> A null distribution of <em>t</em>-values – the <em>t</em> distribution</a></li>
<li><a href="6-4-p-values-from-the-perspective-of-permutation.html#p-values-from-the-perspective-of-permutation"><span class="toc-section-number">6.4</span> P-values from the perspective of permutation</a></li>
<li><a href="6-5-parametric-vs-non-parametric-statistics.html#parametric-vs.-non-parametric-statistics"><span class="toc-section-number">6.5</span> Parametric vs. non-parametric statistics</a></li>
<li class="has-sub"><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><span class="toc-section-number">6.6</span> frequentist probability and the interpretation of p-values</a><ul>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#background"><span class="toc-section-number">6.6.1</span> Background</a></li>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><span class="toc-section-number">6.6.2</span> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <em>p</em>-value of a test statistic, this will be a frequentist probability.</a></li>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#two-interpretations-of-the-p-value"><span class="toc-section-number">6.6.3</span> Two interpretations of the <em>p</em>-value</a></li>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#nhst"><span class="toc-section-number">6.6.4</span> NHST</a></li>
</ul></li>
<li class="has-sub"><a href="6-7-some-major-misconceptions-of-the-p-value.html#some-major-misconceptions-of-the-p-value"><span class="toc-section-number">6.7</span> Some major misconceptions of the <em>p</em>-value</a><ul>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-p-is-the-probability-that-the-null-is-true-and-1-p-is-probability-that-the-alternative-is-true"><span class="toc-section-number">6.7.1</span> Misconception: <em>p</em> is the probability that the null is true <em>and</em> <span class="math inline">\(1-p\)</span> is probability that the alternative is true</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-a-p-value-is-repeatable"><span class="toc-section-number">6.7.2</span> Misconception: a <em>p</em>-value is repeatable</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-0.05-is-the-lifetime-rate-of-false-discoveries"><span class="toc-section-number">6.7.3</span> Misconception: 0.05 is the lifetime rate of false discoveries</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-a-low-p-value-indicates-an-important-effect"><span class="toc-section-number">6.7.4</span> Misconception: a low <em>p</em>-value indicates an important effect</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-a-low-p-value-indicates-high-model-fit-or-high-predictive-capacity"><span class="toc-section-number">6.7.5</span> Misconception: a low <em>p</em>-value indicates high model fit or high predictive capacity</a></li>
</ul></li>
<li><a href="6-8-what-the-p-value-does-not-mean.html#what-the-p-value-does-not-mean"><span class="toc-section-number">6.8</span> What the <em>p</em>-value does not mean</a></li>
<li class="has-sub"><a href="6-9-recommendations.html#recommendations"><span class="toc-section-number">6.9</span> Recommendations</a><ul>
<li><a href="6-9-recommendations.html#primary-sources-for-recommendations"><span class="toc-section-number">6.9.1</span> Primary sources for recommendations</a></li>
</ul></li>
<li><a href="6-10-problems.html#problems"><span class="toc-section-number">6.10</span> Problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-errors-in-inference.html#errors-in-inference"><span class="toc-section-number">7</span> Errors in inference</a><ul>
<li class="has-sub"><a href="7-1-classical-nhst-concepts-of-wrong.html#classical-nhst-concepts-of-wrong"><span class="toc-section-number">7.1</span> Classical NHST concepts of wrong</a><ul>
<li><a href="7-1-classical-nhst-concepts-of-wrong.html#type-i-error"><span class="toc-section-number">7.1.1</span> Type I error</a></li>
<li><a href="7-1-classical-nhst-concepts-of-wrong.html#power"><span class="toc-section-number">7.1.2</span> Power</a></li>
</ul></li>
<li class="has-sub"><a href="7-2-a-non-neyman-pearson-concept-of-power.html#a-non-neyman-pearson-concept-of-power"><span class="toc-section-number">7.2</span> A non-Neyman-Pearson concept of power</a><ul>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#estimation-error"><span class="toc-section-number">7.2.1</span> Estimation error</a></li>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#coverage"><span class="toc-section-number">7.2.2</span> Coverage</a></li>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#type-s-error"><span class="toc-section-number">7.2.3</span> Type S error</a></li>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#type-m-error"><span class="toc-section-number">7.2.4</span> Type M error</a></li>
</ul></li>
</ul></li>
<li><a href="part-v-introduction-to-linear-models.html#part-v-introduction-to-linear-models">Part V: Introduction to Linear Models</a></li>
<li class="has-sub"><a href="8-an-introduction-to-linear-models.html#an-introduction-to-linear-models"><span class="toc-section-number">8</span> An introduction to linear models</a><ul>
<li class="has-sub"><a href="8-1-two-specifications-of-a-linear-model.html#two-specifications-of-a-linear-model"><span class="toc-section-number">8.1</span> Two specifications of a linear model</a><ul>
<li><a href="8-1-two-specifications-of-a-linear-model.html#the-error-draw-specification"><span class="toc-section-number">8.1.1</span> The “error draw” specification</a></li>
<li><a href="8-1-two-specifications-of-a-linear-model.html#the-conditional-draw-specification"><span class="toc-section-number">8.1.2</span> The “conditional draw” specification</a></li>
<li><a href="8-1-two-specifications-of-a-linear-model.html#comparing-the-two-ways-of-specifying-the-linear-model"><span class="toc-section-number">8.1.3</span> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="has-sub"><a href="8-2-a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables.html#a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables"><span class="toc-section-number">8.2</span> A linear model can be fit to data with continuous, discrete, or categorical <span class="math inline">\(X\)</span> variables</a><ul>
<li><a href="8-2-a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-continuous-or-discrete"><span class="toc-section-number">8.2.1</span> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is continuous or discrete</a></li>
<li><a href="8-2-a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-categorical"><span class="toc-section-number">8.2.2</span> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is categorical</a></li>
</ul></li>
<li><a href="8-3-statistical-models-are-used-for-prediction-explanation-and-description.html#statistical-models-are-used-for-prediction-explanation-and-description"><span class="toc-section-number">8.3</span> Statistical models are used for prediction, explanation, and description</a></li>
<li><a href="8-4-what-do-we-call-the-x-and-y-variables.html#what-do-we-call-the-x-and-y-variables"><span class="toc-section-number">8.4</span> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li><a href="8-5-modeling-strategy.html#modeling-strategy"><span class="toc-section-number">8.5</span> Modeling strategy</a></li>
<li><a href="8-6-predictions-from-the-model.html#predictions-from-the-model"><span class="toc-section-number">8.6</span> Predictions from the model</a></li>
<li class="has-sub"><a href="8-7-inference-from-the-model.html#inference-from-the-model"><span class="toc-section-number">8.7</span> Inference from the model</a><ul>
<li><a href="8-7-inference-from-the-model.html#assumptions-for-inference-with-a-statistical-model"><span class="toc-section-number">8.7.1</span> Assumptions for inference with a statistical model</a></li>
<li><a href="8-7-inference-from-the-model.html#specific-assumptions-for-inference-with-a-linear-model"><span class="toc-section-number">8.7.2</span> Specific assumptions for inference with a linear model</a></li>
</ul></li>
<li><a href="8-8-linear-modelregression-model-orstatistical-model.html#linear-modelregression-model-orstatistical-model"><span class="toc-section-number">8.8</span> “linear model,”regression model“, or”statistical model"?</a></li>
</ul></li>
<li class="has-sub"><a href="9-linear-models-with-a-single-continuous-x.html#linear-models-with-a-single-continuous-x"><span class="toc-section-number">9</span> Linear models with a single, continuous <em>X</em></a><ul>
<li class="has-sub"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><span class="toc-section-number">9.1</span> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#analysis-of-green-down-data"><span class="toc-section-number">9.1.1</span> Analysis of “green-down” data</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#learning-from-the-green-down-example"><span class="toc-section-number">9.1.2</span> Learning from the green-down example</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-explanation-causal-models"><span class="toc-section-number">9.1.3</span> Using a regression model for “explanation” – causal models</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-prediction-prediction-models"><span class="toc-section-number">9.1.4</span> Using a regression model for prediction – prediction models</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-creating-a-new-response-variable-comparing-slopes-of-longitudinal-data"><span class="toc-section-number">9.1.5</span> Using a regression model for creating a new response variable – comparing slopes of longitudinal data</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-for-calibration"><span class="toc-section-number">9.1.6</span> Using a regression model for for calibration</a></li>
</ul></li>
<li class="has-sub"><a href="9-2-working-in-r-1.html#working-in-r-1"><span class="toc-section-number">9.2</span> Working in R</a><ul>
<li><a href="9-2-working-in-r-1.html#fitting-the-linear-model"><span class="toc-section-number">9.2.1</span> Fitting the linear model</a></li>
<li><a href="9-2-working-in-r-1.html#getting-to-know-the-linear-model-the-summary-function"><span class="toc-section-number">9.2.2</span> Getting to know the linear model: the <code>summary</code> function</a></li>
<li><a href="9-2-working-in-r-1.html#inference-the-coefficient-table-and-confidence-intervals"><span class="toc-section-number">9.2.3</span> Inference – the coefficient table and Confidence intervals</a></li>
<li><a href="9-2-working-in-r-1.html#how-good-is-our-model-model-checking"><span class="toc-section-number">9.2.4</span> How good is our model? – Model checking</a></li>
<li><a href="9-2-working-in-r-1.html#plotting-models-with-continuous-x"><span class="toc-section-number">9.2.5</span> Plotting models with continuous <em>X</em></a></li>
<li><a href="9-2-working-in-r-1.html#creating-a-table-of-predicted-values-and-95-prediction-intervals"><span class="toc-section-number">9.2.6</span> Creating a table of predicted values and 95% prediction intervals</a></li>
</ul></li>
<li class="has-sub"><a href="9-3-hidden-code.html#hidden-code"><span class="toc-section-number">9.3</span> Hidden code</a><ul>
<li><a href="9-3-hidden-code.html#import-and-plot-of-fig2c-ecosystem-warming-experimental-data"><span class="toc-section-number">9.3.1</span> Import and plot of fig2c (ecosystem warming experimental) data</a></li>
<li><a href="9-3-hidden-code.html#import-and-plot-efig_3d-ecosysem-warming-observational-data"><span class="toc-section-number">9.3.2</span> Import and plot efig_3d (Ecosysem warming observational) data</a></li>
<li><a href="9-3-hidden-code.html#import-and-plot-of-fig1f-methionine-restriction-data"><span class="toc-section-number">9.3.3</span> Import and plot of fig1f (methionine restriction) data</a></li>
</ul></li>
<li class="has-sub"><a href="9-4-try-it.html#try-it"><span class="toc-section-number">9.4</span> Try it</a><ul>
<li><a href="9-4-try-it.html#a-prediction-model-from-the-literature"><span class="toc-section-number">9.4.1</span> A prediction model from the literature</a></li>
</ul></li>
<li class="has-sub"><a href="9-5-intuition-pumps.html#intuition-pumps"><span class="toc-section-number">9.5</span> Intuition pumps</a><ul>
<li><a href="9-5-intuition-pumps.html#correlation-and-r2"><span class="toc-section-number">9.5.1</span> Correlation and $R^2</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="10-linear-models-with-a-single-categorical-x.html#linear-models-with-a-single-categorical-x"><span class="toc-section-number">10</span> Linear models with a single, categorical <em>X</em></a><ul>
<li class="has-sub"><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response."><span class="toc-section-number">10.1</span> A linear model with a single, categorical <em>X</em> variable estimates the effects of the levels of <em>X</em> on the response.</a><ul>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#example-1-two-treatment-levels-groups"><span class="toc-section-number">10.1.1</span> Example 1 – two treatment levels (“groups”)</a></li>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#understanding-the-analysis-with-two-treatment-levels"><span class="toc-section-number">10.1.2</span> Understanding the analysis with two treatment levels</a></li>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#example-2-three-treatment-levels-groups"><span class="toc-section-number">10.1.3</span> Example 2 – three treatment levels (“groups”)</a></li>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#understanding-the-analysis-with-three-or-more-treatment-levels"><span class="toc-section-number">10.1.4</span> Understanding the analysis with three (or more) treatment levels</a></li>
</ul></li>
<li class="has-sub"><a href="10-2-working-in-r-2.html#working-in-r-2"><span class="toc-section-number">10.2</span> Working in R</a><ul>
<li><a href="10-2-working-in-r-2.html#specifying-the-contrasts"><span class="toc-section-number">10.2.1</span> Specifying the contrasts</a></li>
<li><a href="10-2-working-in-r-2.html#adjustment-for-multiple-comparisons"><span class="toc-section-number">10.2.2</span> Adjustment for multiple comparisons</a></li>
<li><a href="10-2-working-in-r-2.html#plotting-models-with-a-single-categorical-x"><span class="toc-section-number">10.2.3</span> Plotting models with a single, categorical <span class="math inline">\(X\)</span></a></li>
</ul></li>
<li class="has-sub"><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#issues-in-inference-in-models-with-a-single-categorical-x"><span class="toc-section-number">10.3</span> Issues in inference in models with a single, categorical <span class="math inline">\(X\)</span></a><ul>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#lack-of-independence"><span class="toc-section-number">10.3.1</span> Lack of independence</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#heterogeneity-of-variances"><span class="toc-section-number">10.3.2</span> Heterogeneity of variances</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#the-conditional-response-isnt-normal"><span class="toc-section-number">10.3.3</span> The conditional response isn’t Normal</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#pre-post-designs"><span class="toc-section-number">10.3.4</span> Pre-post designs</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#longitudinal-designs"><span class="toc-section-number">10.3.5</span> Longitudinal designs</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#comparing-responses-normalized-to-a-standard"><span class="toc-section-number">10.3.6</span> Comparing responses normalized to a standard</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#comparing-responses-that-are-ratios"><span class="toc-section-number">10.3.7</span> Comparing responses that are ratios</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#researcher-degrees-of-freedom"><span class="toc-section-number">10.3.8</span> Researcher degrees of freedom</a></li>
</ul></li>
<li class="has-sub"><a href="10-4-hidden-code-1.html#hidden-code-1"><span class="toc-section-number">10.4</span> Hidden Code</a><ul>
<li><a href="10-4-hidden-code-1.html#fig2a-data"><span class="toc-section-number">10.4.1</span> fig2a data</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="11-model-checking.html#model-checking"><span class="toc-section-number">11</span> Model Checking</a><ul>
<li><a href="11-1-all-statistical-analyses-should-be-followed-by-model-checking.html#all-statistical-analyses-should-be-followed-by-model-checking"><span class="toc-section-number">11.1</span> All statistical analyses should be followed by model checking</a></li>
<li class="has-sub"><a href="11-2-linear-model-assumptions.html#linear-model-assumptions"><span class="toc-section-number">11.2</span> Linear model assumptions</a><ul>
<li><a href="11-2-linear-model-assumptions.html#a-bit-about-iid"><span class="toc-section-number">11.2.1</span> A bit about IID</a></li>
</ul></li>
<li class="has-sub"><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><span class="toc-section-number">11.3</span> Diagnostic plots use the residuals from the model fit</a><ul>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#residuals"><span class="toc-section-number">11.3.1</span> Residuals</a></li>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#a-normal-q-q-plot-is-used-to-check-for-characteristic-departures-from-normality"><span class="toc-section-number">11.3.2</span> A Normal Q-Q plot is used to check for characteristic departures from Normality</a></li>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#mapping-qq-plot-departures-from-normality"><span class="toc-section-number">11.3.3</span> Mapping QQ-plot departures from Normality</a></li>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#model-checking-homoskedasticity"><span class="toc-section-number">11.3.4</span> Model checking homoskedasticity</a></li>
</ul></li>
<li class="has-sub"><a href="11-4-using-r.html#using-r"><span class="toc-section-number">11.4</span> Using R</a><ul>
<li><a href="11-4-using-r.html#normal-q-q-plots"><span class="toc-section-number">11.4.1</span> Normal Q-Q plots</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="12-model-fitting-and-model-fit-ols.html#model-fitting-and-model-fit-ols"><span class="toc-section-number">12</span> Model Fitting and Model Fit (OLS)</a><ul>
<li><a href="12-1-least-squares-estimation-and-the-decomposition-of-variance.html#least-squares-estimation-and-the-decomposition-of-variance"><span class="toc-section-number">12.1</span> Least Squares Estimation and the Decomposition of Variance</a></li>
<li><a href="12-2-ols-regression.html#ols-regression"><span class="toc-section-number">12.2</span> OLS regression</a></li>
<li><a href="12-3-how-well-does-the-model-fit-the-data-r2-and-variance-explained.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><span class="toc-section-number">12.3</span> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="has-sub"><a href="13-best-practices-issues-in-inference.html#best-practices-issues-in-inference"><span class="toc-section-number">13</span> Best practices – issues in inference</a><ul>
<li class="has-sub"><a href="13-1-multiple-testing.html#multiple-testing"><span class="toc-section-number">13.1</span> Multiple testing</a><ul>
<li><a href="13-1-multiple-testing.html#some-background"><span class="toc-section-number">13.1.1</span> Some background</a></li>
<li><a href="13-1-multiple-testing.html#multiple-testing-working-in-r"><span class="toc-section-number">13.1.2</span> Multiple testing – working in R</a></li>
<li><a href="13-1-multiple-testing.html#false-discovery-rate"><span class="toc-section-number">13.1.3</span> False Discovery Rate</a></li>
</ul></li>
<li><a href="13-2-difference-in-p-is-not-different.html#difference-in-p-is-not-different"><span class="toc-section-number">13.2</span> difference in p is not different</a></li>
<li class="has-sub"><a href="13-3-inference-when-data-are-not-normal.html#inference-when-data-are-not-normal"><span class="toc-section-number">13.3</span> Inference when data are not Normal</a><ul>
<li><a href="13-3-inference-when-data-are-not-normal.html#working-in-r-3"><span class="toc-section-number">13.3.1</span> Working in R</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#bootstrap-confidence-intervals"><span class="toc-section-number">13.3.2</span> Bootstrap Confidence Intervals</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#permutation-test"><span class="toc-section-number">13.3.3</span> Permutation test</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#non-parametric-tests"><span class="toc-section-number">13.3.4</span> Non-parametric tests</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#log-transformations"><span class="toc-section-number">13.3.5</span> Log transformations</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#performance-of-parametric-tests-and-alternatives"><span class="toc-section-number">13.3.6</span> Performance of parametric tests and alternatives</a></li>
</ul></li>
</ul></li>
<li><a href="part-vi-more-than-one-x-multivariable-models.html#part-vi-more-than-one-x-multivariable-models">Part VI: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="has-sub"><a href="14-adding-covariates-to-a-linear-model.html#adding-covariates-to-a-linear-model"><span class="toc-section-number">14</span> Adding covariates to a linear model</a><ul>
<li><a href="14-1-adding-covariates-can-increases-the-precision-of-the-effect-of-interest.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><span class="toc-section-number">14.1</span> Adding covariates can increases the precision of the effect of interest</a></li>
<li class="has-sub"><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data"><span class="toc-section-number">14.2</span> Understanding a linear model with an added covariate – heart necrosis data</a><ul>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#fit-the-model-1"><span class="toc-section-number">14.2.1</span> Fit the model</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#plot-the-model-1"><span class="toc-section-number">14.2.2</span> Plot the model</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#interpretation-of-the-model-coefficients"><span class="toc-section-number">14.2.3</span> Interpretation of the model coefficients</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#everything-adds-up"><span class="toc-section-number">14.2.4</span> Everything adds up</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#interpretation-of-the-estimated-marginal-means"><span class="toc-section-number">14.2.5</span> Interpretation of the estimated marginal means</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#interpretation-of-the-contrasts"><span class="toc-section-number">14.2.6</span> Interpretation of the contrasts</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#adding-the-covariate-improves-inference"><span class="toc-section-number">14.2.7</span> Adding the covariate improves inference</a></li>
</ul></li>
<li class="has-sub"><a href="14-3-understanding-interaction-effects-with-covariates.html#understanding-interaction-effects-with-covariates"><span class="toc-section-number">14.3</span> Understanding interaction effects with covariates</a><ul>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#fit-the-model-2"><span class="toc-section-number">14.3.1</span> Fit the model</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#plot-the-model-with-interaction-effect"><span class="toc-section-number">14.3.2</span> Plot the model with interaction effect</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#interpretation-of-the-model-coefficients-1"><span class="toc-section-number">14.3.3</span> Interpretation of the model coefficients</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#what-is-the-effect-of-a-treatment-if-interactions-are-modeled-it-depends."><span class="toc-section-number">14.3.4</span> What is the effect of a treatment, if interactions are modeled? – it depends.</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#which-model-do-we-use-mathcalm_1-or-mathcalm_2"><span class="toc-section-number">14.3.5</span> Which model do we use, <span class="math inline">\(\mathcal{M}_1\)</span> or <span class="math inline">\(\mathcal{M}_2\)</span>?</a></li>
</ul></li>
<li><a href="14-4-understanding-ancova-tables.html#understanding-ancova-tables"><span class="toc-section-number">14.4</span> Understanding ANCOVA tables</a></li>
<li class="has-sub"><a href="14-5-working-in-r-4.html#working-in-r-4"><span class="toc-section-number">14.5</span> Working in R</a><ul>
<li><a href="14-5-working-in-r-4.html#importing-the-heart-necrosis-data"><span class="toc-section-number">14.5.1</span> Importing the heart necrosis data</a></li>
<li><a href="14-5-working-in-r-4.html#fitting-the-model"><span class="toc-section-number">14.5.2</span> Fitting the model</a></li>
<li><a href="14-5-working-in-r-4.html#ancova-tables"><span class="toc-section-number">14.5.3</span> ANCOVA tables</a></li>
<li><a href="14-5-working-in-r-4.html#plotting-the-model"><span class="toc-section-number">14.5.4</span> Plotting the model</a></li>
</ul></li>
<li class="has-sub"><a href="14-6-best-practices.html#best-practices"><span class="toc-section-number">14.6</span> Best practices</a><ul>
<li><a href="14-6-best-practices.html#do-not-use-a-ratio-of-partwhole-as-a-response-variable-instead-add-the-denominator-as-a-covariate"><span class="toc-section-number">14.6.1</span> Do not use a ratio of part:whole as a response variable – instead add the denominator as a covariate</a></li>
<li><a href="14-6-best-practices.html#do-not-use-change-from-baseline-as-a-response-variable-instead-add-the-baseline-measure-as-a-covariate"><span class="toc-section-number">14.6.2</span> Do not use change from baseline as a response variable – instead add the baseline measure as a covariate</a></li>
<li><a href="14-6-best-practices.html#do-not-test-for-balance-of-baseline-measures"><span class="toc-section-number">14.6.3</span> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li><a href="14-7-best-practices-2-use-a-covariate-instead-of-normalizing-a-response.html#best-practices-2-use-a-covariate-instead-of-normalizing-a-response"><span class="toc-section-number">14.7</span> Best practices 2: Use a covariate instead of normalizing a response</a></li>
</ul></li>
<li class="has-sub"><a href="15-two-or-more-categorical-x-factorial-designs.html#two-or-more-categorical-x-factorial-designs"><span class="toc-section-number">15</span> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="has-sub"><a href="15-1-factorial-experiments.html#factorial-experiments"><span class="toc-section-number">15.1</span> Factorial experiments</a><ul>
<li><a href="15-1-factorial-experiments.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><span class="toc-section-number">15.1.1</span> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li><a href="15-1-factorial-experiments.html#what-is-the-biological-meaning-of-an-interaction-effect"><span class="toc-section-number">15.1.2</span> What is the biological meaning of an interaction effect?</a></li>
<li><a href="15-1-factorial-experiments.html#the-interpretation-of-the-coefficients-in-a-factorial-model-is-entirely-dependent-on-the-reference"><span class="toc-section-number">15.1.3</span> The interpretation of the coefficients in a factorial model is entirely dependent on the reference…</a></li>
<li><a href="15-1-factorial-experiments.html#estimated-marginal-means"><span class="toc-section-number">15.1.4</span> Estimated marginal means</a></li>
<li><a href="15-1-factorial-experiments.html#in-a-factorial-model-there-are-multiple-effects-of-each-factor-simple-effects"><span class="toc-section-number">15.1.5</span> In a factorial model, there are multiple effects of each factor (simple effects)</a></li>
<li><a href="15-1-factorial-experiments.html#marginal-effects"><span class="toc-section-number">15.1.6</span> Marginal effects</a></li>
<li><a href="15-1-factorial-experiments.html#the-additive-model"><span class="toc-section-number">15.1.7</span> The additive model</a></li>
<li><a href="15-1-factorial-experiments.html#reduce-models-for-the-right-reason"><span class="toc-section-number">15.1.8</span> Reduce models for the right reason</a></li>
<li><a href="15-1-factorial-experiments.html#what-about-models-with-more-than-two-factors"><span class="toc-section-number">15.1.9</span> What about models with more than two factors?</a></li>
</ul></li>
<li class="has-sub"><a href="15-2-reporting-results.html#reporting-results"><span class="toc-section-number">15.2</span> Reporting results</a><ul>
<li><a href="15-2-reporting-results.html#text-results"><span class="toc-section-number">15.2.1</span> Text results</a></li>
</ul></li>
<li class="has-sub"><a href="15-3-working-in-r-5.html#working-in-r-5"><span class="toc-section-number">15.3</span> Working in R</a><ul>
<li><a href="15-3-working-in-r-5.html#model-formula"><span class="toc-section-number">15.3.1</span> Model formula</a></li>
<li><a href="15-3-working-in-r-5.html#modeled-means"><span class="toc-section-number">15.3.2</span> Modeled means</a></li>
<li><a href="15-3-working-in-r-5.html#marginal-means"><span class="toc-section-number">15.3.3</span> Marginal means</a></li>
<li><a href="15-3-working-in-r-5.html#contrasts"><span class="toc-section-number">15.3.4</span> Contrasts</a></li>
<li><a href="15-3-working-in-r-5.html#simple-effects"><span class="toc-section-number">15.3.5</span> Simple effects</a></li>
<li><a href="15-3-working-in-r-5.html#marginal-effects-1"><span class="toc-section-number">15.3.6</span> Marginal effects</a></li>
<li><a href="15-3-working-in-r-5.html#plotting-results"><span class="toc-section-number">15.3.7</span> Plotting results</a></li>
</ul></li>
<li><a href="15-4-problems-1.html#problems-1"><span class="toc-section-number">15.4</span> Problems</a></li>
</ul></li>
<li class="has-sub"><a href="16-anova-tables.html#anova-tables"><span class="toc-section-number">16</span> ANOVA Tables</a><ul>
<li><a href="16-1-summary-of-usage.html#summary-of-usage"><span class="toc-section-number">16.1</span> Summary of usage</a></li>
<li><a href="16-2-example-a-one-way-anova-using-the-vole-data.html#example-a-one-way-anova-using-the-vole-data"><span class="toc-section-number">16.2</span> Example: a one-way ANOVA using the vole data</a></li>
<li class="has-sub"><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#example-a-two-way-anova-using-the-urchin-data"><span class="toc-section-number">16.3</span> Example: a two-way ANOVA using the urchin data</a><ul>
<li><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#how-to-read-an-anova-table"><span class="toc-section-number">16.3.1</span> How to read an ANOVA table</a></li>
<li><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#how-to-read-anova-results-reported-in-the-text"><span class="toc-section-number">16.3.2</span> How to read ANOVA results reported in the text</a></li>
<li><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#better-practice-estimates-and-their-uncertainty"><span class="toc-section-number">16.3.3</span> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="has-sub"><a href="16-4-unbalanced-designs.html#unbalanced-designs"><span class="toc-section-number">16.4</span> Unbalanced designs</a><ul>
<li><a href="16-4-unbalanced-designs.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><span class="toc-section-number">16.4.1</span> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li><a href="16-4-unbalanced-designs.html#back-to-interpretation-of-main-effects"><span class="toc-section-number">16.4.2</span> Back to interpretation of main effects</a></li>
<li><a href="16-4-unbalanced-designs.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><span class="toc-section-number">16.4.3</span> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="has-sub"><a href="16-5-working-in-r-6.html#working-in-r-6"><span class="toc-section-number">16.5</span> Working in R</a><ul>
<li><a href="16-5-working-in-r-6.html#type-i-sum-of-squares-in-r"><span class="toc-section-number">16.5.1</span> Type I sum of squares in R</a></li>
<li><a href="16-5-working-in-r-6.html#type-ii-and-iii-sum-of-squares"><span class="toc-section-number">16.5.2</span> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="17-predictive-models.html#predictive-models"><span class="toc-section-number">17</span> Predictive Models</a><ul>
<li><a href="17-1-overfitting.html#overfitting"><span class="toc-section-number">17.1</span> Overfitting</a></li>
<li class="has-sub"><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#model-building-vs.-variable-selection-vs.-model-selection"><span class="toc-section-number">17.2</span> Model building vs. Variable selection vs. Model selection</a><ul>
<li><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#stepwise-regression"><span class="toc-section-number">17.2.1</span> Stepwise regression</a></li>
<li><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#cross-validation"><span class="toc-section-number">17.2.2</span> Cross-validation</a></li>
<li><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#penalization"><span class="toc-section-number">17.2.3</span> Penalization</a></li>
</ul></li>
<li><a href="17-3-shrinkage.html#shrinkage"><span class="toc-section-number">17.3</span> Shrinkage</a></li>
</ul></li>
<li><a href="part-vii-expanding-the-linear-model.html#part-vii-expanding-the-linear-model">Part VII – Expanding the Linear Model</a></li>
<li class="has-sub"><a href="18-models-with-random-effects-blocking-and-pseudoreplication.html#models-with-random-effects-blocking-and-pseudoreplication"><span class="toc-section-number">18</span> Models with random effects – Blocking and pseudoreplication</a><ul>
<li><a href="18-1-random-effects.html#random-effects"><span class="toc-section-number">18.1</span> Random effects</a></li>
<li><a href="18-2-random-effects-in-statistical-models.html#random-effects-in-statistical-models"><span class="toc-section-number">18.2</span> Random effects in statistical models</a></li>
<li><a href="18-3-linear-mixed-models-are-flexible.html#linear-mixed-models-are-flexible"><span class="toc-section-number">18.3</span> Linear mixed models are flexible</a></li>
<li class="has-sub"><a href="18-4-blocking.html#blocking"><span class="toc-section-number">18.4</span> Blocking</a><ul>
<li><a href="18-4-blocking.html#visualing-variation-due-to-blocks"><span class="toc-section-number">18.4.1</span> Visualing variation due to blocks</a></li>
<li><a href="18-4-blocking.html#blocking-increases-precision-of-point-estimates"><span class="toc-section-number">18.4.2</span> Blocking increases precision of point estimates</a></li>
</ul></li>
<li class="has-sub"><a href="18-5-pseudoreplication.html#pseudoreplication"><span class="toc-section-number">18.5</span> Pseudoreplication</a><ul>
<li><a href="18-5-pseudoreplication.html#visualizing-pseduoreplication"><span class="toc-section-number">18.5.1</span> Visualizing pseduoreplication</a></li>
</ul></li>
<li><a href="18-6-mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model.html#mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model"><span class="toc-section-number">18.6</span> Mapping NHST to estimation: A paired t-test is a special case of a linear mixed model</a></li>
<li><a href="18-7-advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling.html#advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling"><span class="toc-section-number">18.7</span> Advanced topic – Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="has-sub"><a href="18-8-working-in-r-7.html#working-in-r-7"><span class="toc-section-number">18.8</span> Working in R</a><ul>
<li><a href="18-8-working-in-r-7.html#coral-data"><span class="toc-section-number">18.8.1</span> coral data</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="19-models-for-longitudinal-experiments-pre-post-designs.html#models-for-longitudinal-experiments-pre-post-designs"><span class="toc-section-number">19</span> Models for longitudinal experiments – pre-post designs</a><ul>
<li><a href="19-1-best-practice-models.html#best-practice-models"><span class="toc-section-number">19.1</span> Best practice models</a></li>
<li><a href="19-2-common-alternatives-that-are-not-recommended.html#common-alternatives-that-are-not-recommended"><span class="toc-section-number">19.2</span> Common alternatives that are not recommended</a></li>
<li><a href="19-3-advanced-models.html#advanced-models"><span class="toc-section-number">19.3</span> Advanced models</a></li>
<li class="has-sub"><a href="19-4-understanding-the-alternative-models.html#understanding-the-alternative-models"><span class="toc-section-number">19.4</span> Understanding the alternative models</a><ul>
<li><a href="19-4-understanding-the-alternative-models.html#m1-linear-model-with-the-baseline-measure-as-the-covariate-ancova-model"><span class="toc-section-number">19.4.1</span> (M1) Linear model with the baseline measure as the covariate (ANCOVA model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m2-linear-model-of-the-change-score-change-score-model"><span class="toc-section-number">19.4.2</span> (M2) Linear model of the change score (change-score model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m3-linear-model-of-post-baseline-values-without-the-baseline-as-a-covariate-post-model"><span class="toc-section-number">19.4.3</span> (M3) Linear model of post-baseline values without the baseline as a covariate (post model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m4-linear-model-with-factorial-fixed-effects-fixed-effects-model"><span class="toc-section-number">19.4.4</span> (M4) Linear model with factorial fixed effects (fixed-effects model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m5-repeated-measures-anova"><span class="toc-section-number">19.4.5</span> (M5) Repeated measures ANOVA</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m6-linear-mixed-model"><span class="toc-section-number">19.4.6</span> (M6) Linear mixed model</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m7-linear-model-with-correlated-error"><span class="toc-section-number">19.4.7</span> (M7) Linear model with correlated error</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m8-constrained-fixed-effects-model-with-correlated-error-clda-model"><span class="toc-section-number">19.4.8</span> (M8) Constrained fixed effects model with correlated error (cLDA model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#comparison-table"><span class="toc-section-number">19.4.9</span> Comparison table</a></li>
</ul></li>
<li class="has-sub"><a href="19-5-example-1-a-single-post-baseline-measure-pre-post-design.html#example-1-a-single-post-baseline-measure-pre-post-design"><span class="toc-section-number">19.5</span> Example 1 – a single post-baseline measure (pre-post design)</a><ul>
<li><a href="19-5-example-1-a-single-post-baseline-measure-pre-post-design.html#analysis"><span class="toc-section-number">19.5.1</span> Analysis</a></li>
</ul></li>
<li><a href="19-6-working-in-r-8.html#working-in-r-8"><span class="toc-section-number">19.6</span> Working in R</a></li>
</ul></li>
<li class="has-sub"><a href="20-generalized-linear-models-i-count-data.html#generalized-linear-models-i-count-data"><span class="toc-section-number">20</span> Generalized linear models I: Count data</a><ul>
<li><a href="20-1-the-generalized-linear-model.html#the-generalized-linear-model"><span class="toc-section-number">20.1</span> The generalized linear model</a></li>
<li class="has-sub"><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><span class="toc-section-number">20.2</span> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#modeling-strategy-1"><span class="toc-section-number">20.2.1</span> Modeling strategy</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#checking-the-model-i-a-normal-q-q-plot"><span class="toc-section-number">20.2.2</span> Checking the model I – a Normal Q-Q plot</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><span class="toc-section-number">20.2.3</span> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#two-distributions-for-count-data-poisson-and-negative-binomial"><span class="toc-section-number">20.2.4</span> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><span class="toc-section-number">20.2.5</span> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#model-checking-fits-to-count-data"><span class="toc-section-number">20.2.6</span> Model checking fits to count data</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><span class="toc-section-number">20.2.7</span> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="has-sub"><a href="20-3-working-in-r-9.html#working-in-r-9"><span class="toc-section-number">20.3</span> Working in R</a><ul>
<li><a href="20-3-working-in-r-9.html#fitting-a-glm-to-count-data"><span class="toc-section-number">20.3.1</span> Fitting a GLM to count data</a></li>
<li><a href="20-3-working-in-r-9.html#fitting-a-generalized-linear-mixed-model-glmm-to-count-data"><span class="toc-section-number">20.3.2</span> Fitting a generalized linear mixed model (GLMM) to count data</a></li>
<li><a href="20-3-working-in-r-9.html#fitting-a-generalized-linear-model-to-continouus-data"><span class="toc-section-number">20.3.3</span> Fitting a generalized linear model to continouus data</a></li>
</ul></li>
<li><a href="20-4-problems-2.html#problems-2"><span class="toc-section-number">20.4</span> Problems</a></li>
</ul></li>
<li class="has-sub"><a href="21-linear-models-with-heterogenous-variance.html#linear-models-with-heterogenous-variance"><span class="toc-section-number">21</span> Linear models with heterogenous variance</a><ul>
<li><a href="21-1-gls.html#gls"><span class="toc-section-number">21.1</span> gls</a></li>
</ul></li>
<li><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html#part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models">Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="has-sub"><a href="22-plotting-functions-ggplotsci.html#plotting-functions-ggplotsci"><span class="toc-section-number">22</span> Plotting functions (#ggplotsci)</a><ul>
<li><a href="22-1-odd-even.html#odd-even"><span class="toc-section-number">22.1</span> odd-even</a></li>
<li><a href="22-2-estimate-response-and-effects-with-emmeans.html#estimate-response-and-effects-with-emmeans"><span class="toc-section-number">22.2</span> estimate response and effects with emmeans</a></li>
<li><a href="22-3-emm-table.html#emm_table"><span class="toc-section-number">22.3</span> emm_table</a></li>
<li><a href="22-4-pairs-table.html#pairs_table"><span class="toc-section-number">22.4</span> pairs_table</a></li>
<li><a href="22-5-gg-mean-error.html#gg_mean_error"><span class="toc-section-number">22.5</span> gg_mean_error</a></li>
<li><a href="22-6-gg-ancova.html#gg_ancova"><span class="toc-section-number">22.6</span> gg_ancova</a></li>
<li><a href="22-7-gg-mean-ci-ancova.html#gg_mean_ci_ancova"><span class="toc-section-number">22.7</span> gg_mean_ci_ancova</a></li>
<li><a href="22-8-gg-effects.html#gg_effects"><span class="toc-section-number">22.8</span> gg_effects</a></li>
</ul></li>
<li class="has-sub"><a href="appendix-1-getting-started-with-r.html#appendix-1-getting-started-with-r">Appendix 1: Getting Started with R</a><ul>
<li class="has-sub"><a href="22-9-get-your-computer-ready.html#get-your-computer-ready"><span class="toc-section-number">22.9</span> Get your computer ready</a><ul>
<li><a href="22-9-get-your-computer-ready.html#start-here"><span class="toc-section-number">22.9.1</span> Start here</a></li>
<li><a href="22-9-get-your-computer-ready.html#install-r"><span class="toc-section-number">22.9.2</span> Install R</a></li>
<li><a href="22-9-get-your-computer-ready.html#install-r-studio"><span class="toc-section-number">22.9.3</span> Install R Studio</a></li>
<li><a href="22-9-get-your-computer-ready.html#install-r-markdown-1"><span class="toc-section-number">22.9.4</span> Install R Markdown</a></li>
<li><a href="22-9-get-your-computer-ready.html#optional-alternative-latex-installations"><span class="toc-section-number">22.9.5</span> (optional) Alternative LaTeX installations</a></li>
</ul></li>
<li><a href="22-10-start-learning-r-studio.html#start-learning-r-studio"><span class="toc-section-number">22.10</span> Start learning R Studio</a></li>
</ul></li>
<li><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html#appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r">Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="has-sub"><a href="appendix-3-fake-data-simulations.html#appendix-3-fake-data-simulations">Appendix 3: Fake Data Simulations</a><ul>
<li><a href="22-11-performance-of-blocking-relative-to-a-linear-model.html#performance-of-blocking-relative-to-a-linear-model"><span class="toc-section-number">22.11</span> Performance of Blocking relative to a linear model</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="inference-when-data-are-not-normal" class="section level2">
<h2><span class="header-section-number">13.3</span> Inference when data are not Normal</h2>
<p>No real data are normal, although many are pretty good approximations of a normal distribution.</p>
<p>I’ll come back to this point, but first, let’s back up. Inference in statistical models (standard errors, confidence intervals, <em>p</em>-values) are a function of the modeled distributions of the parameters (for linear models, this parameter is the conditional (or error) variance <span class="math inline">\(\sigma^2\)</span>); if the data do not approximate the modeled distribution, then inferential statistics might be to liberal (standard errors are too small, confidence intervals are too narrow, Type I error is more than nominal) or to conservative (standard errors are too large, confidence intervals are too wide, Type I error is less than nominal).</p>
<p>Linear models assume that “the data” (specifically, the conditional response, or, equivalently, the residuals from the model) approximate a Normal distribution. Chapter xxx showed how to qualitatively assess how well residuals approximate a Normal distribution using a Q-Q plot. If the researcher concludes that the data poorly approximate a normal distribution because of outliers, the researcher can use robust methods to estimate the parameters. If the approximation is poor because the residuals suggest a skewed distribution or one with heavy or light tails, the researcher can choose among several strategies</p>
<ol style="list-style-type: decimal">
<li>continue to use the linear model; inference can be fairly robust to non-normal data, especially when the sample size is not small.</li>
<li>use a generalized linear model (GLM), which is appropriate if the conditional response approximates any of the distributions that can be modeled using GLM (Chapter xxx)</li>
<li>use bootstrap for confidence intervals and permutation test for <em>p</em>-values</li>
<li>transform the data in a way that makes the conditional response more closely approximate a normal distribution.</li>
<li>use a classic non-parametric test, which are methods that do not assume a particular distribution</li>
</ol>
<p>This list is roughly in the order of how I would advise researchers, although the order of 1-3 is pretty arbitrary. I would rarely advise a researcher to use (4) and never advise (5). Probably the most common strategies in the biology literature are (4) and (5). The first is also common but probably more from lack of recognition of issues or because a “test of normality” failed to reject that the data are “not normal”.</p>
<p>On this last point, do not use the <em>p</em>-value from a “test for normality” (such as a Shapiro-Wilk test) to decide between using the linear model (or t-test or ANOVA) and an alternative such as a generalized linear model (or transformation or non-parametric test). No real data is normal. Tests of normality will tend to “not reject” normality (p &gt; 0.05) when the sample size is small and “reject” normality (p &lt; 0.05) when the sample size is very large. But again, a “not rejected” hypothesis test does not mean the null (in this case, the data are normal) is true. More importantly, where the test for normality tends to fail to reject (encouraging a researcher to use parametric statistics) is where parametric inference performs the worst (because of small <em>n</em>) and where the test for normality tends to reject (encouraging a researcher to use non-parametric statistics) is where the parametric inference performs the best (because of large sample size) (Lumley xxx).</p>
<div id="working-in-r-3" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Working in R</h3>
<p>The data for demonstrating different strategies are from Fig. 4A of “Data from The enteric nervous system promotes intestinal health by constraining microbiota composition”. There is a single factor with two treatment levels. The response is neutrophil count.</p>
<div class="figure"><span id="fig:best-import-non-normal-counts"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/best-import-non-normal-counts-1.png" alt="Distribution of the counts in the wildtype (WT) and sox10 knockout (sox10-) groups. Both groups show a strong right skew, which is common with count data." width="576" />
<p class="caption">
Figure 9.6: Distribution of the counts in the wildtype (WT) and sox10 knockout (sox10-) groups. Both groups show a strong right skew, which is common with count data.
</p>
</div>
<p>A linear model to estimate the treatment effect and 95% confidence interval.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="13-3-inference-when-data-are-not-normal.html#cb369-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span>
<span id="cb369-2"><a href="13-3-inference-when-data-are-not-normal.html#cb369-2"></a>m1_emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m1, <span class="dt">specs=</span><span class="st">&quot;treatment&quot;</span>)</span>
<span id="cb369-3"><a href="13-3-inference-when-data-are-not-normal.html#cb369-3"></a><span class="kw">summary</span>(<span class="kw">contrast</span>(m1_emm, <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>),</span>
<span id="cb369-4"><a href="13-3-inference-when-data-are-not-normal.html#cb369-4"></a>        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  contrast   estimate   SE  df lower.CL upper.CL t.ratio p.value
##  sox10 - wt     5.16 1.75 174      1.7     8.62 2.947   0.0037 
## 
## Confidence level used: 0.95</code></pre>
</div>
<div id="bootstrap-confidence-intervals" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Bootstrap Confidence Intervals</h3>
<p>A bootstrap confidence interval is computed from the distribution of a statistic from many sets of re-sampled data. The basic algorithm is</p>
<ol style="list-style-type: decimal">
<li>compute the statistic for the observed data, assign this to <span class="math inline">\(\theta_1\)</span></li>
<li>resample <span class="math inline">\(n\)</span> rows of the data, with replacement. “with replacement” means to sample from the entire set of data and not the set that has yet to be sampled. <span class="math inline">\(n\)</span> is the original sample size; by resampling <span class="math inline">\(n\)</span> rows with replacement, some rows will be sampled more than once, and some rows will not be sampled at all.</li>
<li>compute the statistic for the resampled data, assign these to <span class="math inline">\(\theta_{2..m}\)</span></li>
<li>repeat 2 and 3 <span class="math inline">\(m-1\)</span> times</li>
<li>Given the distribution of <span class="math inline">\(m\)</span> estimates, compute the lower interval as the <span class="math inline">\(\frac{\alpha}{2}\)</span>th percentile and the upper interval as the <span class="math inline">\(1 - \frac{\alpha}{2}\)</span>th percentile. For 95% confidence intervals, these are the 2.5th and 97.5th percentiles.</li>
</ol>
<p>Let’s apply this algorithm to the data from fig4A neutrophil count data in the coefficient table above. The focal statistic in these data is the difference in the mean count for the sox10 and wild type groups (the parameter for <span class="math inline">\(treatment\)</span> in the linear model). The script below, which computes the 95% confidence intervals of this difference, resamples within <strong>strata</strong>, that is, within each group; it does this to preserve the original sample size within each group.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="13-3-inference-when-data-are-not-normal.html#cb371-1"></a>n_iter &lt;-<span class="st"> </span><span class="dv">5000</span></span>
<span id="cb371-2"><a href="13-3-inference-when-data-are-not-normal.html#cb371-2"></a>b1 &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">5000</span>)</span>
<span id="cb371-3"><a href="13-3-inference-when-data-are-not-normal.html#cb371-3"></a>inc &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(fig4a) <span class="co"># the rows for the first iteration are all rows, so this is the observed effect</span></span>
<span id="cb371-4"><a href="13-3-inference-when-data-are-not-normal.html#cb371-4"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_iter){</span>
<span id="cb371-5"><a href="13-3-inference-when-data-are-not-normal.html#cb371-5"></a>  <span class="co"># inc creates the index of rows to resample preserving the sample size specific to each group</span></span>
<span id="cb371-6"><a href="13-3-inference-when-data-are-not-normal.html#cb371-6"></a>  b1[i] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a[inc, ]))[<span class="st">&quot;treatmentsox10&quot;</span>]</span>
<span id="cb371-7"><a href="13-3-inference-when-data-are-not-normal.html#cb371-7"></a>  inc &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">sample</span>(<span class="kw">which</span>(fig4a[, treatment] <span class="op">==</span><span class="st"> &quot;wt&quot;</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>),</span>
<span id="cb371-8"><a href="13-3-inference-when-data-are-not-normal.html#cb371-8"></a>           <span class="kw">sample</span>(<span class="kw">which</span>(fig4a[, treatment] <span class="op">==</span><span class="st"> &quot;sox10&quot;</span>), <span class="dt">replace=</span><span class="ot">TRUE</span>))</span>
<span id="cb371-9"><a href="13-3-inference-when-data-are-not-normal.html#cb371-9"></a>}</span>
<span id="cb371-10"><a href="13-3-inference-when-data-are-not-normal.html#cb371-10"></a>ci &lt;-<span class="st"> </span><span class="kw">quantile</span>(b1, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb371-11"><a href="13-3-inference-when-data-are-not-normal.html#cb371-11"></a><span class="kw">c</span>(<span class="dt">contrast =</span> b1[<span class="dv">1</span>], ci[<span class="dv">1</span>], ci[<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## contrast     2.5%    97.5% 
## 5.163215 2.077892 8.264316</code></pre>
<p>The intervals calculated in step 5 are <strong>percentile intervals</strong>. A histogram of the the re-sampled differences helps to visualize the bootstrap (this is a pedagogical tool, not something you would want to publish).</p>
<div class="figure"><span id="fig:best-bootstrap-histogram"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/best-bootstrap-histogram-1.png" alt="Distribution of the 5000 resampled estimates of the difference in means between the sox10 and wt treatment levels. The dashed lines are located at the 2.5th and 97.5th percentiles of the distribution." width="576" />
<p class="caption">
Figure 9.7: Distribution of the 5000 resampled estimates of the difference in means between the sox10 and wt treatment levels. The dashed lines are located at the 2.5th and 97.5th percentiles of the distribution.
</p>
</div>
<div id="some-r-packages-for-bootstrap-confidence-intervals" class="section level4">
<h4><span class="header-section-number">13.3.2.1</span> Some R packages for bootstrap confidence intervals</h4>
<p>Percentile intervals are known to be biased, meaning the intervals are shifted. The <code>boot</code> package computes a bias-corrected interval in addition to a percentile interval. <code>boot</code> is a very powerful bootstrap package but requires the researcher to write functions to compute the parameter of interest. <code>simpleboot</code> provides functions for common analysis that does this for you (in R speak, we say that <code>simpleboot</code> is a “wrapper” to <code>boot</code>). The function <code>simpleboot::two.boot</code> computes a <code>boot</code>-like object that returns, among other values, the distribution of <span class="math inline">\(m\)</span> statistics. The <code>simpleboot</code> object is then be fed to <code>boot::boot.ci</code> to get bias-corrected intervals.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="13-3-inference-when-data-are-not-normal.html#cb373-1"></a>bs_diff &lt;-<span class="st"> </span><span class="kw">two.boot</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count],</span>
<span id="cb373-2"><a href="13-3-inference-when-data-are-not-normal.html#cb373-2"></a>                    fig4a[treatment<span class="op">==</span><span class="st">&quot;wt&quot;</span>, count],</span>
<span id="cb373-3"><a href="13-3-inference-when-data-are-not-normal.html#cb373-3"></a>                    mean, </span>
<span id="cb373-4"><a href="13-3-inference-when-data-are-not-normal.html#cb373-4"></a>                    <span class="dt">R=</span><span class="dv">5000</span>)</span>
<span id="cb373-5"><a href="13-3-inference-when-data-are-not-normal.html#cb373-5"></a><span class="kw">boot.ci</span>(bs_diff, <span class="dt">type=</span><span class="st">&quot;bca&quot;</span>)</span></code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 5000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = bs_diff, type = &quot;bca&quot;)
## 
## Intervals : 
## Level       BCa          
## 95%   ( 2.087,  8.410 )  
## Calculations and Intervals on Original Scale</code></pre>
</div>
</div>
<div id="permutation-test" class="section level3">
<h3><span class="header-section-number">13.3.3</span> Permutation test</h3>
<p>A permutation test effectively computes the probability that a random assignment of a response to a particular value of <em>X</em> generates a test statistic as large or larger than the observed statistic. If this probability is small, then this “random assignment” is unlikely. From this we infer that the actual assignment matters, which implies a treatment effect.</p>
<p>The basic algorithm is</p>
<ol style="list-style-type: decimal">
<li>compute the test statistic for the observed data, assign this to <span class="math inline">\(\theta_1\)</span></li>
<li>permute the response</li>
<li>compute the test statistic for the permuted data, assign these to <span class="math inline">\(\theta_{2..m}\)</span></li>
<li>repeat 2 and 3 <span class="math inline">\(m-1\)</span> times</li>
<li>compute <span class="math inline">\(p\)</span> as</li>
</ol>
<p><span class="math display">\[\begin{equation}
p_{perm} = \frac{N_{\theta_i \ge \theta_{1}}}{m}
\end{equation}\]</span></p>
<p>This is easily done with a <strong>for loop</strong> in which the observed statistic is the first value in the vector of statistics. If this is done, the minimum value in the numerator for the computation of <span class="math inline">\(p_{perm}\)</span> is 1, which insures that <span class="math inline">\(p_{perm}\)</span> is not zero.</p>
<p>The test statistic depends on the analysis. For the simple comparison of means, a simple test statistic is the difference in means. This is the numerator of the test statistic in a <em>t</em>-test. The test has more power if the test-statistic is scaled (Manley xxx), so a better test statistic would be <em>t</em>, which scales the difference by its standard error.</p>
<p>Here, I implement this algorithm. The test is two-tailed, so the absolute difference is recorded. The first value computed is the observed absolute difference.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="13-3-inference-when-data-are-not-normal.html#cb375-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb375-2"><a href="13-3-inference-when-data-are-not-normal.html#cb375-2"></a>n_permutations &lt;-<span class="st"> </span><span class="dv">5000</span></span>
<span id="cb375-3"><a href="13-3-inference-when-data-are-not-normal.html#cb375-3"></a>d &lt;-<span class="st"> </span><span class="kw">numeric</span>(n_permutations)</span>
<span id="cb375-4"><a href="13-3-inference-when-data-are-not-normal.html#cb375-4"></a></span>
<span id="cb375-5"><a href="13-3-inference-when-data-are-not-normal.html#cb375-5"></a><span class="co"># create a new column which will contain the permuted response</span></span>
<span id="cb375-6"><a href="13-3-inference-when-data-are-not-normal.html#cb375-6"></a><span class="co"># for the first iteration, this will be the observed order</span></span>
<span id="cb375-7"><a href="13-3-inference-when-data-are-not-normal.html#cb375-7"></a>fig4a[, count_perm <span class="op">:</span><span class="er">=</span><span class="st"> </span>count]</span>
<span id="cb375-8"><a href="13-3-inference-when-data-are-not-normal.html#cb375-8"></a></span>
<span id="cb375-9"><a href="13-3-inference-when-data-are-not-normal.html#cb375-9"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_permutations){</span>
<span id="cb375-10"><a href="13-3-inference-when-data-are-not-normal.html#cb375-10"></a>  d[i] &lt;-<span class="st"> </span><span class="kw">abs</span>(<span class="kw">t.test</span>(count_perm <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data =</span> fig4a)<span class="op">$</span>statistic)</span>
<span id="cb375-11"><a href="13-3-inference-when-data-are-not-normal.html#cb375-11"></a>  </span>
<span id="cb375-12"><a href="13-3-inference-when-data-are-not-normal.html#cb375-12"></a>  <span class="co"># permute the count_perm column for the next iteration</span></span>
<span id="cb375-13"><a href="13-3-inference-when-data-are-not-normal.html#cb375-13"></a>  fig4a[, count_perm <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">sample</span>(count)]</span>
<span id="cb375-14"><a href="13-3-inference-when-data-are-not-normal.html#cb375-14"></a>}</span>
<span id="cb375-15"><a href="13-3-inference-when-data-are-not-normal.html#cb375-15"></a>p &lt;-<span class="st"> </span><span class="kw">sum</span>(d <span class="op">&gt;=</span><span class="st"> </span>d[<span class="dv">1</span>])<span class="op">/</span>n_permutations</span>
<span id="cb375-16"><a href="13-3-inference-when-data-are-not-normal.html#cb375-16"></a>p</span></code></pre></div>
<pre><code>## [1] 0.002</code></pre>
<div id="some-r-packages-with-permutation-tests." class="section level4">
<h4><span class="header-section-number">13.3.3.1</span> Some R packages with permutation tests.</h4>
<p><code>lmPerm::lmp</code> generates permutation p-values for parameters of any kind of linear model. The test statistic is the sum of squares of the term scaled by the residual sum of squares of the model.</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="13-3-inference-when-data-are-not-normal.html#cb377-1"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb377-2"><a href="13-3-inference-when-data-are-not-normal.html#cb377-2"></a><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>, </span>
<span id="cb377-3"><a href="13-3-inference-when-data-are-not-normal.html#cb377-3"></a>                 <span class="dt">data=</span>fig4a)))</span></code></pre></div>
<pre><code>## [1] &quot;Settings:  unique SS &quot;</code></pre>
<pre><code>##              Estimate Iter Pr(Prob)
## (Intercept) 13.694815 5000   0.0042
## treatment1  -2.581608 5000   0.0042</code></pre>
</div>
</div>
<div id="non-parametric-tests" class="section level3">
<h3><span class="header-section-number">13.3.4</span> Non-parametric tests</h3>
<ol style="list-style-type: decimal">
<li>In general, the role of a non-parametric test is a better-behaved <em>p</em>-value, that is, one whose Type I error is well controlled. As such, non-parametric tests are more about Null-Hypothesis Statistical Testing and less (or not at all) about Estimation.</li>
<li>In general, classic non-parametric tests are only available for fairly simple experimental designs. Classic non-parametric tests include
<ul>
<li>Independent sample (Student’s) <em>t</em> test: Mann-Whitney-Wilcoxan</li>
<li>Paired <em>t</em> test: Wilcoxan signed-rank test</li>
</ul></li>
</ol>
<p>One rarely sees non-parametric tests for more complex designs that include covariates, or multiple factors, but for these, one could 1) convert the response to ranks and fit the usual linear model, or 2) implement a permutation test that properly preserves <strong>exchangeability</strong>.</p>
<p>Permutation tests control Type I error and are powerful. That said, I would recommend a permutation test as a supplment to, and not replacement of, inference from a generalized linear model.</p>
<p>A non-parametric (Mann-Whitney-Wilcoxon) test of the fake data generated above</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="13-3-inference-when-data-are-not-normal.html#cb380-1"></a><span class="kw">wilcox.test</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  count by treatment
## W = 2275, p-value = 0.001495
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="log-transformations" class="section level3">
<h3><span class="header-section-number">13.3.5</span> Log transformations</h3>
<p>Many response variables within biology, including count data, and almost anything that grows, are right skewed and have variances that increase with the mean. A log transform of a response variable with this kind of distribution will tend to make the residuals more approximately normal and the variance less dependent of the mean. At least two issues arise</p>
<ol style="list-style-type: decimal">
<li>if the response is count data, and the data include counts of zero, then a fudge factor has to be added to the response since log(0) doesn’t exist. The typical fudge factor is to add 1 to <em>all</em> values, but this is arbitrary and results do depend on the magnitude of this fudge factor.</li>
<li>the estimates are on a log scale and do not have the units of the response. The estimates can be back-transformed by taking the exponent of a coefficient or contrast but this itself produces problems. For example, the backtransformed mean of the log-transformed response is not the mean on the origianl scale (the arithmetic mean) but the <strong>geometric mean</strong>. Geometric means are smaller than arithmetic means, appreciably so if the data are heavily skewed. Do we want our understanding of a system to be based on geometric means?</li>
</ol>
<div id="working-in-r-log-transformations" class="section level4">
<h4><span class="header-section-number">13.3.5.1</span> Working in R – log transformations</h4>
<p>If we fit a linear model to a log-transformed response then the resulting coefficients and predictions are on the <strong>log scale</strong>. To make interpretation of the analysies easier, we probably want to <strong>back-transform</strong> the coefficients or the predictions to the original scale of the response, which is called the <strong>response scale</strong>.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="13-3-inference-when-data-are-not-normal.html#cb382-1"></a>m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(count <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span>
<span id="cb382-2"><a href="13-3-inference-when-data-are-not-normal.html#cb382-2"></a>(m2_emm &lt;-<span class="st"> </span><span class="kw">emmeans</span>(m2,</span>
<span id="cb382-3"><a href="13-3-inference-when-data-are-not-normal.html#cb382-3"></a>                  <span class="dt">specs=</span><span class="st">&quot;treatment&quot;</span>,</span>
<span id="cb382-4"><a href="13-3-inference-when-data-are-not-normal.html#cb382-4"></a>                  <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))</span></code></pre></div>
<pre><code>##  treatment response    SE  df lower.CL upper.CL
##  wt            8.22 0.965 174      6.5     10.3
##  sox10        12.59 0.934 174     10.9     14.6
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log(mu + 1) scale</code></pre>
<p>The emmeans package is amazing. Using the argument <code>type = "response"</code> not only backtransforms the means to the response scale but also substracts the 1 that was added to all values in the model.</p>
<p>What about the effect of treatment on count?</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="13-3-inference-when-data-are-not-normal.html#cb384-1"></a><span class="kw">summary</span>(<span class="kw">contrast</span>(m2_emm, </span>
<span id="cb384-2"><a href="13-3-inference-when-data-are-not-normal.html#cb384-2"></a>                 <span class="dt">method=</span><span class="st">&quot;revpairwise&quot;</span>,</span>
<span id="cb384-3"><a href="13-3-inference-when-data-are-not-normal.html#cb384-3"></a>                 <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb384-4"><a href="13-3-inference-when-data-are-not-normal.html#cb384-4"></a>        <span class="dt">infer=</span><span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>##  contrast   ratio    SE  df lower.CL upper.CL t.ratio p.value
##  sox10 / wt  1.47 0.185 174     1.15     1.89 3.100   0.0023 
## 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale 
## Tests are performed on the log scale</code></pre>
<p>It isn’t necessary to backtransform the estimated marginal means prior to computing the contrasts as this can be done in the contrast function itself. Here, the <code>type = "response"</code> argument in the contrast function is redundant since this was done in the computation of the means. But it is transparent so I want it there.</p>
<p><strong>Don’t skip this paragraph</strong> Look at the value in the “contrast” column – it is “sox10 / wt” and not “sox10 - wt”. The backtransformed effect is a ratio instead of a difference. <strong>A difference on the log scale is a ratio on the response scale</strong> because of this equality</p>
<p><span class="math display">\[\begin{equation}
\mathrm{exp}(\mu_2-\mu_1) = \frac{\mathrm{exp}(\mu_2)}{\mathrm{exp}(\mu_1)})
\end{equation}\]</span></p>
<p>The interpretation is: If <span class="math inline">\(b^*\)</span> is the backtransformed effect, then, given a one unit increase in <span class="math inline">\(X\)</span>, the expected value of the response increases <span class="math inline">\(b^*\times\)</span>. For a categorical <span class="math inline">\(X\)</span>, this means the backtransformed effect is the ratio of backtransformed means – its what you have to multiply the mean of the reference by to get the mean of the treated group. And, because it is the response that is log-transformed, these means are not arithemetic means but geometric means. Here, this is complicated by the model – the response is not a simple log transformation but log(response + 1). It is easy enough to get the geometric mean of the treated group – multiply the backtransformed intercept by the backtransformed coefficient and then subtract 1 – but because of this subtraction of 1, the interpretation of the backtransformed effect is awkward at best (recall that I told you that a linear model of a log transformed response, and especially the log of the response plus one, leads to difficulty in interpreting the effects).</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="13-3-inference-when-data-are-not-normal.html#cb386-1"></a><span class="co"># backtransformed control mean -- a geometric mean</span></span>
<span id="cb386-2"><a href="13-3-inference-when-data-are-not-normal.html#cb386-2"></a>mu_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">coef</span>(m2)[<span class="dv">1</span>])</span>
<span id="cb386-3"><a href="13-3-inference-when-data-are-not-normal.html#cb386-3"></a></span>
<span id="cb386-4"><a href="13-3-inference-when-data-are-not-normal.html#cb386-4"></a><span class="co"># backtransformed effect</span></span>
<span id="cb386-5"><a href="13-3-inference-when-data-are-not-normal.html#cb386-5"></a>b1_star &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">coef</span>(m2)[<span class="dv">2</span>])</span>
<span id="cb386-6"><a href="13-3-inference-when-data-are-not-normal.html#cb386-6"></a></span>
<span id="cb386-7"><a href="13-3-inference-when-data-are-not-normal.html#cb386-7"></a><span class="co"># product minus 1</span></span>
<span id="cb386-8"><a href="13-3-inference-when-data-are-not-normal.html#cb386-8"></a>mu_<span class="dv">1</span><span class="op">*</span>b1_star <span class="dv">-1</span></span></code></pre></div>
<pre><code>## (Intercept) 
##    12.59357</code></pre>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="13-3-inference-when-data-are-not-normal.html#cb388-1"></a><span class="co"># geometric mean of treatment group</span></span>
<span id="cb388-2"><a href="13-3-inference-when-data-are-not-normal.html#cb388-2"></a>n &lt;-<span class="st"> </span><span class="kw">length</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count])</span>
<span id="cb388-3"><a href="13-3-inference-when-data-are-not-normal.html#cb388-3"></a><span class="kw">exp</span>(<span class="kw">mean</span>(<span class="kw">log</span>(fig4a[treatment<span class="op">==</span><span class="st">&quot;sox10&quot;</span>, count<span class="op">+</span><span class="dv">1</span>])))<span class="op">-</span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 12.59357</code></pre>
<p>Back-transformed effect</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="13-3-inference-when-data-are-not-normal.html#cb390-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(count <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data=</span>fig4a)</span></code></pre></div>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="13-3-inference-when-data-are-not-normal.html#cb391-1"></a><span class="kw">exp</span>(<span class="kw">coef</span>(m2)) </span></code></pre></div>
<pre><code>##    (Intercept) treatmentsox10 
##       9.219770       1.474394</code></pre>
</div>
</div>
<div id="performance-of-parametric-tests-and-alternatives" class="section level3">
<h3><span class="header-section-number">13.3.6</span> Performance of parametric tests and alternatives</h3>
<div id="type-i-error-1" class="section level4">
<h4><span class="header-section-number">13.3.6.1</span> Type I error</h4>
<p>If we are going to compute a <span class="math inline">\(p\)</span>-value, we want it to be uniformly distributed “under the null”. A simple way to check this is to compute Type I error. If we set <span class="math inline">\(\alpha = 0.05\)</span>, then we’d expect 5% of tests of an experiment with no effect to have <span class="math inline">\(p &lt; 0.05\)</span>.</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="13-3-inference-when-data-are-not-normal.html#cb393-1"></a><span class="co"># first create a matrix with a bunch of data sets, each in its own column</span></span>
<span id="cb393-2"><a href="13-3-inference-when-data-are-not-normal.html#cb393-2"></a>n &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb393-3"><a href="13-3-inference-when-data-are-not-normal.html#cb393-3"></a>n_sets &lt;-<span class="st"> </span><span class="dv">4000</span></span>
<span id="cb393-4"><a href="13-3-inference-when-data-are-not-normal.html#cb393-4"></a>fake_matrix &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n),</span>
<span id="cb393-5"><a href="13-3-inference-when-data-are-not-normal.html#cb393-5"></a>                   <span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n))</span>
<span id="cb393-6"><a href="13-3-inference-when-data-are-not-normal.html#cb393-6"></a>treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>, <span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)</span>
<span id="cb393-7"><a href="13-3-inference-when-data-are-not-normal.html#cb393-7"></a></span>
<span id="cb393-8"><a href="13-3-inference-when-data-are-not-normal.html#cb393-8"></a>tests &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>, <span class="st">&quot;log_lm&quot;</span>,<span class="st">&quot;mww&quot;</span>, <span class="st">&quot;perm&quot;</span>)</span>
<span id="cb393-9"><a href="13-3-inference-when-data-are-not-normal.html#cb393-9"></a>res_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_sets, <span class="dt">ncol=</span><span class="kw">length</span>(tests))</span>
<span id="cb393-10"><a href="13-3-inference-when-data-are-not-normal.html#cb393-10"></a><span class="kw">colnames</span>(res_matrix) &lt;-<span class="st"> </span>tests</span>
<span id="cb393-11"><a href="13-3-inference-when-data-are-not-normal.html#cb393-11"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sets){</span>
<span id="cb393-12"><a href="13-3-inference-when-data-are-not-normal.html#cb393-12"></a>  res_matrix[j, <span class="st">&quot;lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb393-13"><a href="13-3-inference-when-data-are-not-normal.html#cb393-13"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb393-14"><a href="13-3-inference-when-data-are-not-normal.html#cb393-14"></a>  res_matrix[j, <span class="st">&quot;log_lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(fake_matrix[,j] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb393-15"><a href="13-3-inference-when-data-are-not-normal.html#cb393-15"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb393-16"><a href="13-3-inference-when-data-are-not-normal.html#cb393-16"></a>  res_matrix[j, <span class="st">&quot;mww&quot;</span>] &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb393-17"><a href="13-3-inference-when-data-are-not-normal.html#cb393-17"></a>                                      <span class="dt">exact=</span><span class="ot">FALSE</span>)<span class="op">$</span>p.value</span>
<span id="cb393-18"><a href="13-3-inference-when-data-are-not-normal.html#cb393-18"></a>  res_matrix[j, <span class="st">&quot;perm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb393-19"><a href="13-3-inference-when-data-are-not-normal.html#cb393-19"></a>                                 <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>)))[<span class="dv">2</span>, <span class="st">&quot;Pr(Prob)&quot;</span>]</span>
<span id="cb393-20"><a href="13-3-inference-when-data-are-not-normal.html#cb393-20"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="13-3-inference-when-data-are-not-normal.html#cb394-1"></a><span class="kw">apply</span>(res_matrix, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span>)<span class="op">/</span>n_sets)</span></code></pre></div>
<pre><code>##      lm  log_lm     mww    perm 
## 0.04150 0.05250 0.04350 0.04675</code></pre>
<p>Type I error is computed for the linear model, the linear model with a log transformed responpse, Mann-Whitney-Wilcoxon, and permutation tests. All four tests are slightly conservative for data that look like that modeled. The computed Type I error of the permutation test is closest to the nominal value of 0.05.</p>
</div>
<div id="power-1" class="section level4">
<h4><span class="header-section-number">13.3.6.2</span> Power</h4>
<p>Power is the probability of a test to reject the null hypothesis if the null hypothesis is false (that is, if an effect exists)</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Power} = \mathrm{Prob}(p &lt; \alpha | mathrm{effect} \neq 0)
\end{equation}\]</span></p>
<p>If all we care about is a <span class="math inline">\(p-value\)</span> then we want to use a test that is most powerful. But, while power is defined using <span class="math inline">\(\alpha\)</span>, we <em>can</em> care about power even if we don’t consider <span class="math inline">\(\alpha\)</span> to be a very useful concept because increased power also increases the precision of an estimate (that is, narrows confidence intervals).</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="13-3-inference-when-data-are-not-normal.html#cb396-1"></a><span class="co"># first create a matrix with a bunch of data sets, each in its own column</span></span>
<span id="cb396-2"><a href="13-3-inference-when-data-are-not-normal.html#cb396-2"></a>n &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb396-3"><a href="13-3-inference-when-data-are-not-normal.html#cb396-3"></a>n_sets &lt;-<span class="st"> </span><span class="dv">4000</span></span>
<span id="cb396-4"><a href="13-3-inference-when-data-are-not-normal.html#cb396-4"></a>fake_matrix &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n),</span>
<span id="cb396-5"><a href="13-3-inference-when-data-are-not-normal.html#cb396-5"></a>                   <span class="kw">matrix</span>(<span class="kw">rnegbin</span>(n<span class="op">*</span>n_sets, <span class="dt">mu=</span><span class="dv">20</span>, <span class="dt">theta=</span><span class="dv">1</span>), <span class="dt">nrow=</span>n))</span>
<span id="cb396-6"><a href="13-3-inference-when-data-are-not-normal.html#cb396-6"></a>treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cn&quot;</span>, <span class="st">&quot;tr&quot;</span>), <span class="dt">each=</span>n)</span>
<span id="cb396-7"><a href="13-3-inference-when-data-are-not-normal.html#cb396-7"></a></span>
<span id="cb396-8"><a href="13-3-inference-when-data-are-not-normal.html#cb396-8"></a>tests &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lm&quot;</span>, <span class="st">&quot;log_lm&quot;</span>,<span class="st">&quot;mww&quot;</span>, <span class="st">&quot;perm&quot;</span>)</span>
<span id="cb396-9"><a href="13-3-inference-when-data-are-not-normal.html#cb396-9"></a>res_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_sets, <span class="dt">ncol=</span><span class="kw">length</span>(tests))</span>
<span id="cb396-10"><a href="13-3-inference-when-data-are-not-normal.html#cb396-10"></a><span class="kw">colnames</span>(res_matrix) &lt;-<span class="st"> </span>tests</span>
<span id="cb396-11"><a href="13-3-inference-when-data-are-not-normal.html#cb396-11"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sets){</span>
<span id="cb396-12"><a href="13-3-inference-when-data-are-not-normal.html#cb396-12"></a>  res_matrix[j, <span class="st">&quot;lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb396-13"><a href="13-3-inference-when-data-are-not-normal.html#cb396-13"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb396-14"><a href="13-3-inference-when-data-are-not-normal.html#cb396-14"></a>  res_matrix[j, <span class="st">&quot;log_lm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(fake_matrix[,j] <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">~</span><span class="st"> </span>treatment</span>
<span id="cb396-15"><a href="13-3-inference-when-data-are-not-normal.html#cb396-15"></a>                                 )))[<span class="dv">2</span>, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</span>
<span id="cb396-16"><a href="13-3-inference-when-data-are-not-normal.html#cb396-16"></a>  res_matrix[j, <span class="st">&quot;mww&quot;</span>] &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb396-17"><a href="13-3-inference-when-data-are-not-normal.html#cb396-17"></a>                                      <span class="dt">exact=</span><span class="ot">FALSE</span>)<span class="op">$</span>p.value</span>
<span id="cb396-18"><a href="13-3-inference-when-data-are-not-normal.html#cb396-18"></a>  res_matrix[j, <span class="st">&quot;perm&quot;</span>] &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(<span class="kw">lmp</span>(fake_matrix[,j] <span class="op">~</span><span class="st"> </span>treatment,</span>
<span id="cb396-19"><a href="13-3-inference-when-data-are-not-normal.html#cb396-19"></a>                                 <span class="dt">perm=</span><span class="st">&quot;Prob&quot;</span>, <span class="dt">Ca=</span><span class="fl">0.01</span>)))[<span class="dv">2</span>, <span class="st">&quot;Pr(Prob)&quot;</span>]</span>
<span id="cb396-20"><a href="13-3-inference-when-data-are-not-normal.html#cb396-20"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="13-3-inference-when-data-are-not-normal.html#cb397-1"></a><span class="kw">apply</span>(res_matrix, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span>)<span class="op">/</span>n_sets)</span></code></pre></div>
<pre><code>##      lm  log_lm     mww    perm 
## 0.09200 0.12525 0.08375 0.10600</code></pre>
<p>As above, Power is computed for the linear model, linear model with a log-transformed response, Mann-Whitney-Wilcoxan, and permutation, by simulating a “low power” experiment. The effect is huge (twice as many cells) but the power is low because the sample size is small (<span class="math inline">\(n = 5\)</span>). At this sample size, and for this model of fake data, all tests have low power. The power of the log-transformed response is the largest. A problem is, this is not a test of the means but of the log transformed mean plus 1. The power of the permutation test is about 25% larger than that of the linear model and Mann-Whitney-Wilcoxan test. An advantage of this test is that it is a p-value of the mean. A good complement to this p-value would be bootstraped confidence intervals. Repeat this simulation using <span class="math inline">\(n=40\)</span> do see how the relative power among the three change in a simulation of an experiment with more power.</p>

</div>
</div>
</div>
<!-- </div> -->
<p style="text-align: center;">
<a href="13-2-difference-in-p-is-not-different.html"><button class="btn btn-default">Previous</button></a>
<a href="part-vi-more-than-one-x-multivariable-models.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
