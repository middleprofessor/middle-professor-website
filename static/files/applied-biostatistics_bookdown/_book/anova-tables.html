<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Elementary Statistical Modeling for Applied Biostatistics</title>
  <meta name="description" content="A first course in statistical modeling for biology students">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Elementary Statistical Modeling for Applied Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for biology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Elementary Statistical Modeling for Applied Biostatistics" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for biology students" />
  

<meta name="author" content="Copyright 2018 Jeffrey A. Walker">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="two-or-more-categorical-x-factorial-designs.html">
<link rel="next" href="adding-covariates-to-a-linear-model-i-ancova.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html"><i class="fa fa-check"></i><b>1</b> Linear models as statistical models</a><ul>
<li class="chapter" data-level="1.1" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#two-specifications-of-a-linear-model-i-the-linear-model-way"><i class="fa fa-check"></i><b>1.1</b> Two specifications of a linear model I: the “linear model” way</a></li>
<li class="chapter" data-level="1.2" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#two-specifications-of-a-linear-model-ii-the-statistical-model-way"><i class="fa fa-check"></i><b>1.2</b> Two specifications of a linear model II: the “statistical model” way</a></li>
<li class="chapter" data-level="1.3" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#statistical-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>1.3</b> Statistical models are used for prediction, explanation, and description</a></li>
<li class="chapter" data-level="1.4" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#model-fitting"><i class="fa fa-check"></i><b>1.4</b> Model fitting</a></li>
<li class="chapter" data-level="1.5" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#a-mean-is-the-simplest-model"><i class="fa fa-check"></i><b>1.5</b> A mean is the simplest model</a></li>
<li class="chapter" data-level="1.6" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#assumptions-for-inference-with-a-statistical-model"><i class="fa fa-check"></i><b>1.6</b> Assumptions for inference with a statistical model</a></li>
<li class="chapter" data-level="1.7" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#specific-assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>1.7</b> Specific assumptions for inference with a linear model</a></li>
<li class="chapter" data-level="1.8" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#statistical-model-or-regression-model"><i class="fa fa-check"></i><b>1.8</b> “Statistical model” or “regression model”?</a></li>
<li class="chapter" data-level="1.9" data-path="linear-models-as-statistical-models.html"><a href="linear-models-as-statistical-models.html#glm-vs.glm-vs.gls"><i class="fa fa-check"></i><b>1.9</b> GLM vs. GLM vs. GLS</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html"><i class="fa fa-check"></i><b>2</b> Organization – R Projects and R Notebooks</a><ul>
<li class="chapter" data-level="2.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#importing-packages"><i class="fa fa-check"></i><b>2.1</b> Importing Packages</a></li>
<li class="chapter" data-level="2.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-studio-project-for-this-class"><i class="fa fa-check"></i><b>2.2</b> Create an R Studio Project for this Class</a></li>
<li class="chapter" data-level="2.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-notebooks"><i class="fa fa-check"></i><b>2.3</b> R Notebooks</a><ul>
<li class="chapter" data-level="2.3.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-notebook-for-this-chapter"><i class="fa fa-check"></i><b>2.3.1</b> Create an R Notebook for this Chapter</a></li>
<li class="chapter" data-level="2.3.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-setup-chunk"><i class="fa fa-check"></i><b>2.3.2</b> Create a “setup” chunk</a></li>
<li class="chapter" data-level="2.3.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-simple-plot-chunk"><i class="fa fa-check"></i><b>2.3.3</b> Create a “simple plot” chunk</a></li>
<li class="chapter" data-level="2.3.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-more-r-chunks-and-explore-options-and-play-with-r-code"><i class="fa fa-check"></i><b>2.3.4</b> Create more R chunks and explore options and play with R code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html"><i class="fa fa-check"></i><b>3</b> Data – Reading, Writing, and Fake</a><ul>
<li class="chapter" data-level="3.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#create-new-notebook-for-this-chapter"><i class="fa fa-check"></i><b>3.1</b> Create new notebook for this chapter</a></li>
<li class="chapter" data-level="3.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#importing-data"><i class="fa fa-check"></i><b>3.2</b> Importing Data</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#excel-file"><i class="fa fa-check"></i><b>3.2.1</b> Excel File</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#text-file"><i class="fa fa-check"></i><b>3.2.2</b> Text File</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#creating-fake-data"><i class="fa fa-check"></i><b>3.3</b> Creating Fake Data</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#continuous-x-fake-observational-data"><i class="fa fa-check"></i><b>3.3.1</b> Continuous X (fake observational data)</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#categorical-x-fake-experimental-data"><i class="fa fa-check"></i><b>3.3.2</b> Categorical X (fake experimental data)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#saving-data"><i class="fa fa-check"></i><b>3.4</b> Saving Data</a></li>
<li class="chapter" data-level="3.5" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#problems"><i class="fa fa-check"></i><b>3.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><i class="fa fa-check"></i><b>4</b> Variability and Uncertainty (Standard Deviations and Standard Errors)</a><ul>
<li class="chapter" data-level="4.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#the-sample-standard-deviation-vs.the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#sample-standard-deviation"><i class="fa fa-check"></i><b>4.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="4.1.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#using-google-sheets-to-generate-fake-data-to-explore-uncertainty"><i class="fa fa-check"></i><b>4.2</b> Using Google Sheets to generate fake data to explore uncertainty</a><ul>
<li class="chapter" data-level="4.2.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#steps"><i class="fa fa-check"></i><b>4.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#using-r-to-generate-fake-data-to-explore-uncertainty"><i class="fa fa-check"></i><b>4.3</b> Using R to generate fake data to explore uncertainty</a><ul>
<li class="chapter" data-level="4.3.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-i"><i class="fa fa-check"></i><b>4.3.1</b> part I</a></li>
<li class="chapter" data-level="4.3.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-ii---means"><i class="fa fa-check"></i><b>4.3.2</b> part II - means</a></li>
<li class="chapter" data-level="4.3.3" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>4.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="4.3.4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>4.3.4</b> Part IV – Generating fake data with “for loops”</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#bootstrapped-standard-errors"><i class="fa fa-check"></i><b>4.4</b> Bootstrapped standard errors</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>5</b> Plotting</a><ul>
<li class="chapter" data-level="5.1" data-path="plotting.html"><a href="plotting.html#plots-should-be-the-center-of-your-papers-universe"><i class="fa fa-check"></i><b>5.1</b> Plots should be the center of your paper’s universe</a></li>
<li class="chapter" data-level="5.2" data-path="plotting.html"><a href="plotting.html#pretty-good-plots-show-the-data"><i class="fa fa-check"></i><b>5.2</b> Pretty good plots show the data</a></li>
<li class="chapter" data-level="5.3" data-path="plotting.html"><a href="plotting.html#even-better-plots"><i class="fa fa-check"></i><b>5.3</b> Even better plots…</a><ul>
<li class="chapter" data-level="5.3.1" data-path="plotting.html"><a href="plotting.html#let-interaction-plots-be-interaction-plots"><i class="fa fa-check"></i><b>5.3.1</b> Let interaction plots be interaction plots</a></li>
<li class="chapter" data-level="5.3.2" data-path="plotting.html"><a href="plotting.html#even-better-plots-continuedshow-the-model"><i class="fa fa-check"></i><b>5.3.2</b> Even better plots (continued)…Show the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html"><i class="fa fa-check"></i><b>6</b> A linear model with a single, continous <em>X</em></a><ul>
<li class="chapter" data-level="6.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#a-linear-model-with-a-single-continous-x-is-classical-regression"><i class="fa fa-check"></i><b>6.1</b> A linear model with a single, continous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="6.1.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#using-a-linear-model-to-estimate-explanatory-effects"><i class="fa fa-check"></i><b>6.1.1</b> Using a linear model to estimate explanatory effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#using-a-linear-model-for-prediction"><i class="fa fa-check"></i><b>6.1.2</b> Using a linear model for prediction</a></li>
<li class="chapter" data-level="6.1.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#reporting-results"><i class="fa fa-check"></i><b>6.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#working-in-r"><i class="fa fa-check"></i><b>6.2</b> Working in R</a><ul>
<li class="chapter" data-level="6.2.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#exploring-the-bivariate-relationship-between-y-and-x"><i class="fa fa-check"></i><b>6.2.1</b> Exploring the bivariate relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="6.2.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>6.2.2</b> Fitting the linear model</a></li>
<li class="chapter" data-level="6.2.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>6.2.3</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="6.2.4" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#display-an-alternative-to-summary"><i class="fa fa-check"></i><b>6.2.4</b> display: An alternative to summary</a></li>
<li class="chapter" data-level="6.2.5" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#confidence-intervals"><i class="fa fa-check"></i><b>6.2.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="6.2.6" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>6.2.6</b> How good is our model?</a></li>
<li class="chapter" data-level="6.2.7" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#exploring-a-lm-object"><i class="fa fa-check"></i><b>6.2.7</b> exploring a lm object</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#problems-1"><i class="fa fa-check"></i><b>6.3</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html"><i class="fa fa-check"></i><b>7</b> Least Squares Estimation and the Decomposition of Variance</a><ul>
<li class="chapter" data-level="7.1" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html#ols-regression"><i class="fa fa-check"></i><b>7.1</b> OLS regression</a></li>
<li class="chapter" data-level="7.2" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>7.2</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>8</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="8.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-is-the-engine-behind-a-single-factor-one-way-anova-and-a-t-test-is-a-special-case-of-this-model."><i class="fa fa-check"></i><b>8.1</b> A linear model with a single, categorical <em>X</em> is the engine behind a single factor (one-way) ANOVA and a t-test is a special case of this model.</a><ul>
<li class="chapter" data-level="8.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#table-of-model-coefficients"><i class="fa fa-check"></i><b>8.1.1</b> Table of model coefficients</a></li>
<li class="chapter" data-level="8.1.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#the-linear-model"><i class="fa fa-check"></i><b>8.1.2</b> The linear model</a></li>
<li class="chapter" data-level="8.1.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#reporting-results-1"><i class="fa fa-check"></i><b>8.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#working-in-r-1"><i class="fa fa-check"></i><b>8.2</b> Working in R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#exploring-the-relationship-between-y-and-x"><i class="fa fa-check"></i><b>8.2.1</b> Exploring the relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#fitting-the-model"><i class="fa fa-check"></i><b>8.2.2</b> Fitting the model</a></li>
<li class="chapter" data-level="8.2.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#an-introduction-to-contrasts"><i class="fa fa-check"></i><b>8.2.3</b> An introduction to contrasts</a></li>
<li class="chapter" data-level="8.2.4" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#harrell-plot"><i class="fa fa-check"></i><b>8.2.4</b> Harrell plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>9</b> P-values</a><ul>
<li class="chapter" data-level="9.1" data-path="p-values.html"><a href="p-values.html#p-values"><i class="fa fa-check"></i><b>9.1</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="9.2" data-path="p-values.html"><a href="p-values.html#creating-a-null-distribution."><i class="fa fa-check"></i><b>9.2</b> Creating a null distribution.</a><ul>
<li class="chapter" data-level="9.2.1" data-path="p-values.html"><a href="p-values.html#the-null-distribution"><i class="fa fa-check"></i><b>9.2.1</b> the Null Distribution</a></li>
<li class="chapter" data-level="9.2.2" data-path="p-values.html"><a href="p-values.html#t-tests"><i class="fa fa-check"></i><b>9.2.2</b> <span class="math inline">\(t\)</span>-tests</a></li>
<li class="chapter" data-level="9.2.3" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>9.2.3</b> P-values from the perspective of permutation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="p-values.html"><a href="p-values.html#statistical-modeling-instead-of-hypothesis-testing"><i class="fa fa-check"></i><b>9.3</b> Statistical modeling instead of hypothesis testing</a></li>
<li class="chapter" data-level="9.4" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>9.4</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="9.4.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>9.4.1</b> Background</a></li>
<li class="chapter" data-level="9.4.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>9.4.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <span class="math inline">\(p\)</span>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="9.4.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>9.4.3</b> Two interpretations of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="9.4.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>9.4.4</b> NHST</a></li>
<li class="chapter" data-level="9.4.5" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>9.4.5</b> Some major misconceptions of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="9.4.6" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>9.4.6</b> Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="p-values.html"><a href="p-values.html#problems-2"><i class="fa fa-check"></i><b>9.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>10</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="10.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>10.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="10.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>10.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="10.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>10.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="10.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>10.1.3</b> What about models with more than two factors?</a></li>
<li class="chapter" data-level="10.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>10.1.4</b> The additive model</a></li>
<li class="chapter" data-level="10.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts-simple-vs.main-effects"><i class="fa fa-check"></i><b>10.1.5</b> Contrasts – simple vs. main effects</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results-2"><i class="fa fa-check"></i><b>10.2</b> Reporting results</a><ul>
<li class="chapter" data-level="10.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>10.2.1</b> Text results</a></li>
<li class="chapter" data-level="10.2.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#harrellplot"><i class="fa fa-check"></i><b>10.2.2</b> Harrellplot</a></li>
<li class="chapter" data-level="10.2.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#interaction-plots"><i class="fa fa-check"></i><b>10.2.3</b> Interaction plots</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#recommendations-1"><i class="fa fa-check"></i><b>10.3</b> Recommendations</a></li>
<li class="chapter" data-level="10.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-2"><i class="fa fa-check"></i><b>10.4</b> Working in R</a></li>
<li class="chapter" data-level="10.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-3"><i class="fa fa-check"></i><b>10.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>11</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="11.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>11.1</b> Summary of usage</a></li>
<li class="chapter" data-level="11.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>11.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="11.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>11.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="11.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>11.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="11.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>11.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="11.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>11.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>11.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="11.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>11.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="11.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>11.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="11.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>11.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-3"><i class="fa fa-check"></i><b>11.5</b> Working in R</a><ul>
<li class="chapter" data-level="11.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>11.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="11.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>11.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html"><i class="fa fa-check"></i><b>12</b> Adding covariates to a linear model I: ANCOVA</a><ul>
<li class="chapter" data-level="12.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>12.1</b> Adding covariates can increases the precision of the effect of interest</a><ul>
<li class="chapter" data-level="12.1.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#interaction-effects-with-covariates"><i class="fa fa-check"></i><b>12.1.1</b> Interaction effects with covariates</a></li>
<li class="chapter" data-level="12.1.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#add-only-covariates-that-were-measured-before-peaking-at-the-data"><i class="fa fa-check"></i><b>12.1.2</b> Add only covariates that were measured before peaking at the data</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#regression-to-the-mean"><i class="fa fa-check"></i><b>12.2</b> Regression to the mean</a><ul>
<li class="chapter" data-level="12.2.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>12.2.1</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="12.2.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>12.2.2</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html"><i class="fa fa-check"></i><b>13</b> Generalized linear models I: Count data</a><ul>
<li class="chapter" data-level="13.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>13.1</b> The generalized linear model</a></li>
<li class="chapter" data-level="13.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><i class="fa fa-check"></i><b>13.2</b> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li class="chapter" data-level="13.2.1" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#modeling-strategy"><i class="fa fa-check"></i><b>13.2.1</b> Modeling strategy</a></li>
<li class="chapter" data-level="13.2.2" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>13.2.2</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="13.2.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>13.2.3</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="13.2.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>13.2.4</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="13.2.5" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>13.2.5</b> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li class="chapter" data-level="13.2.6" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#model-checking-fits-to-count-data"><i class="fa fa-check"></i><b>13.2.6</b> Model checking fits to count data</a></li>
<li class="chapter" data-level="13.2.7" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><i class="fa fa-check"></i><b>13.2.7</b> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#working-in-r-4"><i class="fa fa-check"></i><b>13.3</b> Working in R</a></li>
<li class="chapter" data-level="13.4" data-path="generalized-linear-models-i-count-data.html"><a href="generalized-linear-models-i-count-data.html#problems-4"><i class="fa fa-check"></i><b>13.4</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>14</b> Linear mixed models</a><ul>
<li class="chapter" data-level="14.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects"><i class="fa fa-check"></i><b>14.1</b> Random effects</a></li>
<li class="chapter" data-level="14.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#random-effects-in-statistical-models"><i class="fa fa-check"></i><b>14.2</b> Random effects in statistical models</a></li>
<li class="chapter" data-level="14.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-flexible"><i class="fa fa-check"></i><b>14.3</b> Linear mixed models are flexible</a></li>
<li class="chapter" data-level="14.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#visualizing-block-effects"><i class="fa fa-check"></i><b>14.4</b> Visualizing block effects</a></li>
<li class="chapter" data-level="14.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-can-increase-precision-of-point-estimates"><i class="fa fa-check"></i><b>14.5</b> Linear mixed models can increase precision of point estimates</a></li>
<li class="chapter" data-level="14.6" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-are-used-to-avoid-pseudoreplication"><i class="fa fa-check"></i><b>14.6</b> Linear mixed models are used to avoid pseudoreplication</a></li>
<li class="chapter" data-level="14.7" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#linear-mixed-models-shrink-coefficients-by-partial-pooling"><i class="fa fa-check"></i><b>14.7</b> Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="chapter" data-level="14.8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#working-in-r-5"><i class="fa fa-check"></i><b>14.8</b> Working in R</a><ul>
<li class="chapter" data-level="14.8.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#coral-data"><i class="fa fa-check"></i><b>14.8.1</b> coral data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="14.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>14.9</b> Get your computer ready</a><ul>
<li class="chapter" data-level="14.9.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>14.9.1</b> Install R</a></li>
<li class="chapter" data-level="14.9.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>14.9.2</b> Install R Studio</a></li>
<li class="chapter" data-level="14.9.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#resources-for-installing-r-and-r-studio"><i class="fa fa-check"></i><b>14.9.3</b> Resources for installing R and R Studio</a></li>
<li class="chapter" data-level="14.9.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-latex"><i class="fa fa-check"></i><b>14.9.4</b> Install LaTeX</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning"><i class="fa fa-check"></i><b>14.10</b> Start learning</a><ul>
<li class="chapter" data-level="14.10.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-with-data-camp-introduction-to-r"><i class="fa fa-check"></i><b>14.10.1</b> Start with Data Camp Introduction to R</a></li>
<li class="chapter" data-level="14.10.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#then-move-to-introduction-to-r-studio"><i class="fa fa-check"></i><b>14.10.2</b> Then Move to Introduction to R Studio</a></li>
<li class="chapter" data-level="14.10.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#develop-your-project-with-an-r-studio-notebook"><i class="fa fa-check"></i><b>14.10.3</b> Develop your project with an R Studio Notebook</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#getting-data-into-r"><i class="fa fa-check"></i><b>14.11</b> Getting Data into R</a></li>
<li class="chapter" data-level="14.12" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#additional-r-learning-resources"><i class="fa fa-check"></i><b>14.12</b> Additional R learning resources</a></li>
<li class="chapter" data-level="14.13" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#packages-used-extensively-in-this-text"><i class="fa fa-check"></i><b>14.13</b> Packages used extensively in this text</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-linear-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-linear-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Linear Modeling in R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elementary Statistical Modeling for Applied Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="anova-tables" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> ANOVA Tables</h1>
<p>Treatment effects are most often analyzed using ANOVA, which is short for “Analysis of Variance”. This is somewhat of an odd name for a method to test for treatments effects - what do differences in means have to do with an analyis of variance? The name makes sense in light of the decomposition of the total variance into a model variance and the residual variance (chapter xxx). If there are differences among the means, then the total variance is increased because of variation among groups.</p>
<p>The engine underneath ANOVA is a linear model. If the model has a single categorical factor, the ANOVA is <strong>one-way</strong>. If the model has two categorical factors it is a two-way ANOVA. If the model has a single categorical factor and one continuous factor it is an ANCOVA, short for <strong>analysis of covariance</strong> (next chapter). More complex experimental designs classically analyzed with ANOVA are nested, split-plot, latin-square, and many others.</p>
<div id="summary-of-usage" class="section level2">
<h2><span class="header-section-number">11.1</span> Summary of usage</h2>
<p>If you choose to report an ANOVA, also report the effects and their uncertainty in some way, either the model coefficients or contrasts.</p>
<ol style="list-style-type: decimal">
<li>ANOVA generates a table with one row for each term in the linear model. A term is a factor or a covariate or an interaction. For a two-way factorial ANOVA, these terms are the two main effects and the interaction effect.</li>
<li>The ANOVA generates an <span class="math inline">\(F\)</span> and <span class="math inline">\(p\)</span>-value for the whole model and for each term in the ANOVA table.</li>
<li>The <span class="math inline">\(p\)</span>-value of an interaction term is often used as a decision rule to interpret the main effects. If <span class="math inline">\(p \le 0.05\)</span> then do not interpret the main effects but instead examine the condition (“simple”) effects. If <span class="math inline">\(p &gt; 0.05\)</span>, then interpret the main effects. Regardless, this sort of decision rule is itself controversial, and for good reason.</li>
<li>If the main effects are to be interpreted, some statisticians advocate re-fitting the model without the interaction effect, others advocate interpreting the main effects with the interaction term in the model. This only matters if the design is unbalanced (see below).</li>
<li>Regardles of any decision, always plot the data using a Harrell plot or interaction plot to understand and communicate the magnitude and pattern of interaction.</li>
<li>For factors with more than two levels, the <span class="math inline">\(p\)</span>-value is often used as a decision rule to dissect the factor with post-hoc tests, such as Tukey HSD.</li>
<li>A design is balanced if all the cells have the same number of replicates. A design is unbalanced if one or more of the cells has a different number of replicates. Unbalanced designs make it necessary to make decisions, none of which are perfect, and all of which are controversial. Some statisticians have even advocated randomly excluding data until the design is back in balance. Don’t do this.</li>
<li>There are multiple ways to decompose the sum of squares. I highlight the major three: Type I (sequential), Type II (partial sequential), and Type III. Most statistics software and introductory statistics books default to Type III and, consequently, many researchers are unaware that Types I and II exist. R’s default is Type I, and this can make a difference if the design is unbalanced. This is <em>not</em> a rare error in publications.</li>
<li>Because R defaults to Type I sum of squares, the <span class="math inline">\(p\)</span>-value of a factor depends on the order of the factors in the model if the design is unbalanced. This is a feature, not a bug.</li>
<li>ANOVA based on type II sum of squares do not depend on factor order if the design is unbalanced, but it does assume that the interaction is zero.</li>
<li>ANOVA based on type III sum of squares do not depend on order if the design is unbalanced and does not assume the interaction is zero.</li>
<li>If the design is balanced, Type I, II, and III sum of squares generate the same ANOVA table. And the ANOVA table of just the main effects is the same as the ANOVA table that includes the interaction term. None of this is true when the design is unbalanced, However, the decision to use type II or type III is very controversial.</li>
</ol>
</div>
<div id="example-a-one-way-anova-using-the-vole-data" class="section level2">
<h2><span class="header-section-number">11.2</span> Example: a one-way ANOVA using the vole data</h2>
<p>The vole data has a single factor (“treatment”) with three levels (“control”, “vitamin_E”, “vitamin_C”). In statistics textbooks that emphasize hypothesis testing, the “Which test should I use” flowchart would guide a researcher given this design to a single classification, or one-way ANOVA, since a t-test can only compare two levels but an ANOVA can compare more than two levels. There are better ways to think about what ANOVA is doing, but okay.</p>
<p>Here is an ANOVA table of the vole data:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>treatment</td>
<td align="right">2</td>
<td align="right">248446</td>
<td align="right">124223.0</td>
<td align="right">2.95</td>
<td align="right">0.057</td>
</tr>
<tr class="even">
<td>Residuals</td>
<td align="right">93</td>
<td align="right">3912751</td>
<td align="right">42072.6</td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>I’ll explain all the parts of the ANOVA table later, but for now, focus on the <span class="math inline">\(p\)</span>-value, which is that most researchers want out of the table. What null hypothesis does this <span class="math inline">\(p\)</span>-value test? The p-value gives the probability of the observed <span class="math inline">\(F\)</span> or larger <span class="math inline">\(F\)</span>, if the null were true. The null hypothesis models the data as if they were sampled from a single, normal distribution and randomly assigned to different groups. Thus the null hypotheis includes the equality of the means among factor levels. In the vole data, the single treatment factor has three levels and a small <span class="math inline">\(p\)</span>-value could occur because of a difference in means between the vitamin_E treatment and control, or between the vitamin_C treatment and control, or between the two vitamin treatments. The <span class="math inline">\(p\)</span>-value or ANOVA table doesn’t indicate what is different, only that the observed <span class="math inline">\(F\)</span> is unexpectedly large if the null were true. As a consequence, researchers typically interpret a low <span class="math inline">\(p\)</span>-value in an ANOVA table as evidence of “an effect” of the term but have to use additional tools to dissect this effect. The typical additional tools are either <strong>planned comparisons</strong>, which are contrasts among a subset of a priori identified treatment levels (or groups of levels) or unplanned comparisons (“post-hoc” tests) among all pairs of levels.</p>
<p>The <span class="math inline">\(p\)</span>-value in the ANOVA table acts as a decision rule: if <span class="math inline">\(p &lt; 0.05\)</span> then it is okay to further dissect the factor with planned comparisons or post-hoc tests because the significant <span class="math inline">\(p\)</span> “protects” the type I error of further comparisons. I’m not fond of using <span class="math inline">\(p\)</span>-values for these sorts of decision rules.</p>
</div>
<div id="example-a-two-way-anova-using-the-urchin-data" class="section level2">
<h2><span class="header-section-number">11.3</span> Example: a two-way ANOVA using the urchin data</h2>
<p>Let’s use the urchin data from the previous chapter xxx to explore the ANOVA table, which is what is typically reported. The experiment has two factors (<span class="math inline">\(Temp\)</span> and <span class="math inline">\(CO2\)</span>), each with two levels. Here is the linear model</p>
<span class="math display">\[\begin{equation}
Resp = \beta_0 + \beta_1 Temp + \beta_2 CO2 + \beta_3 TempCO2 + \varepsilon
\end{equation}\]</span>
<p>In order to understand factorial ANOVA (or any ANOVA with multiple factors), it is useful to know the difference between <strong>conditional means</strong> and <strong>marginal means</strong></p>
<pre><code>##          CO2-  CO2+ Temp-mm
## Temp-   8.233 7.917   8.075
## Temp+  12.743 9.742  11.243
## CO2-mm 10.488 8.829   9.659</code></pre>
<p>In the table above, the upper, left <span class="math inline">\(2 \times 2\)</span> grid of cells are the conditional means, which are the means of each group, where a group is a specific combination of factor levels. The first two values of the third row are the marginal means for CO2. The first (10.488) is the mean of the two means when CO2=CO2-. This can be written as <span class="math inline">\(\mathrm{E}(Resp|CO2-)\)</span>. The second (8.829) is the mean of the two means when CO2=CO2+, or <span class="math inline">\(\mathrm{E}(Resp|CO2+)\)</span>. The first two elements of the third column are the marginal means for Temp. These are <span class="math inline">\(\mathrm{E}(Resp|Temp-)\)</span> and <span class="math inline">\(\mathrm{E}(Resp|Temp+)\)</span>. The bottom right value (9.659) is the grand mean.</p>
<p>A <strong>conditional effect</strong> is a difference between conditional means. For example the conditional effect of <span class="math inline">\(Temp\)</span> <em>conditional on</em> CO2=CO2- is <span class="math inline">\(12.743-8.233\)</span>. A <strong>marginal effect</strong> is a difference in marginal means within a factor, for example the marginal effect of <span class="math inline">\(Temp\)</span> is <span class="math inline">\(11.243 - 8.075\)</span>.</p>
<p>Here is the ANOVA table of the urchin data</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">1</td>
<td align="right">60.2</td>
<td align="right">60.2</td>
<td align="right">19.1</td>
<td align="right">0.0003</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">1</td>
<td align="right">16.5</td>
<td align="right">16.5</td>
<td align="right">5.2</td>
<td align="right">0.0332</td>
</tr>
<tr class="odd">
<td>Temp:CO2</td>
<td align="right">1</td>
<td align="right">10.8</td>
<td align="right">10.8</td>
<td align="right">3.4</td>
<td align="right">0.0791</td>
</tr>
<tr class="even">
<td>Residuals</td>
<td align="right">20</td>
<td align="right">63.2</td>
<td align="right">3.2</td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>This ANOVA table uses what are called Type 3 sum of squares, which is <em>NOT</em> the default in R but is the default in many other statistics software and is, therefore, the <em>only</em> type of ANOVA that many researchers know (and, many researchers are unaware that there are multiple types of ANOVA table). Understanding these differences is important, at least if one is reporting ANOVA tables. I’ll return to the importance of this later.</p>
<div id="how-to-read-an-anova-table" class="section level3">
<h3><span class="header-section-number">11.3.1</span> How to read an ANOVA table</h3>
<p>An ANOVA table has a row for each term in the underlying linear model – each of these adds a component of variance to the total, and a row for the residual variance (this residual variance row is frequently excluded from the published table). The urchin model has three terms (one level of <span class="math inline">\(Temp\)</span>, one level of <span class="math inline">\(CO2\)</span>, and one interaction). The statistics for each term are</p>
<ol style="list-style-type: decimal">
<li><strong>Degrees of Freedom</strong> (df) – If the term is a factor, the df will equal the number of levels (<span class="math inline">\(k\)</span>) for the factor minus 1. Think of it this way: the contribution of the variance due to a factor is a function of the variability of the <span class="math inline">\(k\)</span> level means around the grand mean. How many degrees of independent variation do these level means have, given that we know the grand mean? The answer is <span class="math inline">\(k-1\)</span> – once the values of <span class="math inline">\(k-1\)</span> level means are written down, the <span class="math inline">\(k\)</span>th level mean has no freedom to vary; its value has to be <span class="math inline">\(k\bar{\bar{Y}} - \sum_i^{k-1}{Y_i}\)</span>. For an interaction term, the df is the product of the df of each of the factors in the interaction.</li>
<li><strong>Sum of Squares</strong> – the sum of squared differences between the modeled value and the grand mean. In addition to a sum of squares for each term, a <strong>residual mean square</strong> is computed as the sum of squared differences between the measured and modeled values.</li>
<li><strong>Mean Square</strong> – The sum of squares divided by the df (this is a “mean” with df acting as the number of things that were summed).</li>
<li><strong>F-ratio</strong> – the Mean Square of the term dived by the residual mean square.</li>
<li><strong>p-value</strong> – the p-value for the F-ratio. F is compared to an F-distribution, which is a distribution of F-ratios under the null.</li>
</ol>
<div id="each-row-in-the-table-tests-a-null-hypothesis" class="section level4">
<h4><span class="header-section-number">11.3.1.1</span> Each row in the table tests a null hypothesis</h4>
<p>The row for each term in an ANOVA table tests a null hypothesis. In order to understand the null hypotheses, I need to define a few more terms</p>
<p>For the ANOVA table above, which uses Type 3 sum of squares, the probabilities are</p>
<ol style="list-style-type: decimal">
<li>Temp – <span class="math inline">\(p = \mathrm{prob}(F \ge F_o|CO2, Temp:CO2)\)</span>. The null is no difference in means conditional on the level of CO2 and Temp:CO2. This is equivalent to no difference between the grand mean and the marginal mean of Temp+, or</li>
</ol>
<span class="math display">\[\begin{equation}
b_1 = \overline{\overline{Resp}} - \mathrm{E}(Resp|Temp^+)
\end{equation}\]</span>
<ol start="2" style="list-style-type: decimal">
<li>CO2– <span class="math inline">\(p = \mathrm{prob}(F \ge F_o|Temp, Temp:CO2)\)</span>. The null is no difference in means conditional on the level of Temp and Temp:CO2. This is equivalent to no difference between the grand mean and the marginal mean of CO2+, or</li>
</ol>
<span class="math display">\[\begin{equation}
b_2 = \overline{\overline{Resp}} - \mathrm{E}(Resp|CO2^+)
\end{equation}\]</span>
<ol start="3" style="list-style-type: decimal">
<li>Temp:CO2 – <span class="math inline">\(p = \mathrm{prob}(F \ge F_o|Temp, CO2)\)</span>. The null is no difference in means conditional on the level of Temp and CO2. This is equivalent to the difference between the conditional mean of Temp+/CO2+ and the expected conditional mean of Temp+/CO2+ if there were no interaction.</li>
</ol>
<span class="math display">\[\begin{equation}
b_3 = \mathrm{E}(Resp|Temp^+, CO2^+) - (\overline{\overline{Resp}} - b_1 - b_2)
\end{equation}\]</span>
<p>As noted in the equations, these three differences are the coefficients of the linear model behind the ANOVA. Here is the coefficient table</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td align="right">9.66</td>
<td align="right">0.36</td>
<td align="right">26.6</td>
<td align="right">0.00000</td>
</tr>
<tr class="even">
<td>Temp1</td>
<td align="right">-1.58</td>
<td align="right">0.36</td>
<td align="right">-4.4</td>
<td align="right">0.00030</td>
</tr>
<tr class="odd">
<td>CO21</td>
<td align="right">0.83</td>
<td align="right">0.36</td>
<td align="right">2.3</td>
<td align="right">0.03325</td>
</tr>
<tr class="even">
<td>Temp1:CO21</td>
<td align="right">-0.67</td>
<td align="right">0.36</td>
<td align="right">-1.9</td>
<td align="right">0.07910</td>
</tr>
</tbody>
</table>
<p>In ANOVA with type 3 sum of squares, the dummy variables are coded using effect coding, which differs from the dummy coding introduced in chapter xxx. The consequence is that the <strong>grand mean</strong> (the mean of <span class="math inline">\(Resp\)</span> across all values) is now the “reference” value. The intercept in this table, then, is the grand mean. The coefficients are <em>differences from the grand mean</em>, as described above.</p>
<p>Use the table of conditional and marginal effects above to check that the coefficients equal the differences in the equations above. Also not that the <span class="math inline">\(p\)</span>-values for the effects in the coefficient table equals the <span class="math inline">\(p\)</span>-values in the ANOVA table.</p>
<p>It is important to note that this table differs from the coefficient table with dummy coding because that reference is the mean of Temp-/CO2- and not the grand mean.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td align="right">8.23</td>
<td align="right">0.73</td>
<td align="right">11.3</td>
<td align="right">0.00000</td>
</tr>
<tr class="even">
<td>TempTemp+</td>
<td align="right">4.51</td>
<td align="right">1.03</td>
<td align="right">4.4</td>
<td align="right">0.00028</td>
</tr>
<tr class="odd">
<td>CO2CO2+</td>
<td align="right">-0.32</td>
<td align="right">1.03</td>
<td align="right">-0.3</td>
<td align="right">0.76081</td>
</tr>
<tr class="even">
<td>TempTemp+:CO2CO2+</td>
<td align="right">-2.68</td>
<td align="right">1.45</td>
<td align="right">-1.9</td>
<td align="right">0.07910</td>
</tr>
</tbody>
</table>
<p>Importantly, note that <span class="math inline">\(p\)</span>-values for <span class="math inline">\(b_1\)</span> (the Temp effect) and <span class="math inline">\(b_2\)</span> differ between the two tables. This is because the <span class="math inline">\(t\)</span>-value tests different hypotheses! In the coefficient table with effect coding (that behind the ANOVA with type 3 sums of squares), the <span class="math inline">\(p\)</span>-value tests marginal effects and so is a function of both marginal means within a factor. By contrast, in the coefficient table with dummy coding, the <span class="math inline">\(p\)</span>-value tests conditional effects, and so is only a function of the conditional means when the other factor is at its reference level (right? The coefficient <span class="math inline">\(b_1\)</span> in the dummy coded coefficient table is the effect of only increasing <span class="math inline">\(Temp\)</span> – <span class="math inline">\(CO2\)</span> is left at its reference level). For the interaction effect, the coefficient differs between the effects coded model and the dummy coded model (because different reference means) but the <span class="math inline">\(p\)</span>-value ultimately tests the same hypothesis (non-additive effects of the factors) and so the <span class="math inline">\(t\)</span> and <span class="math inline">\(p\)</span> values are the same.</p>
</div>
<div id="what-to-do-after-anova" class="section level4">
<h4><span class="header-section-number">11.3.1.2</span> What to do after ANOVA?</h4>
<p>Researchers frequently report ANOVA statistics (<span class="math inline">\(F\)</span> and <span class="math inline">\(p\)</span> values) for factorial models in a way that suggests that they misunderstand the hypotheses tested. It probably doesn’t help that there is a long-standing debate among statisticians about the most sensible strategy for interpreting factorial ANOVA results. And it doesn’t help that the default ANOVA table in R can suggest a very different interpretation than the default ANOVA table in some other software packages.</p>
<p>Here are three strategies for interpreting a factorial ANOVA table that uses Type III sum of squares. All strategies use <span class="math inline">\(p\)</span>-values to make a series of decision rules. In the first strategy, which is a type of model simplification or model selection, a researcher starts with the interactions at the bottom of the ANOVA table and works up, eliminating terms with <span class="math inline">\(p &gt; 0.05\)</span> and re-fitting the reduced model before interpreting main effects. In the second strategy, the researcher uses the original ANOVA table that includes all terms to interpret main effects.</p>
<p><strong>Strategy 1</strong></p>
<ol style="list-style-type: decimal">
<li>is interaction <em>p</em> &lt; 0.05?
<ol style="list-style-type: lower-alpha">
<li>if yes, then do NOT test main effects. Show a graph to show pattern of conditional effects. Test conditional effects if this is of interest.</li>
<li>if no, then refit model without the interaction and test main effects – This now is equivalent to ANOVA using Type II sum of squares.
<ol start="2" style="list-style-type: decimal">
<li>is main effect <em>p</em> &lt; 0.05$?
<ol style="list-style-type: lower-alpha">
<li>if yes, then keep in model</li>
<li>if no, then refit model without that main effect</li>
</ol></li>
</ol></li>
</ol></li>
</ol>
<p><strong>Strategy 2</strong></p>
<ol start="2" style="list-style-type: decimal">
<li>is interaction <em>p</em> &lt; 0.05?
<ol style="list-style-type: lower-alpha">
<li>if yes, then do NOT test main effects. Show a graph to show pattern of conditional effects. Test conditional effects if this is of interest.</li>
<li>if no, then use the same table as the test of the main effects. This is interpreting the main effects with the interaction term in the model. This is the logic of ANOVA using type III sum of squares.</li>
</ol></li>
</ol>
<p><strong>Strategy 3</strong></p>
<ol start="3" style="list-style-type: decimal">
<li>is interaction <em>p</em> &lt; 0.05?
<ol style="list-style-type: lower-alpha">
<li>if yes, then look at interaction plot to determine if it makes sense test main effects. For example, if CO2+ had obviously lower <span class="math inline">\(Resp\)</span> at both levels of <span class="math inline">\(Temp\)</span>, even if one was much lower (ie. interactaction), then some people would say that the test of the main effect is meaningful. Test conditional effects if this is of interest.</li>
<li>if no, then use the same table as the test of the main effects</li>
</ol></li>
</ol>
<p>In general, statisticians advise against strategy 3 (interpreting main effects in the presence of interaction) – its not wrong, its just that a main effect has an awkward interpretation if there is an interaction. Of course this is true if there is <em>any</em> interaction term in the model, not just a statistically significant term. The controversy is more, if the interaction <span class="math inline">\(p\)</span> is not significant, then do we implement stategy 1 (refit model excluding interaction to test main effects) or strategy 2 (use full factorial anova table to test main effects).</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">1</td>
<td align="right">45.2</td>
<td align="right">45.2</td>
<td align="right">14.5</td>
<td align="right">0.0011</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">1</td>
<td align="right">4.1</td>
<td align="right">4.1</td>
<td align="right">1.3</td>
<td align="right">0.2630</td>
</tr>
<tr class="odd">
<td>Temp:CO2</td>
<td align="right">1</td>
<td align="right">14.8</td>
<td align="right">14.8</td>
<td align="right">4.8</td>
<td align="right">0.0413</td>
</tr>
</tbody>
</table>
<p>then one shouldn’t report the ANOVA results using something like “Temperature had a significant effect on metabolism (<span class="math inline">\(F_{1,20} = 14.5\)</span>, <span class="math inline">\(p=0.001\)</span>). There was no effect of CO2 on metabolism (<span class="math inline">\(F_{1,20} = 4.1\)</span>, <span class="math inline">\(p=0.26\)</span>)”. There was a significant interaction effect between Temperature and CO2 on metabolism (<span class="math inline">\(F_{1,20} = 14.8\)</span>, <span class="math inline">\(p=0.04\)</span>)“. If one accepts that the small interaction <span class="math inline">\(p\)</span>-value is evidence of an interaction effect then this interpretation of the main factors makes no sense, as the first two results imply that the interaction effect is zero (or, that there is a constant effect of <span class="math inline">\(Temp\)</span> or <span class="math inline">\(CO2\)</span> across both levels of the other factor), which is then contradicted by the third result.</p>
<p>More specifically, if one is using a <span class="math inline">\(p\)</span>-value to guide decision making, then a significant interaction <span class="math inline">\(p\)</span> indicates that there is no single “main” effect of a factor. Instead, the effect of <span class="math inline">\(Temp\)</span> is conditional on the level of <span class="math inline">\(CO2\)</span>, and the effect of <span class="math inline">\(CO2\)</span> is conditional on the level of <span class="math inline">\(Temp\)</span>. This is easily seen in the interaction plot, where the effect of <span class="math inline">\(Temp\)</span> is large when <span class="math inline">\(CO2\)</span> is high but much smaller when <span class="math inline">\(CO2\)</span> is low. Indeed, the effect of <span class="math inline">\(Temp\)</span> at the low CO2 is 0.16.</p>
<p>Instead of interpreting the factors as constant effects, A better strategy is to compare the <strong>conditional effects</strong>, that is, the effects of <span class="math inline">\(Temp\)</span> within each level of <span class="math inline">\(CO2\)</span> and the effects of <span class="math inline">\(CO2\)</span> within each level of <span class="math inline">\(Temp\)</span> (conditional effects are sometimes called the “simple effects”).</p>
<p>The controversy arises in what to do after an ANOVA if the interaction effect has a non-significant <span class="math inline">\(p\)</span>-value. At this point, I am punting instead of explaining the basis for the controversy, because ultimately I think the major problem with both strategies is the use of null hypothesis significance testing to make analysis decisions.</p>
<p>In fact, the entire reason that I use the urchin data as the example for factorial ANOVA is because it beautifully illustrates the absurdity of the interaction <span class="math inline">\(p\)</span>-value decision rule. Why should we interpret the results of the ANOVA when the interaction <span class="math inline">\(p\)</span> is 0.079 differently than when the interaction <span class="math inline">\(p\)</span> is 0.04? Remember, the <span class="math inline">\(p\)</span>-value is a “sample” statistic (in the sense that it is entirely a function of the sampled data) and in conditions of low power (which is likely, but not necessarily, true for the urchin data given n=6), a <span class="math inline">\(p\)</span>-value is highly variable.</p>
<p>There are several problems with this approach. 1) a <span class="math inline">\(p\)</span>-value is not evidence of “no effect”, 2) the power to test interaction effects is small relative to that for the main effects (this is a general rule, not something specific to these data), 3) the interaction SS accounts for about 7.2<span class="math inline">\(\%\)</span> of the total SS, which doesn’t seem inconsequential, and 4) the interaction <span class="math inline">\(p\)</span>-value is small enough to raise a red flag, and, most importantly, 5) the confidence interval of the interaction effect indicates that the large, negative values of the interaction are <em>as consistent with the data</em> as trivially small values (or a value of zero). But the CI is not in an ANOVA table and many researchers fail to report it. These five points suggest that this experiment be replicated, with a larger sample size, to get a better estimate of the interaction effect. The problem of course is that experiments are rarely replicated, except in biomedical research.</p>
<p>The absurdity of the <span class="math inline">\(p\)</span>-value decision rule strategy for interpretation of effects after an ANOVA is highlighted by comparing the forest plot of model coefficients of the real and fake urchin data. It would be absurd to use an ANOVA table to interpret these patterns as radically different (one without an interaction and constant main effects, the other with an interactioni and conditional effects).</p>
<div class="figure"><span id="fig:urchin-anova-ggplot"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/urchin-anova-ggplot-1.png" alt="Forest plots (the upper part of a Harrell plot) of the actual and fake urchin data. A) Real urchin data. The interaction effect is not significant ($p=0.079$). B) Fake urchin data. The interaction effect is significant ($p=0.04$)." width="576" />
<p class="caption">
Figure 11.1: Forest plots (the upper part of a Harrell plot) of the actual and fake urchin data. A) Real urchin data. The interaction effect is not significant (<span class="math inline">\(p=0.079\)</span>). B) Fake urchin data. The interaction effect is significant (<span class="math inline">\(p=0.04\)</span>).
</p>
</div>
</div>
</div>
<div id="how-to-read-anova-results-reported-in-the-text" class="section level3">
<h3><span class="header-section-number">11.3.2</span> How to read ANOVA results reported in the text</h3>
<p>ANOVA results are often reported in the text of a results section, using something like “Temperature had a significant effect on metabolism (<span class="math inline">\(F_{1,20} = 14.5\)</span>, <span class="math inline">\(p=0.001\)</span>). There was no effect of CO2 on metabolism (<span class="math inline">\(F_{1,20} = 4.1\)</span>, <span class="math inline">\(p=0.26\)</span>)”. The subscripts of the <span class="math inline">\(F\)</span> statistic are the numerator and denominator degrees of freedom (df) of the <span class="math inline">\(F\)</span>-value (These df are a column in the ANOVA table. The denomintor df may not appear in the table if it is the residual df and the row for the residual term was not reported). Sometimes I find the reported df are not consistent with the description of the design and analysis, which means the data were not analyzed as stated.</p>
</div>
<div id="better-practice-estimates-and-their-uncertainty" class="section level3">
<h3><span class="header-section-number">11.3.3</span> Better practice – estimates and their uncertainty</h3>
<p>As emphasized in the previous chapter, the decision to include or exclude an interaction effect in the model should not be based on a <span class="math inline">\(p\)</span>-value but on the goals of the model.</p>
<ol style="list-style-type: decimal">
<li><p>If the goal is the interaction (because a scientific model predicts one, or because this is biology and everything is conditional), then estimate the interaction effect (as a coefficient of the model!) and its uncertainty, including a CI and <span class="math inline">\(p\)</span>-value. There is no controversy on how to estimate this effect and its uncertainty. The coefficient will be different between dummy and effect coded models but this is okay because they have different specific interpretations but the same general interpretation. Use a Harrel plot with the coefficients (including the interaction coefficient) to show this estimate and uncertainty.</p></li>
<li><p>If the goal is to estimate constant main effects, then exclude the interaction effect from the model and report the main effects (again, as coefficients from the model or contrasts if other pairwise effects are desired) with their uncertainty. Use an interaction plot (or bottom part of the harrell plot) to justify forcing the interaction to zero (for example the interaction effect adds little to the total sum of squares or the interpretation of a single main effect or two (or more) conditional effects would be the same. Use a Harrel plot that excludes the interaction term to show these main effects and uncertainty.</p></li>
<li><p>And if a researcher is interested in the effects of the factors but there is strong evidence for a non-trivial interaction, then report the conditional effects (as contrasts) with their uncertainty. Use a Harrel plot that includes the interaction term to show these conditional effects and uncertainty. If there is an obvious interaction, it probably doesn’t make sense to interpret the main effects, contrary to what some people argue. If there is a positive effect of factor A across all levels of factor B, we don’t really need a <span class="math inline">\(p\)</span>-value to test that the average of these positive effects is significant. This doesn’t add value to the plot and any conditional effects that are reported.</p></li>
</ol>
<p>Notice that an ANOVA table has no role in this recommendation.</p>
</div>
</div>
<div id="unbalanced-designs" class="section level2">
<h2><span class="header-section-number">11.4</span> Unbalanced designs</h2>
<p>My recommendation above is to not bother with ANOVA, but to simply compute the contrasts of interest using the linear model. But if you really want to use ANOVA, you should be aware that <strong>if the design is unbalanced, factor order matters in the default R anova function</strong> and that I routinely find published ANOVA tables that report statistics (<span class="math inline">\(F\)</span> and <span class="math inline">\(p\)</span> values) that are not what the authors think they are.</p>
<p>An <strong>unbalanced</strong> design is one in which the number of replicates differs among the cell. The urchin data is balanced because there are six replicates in each cell. If the respirometer broke before taking the respiratory measures of the final tank, the design would be unbalanced, one of the cells would have only five replicates.</p>
<p>Let’s look at the effect of row order on the statistics of the urchin data using R’s default anova function.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">1</td>
<td align="right">60.20</td>
<td align="right">60.20</td>
<td align="right">19.06</td>
<td align="right">0.00030</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">1</td>
<td align="right">16.52</td>
<td align="right">16.52</td>
<td align="right">5.23</td>
<td align="right">0.03325</td>
</tr>
<tr class="odd">
<td>Temp:CO2</td>
<td align="right">1</td>
<td align="right">10.81</td>
<td align="right">10.81</td>
<td align="right">3.42</td>
<td align="right">0.07910</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CO2</td>
<td align="right">1</td>
<td align="right">16.52</td>
<td align="right">16.52</td>
<td align="right">5.23</td>
<td align="right">0.03325</td>
</tr>
<tr class="even">
<td>Temp</td>
<td align="right">1</td>
<td align="right">60.20</td>
<td align="right">60.20</td>
<td align="right">19.06</td>
<td align="right">0.00030</td>
</tr>
<tr class="odd">
<td>CO2:Temp</td>
<td align="right">1</td>
<td align="right">10.81</td>
<td align="right">10.81</td>
<td align="right">3.42</td>
<td align="right">0.07910</td>
</tr>
<tr class="even">
<td>Now let’s u</td>
<td align="right">nbala</td>
<td align="right">nce the d</td>
<td align="right">ata, by re</td>
<td align="right">moving thr</td>
<td align="right">ee random replicates (these may be both in one cell or spread across cells. First, here is the number of replicates in each cell:</td>
</tr>
</tbody>
</table>
<pre><code>##        
##         CO2- CO2+
##   Temp-    6    4
##   Temp+    6    5</code></pre>
<p>And here are the two tables with the order of Temp and CO2 reversed in the model</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">1</td>
<td align="right">62.25</td>
<td align="right">62.25</td>
<td align="right">18.44</td>
<td align="right">0.00049</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">1</td>
<td align="right">21.49</td>
<td align="right">21.49</td>
<td align="right">6.36</td>
<td align="right">0.02190</td>
</tr>
<tr class="odd">
<td>Temp:CO2</td>
<td align="right">1</td>
<td align="right">6.38</td>
<td align="right">6.38</td>
<td align="right">1.89</td>
<td align="right">0.18720</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CO2</td>
<td align="right">1</td>
<td align="right">17.59</td>
<td align="right">17.59</td>
<td align="right">5.21</td>
<td align="right">0.03561</td>
</tr>
<tr class="even">
<td>Temp</td>
<td align="right">1</td>
<td align="right">66.14</td>
<td align="right">66.14</td>
<td align="right">19.59</td>
<td align="right">0.00037</td>
</tr>
<tr class="odd">
<td>CO2:Temp</td>
<td align="right">1</td>
<td align="right">6.38</td>
<td align="right">6.38</td>
<td align="right">1.89</td>
<td align="right">0.18720</td>
</tr>
</tbody>
</table>
<p>Several observations are important.</p>
<ol style="list-style-type: decimal">
<li>the statistics for the last row, which is the interaction, does not change.</li>
<li><p>if these data were analyzed in the software package JMP, or SAS, or SSPS then <strong>order wouldn’t matter</strong>. Here is what the tables would look like</p>
<table>
<thead>
<tr class="header">
<th align="right">Sum</th>
<th align="right">Sq Df</th>
<th align="right">F v</th>
<th>alue Pr</th>
<th align="left">(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Temp</td>
<td align="right">58.77</td>
<td align="right">1</td>
<td>17.41</td>
<td align="left">0.00064</td>
</tr>
<tr class="even">
<td align="right">CO2</td>
<td align="right">19.93</td>
<td align="right">1</td>
<td>5.90</td>
<td align="left">0.02648</td>
</tr>
<tr class="odd">
<td align="right">Temp:CO2</td>
<td align="right">6.38</td>
<td align="right">1</td>
<td>1.89</td>
<td align="left">0.18720</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="right">Sum</th>
<th align="right">Sq Df</th>
<th align="right">F v</th>
<th>alue Pr</th>
<th align="left">(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">CO2</td>
<td align="right">19.93</td>
<td align="right">1</td>
<td>5.90</td>
<td align="left">0.02648</td>
</tr>
<tr class="even">
<td align="right">Temp</td>
<td align="right">58.77</td>
<td align="right">1</td>
<td>17.41</td>
<td align="left">0.00064</td>
</tr>
<tr class="odd">
<td align="right">CO2:Temp</td>
<td align="right">6.38</td>
<td align="right">1</td>
<td>1.89</td>
<td align="left">0.18720</td>
</tr>
</tbody>
</table></li>
<li><p>Order does not change the statistics in the coefficient table, even for unbalanced data:</p>
<table>
<thead>
<tr class="header">
<th align="right">Est</th>
<th>imate Std</th>
<th>. Error t v</th>
<th>alue Pr(</th>
<th align="left">&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">(Intercept)</td>
<td>9.50</td>
<td>0.407</td>
<td>23.367</td>
<td align="left">0.0000</td>
</tr>
<tr class="even">
<td align="right">Temp1</td>
<td>-1.70</td>
<td>0.407</td>
<td>-4.172</td>
<td align="left">0.0006</td>
</tr>
<tr class="odd">
<td align="right">CO21</td>
<td>0.99</td>
<td>0.407</td>
<td>2.430</td>
<td align="left">0.0265</td>
</tr>
<tr class="even">
<td align="right">Temp1:CO21</td>
<td>-0.56</td>
<td>0.407</td>
<td>-1.374</td>
<td align="left">0.1872</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="right">Est</th>
<th>imate Std</th>
<th>. Error t v</th>
<th>alue Pr(</th>
<th align="left">&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">(Intercept)</td>
<td>9.50</td>
<td>0.407</td>
<td>23.367</td>
<td align="left">0.0000</td>
</tr>
<tr class="even">
<td align="right">CO21</td>
<td>0.99</td>
<td>0.407</td>
<td>2.430</td>
<td align="left">0.0265</td>
</tr>
<tr class="odd">
<td align="right">Temp1</td>
<td>-1.70</td>
<td>0.407</td>
<td>-4.172</td>
<td align="left">0.0006</td>
</tr>
<tr class="even">
<td align="right">CO21:Temp1</td>
<td>-0.56</td>
<td>0.407</td>
<td>-1.374</td>
<td align="left">0.1872</td>
</tr>
</tbody>
</table></li>
</ol>
<div id="what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares" class="section level3">
<h3><span class="header-section-number">11.4.1</span> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</h3>
<p><strong>Type I sum of squares</strong>. Here is the (default) ANOVA table using Type I sum of squares for the urchin data with the three missing rows.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">1</td>
<td align="right">62.248</td>
<td align="right">62.248</td>
<td align="right">18.4</td>
<td align="right">0.0005</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">1</td>
<td align="right">21.488</td>
<td align="right">21.488</td>
<td align="right">6.4</td>
<td align="right">0.0219</td>
</tr>
<tr class="odd">
<td>Temp:CO2</td>
<td align="right">1</td>
<td align="right">6.377</td>
<td align="right">6.377</td>
<td align="right">1.9</td>
<td align="right">0.1872</td>
</tr>
<tr class="even">
<td>Residuals</td>
<td align="right">17</td>
<td align="right">57.399</td>
<td align="right">3.376</td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>The default coding of dummy variables in R’s <code>lm</code> function is dummy coding, which is the coding used for Type I or <strong>Sequential Sum of Squares</strong>. The hypothesis tested by each row in the ANOVA table using Type I sum of squares is the effect of that row’s term conditional on all terms before it in the model (or above it in the table) and ignoring all terms after it in the model (or below it in the table).</p>
<ol style="list-style-type: decimal">
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(Temp\)</span> is the same as if <span class="math inline">\(Temp\)</span> were the only term in the model (other than the intercept). That is, the means are estimated for each level of <span class="math inline">\(Temp\)</span> ignoring the fact that half the replicates within each level of <span class="math inline">\(Temp\)</span> experienced low <span class="math inline">\(CO2\)</span> and half experienced high <span class="math inline">\(CO2\)</span></p></li>
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(CO2\)</span> is conditional on <span class="math inline">\(Temp\)</span>. That is, the difference in metabolism between <span class="math inline">\(CO2+\)</span> and <span class="math inline">\(CO2-\)</span> when <span class="math inline">\(Temp\)</span> is “held constant” (or for all cases where <span class="math inline">\(Temp\)</span> takes the same value). This is equivalent to the hypothesis that the difference in the marginal means of CO2 is zero.</p></li>
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for the interaction is conditional on all other terms and nothing is ignored.</p></li>
</ol>
<p><strong>Type II sum of squares</strong>. Here is the ANOVA table using Type II sum of squares for the urchin data with missing values. The interaction term is excluded from the linear model, because type II sum of squares are used to estimate main effects ignoring the interaction (so this would make sense only if a plot of the effects suggested a small interaction relative to the main effects). The sum of squares for the main effects would be the same if the interaction were included but the residual df, and thus the F and P-values would differ.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">1</td>
<td align="right">66.145</td>
<td align="right">66.145</td>
<td align="right">18.7</td>
<td align="right">0.0004</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">1</td>
<td align="right">21.488</td>
<td align="right">21.488</td>
<td align="right">6.1</td>
<td align="right">0.0241</td>
</tr>
<tr class="odd">
<td>Residuals</td>
<td align="right">18</td>
<td align="right">63.776</td>
<td align="right">3.543</td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>The hypothesis tested by each row in the ANOVA table using Type II sum of squares is the effect of that row’s term conditional on all terms <em>at the same level or below</em> but ignoring all terms at a higher level in the model (or below it in the table). For example, the hypothesis test for a factor is conditioned on other factors but ignores interaction terms among the factors. Consequently, these hypotheses tested are</p>
<ol style="list-style-type: decimal">
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(Temp\)</span> is conditional on <span class="math inline">\(CO2\)</span>. This is the same hypothesis that would occur using Type I sum of squares but placing <span class="math inline">\(Temp\)</span> second in the model, after <span class="math inline">\(CO2\)</span> (and it is in fact how I computed it for the table).</p></li>
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(CO2\)</span> is conditional on <span class="math inline">\(Temp\)</span>. This is exactly the hypothesis for <span class="math inline">\(CO2\)</span> using the Type I sum of squares above.</p></li>
</ol>
<p><strong>Type III sum of squares</strong>. Here is the ANOVA table using Type III sum of squares for the urchin data for missing data. The interaction term is excluded from the linear model, and advocates of using Type III sum of squares explicitly want this in the model.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Sum Sq</th>
<th align="right">Df</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Temp</td>
<td align="right">58.770</td>
<td align="right">1</td>
<td align="right">17.406</td>
<td align="right">0.0006</td>
</tr>
<tr class="even">
<td>CO2</td>
<td align="right">19.935</td>
<td align="right">1</td>
<td align="right">5.904</td>
<td align="right">0.0265</td>
</tr>
<tr class="odd">
<td>Temp:CO2</td>
<td align="right">6.377</td>
<td align="right">1</td>
<td align="right">1.889</td>
<td align="right">0.1872</td>
</tr>
<tr class="even">
<td>Residuals</td>
<td align="right">57.399</td>
<td align="right">17</td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>The hypothesis tested by each row in the ANOVA table using Type III sum of squares is the effect of that row’s term conditional on all terms in the model.</p>
<ol style="list-style-type: decimal">
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(Temp\)</span> is conditional on <span class="math inline">\(CO2\)</span> and <span class="math inline">\(Temp:CO2\)</span>.</p></li>
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(CO2\)</span> is conditional on <span class="math inline">\(Temp\)</span> and <span class="math inline">\(Temp:CO2\)</span>.</p></li>
<li><p>The hypothesis tested by the <span class="math inline">\(p\)</span>-value for <span class="math inline">\(Temp:CO2\)</span> is conditional on <span class="math inline">\(Temp\)</span> and <span class="math inline">\(CO2\)</span>. This is the same for Type I sum of squares (and Type II, if the interaction term were included)</p></li>
</ol>
</div>
<div id="back-to-interpretation-of-main-effects" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Back to interpretation of main effects</h3>
</div>
<div id="the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced." class="section level3">
<h3><span class="header-section-number">11.4.3</span> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</h3>
</div>
</div>
<div id="working-in-r-3" class="section level2">
<h2><span class="header-section-number">11.5</span> Working in R</h2>
<div id="type-i-sum-of-squares-in-r" class="section level3">
<h3><span class="header-section-number">11.5.1</span> Type I sum of squares in R</h3>
<p>The base R function <code>anova()</code> computes the ANOVA table using Type I sum of squares for any fit model object, such as that returned by <code>lm</code>. Here is a script for the urchin data. I first create unbalanced data by deleting the first row that is the control row.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cn_rows &lt;-<span class="st"> </span><span class="kw">which</span>(urchin[, Temp]<span class="op">==</span><span class="st">&quot;Temp-&quot;</span> <span class="op">&amp;</span><span class="st"> </span>urchin[, CO2]<span class="op">==</span><span class="st">&quot;CO2-&quot;</span>) <span class="co"># gives the rows of the controls</span>
urchin_unbalanced &lt;-<span class="st"> </span>urchin[<span class="op">-</span>cn_rows[<span class="dv">1</span>],] <span class="co"># deletes the row that is in first element of cn_rows</span>
urchin.t1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Resp <span class="op">~</span><span class="st"> </span>Temp<span class="op">*</span>CO2, <span class="dt">data=</span>urchin_unbalanced)
<span class="kw">anova</span>(urchin.t1)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Resp
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Temp       1 55.696  55.696 16.9244 0.0005907 ***
## CO2        1 18.411  18.411  5.5946 0.0288072 *  
## Temp:CO2   1  9.204   9.204  2.7970 0.1108298    
## Residuals 19 62.527   3.291                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="type-ii-and-iii-sum-of-squares" class="section level3">
<h3><span class="header-section-number">11.5.2</span> Type II and III Sum of Squares</h3>
<p>Type II sum of squares can be computed manually simply by fitting the model twice, once with the factors ordered one way and then with the factors ordered the opposite way. The car package has the function <code>Anova</code> that specifically outputs Type II and Type III ANOVA tables.</p>
<p>Type II sum of squares can be fit with the interaction in the model, and this generates the Type II sum of squares for the main terms but the residual is wrong for the <span class="math inline">\(F\)</span>-ratio because it is the residual from the full model and Type II assumes the interaction effect is zero. So, if one wants an ANOVA table with a <span class="math inline">\(F\)</span> and <span class="math inline">\(p\)</span> that reflect this, then the interaction should be dropped from the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">urchin.t2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Resp <span class="op">~</span><span class="st"> </span>Temp<span class="op">*</span>CO2, <span class="dt">data=</span>urchin_unbalanced)
<span class="kw">Anova</span>(urchin.t2, <span class="dt">type=</span><span class="st">&quot;2&quot;</span>)</code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: Resp
##           Sum Sq Df F value    Pr(&gt;F)    
## Temp      52.711  1 16.0173 0.0007624 ***
## CO2       18.411  1  5.5946 0.0288072 *  
## Temp:CO2   9.204  1  2.7970 0.1108298    
## Residuals 62.527 19                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">urchin.t2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Resp <span class="op">~</span><span class="st"> </span>Temp <span class="op">+</span><span class="st"> </span>CO2, <span class="dt">data=</span>urchin_unbalanced)
<span class="kw">Anova</span>(urchin.t2, <span class="dt">type=</span><span class="st">&quot;2&quot;</span>)</code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: Resp
##           Sum Sq Df F value   Pr(&gt;F)   
## Temp      52.711  1 14.6968 0.001038 **
## CO2       18.411  1  5.1333 0.034725 * 
## Residuals 71.731 20                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>To get type III sum of squares, we need to specify effects coding for the model matrix. The safest way to do this is something like this</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">con3 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Temp=</span>contr.sum, <span class="dt">CO2=</span>contr.sum) <span class="co"># change the contrasts coding for the model matrix</span>
urchin.t3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Resp <span class="op">~</span><span class="st"> </span>Temp<span class="op">*</span>CO2, <span class="dt">data=</span>urchin_unbalanced, <span class="dt">contrasts=</span>con3)
<span class="kw">Anova</span>(urchin.t3, <span class="dt">type=</span><span class="st">&quot;3&quot;</span>)</code></pre></div>
<pre><code>## Anova Table (Type III tests)
## 
## Response: Resp
##              Sum Sq Df  F value    Pr(&gt;F)    
## (Intercept) 2148.60  1 652.8939 3.559e-16 ***
## Temp          54.71  1  16.6241 0.0006422 ***
## CO2           17.15  1   5.2119 0.0341221 *  
## Temp:CO2       9.20  1   2.7970 0.1108298    
## Residuals     62.53 19                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="two-or-more-categorical-x-factorial-designs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="adding-covariates-to-a-linear-model-i-ancova.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/chapters/30-anova.Rmd",
"text": "Edit"
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
