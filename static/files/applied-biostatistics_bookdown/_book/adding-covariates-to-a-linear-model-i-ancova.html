<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Elementary Statistical Modeling for Applied Biostatistics</title>
  <meta name="description" content="A first course in statistical modeling for biology students">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Elementary Statistical Modeling for Applied Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A first course in statistical modeling for biology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Elementary Statistical Modeling for Applied Biostatistics" />
  
  <meta name="twitter:description" content="A first course in statistical modeling for biology students" />
  

<meta name="author" content="Jeffrey A. Walker">


<meta name="date" content="2018-11-22">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="anova-tables.html">
<link rel="next" href="appendix-1-getting-started-with-r.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Elements of Applied Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Statistical Modeling</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#statistical-modeling-with-linear-models"><i class="fa fa-check"></i><b>1.1</b> Statistical modeling with linear models</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#linear-models-are-used-for-prediction-explanation-and-description"><i class="fa fa-check"></i><b>1.1.1</b> Linear models are used for prediction, explanation, and description</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#model-fitting"><i class="fa fa-check"></i><b>1.2</b> Model fitting</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#assumptions-for-inference-with-a-linear-model"><i class="fa fa-check"></i><b>1.3</b> Assumptions for inference with a linear model</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#statistical-model-or-regression-model"><i class="fa fa-check"></i><b>1.3.1</b> “Statistical model” or “regression model”?</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#linear-models-versus-non-linear-models"><i class="fa fa-check"></i><b>1.4</b> Linear models versus non-linear models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html"><i class="fa fa-check"></i><b>2</b> Organization – R Projects and R Notebooks</a><ul>
<li class="chapter" data-level="2.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#importing-packages"><i class="fa fa-check"></i><b>2.1</b> Importing Packages</a></li>
<li class="chapter" data-level="2.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-studio-project-for-this-class"><i class="fa fa-check"></i><b>2.2</b> Create an R Studio Project for this Class</a></li>
<li class="chapter" data-level="2.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#r-notebooks"><i class="fa fa-check"></i><b>2.3</b> R Notebooks</a><ul>
<li class="chapter" data-level="2.3.1" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-an-r-notebook-for-this-chapter"><i class="fa fa-check"></i><b>2.3.1</b> Create an R Notebook for this Chapter</a></li>
<li class="chapter" data-level="2.3.2" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-setup-chunk"><i class="fa fa-check"></i><b>2.3.2</b> Create a “setup” chunk</a></li>
<li class="chapter" data-level="2.3.3" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-a-simple-plot-chunk"><i class="fa fa-check"></i><b>2.3.3</b> Create a “simple plot” chunk</a></li>
<li class="chapter" data-level="2.3.4" data-path="organization-r-projects-and-r-notebooks.html"><a href="organization-r-projects-and-r-notebooks.html#create-more-r-chunks-and-explore-options-and-play-with-r-code"><i class="fa fa-check"></i><b>2.3.4</b> Create more R chunks and explore options and play with R code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html"><i class="fa fa-check"></i><b>3</b> Data – Reading, Writing, and Fake</a><ul>
<li class="chapter" data-level="3.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#create-new-notebook-for-this-chapter"><i class="fa fa-check"></i><b>3.1</b> Create new notebook for this chapter</a></li>
<li class="chapter" data-level="3.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#importing-data"><i class="fa fa-check"></i><b>3.2</b> Importing Data</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#excel-file"><i class="fa fa-check"></i><b>3.2.1</b> Excel File</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#text-file"><i class="fa fa-check"></i><b>3.2.2</b> Text File</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#creating-fake-data"><i class="fa fa-check"></i><b>3.3</b> Creating Fake Data</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#continuous-x-fake-observational-data"><i class="fa fa-check"></i><b>3.3.1</b> Continuous X (fake observational data)</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#categorical-x-fake-experimental-data"><i class="fa fa-check"></i><b>3.3.2</b> Categorical X (fake experimental data)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#saving-data"><i class="fa fa-check"></i><b>3.4</b> Saving Data</a></li>
<li class="chapter" data-level="3.5" data-path="data-reading-writing-and-fake.html"><a href="data-reading-writing-and-fake.html#problems"><i class="fa fa-check"></i><b>3.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><i class="fa fa-check"></i><b>4</b> Variability and Uncertainty (Standard Deviations and Standard Errors)</a><ul>
<li class="chapter" data-level="4.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#the-sample-standard-deviation-vs.the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1</b> The sample standard deviation vs. the standard error of the mean</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#sample-standard-deviation"><i class="fa fa-check"></i><b>4.1.1</b> Sample standard deviation</a></li>
<li class="chapter" data-level="4.1.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>4.1.2</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#using-google-sheets-to-generate-fake-data-to-explore-uncertainty"><i class="fa fa-check"></i><b>4.2</b> Using Google Sheets to generate fake data to explore uncertainty</a><ul>
<li class="chapter" data-level="4.2.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#steps"><i class="fa fa-check"></i><b>4.2.1</b> Steps</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#using-r-to-generate-fake-data-to-explore-uncertainty"><i class="fa fa-check"></i><b>4.3</b> Using R to generate fake data to explore uncertainty</a><ul>
<li class="chapter" data-level="4.3.1" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-i"><i class="fa fa-check"></i><b>4.3.1</b> part I</a></li>
<li class="chapter" data-level="4.3.2" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-ii---means"><i class="fa fa-check"></i><b>4.3.2</b> part II - means</a></li>
<li class="chapter" data-level="4.3.3" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><i class="fa fa-check"></i><b>4.3.3</b> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li class="chapter" data-level="4.3.4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#part-iv-generating-fake-data-with-for-loops"><i class="fa fa-check"></i><b>4.3.4</b> Part IV – Generating fake data with “for loops”</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variability-and-uncertainty-standard-deviations-and-standard-errors.html"><a href="variability-and-uncertainty-standard-deviations-and-standard-errors.html#bootstrapped-standard-errors"><i class="fa fa-check"></i><b>4.4</b> Bootstrapped standard errors</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>5</b> Plotting</a><ul>
<li class="chapter" data-level="5.1" data-path="plotting.html"><a href="plotting.html#plots-should-be-the-center-of-your-papers-universe"><i class="fa fa-check"></i><b>5.1</b> Plots should be the center of your paper’s universe</a></li>
<li class="chapter" data-level="5.2" data-path="plotting.html"><a href="plotting.html#pretty-good-plots-show-the-data"><i class="fa fa-check"></i><b>5.2</b> Pretty good plots show the data</a></li>
<li class="chapter" data-level="5.3" data-path="plotting.html"><a href="plotting.html#even-better-plots"><i class="fa fa-check"></i><b>5.3</b> Even better plots…</a><ul>
<li class="chapter" data-level="5.3.1" data-path="plotting.html"><a href="plotting.html#let-interaction-plots-be-interaction-plots"><i class="fa fa-check"></i><b>5.3.1</b> Let interaction plots be interaction plots</a></li>
<li class="chapter" data-level="5.3.2" data-path="plotting.html"><a href="plotting.html#even-better-plots-continuedshow-the-model"><i class="fa fa-check"></i><b>5.3.2</b> Even better plots (continued)…Show the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html"><i class="fa fa-check"></i><b>6</b> A linear model with a single, continous <em>X</em></a><ul>
<li class="chapter" data-level="6.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#a-linear-model-with-a-single-continous-x-is-classical-regression"><i class="fa fa-check"></i><b>6.1</b> A linear model with a single, continous <em>X</em> is classical “regression”</a><ul>
<li class="chapter" data-level="6.1.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#using-a-linear-model-to-estimate-explanatory-effects"><i class="fa fa-check"></i><b>6.1.1</b> Using a linear model to estimate explanatory effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#using-a-linear-model-for-prediction"><i class="fa fa-check"></i><b>6.1.2</b> Using a linear model for prediction</a></li>
<li class="chapter" data-level="6.1.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#reporting-results"><i class="fa fa-check"></i><b>6.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#working-in-r"><i class="fa fa-check"></i><b>6.2</b> Working in R</a><ul>
<li class="chapter" data-level="6.2.1" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#exploring-the-bivariate-relationship-between-y-and-x"><i class="fa fa-check"></i><b>6.2.1</b> Exploring the bivariate relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="6.2.2" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#fitting-the-linear-model"><i class="fa fa-check"></i><b>6.2.2</b> Fitting the linear model</a></li>
<li class="chapter" data-level="6.2.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#getting-to-know-the-linear-model-the-summary-function"><i class="fa fa-check"></i><b>6.2.3</b> Getting to know the linear model: the <code>summary</code> function</a></li>
<li class="chapter" data-level="6.2.4" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#display-an-alternative-to-summary"><i class="fa fa-check"></i><b>6.2.4</b> display: An alternative to summary</a></li>
<li class="chapter" data-level="6.2.5" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#confidence-intervals"><i class="fa fa-check"></i><b>6.2.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="6.2.6" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#how-good-is-our-model"><i class="fa fa-check"></i><b>6.2.6</b> How good is our model?</a></li>
<li class="chapter" data-level="6.2.7" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#exploring-a-lm-object"><i class="fa fa-check"></i><b>6.2.7</b> exploring a lm object</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="a-linear-model-with-a-single-continous-x.html"><a href="a-linear-model-with-a-single-continous-x.html#problems-1"><i class="fa fa-check"></i><b>6.3</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html"><i class="fa fa-check"></i><b>7</b> Least Squares Estimation and the Decomposition of Variance</a><ul>
<li class="chapter" data-level="7.1" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html#ols-regression"><i class="fa fa-check"></i><b>7.1</b> OLS regression</a></li>
<li class="chapter" data-level="7.2" data-path="least-squares-estimation-and-the-decomposition-of-variance.html"><a href="least-squares-estimation-and-the-decomposition-of-variance.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><i class="fa fa-check"></i><b>7.2</b> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html"><i class="fa fa-check"></i><b>8</b> A linear model with a single, categorical <em>X</em></a><ul>
<li class="chapter" data-level="8.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#a-linear-model-with-a-single-categorical-x-is-the-engine-behind-a-single-factor-one-way-anova-and-a-t-test-is-a-special-case-of-this-model."><i class="fa fa-check"></i><b>8.1</b> A linear model with a single, categorical <em>X</em> is the engine behind a single factor (one-way) ANOVA and a t-test is a special case of this model.</a><ul>
<li class="chapter" data-level="8.1.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#table-of-model-coefficients"><i class="fa fa-check"></i><b>8.1.1</b> Table of model coefficients</a></li>
<li class="chapter" data-level="8.1.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#the-linear-model"><i class="fa fa-check"></i><b>8.1.2</b> The linear model</a></li>
<li class="chapter" data-level="8.1.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#reporting-results-1"><i class="fa fa-check"></i><b>8.1.3</b> Reporting results</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#working-in-r-1"><i class="fa fa-check"></i><b>8.2</b> Working in R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#exploring-the-relationship-between-y-and-x"><i class="fa fa-check"></i><b>8.2.1</b> Exploring the relationship between <em>Y</em> and <em>X</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#fitting-the-model"><i class="fa fa-check"></i><b>8.2.2</b> Fitting the model</a></li>
<li class="chapter" data-level="8.2.3" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#an-introduction-to-contrasts"><i class="fa fa-check"></i><b>8.2.3</b> An introduction to contrasts</a></li>
<li class="chapter" data-level="8.2.4" data-path="a-linear-model-with-a-single-categorical-x.html"><a href="a-linear-model-with-a-single-categorical-x.html#harrell-plot"><i class="fa fa-check"></i><b>8.2.4</b> Harrell plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="p-values.html"><a href="p-values.html"><i class="fa fa-check"></i><b>9</b> P-values</a><ul>
<li class="chapter" data-level="9.1" data-path="p-values.html"><a href="p-values.html#p-values"><i class="fa fa-check"></i><b>9.1</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="9.2" data-path="p-values.html"><a href="p-values.html#creating-a-null-distribution."><i class="fa fa-check"></i><b>9.2</b> Creating a null distribution.</a><ul>
<li class="chapter" data-level="9.2.1" data-path="p-values.html"><a href="p-values.html#the-null-distribution"><i class="fa fa-check"></i><b>9.2.1</b> the Null Distribution</a></li>
<li class="chapter" data-level="9.2.2" data-path="p-values.html"><a href="p-values.html#t-tests"><i class="fa fa-check"></i><b>9.2.2</b> <span class="math inline">\(t\)</span>-tests</a></li>
<li class="chapter" data-level="9.2.3" data-path="p-values.html"><a href="p-values.html#p-values-from-the-perspective-of-permutation"><i class="fa fa-check"></i><b>9.2.3</b> P-values from the perspective of permutation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="p-values.html"><a href="p-values.html#statistical-modeling-instead-of-hypothesis-testing"><i class="fa fa-check"></i><b>9.3</b> Statistical modeling instead of hypothesis testing</a></li>
<li class="chapter" data-level="9.4" data-path="p-values.html"><a href="p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><i class="fa fa-check"></i><b>9.4</b> frequentist probability and the interpretation of p-values</a><ul>
<li class="chapter" data-level="9.4.1" data-path="p-values.html"><a href="p-values.html#background"><i class="fa fa-check"></i><b>9.4.1</b> Background</a></li>
<li class="chapter" data-level="9.4.2" data-path="p-values.html"><a href="p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><i class="fa fa-check"></i><b>9.4.2</b> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <span class="math inline">\(p\)</span>-value of a test statistic, this will be a frequentist probability.</a></li>
<li class="chapter" data-level="9.4.3" data-path="p-values.html"><a href="p-values.html#two-interpretations-of-the-p-value"><i class="fa fa-check"></i><b>9.4.3</b> Two interpretations of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="9.4.4" data-path="p-values.html"><a href="p-values.html#nhst"><i class="fa fa-check"></i><b>9.4.4</b> NHST</a></li>
<li class="chapter" data-level="9.4.5" data-path="p-values.html"><a href="p-values.html#some-major-misconceptions-of-the-p-value"><i class="fa fa-check"></i><b>9.4.5</b> Some major misconceptions of the <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="9.4.6" data-path="p-values.html"><a href="p-values.html#recommendations"><i class="fa fa-check"></i><b>9.4.6</b> Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="p-values.html"><a href="p-values.html#problems-2"><i class="fa fa-check"></i><b>9.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html"><i class="fa fa-check"></i><b>10</b> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="chapter" data-level="10.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#factorial-experiments"><i class="fa fa-check"></i><b>10.1</b> Factorial experiments</a><ul>
<li class="chapter" data-level="10.1.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><i class="fa fa-check"></i><b>10.1.1</b> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li class="chapter" data-level="10.1.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-is-the-biological-meaning-of-an-interaction-effect"><i class="fa fa-check"></i><b>10.1.2</b> What is the biological meaning of an interaction effect?</a></li>
<li class="chapter" data-level="10.1.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#what-about-models-with-more-than-two-factors"><i class="fa fa-check"></i><b>10.1.3</b> What about models with more than two factors?</a></li>
<li class="chapter" data-level="10.1.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#the-additive-model"><i class="fa fa-check"></i><b>10.1.4</b> The additive model</a></li>
<li class="chapter" data-level="10.1.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#contrasts-simple-vs.main-effects"><i class="fa fa-check"></i><b>10.1.5</b> Contrasts – simple vs. main effects</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#reporting-results-2"><i class="fa fa-check"></i><b>10.2</b> Reporting results</a><ul>
<li class="chapter" data-level="10.2.1" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#text-results"><i class="fa fa-check"></i><b>10.2.1</b> Text results</a></li>
<li class="chapter" data-level="10.2.2" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#harrellplot"><i class="fa fa-check"></i><b>10.2.2</b> Harrellplot</a></li>
<li class="chapter" data-level="10.2.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#interaction-plots"><i class="fa fa-check"></i><b>10.2.3</b> Interaction plots</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#recommendations-1"><i class="fa fa-check"></i><b>10.3</b> Recommendations</a></li>
<li class="chapter" data-level="10.4" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#working-in-r-2"><i class="fa fa-check"></i><b>10.4</b> Working in R</a></li>
<li class="chapter" data-level="10.5" data-path="two-or-more-categorical-x-factorial-designs.html"><a href="two-or-more-categorical-x-factorial-designs.html#problems-3"><i class="fa fa-check"></i><b>10.5</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="anova-tables.html"><a href="anova-tables.html"><i class="fa fa-check"></i><b>11</b> ANOVA Tables</a><ul>
<li class="chapter" data-level="11.1" data-path="anova-tables.html"><a href="anova-tables.html#summary-of-usage"><i class="fa fa-check"></i><b>11.1</b> Summary of usage</a></li>
<li class="chapter" data-level="11.2" data-path="anova-tables.html"><a href="anova-tables.html#example-a-one-way-anova-using-the-vole-data"><i class="fa fa-check"></i><b>11.2</b> Example: a one-way ANOVA using the vole data</a></li>
<li class="chapter" data-level="11.3" data-path="anova-tables.html"><a href="anova-tables.html#example-a-two-way-anova-using-the-urchin-data"><i class="fa fa-check"></i><b>11.3</b> Example: a two-way ANOVA using the urchin data</a><ul>
<li class="chapter" data-level="11.3.1" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-an-anova-table"><i class="fa fa-check"></i><b>11.3.1</b> How to read an ANOVA table</a></li>
<li class="chapter" data-level="11.3.2" data-path="anova-tables.html"><a href="anova-tables.html#how-to-read-anova-results-reported-in-the-text"><i class="fa fa-check"></i><b>11.3.2</b> How to read ANOVA results reported in the text</a></li>
<li class="chapter" data-level="11.3.3" data-path="anova-tables.html"><a href="anova-tables.html#better-practice-estimates-and-their-uncertainty"><i class="fa fa-check"></i><b>11.3.3</b> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="anova-tables.html"><a href="anova-tables.html#unbalanced-designs"><i class="fa fa-check"></i><b>11.4</b> Unbalanced designs</a><ul>
<li class="chapter" data-level="11.4.1" data-path="anova-tables.html"><a href="anova-tables.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><i class="fa fa-check"></i><b>11.4.1</b> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li class="chapter" data-level="11.4.2" data-path="anova-tables.html"><a href="anova-tables.html#back-to-interpretation-of-main-effects"><i class="fa fa-check"></i><b>11.4.2</b> Back to interpretation of main effects</a></li>
<li class="chapter" data-level="11.4.3" data-path="anova-tables.html"><a href="anova-tables.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><i class="fa fa-check"></i><b>11.4.3</b> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="anova-tables.html"><a href="anova-tables.html#working-in-r-3"><i class="fa fa-check"></i><b>11.5</b> Working in R</a><ul>
<li class="chapter" data-level="11.5.1" data-path="anova-tables.html"><a href="anova-tables.html#type-i-sum-of-squares-in-r"><i class="fa fa-check"></i><b>11.5.1</b> Type I sum of squares in R</a></li>
<li class="chapter" data-level="11.5.2" data-path="anova-tables.html"><a href="anova-tables.html#type-ii-and-iii-sum-of-squares"><i class="fa fa-check"></i><b>11.5.2</b> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html"><i class="fa fa-check"></i><b>12</b> Adding covariates to a linear model I: ANCOVA</a><ul>
<li class="chapter" data-level="12.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><i class="fa fa-check"></i><b>12.1</b> Adding covariates can increases the precision of the effect of interest</a><ul>
<li class="chapter" data-level="12.1.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#interaction-effects-with-covariates"><i class="fa fa-check"></i><b>12.1.1</b> Interaction effects with covariates</a></li>
<li class="chapter" data-level="12.1.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#add-only-covariates-that-were-measured-before-peaking-at-the-data"><i class="fa fa-check"></i><b>12.1.2</b> Add only covariates that were measured before peaking at the data</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#regression-to-the-mean"><i class="fa fa-check"></i><b>12.2</b> Regression to the mean</a><ul>
<li class="chapter" data-level="12.2.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights"><i class="fa fa-check"></i><b>12.2.1</b> Do not use percent change, believing that percents account for effects of initial weights</a></li>
<li class="chapter" data-level="12.2.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#do-not-test-for-balance-of-baseline-measures"><i class="fa fa-check"></i><b>12.2.2</b> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#the-generalized-linear-model"><i class="fa fa-check"></i><b>12.3</b> The generalized linear model</a></li>
<li class="chapter" data-level="12.4" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#count-data-example"><i class="fa fa-check"></i><b>12.4</b> Count data example</a><ul>
<li class="chapter" data-level="12.4.1" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#checking-the-model-i-a-normal-q-q-plot"><i class="fa fa-check"></i><b>12.4.1</b> Checking the model I – a Normal Q-Q plot</a></li>
<li class="chapter" data-level="12.4.2" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><i class="fa fa-check"></i><b>12.4.2</b> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li class="chapter" data-level="12.4.3" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#two-distributions-for-count-data-poisson-and-negative-binomial"><i class="fa fa-check"></i><b>12.4.3</b> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li class="chapter" data-level="12.4.4" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#fitting-a-glm-with-a-poisson-link-to-the-worm-data"><i class="fa fa-check"></i><b>12.4.4</b> Fitting a GLM with a Poisson link to the worm data</a></li>
<li class="chapter" data-level="12.4.5" data-path="adding-covariates-to-a-linear-model-i-ancova.html"><a href="adding-covariates-to-a-linear-model-i-ancova.html#fitting-a-glm-with-a-negative-binomial-link-to-the-worm-data"><i class="fa fa-check"></i><b>12.4.5</b> Fitting a GLM with a Negative Binomial link to the worm data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html"><i class="fa fa-check"></i>Appendix 1: Getting Started with R</a><ul>
<li class="chapter" data-level="12.5" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#get-your-computer-ready"><i class="fa fa-check"></i><b>12.5</b> Get your computer ready</a><ul>
<li class="chapter" data-level="12.5.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r"><i class="fa fa-check"></i><b>12.5.1</b> Install R</a></li>
<li class="chapter" data-level="12.5.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-r-studio"><i class="fa fa-check"></i><b>12.5.2</b> Install R Studio</a></li>
<li class="chapter" data-level="12.5.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#resources-for-installing-r-and-r-studio"><i class="fa fa-check"></i><b>12.5.3</b> Resources for installing R and R Studio</a></li>
<li class="chapter" data-level="12.5.4" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#install-latex"><i class="fa fa-check"></i><b>12.5.4</b> Install LaTeX</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-learning"><i class="fa fa-check"></i><b>12.6</b> Start learning</a><ul>
<li class="chapter" data-level="12.6.1" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#start-with-data-camp-introduction-to-r"><i class="fa fa-check"></i><b>12.6.1</b> Start with Data Camp Introduction to R</a></li>
<li class="chapter" data-level="12.6.2" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#then-move-to-introduction-to-r-studio"><i class="fa fa-check"></i><b>12.6.2</b> Then Move to Introduction to R Studio</a></li>
<li class="chapter" data-level="12.6.3" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#develop-your-project-with-an-r-studio-notebook"><i class="fa fa-check"></i><b>12.6.3</b> Develop your project with an R Studio Notebook</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#getting-data-into-r"><i class="fa fa-check"></i><b>12.7</b> Getting Data into R</a></li>
<li class="chapter" data-level="12.8" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#additional-r-learning-resources"><i class="fa fa-check"></i><b>12.8</b> Additional R learning resources</a></li>
<li class="chapter" data-level="12.9" data-path="appendix-1-getting-started-with-r.html"><a href="appendix-1-getting-started-with-r.html#packages-used-extensively-in-this-text"><i class="fa fa-check"></i><b>12.9</b> Packages used extensively in this text</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-online-resources-for-getting-started-with-linear-modeling-in-r.html"><a href="appendix-2-online-resources-for-getting-started-with-linear-modeling-in-r.html"><i class="fa fa-check"></i>Appendix 2: Online Resources for Getting Started with Linear Modeling in R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Elementary Statistical Modeling for Applied Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="adding-covariates-to-a-linear-model-i-ancova" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Adding covariates to a linear model I: ANCOVA</h1>
<p>In its most general sense, <strong>Covariates</strong> are simply the <span class="math inline">\(X\)</span> variables in a statistical model. With data from experiments, “covariates” more typically refers to <span class="math inline">\(X\)</span> variables that are added to a model to increase precision of the treatment effects. In observational designs, covariates might be added to a model to 1) increase predictive ability, 2) because the researcher is interested in specific conditional effects, or 3) to eliminate confounding. These are discussed in later chapters.</p>
<div id="adding-covariates-can-increases-the-precision-of-the-effect-of-interest" class="section level2">
<h2><span class="header-section-number">12.1</span> Adding covariates can increases the precision of the effect of interest</h2>
<p>I use fake data to introduce the concept of <strong>statistical elimination</strong> of a <strong>covariate</strong> in a statistical model. Here I am modeling the effect of a new drug on blood LDL-C levels. LDL is a kind of lipoprotein, which are particles in the blood that transport fats and cholesterol to and from different tissues. LDL-C is cholesterol associated with LDL particles. LDL-C is considered “bad cholesterol” because LDL is believed to transport cholesterol and other lipids to arterial walls, which is the basis for atherosclerosis.</p>
<p>Twenty applied biostats students are recruited and are randomly assigned to either the new or old drug. The response is blood LDL-C level and the two treatment levels are “old” and “new”. For the dummy variable coding, I’ll make “old” the reference level.</p>
<p>Let’s model this with</p>
<span class="math display" id="eq:ancova-1">\[\begin{equation}
ldlc = \beta_0 + \beta_1 drug + \varepsilon
\tag{12.1}
\end{equation}\]</span>
<p>where <span class="math inline">\(drug\)</span> is the dummy variable with <span class="math inline">\(old=0\)</span> and <span class="math inline">\(new=1\)</span>.</p>
<div class="figure"><span id="fig:ancova-plot1"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/ancova-plot1-1.png" alt="The fake LDL-C experiment." width="576" />
<p class="caption">
Figure 12.1: The fake LDL-C experiment.
</p>
</div>
<pre><code>##               Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept) 161.640772   3.974506 40.6694043 3.620049e-19
## drugnew       1.785414   5.620800  0.3176442 7.544101e-01</code></pre>
<p>The plot shows large overlap in LDL-C and no obvious effect of the drug. There “is no effect of the drug (<span class="math inline">\(p = 0.754\)</span>)” is of course an incorrect interpretation of the hypothesis test of the estimate of <span class="math inline">\(\beta_1\)</span>. A correct interpretation is, there is too much noise to say much about any effect.</p>
<p>In addition to assigning treatment level randomly, I also had the 20 students count calories from fat over the course of the experiment. Here is a plot of LDL-C vs. percent calories from fat, with treatment assignment color coded. Remember, these are the exact same values of LDL-C as in the first figure.</p>
<div class="figure"><span id="fig:ancova-plot2"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/ancova-plot2-1.png" alt="Linear regression of $ldlc$ on dietary $fat$ fit to the fake LDL-C data. The points are color coded by treatment." width="576" />
<p class="caption">
Figure 12.2: Linear regression of <span class="math inline">\(ldlc\)</span> on dietary <span class="math inline">\(fat\)</span> fit to the fake LDL-C data. The points are color coded by treatment.
</p>
</div>
<p>The line is the bivariate regression fit to the data ignoring treatment level so is the model</p>
<span class="math display" id="eq:ancova-2">\[\begin{equation}
ldlc = \beta_0 + \beta_1 fat + \varepsilon
\tag{12.2}
\end{equation}\]</span>
<p>I’ve color coded the points by treatment level but <span class="math inline">\(drug\)</span> is not in the model. It is clear that most of the “old” data points are above the line, or have positive residuals from the model, while the “new” data points are below the line, or have negative residuals from the model. A better way to think about this pattern is that <strong>at any specific level of fat, the LDL-C for old is higher than the LDL-C for new</strong>.</p>
<p>What is happening? Dietary fat is contributing to the variance of LDL-C and this added noise makes it harder to measure the effect of the new drug relative to the old drug. If we could somehow measure the effect of drug at a specific level of dietary fat, then we could get a more precise estimate of the effect. But how to do this?</p>
<ol style="list-style-type: decimal">
<li><p>We could just analyze a subset of the data, that is, only the cases in which the value of dietary fat is nearly equal. This throws away perfectly good data and, consequently, greatly reduces the sample size and thus precision to estimate the effect.</p></li>
<li><p>We could use the residuals of the fitted model <a href="adding-covariates-to-a-linear-model-i-ancova.html#eq:ancova-2">(12.2)</a> to estimate the effect of drug treatment (this is what we did by eye in figure <a href="adding-covariates-to-a-linear-model-i-ancova.html#fig:ancova-plot2">12.2</a>). Here is the new model</p></li>
</ol>
<span class="math display" id="eq:ancova-3">\[\begin{equation}
ldlc.r = \beta_0 + \beta_1 drug + \varepsilon
\tag{12.3}
\end{equation}\]</span>
<p>where <span class="math inline">\(ldlc.r\)</span> are the residuals. The effect of the new drug on these residuals is</p>
<pre><code>## `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/unnamed-chunk-14-1.png" width="576" /></p>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)  2.361321  0.6190269  3.814570 1.269495e-03
## drugnew     -4.722642  0.8754362 -5.394616 3.984159e-05</code></pre>
<p>In this two-stage analysis (stage 1: fit ldlc ~ fat to get residuals, stage 2: fit residuals ~ drug), we have <em>eliminated the effect of dietary fat</em> on the variance of the response and, as a consequence, the estimate of the effect of the drug is much more precise. Now the estimate of the effect is -4.7 mg/dL blood and the SE is only .9 (compare this to the values in the original analysis). While the SE of the diference is correct, any confidence interval or <span class="math inline">\(t\)</span>-value is not because the df is wrong. In the two stage analysis we fit two parameters – the slope (coefficient <span class="math inline">\(b_1\)</span>) in stage 1 and the difference in means (coefficient <span class="math inline">\(b_1\)</span>) in stage 2 – but the <span class="math inline">\(t\)</span> in the table assumes we only fit one parameter (that from stage 2). Effectively, the stage 2 test is ignorant that the data (<span class="math inline">\(ldlc.r\)</span>) are the result of a previous model fit. We could manually modify the computation of <span class="math inline">\(t\)</span>, but the more proper method is to simply…</p>
<ol start="3" style="list-style-type: decimal">
<li>Add dietary fat into the original linear model.</li>
</ol>
<span class="math display">\[\begin{equation}
ldlc = \beta_0 + \beta_1 fat + \beta_2 drug + \varepsilon
\end{equation}\]</span>
<pre><code>##               Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)  99.449257  2.2812187 43.59479 6.880431e-19
## fat         203.773799  7.2192309 28.22652 1.009563e-15
## drugnew      -5.128034  0.8711147 -5.88675 1.794002e-05</code></pre>
<p>Here, the estimate is -5.1 and the SE is 0.9. Look back at the script generating the fake data; the true effect (<span class="math inline">\(\beta_1\)</span>) of the new drug was set to -5.0 so this estimate is quite good.</p>
<div id="interaction-effects-with-covariates" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Interaction effects with covariates</h3>
</div>
<div id="add-only-covariates-that-were-measured-before-peaking-at-the-data" class="section level3">
<h3><span class="header-section-number">12.1.2</span> Add only covariates that were measured before peaking at the data</h3>
</div>
</div>
<div id="regression-to-the-mean" class="section level2">
<h2><span class="header-section-number">12.2</span> Regression to the mean</h2>
<p>It is common to measure the outcome variable (<span class="math inline">\(Y\)</span>) both before and after the experimental treatments are applied and then compare the pre-post <em>change</em> in <span class="math inline">\(Y\)</span> in response to the treatment using a <span class="math inline">\(t\)</span>-test or ANOVA. Don’t do this.</p>
<p>Instead, add the pre-treatment measure into the model as a covariate.</p>
<span class="math display" id="eq:ancova-4">\[\begin{equation}
Y_{post} = \beta_0 + \beta_1 Y_{pre} + \beta_2 Treatment + \varepsilon
\tag{12.4}
\end{equation}\]</span>
<p>where <span class="math inline">\(Treatment\)</span> is a dummy variable for a two-level factor. A pre-treatment measure (<span class="math inline">\(Y_{pre}\)</span>) is often called the <em>baseline</em> measure. The change in <span class="math inline">\(Y\)</span> (<span class="math inline">\(\Delta Y = Y{post} - Y_{pre}\)</span>) is sometimes called a change score or gain score. <span class="math inline">\(\Delta Y\)</span> can be modeled as in equation <a href="adding-covariates-to-a-linear-model-i-ancova.html#eq:ancova-4">(12.4)</a> and the <span class="math inline">\(p\)</span>-value will be precisely the same (the estimate and SE will differ of course because the response variable is different).</p>
<span class="math display" id="eq:ancova-5">\[\begin{equation}
\Delta Y = \beta_0 + \beta_1 Y_{pre} + \beta_2 Treatment + \varepsilon
\tag{12.5}
\end{equation}\]</span>
<p>The reason why a researcher should not model <span class="math inline">\(\Delta Y\)</span> as a function of <span class="math inline">\(Treatment\)</span> without <span class="math inline">\(Y_{pre}\)</span> as a covariate is that the <strong>regression to the mean</strong>. To explain regression to the mean, I use fake data simulated to model the results from an important study on gut microbiomes. In this study, the authors (Turnbaugh et al. xxx) showed that mice with feces from obese (genotype <em>ob/ob</em>) donors had higher weight gain than mice with feces from lean (genotype <em>+/+</em>) donors, presumably because of the differences in microbial communities between the donor types (shown elsewhere in their paper). To support the inference of a large difference in weight change, they illustrated the percent change in each treatment level in their Fig 3C, which is replicated here using simulated data generated to match the original summary statistics (Figure <a href="adding-covariates-to-a-linear-model-i-ancova.html#fig:ancova-mouseplot1">12.3</a>).</p>
<div class="figure"><span id="fig:ancova-mouseplot1"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/ancova-mouseplot1-1.png" alt="Figure 3c of Turnbaugh *et al* 2006. This figure was generated with simulated data matching the summary statistics given in Turnbaugh *et al* 2006" width="576" />
<p class="caption">
Figure 12.3: Figure 3c of Turnbaugh <em>et al</em> 2006. This figure was generated with simulated data matching the summary statistics given in Turnbaugh <em>et al</em> 2006
</p>
</div>
<p>That looks like a big difference, with the mice from the obese-donor treatment level gaining much more fat than the mice from the lean-donor treatment level. Turnbaugh et al. used a simple t-test of this percent change to test the effect of the <em>ob/ob</em> treatment. The linear model underneath this <span class="math inline">\(t\)</span>-test is</p>
<span class="math display">\[\begin{equation}
fat.gain = \beta_0 + \beta_1 obese + \varepsilon
\end{equation}\]</span>
<p>where <span class="math inline">\(fat.gain\)</span> is the percent gain in fat from baseline and <span class="math inline">\(obese\)</span> is a dummy variable with <em>ob/ob</em> <span class="math inline">\(= 1\)</span>. The model coefficients are</p>
<pre><code>##                Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)    25.24015   5.627515 4.485134 0.0003259533
## treatmentob/ob 21.92156   8.176589 2.681016 0.0157879742</code></pre>
<pre><code>##                    2.5 %   97.5 %
## (Intercept)    13.367137 37.11317
## treatmentob/ob  4.670468 39.17266</code></pre>
<p>Or, the increase in fat in the obese-treated mice was 21.9% (95%CI: 4.7, 39.2%, <span class="math inline">\(p=0.016\)</span>) greater than the increase in lean-treated mice. This result, if generally verified with replication and rigorous probing, would have spectacular implications for human health.</p>
<p>One might reasonably expect that if mice are randomized into two groups, then the expected difference in percent change from baseline is zero. This is unconditionally true but not conditionally true. That is, if we ignore initial fat weight, the expected difference is zero. But, the expected difference is also conditional on the initial difference in fat weights. More specifically, the expected difference is opposite in sign but proportional in magnitude to the initial difference. This conditional expectation is a consequence of regression to the mean. If the first measure of a random variable is extreme, the second measure will tend to be less extreme. And, if a second measure is extreme, the first measure will tend to be less extreme.</p>
<p>Despite random treatment assignment, the mean initial fat weight of the <em>ob/ob</em> group was 1.2SD less than the mean initial weight of the <em>+/+</em> group. By contrast, the mean final weight of the <em>ob/ob</em> group was 0.06SD larger than the mean final weight of the <em>+/+</em> group. This first difference is an extreme measure. The second is extremely close to the expectation if there is no treatment effect. Because the initial difference in weight is unusually negative, the expected difference in percent change will be unusually positive.</p>
<p>This dependency between difference in percent change from baseline and difference in initial weight is easy to simulate. Simply</p>
<ol style="list-style-type: decimal">
<li>randomly sample a normal distribution as the “initial weight” and randomly assign to treatment class</li>
<li>let the final weight have some correlation (<span class="math inline">\(\rho\)</span>) with the initial weight. Some correlation should make sense – we expect a mouse that has more fat than average at the start of the experiment to also have more fat than average at the end of the experiment. Run the experiment at different values of this correlation to see how it effects regression to the mean.</li>
<li>Do not add a treatment effect. We want to explore the behavior of the nill null hypothesis.</li>
</ol>
<div class="figure"><span id="fig:ancova-sim1"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/ancova-sim1-1.png" alt="Effect of initial difference in weight on the difference in change score. Increased initial difference in weight results in an increased differences in change score between treatment and control. Four different values of *rho* (the correlation between initial and final weights) were simulated. Only when *rho*=1 is there no influence of initial difference, because whatever differences occur at baseline will be perfectly preserved in the final measure. The X gives the values in the original Turnbaugh data" width="576" />
<p class="caption">
Figure 12.4: Effect of initial difference in weight on the difference in change score. Increased initial difference in weight results in an increased differences in change score between treatment and control. Four different values of <em>rho</em> (the correlation between initial and final weights) were simulated. Only when <em>rho</em>=1 is there no influence of initial difference, because whatever differences occur at baseline will be perfectly preserved in the final measure. The X gives the values in the original Turnbaugh data
</p>
</div>
<p>What’s happening in Figure <a href="adding-covariates-to-a-linear-model-i-ancova.html#fig:ancova-sim1">12.4</a>? Each point is a result for a single, simulated experiment. In total, there are 1000 simulated experiments for each of four values of <span class="math inline">\(\rho\)</span>. The <em>x</em>-axis is the difference between the means of the two treatment levels at baseline (<em>Initial difference</em>). The <em>y</em>-axis is the difference in mean change score between the two treatment levels – that is the difference in the means of <span class="math inline">\(\Delta Y\)</span> from equation <a href="adding-covariates-to-a-linear-model-i-ancova.html#eq:ancova-5">(12.5)</a>. This difference in <span class="math inline">\(\Delta Y\)</span> is the effect of the treatment the researchers are interested in. The <em>unconditional</em> expectation of this difference is zero</p>
<span class="math display">\[\begin{equation}
\mathrm{E}(\Delta Y_{ob/ob} - \Delta Y_{+/+}) = 0
\end{equation}\]</span>
<p>but the change conditional on baseline is not zero</p>
<span class="math display">\[\begin{equation}
\mathrm{E}(\Delta Y_{ob/ob} - \Delta Y_{+/+}) \ne 0
\end{equation}\]</span>
<p>Instead, the conditional expectation is a function of the difference at baseline. If the initial difference in weight happens to be unusually large and negative, the expected difference in change score is unusually positive. This non-zero expectation means that the estimate of the treatment effect is <strong>conditionally biased</strong> for any model that does not include the baseline fat weight as a covariate. And, from a frequentist perspective, the Type I error for a test of a difference in <span class="math inline">\(\Delta Y\)</span> is strongly dependent on the initial difference in weight.</p>
<p>The big X in the plot indicates the difference at baseline and difference in <span class="math inline">\(\Delta Y\)</span> for the original mice study. The difference in <span class="math inline">\(Delta Y\)</span> is unusually positive (about .6% of the <span class="math inline">\(|\delta Y|\)</span> are larger) but very close to the expected value given the unusually large, negative difference at baseline. In other words, the probability of the data, or more extreme than the data, is not 0.006 but something larger and perhaps, much larger (the computed value depends on the observed <span class="math inline">\(\rho\)</span>. From, the plot, the X is very unusual if <span class="math inline">\(\rho=1\)</span>, pretty unusual if <span class="math inline">\(\rho=0.66\)</span>, but pretty common if <span class="math inline">\(\rho=0.33\)</span> or if <span class="math inline">\(\rho=0\)</span>).</p>
<div id="do-not-use-percent-change-believing-that-percents-account-for-effects-of-initial-weights" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Do not use percent change, believing that percents account for effects of initial weights</h3>
<p>Some researchers mistakenly believe that a <span class="math inline">\(t\)</span>-test of percent change automatically adjusts for effects in initial weight, since this initial weight is in the denominator of the percent. This is wrong. The dependency of the difference in change between treatments on the initial difference between treatments is more severe if change is measured as a percent, because the numerator (the change score) is expected to be larger if the denominator is smaller (initial measure). Using the simulated data from above, here is this dependency.</p>
<div class="figure"><span id="fig:ancova-sim2"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/ancova-sim2-1.png" alt="Effect of initial difference in weight on the difference in percent change. Increased initial difference in weight results in an increased differences in Percent change between treatment and control. Four different values of *rho* (the correlation between initial and final weights) were simulated. Note there is no value of *rho* where the difference in percent change is independent of the initial difference. The X gives the values in the original Turnbaugh data." width="576" />
<p class="caption">
Figure 12.5: Effect of initial difference in weight on the difference in percent change. Increased initial difference in weight results in an increased differences in Percent change between treatment and control. Four different values of <em>rho</em> (the correlation between initial and final weights) were simulated. Note there is no value of <em>rho</em> where the difference in percent change is independent of the initial difference. The X gives the values in the original Turnbaugh data.
</p>
</div>
</div>
<div id="do-not-test-for-balance-of-baseline-measures" class="section level3">
<h3><span class="header-section-number">12.2.2</span> Do not “test for balance” of baseline measures</h3>
<p>Contrary to some advice and maybe to intuition, it makes no sense to “test for balance” at baseline with a <em>t</em>-test of the difference in initial measures of <span class="math inline">\(Y\)</span>. And, it makes no sense to use this test as a decision rule for how to proceed: if <span class="math inline">\(p&gt;0.05\)</span> then use a simple <span class="math inline">\(t\)</span> test of the change scores, if <span class="math inline">\(p&lt;0.05\)</span> then use ANCOVA with baseline measures in the model. First, a null-hypothesis significance test cannot tell you that there is “no difference” – this is not what null-hypothesis tests do. Second, any <span class="math inline">\(p\)</span>-value after the initial test isn’t strictly valid as it does not take into account this decision step, but this is minor. Third, it doesn’t matter; there will always be some difference in the actual means of the initial measures and, consequently, the conditional expectation of the final measures, or change in measures, or percent change will be dependent on this initial difference. So, if one has initial measures, one should use an linear model that adjusts for baseline measures to estimate the treatment effect in pre-post designs. And, if one isn’t planning on taking an initial measure, then maybe you should, because the initial measure used in a linear model allows a better estimate of the treatment effect!</p>

<p>Biologists frequently count stuff, and design experiments to estimate the effects of different factors on these counts. For example, the effects of environmental mercury on clutch size in a bird, the effects of warming on parasite load in a fish, or the effect of exercise on RNA expression.</p>
<p>Count data differ from data with Normal error in many ways, including 1) counts are discrete 2) counts tend to bunch up on the small side of the range, creating a distribution with a positive skew, 3) counts can be zero, and a sample of counts can have an abundance of zeros, and 4) the variance of count data tends to increase with the mean (see Figure <a href="adding-covariates-to-a-linear-model-i-ancova.html#fig:glm1-plot1">12.6</a> for some of these properties). Some count data can be approximated by a normal distribution and reasonably modeled with a linear model but more often, count data are modeled with something other than a normal distribution using a <strong>generalized linear model</strong> (GLM). Back before modern computing and fast processors, count data were often analyzed by either <strong>transforming</strong> the response or by <strong>non-parametric hypothesis tests</strong>. I prefer a GLM because both the analysis of transformed data and non-parametric hypothesis tests are really a response to “correct” <span class="math inline">\(p\)</span>-values instead of interpretable parameter estimates.</p>
<div class="figure"><span id="fig:glm1-plot1"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-plot1-1.png" alt="Histogram of the count of a trematode parasite larvae in Control vs. Infected fish. Fish in the Infected treatment are infected with a tapeworm." width="576" />
<p class="caption">
Figure 12.6: Histogram of the count of a trematode parasite larvae in Control vs. Infected fish. Fish in the Infected treatment are infected with a tapeworm.
</p>
</div>
</div>
</div>
<div id="the-generalized-linear-model" class="section level2">
<h2><span class="header-section-number">12.3</span> The generalized linear model</h2>
<p>Section [Assumptions for inference with statistical models] in Chapter 1 introduced two ways of defining a statistical model fit to data.</p>
<ol style="list-style-type: decimal">
<li>Definition using a distribution of the error term</li>
</ol>
<span class="math display" id="eq:lm-again">\[\begin{align}
Y &amp;= \beta_0 + \beta_1 X + \varepsilon\\
\varepsilon &amp;\sim N(0, \sigma)
\tag{1.5}
\end{align}\]</span>
<ol start="2" style="list-style-type: decimal">
<li>Definition using the response as a combination of stochastic and deterministic components</li>
</ol>
<span class="math display" id="eq:lm-spec2">\[\begin{align}
Y &amp;\sim N(\mu, \sigma)\\
\mu &amp;= \beta_0 + \beta_1 X
\tag{1.6}
\end{align}\]</span>
<p>A generalized linear model has has these two parts of the second definition but adds a third part</p>
<ol style="list-style-type: decimal">
<li>A probability distribution from the exponential family (this is the stochastic part)
<span class="math display">\[\begin{equation}
Y \sim P(\mu)
\end{equation}\]</span></li>
<li>a linear predictor of the form (this is the deterministic part)
<span class="math display">\[\begin{equation}
\eta=\beta_0 + \beta_1 X
\end{equation}\]</span></li>
<li>a <strong>link function</strong> connecting the two parts
<span class="math display">\[\begin{equation}
\eta = g(\mu)
\end{equation}\]</span></li>
</ol>
<p><span class="math inline">\(mu\)</span> (the Greek symbol mu) is the conditional mean (or expectation <span class="math inline">\(\mathrm{E}(Y|X)\)</span>) of the response on the <strong>response scale</strong> and <span class="math inline">\(\eta\)</span> is the conditional mean of the response on the <strong>link scale</strong>. A GLM models the response with a distribution specified by the probability distribution using the link function. The probability distributions introduced here are the Poisson and Negative Binomial for count data, and the Binomial for binary data. Note that a linear model is a GLM with a link to a Normal distribution.</p>
<p>The link scale is linear (it is the log of the response scale), and so the effects are additive on the link scale, while the response scale is nonlinear (it is the exponent of the link scale), and so the effects are multiplicative on the response scale. If this doesn’t make sense now, an example is worked out below. The inverse of the link function backtransforms the parameters from the link scale back to the response scale. So, for example, a prediction on the response sale is <span class="math inline">\(\mathrm{exp}(\hat{\eta})\)</span> and a coefficient on the response scale is <span class="math inline">\(\mathrm{exp}(b_j)\)</span>.</p>
</div>
<div id="count-data-example" class="section level2">
<h2><span class="header-section-number">12.4</span> Count data example</h2>
<p>The example is an experiment measuring the effect of the parasitic tapeworm <em>Schistocephalus solidus</em> infection on the susceptibility of infection from a second parasite, the trematode <em>Diplostomum pseudospathaceum</em>, in the threespine stickleback fish <em>Gasterosteus aculeatus</em>. The treatment levels are “Control” (unexposed to the tapeworm), “Uninfected” &quot; (exposed to the tapeworm but uninfected), “Infected LG” (exposed and infected with the low growth population of the tapeworm), and “Infected HG” (exposed and infected with the high growth population of tapeworm). The response is the number of trematode larvae counted in the eyes (right and left combined) of the fish. A histogram of the counts is shown in Figure <a href="adding-covariates-to-a-linear-model-i-ancova.html#fig:glm1-plot1">12.6</a> for the control and Infected HG treatment levels.</p>
<p>I start the analysis by fitting a linear model to the worm data and then <em>model checking</em>, to gain some insight on how well the linear model fits the data</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>NHST blues</strong> Students are often encouraged by textbooks, colleagues, or the literature to start the analysis by first “testing” assumptions with hypothesis tests – for example using a Shaprio-Wilks test of normality as a decision rule to decide if to use a parametric test such as a <span class="math inline">\(t\)</span>-test or ANOVA if the null hypothesis of normality is not rejected, or a non-parametric test such as a Mann-Whitney U test if the null hypothesis of normality is rejected. I advise against this, because 1) this pre-test filtering automatically invalidates the <span class="math inline">\(p\)</span>-value of the hypothesis test as it does not adjust for the filtering procedure, 2) real data are only approximately normal and as <span class="math inline">\(n\)</span> increses, a normality test will reject any real dataset, and 3) hypothesis tests are pretty robust to non-normality anyway.</p>
</div>
<p>The model is</p>
<span class="math display">\[\begin{align}
Y &amp;= N(\mu, \sigma)\\
\mu &amp;= \beta_0 + \beta_1 Treatment
\end{align}\]</span>
<p>Which models the parasite count conditional on <span class="math inline">\(Treatment\)</span> with a Normal distribution. Remember, this is equivalent to a model with an error term with a Normal distribution (now might be a good time to go back to Chapter 1 and review the section [Assumptions for inference with statistical models]).</p>
<div id="checking-the-model-i-a-normal-q-q-plot" class="section level3">
<h3><span class="header-section-number">12.4.1</span> Checking the model I – a Normal Q-Q plot</h3>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-plot2-1.png" width="576" /></p>
<p>Figure <a href="#fig:glm1-plot2"><strong>??</strong></a>A shows a histogram of the residuals from the fit linear model. The plot shows that the residuals are clumped at the negative end of the range, which suggests that a model with a normally distributed conditional outcome (or normal error) is not well approximated.</p>
<p>A better way to investigate this is with the <strong>Normal Q-Q</strong> plot in Figure <a href="#fig:glm1-plot2"><strong>??</strong></a>B, which plots the sample quantiles for a variable against their theoretical quantiles. If the conditional outcome approximates a normal distribution, the points should roughly follow the line. Instead, for the worm data, the points are above the line at both ends. At the left (negative) end, this means that we aren’t seeing the most negative values that would be expected (the observed values are more positive than the theoretical values). Remembering that this plot is of residuals, if we think about this as counts, this means that our smallest counts are not as small as we would expect given the mean and a normal distribution. This shouldn’t be surprising – the counts range down to zero and counts cannot be below zero. At the positive end, the sample values are again more positive than the theoretical values. Thinking about this as counts, this means that are largest counts are larger than expected given the mean and a normal distribution. This pattern is exactly what we’d expect of count data, or at least count data that borders zero.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p><strong>Intuition Pump</strong> Let’s construct a Normal Q-Q plot. A <strong>quantile</strong> (or percentile) of a vector of numbers is the value of the point at a specified percentage rank. The median is the 50% quantile. The 95% confidence intervals are at the 2.5% and 97.5% quantiles. In a Normal Q-Q plot, we want to plot the quantiles of the residuals against a set of theoretical quantiles.</p>
<ol style="list-style-type: decimal">
<li>To get the observed quantiles, rank the residuals of the fit linear model from most negative to most positive – these are your quantiles! For example, if you have <span class="math inline">\(n=145\)</span> residuals, then the 73rd point is the 50% quantile.</li>
<li>A theoretical quantile from the Normal distribution can be constructed using the <code>qnorm</code> function which returns the Normal quantiles for a specified vector of percents. Alternatively, one could randomly sample <span class="math inline">\(n\)</span> points using <code>rnorm</code>. These of course will be sampled quantiles so will only approximate the expected theoretical quantiles, but I add this here because we use this method below.</li>
</ol>
<p>Now simply plot the observed against theoretical quantiles. Often, the <strong>standardized</strong> quantiles are plotted. A standardized variable has a mean of zero and a standard deviation of one and is computed by 1) centering the vector at zero by subtracting the mean from every value, and 2) dividing each value by the standard deviation of the vector. Recognize that because a standard deviation is a function of deviations from the mean, it doesn’t matter which of these operations is done first. A standardized theoretical quantile is specified by <code>qnorm(p, mean = 0, sd = 1)</code>, which is the default.</p>
<p>Below, I’ve plotted the standardized observed and theoretical quantiles against the vector of percents (from 0 to 100%). This plot also nicely shows how the residuals of the worm data deviate from that expected if these had a normal distribution. The plot nicely shows that the most negative observed quintiles are not as negative as expected given a normal distribution, which again makes sense because this would imply negative counts since the mean is close to zero. And it nicely shows that the most positive observed quantiles are more positive than expected given a normal distribution, again this makes sense in right skewed count data. Finally, the plot nicely shows that the median is less positive than that expected given a normal distribution, which is at the mean (a right skew tends to pull the mean to the right of the median).</p>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-qqplot-sim-1.png" width="576" /></p>
</div>
</div>
<div id="checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity" class="section level3">
<h3><span class="header-section-number">12.4.2</span> Checking the model II – scale-location plot for checking homoskedasticity</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">worm[, scale_y<span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">abs</span>(<span class="kw">scale</span>(Diplo_intensity_residual)))]
worm[, fitted_y<span class="op">:</span><span class="er">=</span><span class="kw">fitted</span>(fit.lm)]
<span class="kw">ggscatter</span>(<span class="dt">data=</span>worm, 
          <span class="dt">x=</span><span class="st">&quot;fitted_y&quot;</span>, 
          <span class="dt">y=</span><span class="st">&quot;scale_y&quot;</span>, 
          <span class="dt">add=</span><span class="st">&quot;reg.line&quot;</span>,
          <span class="dt">conf.int =</span> <span class="ot">TRUE</span>,
          <span class="dt">add.params =</span> <span class="kw">list</span>(<span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>,
          <span class="dt">fill =</span> <span class="st">&quot;lightgray&quot;</span>),
          <span class="dt">title=</span><span class="st">&quot;Scale-Location&quot;</span>,
          <span class="dt">ylab=</span><span class="st">&quot;Square root standardized residuals&quot;</span>,
          <span class="dt">xlab=</span><span class="st">&quot;Fitted value&quot;</span>
          )</code></pre></div>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/unnamed-chunk-16-1.png" width="576" /></p>
<p>A linear model also assumes the error has constant variance (that is, the error variance is not a function of the value of <span class="math inline">\(X\)</span>), or homoskedasticity. The fit model can be checked for homoskedasticity using a scale-location plot, which is a scatterplot of the positive square-root of the standardized residuals against the fitted values<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. If the residuals approximate a normal distribution, then a regression line through the scatter should be close to horizontal. The regression line in the scale-location plot of the fit of the linear model to the worm data shows a distinct increase in the “scale” (the square root of the standardized residuals) with increased fitted value, which is expected of data that are lognormally, Poisson, or negative binomially distributed.</p>
</div>
<div id="two-distributions-for-count-data-poisson-and-negative-binomial" class="section level3">
<h3><span class="header-section-number">12.4.3</span> Two distributions for count data – Poisson and Negative Binomial</h3>
<p>The pattern in the Normal Q-Q plot in Figure <a href="#fig:glm1-plot2"><strong>??</strong></a>B should discourage one from modeling the data with a normal distribution and instead model the data with an alternative distribution using a Generalized Linear Model. There is no unique mapping between how data are generated and a specific distribution, so this decision is not as easy as thinking about the data generation mechanism and then simply choosing the “correct” distribution. Section 4.5 in Bolker (xxx) is an excellent summary of how to think about the generating processes for different distributions in the context of ecological data. Since the response in the worm data are counts, we need to choose a distribution that generates integer values, such as the Poisson or the negative binomial.</p>
<ol style="list-style-type: decimal">
<li>Poisson – A Poisson distribution is the probability distribution of the number of occurrences of some thing (an egg, a parasite, or a specific mRNA transcript) generated by a process that generates the thing at a constant rate per unit effort (duration or space). This constant rate is <span class="math inline">\(\lambda\)</span>, which is the expectation, so <span class="math inline">\(\mathrm{E}(Y) = \mu = \lambda\)</span>. Because the rate per effort is constant, <em>the variance of a Poisson variable equals the mean</em>, <span class="math inline">\(\sigma^2 = \mu = \lambda\)</span>. Figure <a href="#fig:glm1-poisson"><strong>??</strong></a> shows three samples from a Poisson distribution with <span class="math inline">\(\lambda\)</span> set to 1, 5, and 10. The plots show that, as the mean count (<span class="math inline">\(\lambda\)</span>) moves away from zero, a Poisson distribution 1) becomes less skewed and more closely approximates a normal distribution and 2) has an increasingly low probability of including zero (less than 1% zeros when the mean is 5).</li>
</ol>
<p>A Poisson link function, then, is useful for count data in which the conditional variance is close to the conditional mean. Very often, biological count data are not well approximated by a Poisson distribution because the variance is either less than the mean, an example of <strong>underdispersion</strong><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>, or greater than the mean, an example of <strong>overdispersion</strong><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. A useful distribution for count data with overdispersion is the negative binomial.</p>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-poisson-1.png" width="576" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Negative Binomial – The negative binomial distribution is a discrete probability distribution of the number of successes that occur before a specified number of failures <span class="math inline">\(k\)</span> given a probability <span class="math inline">\(p\)</span> of success. This isn’t a very useful way of thinking about modeling count data in biology. What is useful is that the Negative Binomial distribution can be used simply as way of modeling an “overdispersed” Poisson process. The mean of a negative binomial variable is <span class="math inline">\(\mu = k\frac{p}{1-p}\)</span> and the variance is <span class="math inline">\(\sigma^2 = \mu + \mu^2/k\)</span>. As a method for modeling an overdispersed Poisson variable, <span class="math inline">\(k\)</span> functions as a parameter controlling the amount of overdispersion and can be any real, positive value (not simply a positive integer), including values less than 1.</li>
</ol>
</div>
<div id="fitting-a-glm-with-a-poisson-link-to-the-worm-data" class="section level3">
<h3><span class="header-section-number">12.4.4</span> Fitting a GLM with a Poisson link to the worm data</h3>
<p>Let’s fit a GLM with a Poisson lin to the worm data. The model is</p>
<span class="math display">\[\begin{align}
Diplo\_intensity &amp;\sim Poisson(\mu)\\
\mathrm{E}({Diplo\_intensity|Treatment}) &amp;= \mu\\
\mu &amp;= \mathrm{exp}(\eta)\\
\eta &amp;= \beta_0 + \beta_1 Uninfected + \beta_2 Infected\_LG + \beta_3 Infected\_HG
\end{align}\]</span>
<p>A common misconception is that if the distribution of the response approximates a Poisson distribution, then the residuals of a GLM fit with a Poisson link should be normally distributed, which could then be checked with a Normal Q-Q plot, and homoskedastic, which could be checked with scale-location plot. Neither of these is true because a GLM does not transform the data and, in fact, the model definition does not specify anything about the distribution of an “error” term – there is no <span class="math inline">\(\varepsilon\)</span> in the model defintion above! This is why thinking about the definition of a linear model by specifying an error term with a normal distribution can be confusing and lead to misconceptions when learning GLMs.</p>
<p>An alternative to a Normal Q-Q plot is a plot of <strong>quantile residuals</strong>.</p>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-worm-poisson-1.png" width="576" /></p>
</div>
<div id="fitting-a-glm-with-a-negative-binomial-link-to-the-worm-data" class="section level3">
<h3><span class="header-section-number">12.4.5</span> Fitting a GLM with a Negative Binomial link to the worm data</h3>
<pre><code>## DHARMa::plotResiduals - low number of unique predictor values, consider setting asFactor = T
## DHARMa::plotResiduals - low number of unique predictor values, consider setting asFactor = T</code></pre>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-worm-nb-1.png" width="576" /><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-worm-nb-2.png" width="576" /></p>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  simulationOutput$scaledResiduals
## D = 0.044362, p-value = 0.7772
## alternative hypothesis: two-sided</code></pre>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/glm1-worm-nb-3.png" width="576" /></p>
<pre><code>## 
##  DHARMa nonparametric dispersion test via sd of residuals fitted
##  vs. simulated
## 
## data:  simulationOutput
## ratioObsSim = 1.0153, p-value = 0.816
## alternative hypothesis: two.sided</code></pre>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>fitted values are the predicted values, <span class="math inline">\(\hat{Y}\)</span><a href="adding-covariates-to-a-linear-model-i-ancova.html#fnref1">↩</a></p></li>
<li id="fn2"><p>the variance is less than that expected by the probability model<a href="adding-covariates-to-a-linear-model-i-ancova.html#fnref2">↩</a></p></li>
<li id="fn3"><p>the variance is greater than that expected by the probability model<a href="adding-covariates-to-a-linear-model-i-ancova.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anova-tables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendix-1-getting-started-with-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/notebooks/35-covariates.Rmd",
"text": "Edit"
},
"download": ["Walker-elementary-statistical-modeling-draft.pdf", "Walker-elementary-statistical-modeling-draft.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
