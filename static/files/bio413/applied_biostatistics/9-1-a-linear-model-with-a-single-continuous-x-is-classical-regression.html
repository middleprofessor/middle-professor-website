<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="9.1 A linear model with a single, continuous X is classical “regression” | Elements of Statistical Modeling for Experimental Biology" />
<meta property="og:type" content="book" />


<meta property="og:description" content="A first course in statistical modeling for experimental biology researchers" />


<meta name="author" content="Copyright 2018 Jeffrey A. Walker" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A first course in statistical modeling for experimental biology researchers">

<title>9.1 A linear model with a single, continuous X is classical “regression” | Elements of Statistical Modeling for Experimental Biology</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a><ul>
<li><a href="0-1-math.html#math"><span class="toc-section-number">0.1</span> Math</a></li>
<li><a href="0-2-r-and-programming.html#r-and-programming"><span class="toc-section-number">0.2</span> R and programming</a></li>
</ul></li>
<li><a href="part-i-getting-started.html#part-i-getting-started">Part I: Getting Started</a></li>
<li class="has-sub"><a href="1-getting-started-r-projects-and-r-markdown.html#getting-started-r-projects-and-r-markdown"><span class="toc-section-number">1</span> Getting Started – R Projects and R Markdown</a><ul>
<li><a href="1-1-r-vs-r-studio.html#r-vs-r-studio"><span class="toc-section-number">1.1</span> R vs R Studio</a></li>
<li><a href="1-2-download-and-install-r-and-r-studio.html#download-and-install-r-and-r-studio"><span class="toc-section-number">1.2</span> Download and install R and R studio</a></li>
<li><a href="1-3-install-r-markdown.html#install-r-markdown"><span class="toc-section-number">1.3</span> Install R Markdown</a></li>
<li><a href="1-4-importing-packages.html#importing-packages"><span class="toc-section-number">1.4</span> Importing Packages</a></li>
<li class="has-sub"><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-an-r-studio-project-for-this-textbook"><span class="toc-section-number">1.5</span> Create an R Studio Project for this textbook</a><ul>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-an-r-markdown-file-for-this-chapter"><span class="toc-section-number">1.5.1</span> Create an R Markdown file for this Chapter</a></li>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-a-fake-data-chunk"><span class="toc-section-number">1.5.2</span> Create a “fake-data” chunk</a></li>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#create-a-plot-chunk"><span class="toc-section-number">1.5.3</span> Create a “plot” chunk</a></li>
<li><a href="1-5-create-an-r-studio-project-for-this-textbook.html#knit"><span class="toc-section-number">1.5.4</span> Knit</a></li>
</ul></li>
</ul></li>
<li><a href="part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model.html#part-ii-an-introduction-to-the-analysis-of-experimental-data-with-a-linear-model">Part II: An introduction to the analysis of experimental data with a linear model</a></li>
<li class="has-sub"><a href="2-analyzing-experimental-data-with-a-linear-model.html#analyzing-experimental-data-with-a-linear-model"><span class="toc-section-number">2</span> Analyzing experimental data with a linear model</a><ul>
<li><a href="2-1-this-text-is-about-the-estimation-of-treatment-effects-and-the-uncertainty-in-our-estimates-using-linear-models-this-raises-the-question-what-is-an-effect.html#this-text-is-about-the-estimation-of-treatment-effects-and-the-uncertainty-in-our-estimates-using-linear-models.-this-raises-the-question-what-is-an-effect"><span class="toc-section-number">2.1</span> This text is about the estimation of treatment effects and the uncertainty in our estimates using linear models. This, raises the question, what is “an effect”?</a></li>
</ul></li>
<li><a href="background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#background-physiology-to-the-experiments-in-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity">Background physiology to the experiments in Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a></li>
<li class="has-sub"><a href="analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity.html#analyses-for-figure-2-of-ask1-inhibits-browning-of-white-adipose-tissue-in-obesity">Analyses for Figure 2 of “ASK1 inhibits browning of white adipose tissue in obesity”</a><ul>
<li><a href="2-2-setup.html#setup"><span class="toc-section-number">2.2</span> Setup</a></li>
<li><a href="2-3-data-source.html#data-source"><span class="toc-section-number">2.3</span> Data source</a></li>
<li><a href="2-4-control-the-color-palette.html#control-the-color-palette"><span class="toc-section-number">2.4</span> control the color palette</a></li>
<li><a href="2-5-useful-functions.html#useful-functions"><span class="toc-section-number">2.5</span> useful functions</a></li>
<li class="has-sub"><a href="2-6-figure-2b-effect-of-ask1-deletion-on-growth-body-weight.html#figure-2b-effect-of-ask1-deletion-on-growth-body-weight"><span class="toc-section-number">2.6</span> figure 2b – effect of ASK1 deletion on growth (body weight)</a><ul>
<li><a href="2-6-figure-2b-effect-of-ask1-deletion-on-growth-body-weight.html#figure-2b-import"><span class="toc-section-number">2.6.1</span> figure 2b – import</a></li>
<li><a href="2-6-figure-2b-effect-of-ask1-deletion-on-growth-body-weight.html#figure-2b-exploratory-plots"><span class="toc-section-number">2.6.2</span> figure 2b – exploratory plots</a></li>
</ul></li>
<li class="has-sub"><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-effect-of-ask1-deletion-on-final-body-weight"><span class="toc-section-number">2.7</span> Figure 2c – Effect of ASK1 deletion on final body weight</a><ul>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-import"><span class="toc-section-number">2.7.1</span> Figure 2c – import</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-check-own-computation-of-weight-change-v-imported-value"><span class="toc-section-number">2.7.2</span> Figure 2c – check own computation of weight change v imported value</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-exploratory-plots"><span class="toc-section-number">2.7.3</span> Figure 2c – exploratory plots</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-fit-the-model-m1-lm"><span class="toc-section-number">2.7.4</span> Figure 2c – fit the model: m1 (lm)</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-check-the-model-m1"><span class="toc-section-number">2.7.5</span> Figure 2c – check the model: m1</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-fit-the-model-m2-gamma-glm"><span class="toc-section-number">2.7.6</span> Figure 2c – fit the model: m2 (gamma glm)</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-check-the-model-m2"><span class="toc-section-number">2.7.7</span> Figure 2c – check the model, m2</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-inference-from-the-model"><span class="toc-section-number">2.7.8</span> Figure 2c – inference from the model</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-plot-the-model"><span class="toc-section-number">2.7.9</span> Figure 2c – plot the model</a></li>
<li><a href="2-7-figure-2c-effect-of-ask1-deletion-on-final-body-weight.html#figure-2c-report"><span class="toc-section-number">2.7.10</span> Figure 2c – report</a></li>
</ul></li>
<li class="has-sub"><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve"><span class="toc-section-number">2.8</span> Figure 2d – Effect of ASK1 KO on glucose tolerance (whole curve)</a><ul>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-import"><span class="toc-section-number">2.8.1</span> Figure 2d – Import</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-exploratory-plots"><span class="toc-section-number">2.8.2</span> Figure 2d – exploratory plots</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-fit-the-model"><span class="toc-section-number">2.8.3</span> Figure 2d – fit the model</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-check-the-model"><span class="toc-section-number">2.8.4</span> Figure 2d – check the model</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-inference"><span class="toc-section-number">2.8.5</span> Figure 2d – inference</a></li>
<li><a href="2-8-figure-2d-effect-of-ask1-ko-on-glucose-tolerance-whole-curve.html#figure-2d-plot-the-model"><span class="toc-section-number">2.8.6</span> Figure 2d – plot the model</a></li>
</ul></li>
<li class="has-sub"><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure"><span class="toc-section-number">2.9</span> Figure 2e – Effect of ASK1 deletion on glucose tolerance (summary measure)</a><ul>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-message-the-data"><span class="toc-section-number">2.9.1</span> Figure 2e – message the data</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-exploratory-plots"><span class="toc-section-number">2.9.2</span> Figure 2e – exploratory plots</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-fit-the-model"><span class="toc-section-number">2.9.3</span> Figure 2e – fit the model</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-check-the-model"><span class="toc-section-number">2.9.4</span> Figure 2e – check the model</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-inference-from-the-model"><span class="toc-section-number">2.9.5</span> Figure 2e – inference from the model</a></li>
<li><a href="2-9-figure-2e-effect-of-ask1-deletion-on-glucose-tolerance-summary-measure.html#figure-2e-plot-the-model"><span class="toc-section-number">2.9.6</span> Figure 2e – plot the model</a></li>
</ul></li>
<li class="has-sub"><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate"><span class="toc-section-number">2.10</span> Figure 2f – Effect of ASK1 deletion on glucose infusion rate</a><ul>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-import"><span class="toc-section-number">2.10.1</span> Figure 2f – import</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-exploratory-plots"><span class="toc-section-number">2.10.2</span> Figure 2f – exploratory plots</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-fit-the-model"><span class="toc-section-number">2.10.3</span> Figure 2f – fit the model</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-check-the-model"><span class="toc-section-number">2.10.4</span> Figure 2f – check the model</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-inference"><span class="toc-section-number">2.10.5</span> Figure 2f – inference</a></li>
<li><a href="2-10-figure-2f-effect-of-ask1-deletion-on-glucose-infusion-rate.html#figure-2f-plot-the-model"><span class="toc-section-number">2.10.6</span> Figure 2f – plot the model</a></li>
</ul></li>
<li class="has-sub"><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake"><span class="toc-section-number">2.11</span> Figure 2g – Effect of ASK1 deletion on tissue-specific glucose uptake</a><ul>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-import"><span class="toc-section-number">2.11.1</span> Figure 2g – import</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-exploratory-plots"><span class="toc-section-number">2.11.2</span> Figure 2g – exploratory plots</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-fit-the-model"><span class="toc-section-number">2.11.3</span> Figure 2g – fit the model</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-check-the-model"><span class="toc-section-number">2.11.4</span> Figure 2g – check the model</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-inference"><span class="toc-section-number">2.11.5</span> Figure 2g – inference</a></li>
<li><a href="2-11-figure-2g-effect-of-ask1-deletion-on-tissue-specific-glucose-uptake.html#figure-2g-plot-the-model"><span class="toc-section-number">2.11.6</span> Figure 2g – plot the model</a></li>
</ul></li>
<li><a href="2-12-figure-2h.html#figure-2h"><span class="toc-section-number">2.12</span> Figure 2h</a></li>
<li class="has-sub"><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-effect-of-ask1-deletion-on-liver-tg"><span class="toc-section-number">2.13</span> Figure 2i – Effect of ASK1 deletion on liver TG</a><ul>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-fit-the-model"><span class="toc-section-number">2.13.1</span> Figure 2i – fit the model</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-check-the-model"><span class="toc-section-number">2.13.2</span> Figure 2i – check the model</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-inference"><span class="toc-section-number">2.13.3</span> Figure 2i – inference</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-plot-the-model"><span class="toc-section-number">2.13.4</span> Figure 2i – plot the model</a></li>
<li><a href="2-13-figure-2i-effect-of-ask1-deletion-on-liver-tg.html#figure-2i-report-the-model"><span class="toc-section-number">2.13.5</span> Figure 2i – report the model</a></li>
</ul></li>
<li><a href="2-14-figure-2j.html#figure-2j"><span class="toc-section-number">2.14</span> Figure 2j</a></li>
</ul></li>
<li><a href="part-iii-r-fundamentals.html#part-iii-r-fundamentals">Part III: R fundamentals</a></li>
<li class="has-sub"><a href="3-data-reading-wrangling-and-writing.html#data-reading-wrangling-and-writing"><span class="toc-section-number">3</span> Data – Reading, Wrangling, and Writing</a><ul>
<li><a href="3-1-learning-from-this-chapter.html#learning-from-this-chapter"><span class="toc-section-number">3.1</span> Learning from this chapter</a></li>
<li class="has-sub"><a href="3-2-data-working-in-r.html#data-working-in-r"><span class="toc-section-number">3.2</span> Working in R</a><ul>
<li><a href="3-2-data-working-in-r.html#importing-data"><span class="toc-section-number">3.2.1</span> Importing data</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-data-wrangling.html#data-wrangling"><span class="toc-section-number">3.3</span> Data wrangling</a><ul>
<li><a href="3-3-data-wrangling.html#reshaping-data-wide-to-long"><span class="toc-section-number">3.3.1</span> Reshaping data – Wide to long</a></li>
<li><a href="3-3-data-wrangling.html#reshaping-data-transpose-turning-the-columns-into-rows"><span class="toc-section-number">3.3.2</span> Reshaping data – Transpose (turning the columns into rows)</a></li>
<li><a href="3-3-data-wrangling.html#combining-data"><span class="toc-section-number">3.3.3</span> Combining data</a></li>
<li><a href="3-3-data-wrangling.html#subsetting-data"><span class="toc-section-number">3.3.4</span> Subsetting data</a></li>
<li><a href="3-3-data-wrangling.html#wrangling-columns"><span class="toc-section-number">3.3.5</span> Wrangling columns</a></li>
<li><a href="3-3-data-wrangling.html#missing-data"><span class="toc-section-number">3.3.6</span> Missing data</a></li>
</ul></li>
<li><a href="3-4-saving-data.html#saving-data"><span class="toc-section-number">3.4</span> Saving data</a></li>
<li><a href="3-5-exercises.html#exercises"><span class="toc-section-number">3.5</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="4-plotting-models.html#plotting-models"><span class="toc-section-number">4</span> Plotting Models</a><ul>
<li class="has-sub"><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#pretty-good-plots-show-the-model-and-the-data"><span class="toc-section-number">4.1</span> Pretty good plots show the model and the data</a><ul>
<li><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#pretty-good-plot-component-1-modeled-effects-plot"><span class="toc-section-number">4.1.1</span> Pretty good plot component 1: Modeled effects plot</a></li>
<li><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#pretty-good-plot-component-2-modeled-mean-and-ci-plot"><span class="toc-section-number">4.1.2</span> Pretty good plot component 2: Modeled mean and CI plot</a></li>
<li><a href="4-1-pretty-good-plots-show-the-model-and-the-data.html#combining-effects-and-modeled-mean-and-ci-plots-an-effects-and-response-plot."><span class="toc-section-number">4.1.3</span> Combining Effects and Modeled mean and CI plots – an Effects and response plot.</a></li>
</ul></li>
<li><a href="4-2-some-comments-on-plot-components.html#some-comments-on-plot-components"><span class="toc-section-number">4.2</span> Some comments on plot components</a></li>
<li class="has-sub"><a href="4-3-working-in-r.html#working-in-r"><span class="toc-section-number">4.3</span> Working in R</a><ul>
<li><a href="4-3-working-in-r.html#unpooled-se-bars-and-confidence-intervals"><span class="toc-section-number">4.3.1</span> Unpooled SE bars and confidence intervals</a></li>
<li><a href="4-3-working-in-r.html#adding-bootstrap-intervals"><span class="toc-section-number">4.3.2</span> Adding bootstrap intervals</a></li>
<li><a href="4-3-working-in-r.html#adding-modeled-means-and-error-intervals"><span class="toc-section-number">4.3.3</span> Adding modeled means and error intervals</a></li>
<li><a href="4-3-working-in-r.html#adding-p-values"><span class="toc-section-number">4.3.4</span> Adding p-values</a></li>
<li><a href="4-3-working-in-r.html#adding-custom-p-values"><span class="toc-section-number">4.3.5</span> Adding custom p-values</a></li>
<li><a href="4-3-working-in-r.html#plotting-two-factors"><span class="toc-section-number">4.3.6</span> Plotting two factors</a></li>
<li><a href="4-3-working-in-r.html#interaction-plot"><span class="toc-section-number">4.3.7</span> Interaction plot</a></li>
<li><a href="4-3-working-in-r.html#plot-components"><span class="toc-section-number">4.3.8</span> Plot components</a></li>
</ul></li>
</ul></li>
<li><a href="part-iv-some-fundamentals-of-statistical-modeling.html#part-iv-some-fundamentals-of-statistical-modeling">Part IV: Some Fundamentals of Statistical Modeling</a></li>
<li class="has-sub"><a href="5-variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals.html#variability-and-uncertainty-standard-deviations-standard-errors-confidence-intervals"><span class="toc-section-number">5</span> Variability and Uncertainty (Standard Deviations, Standard Errors, Confidence Intervals)</a><ul>
<li class="has-sub"><a href="5-1-the-sample-standard-deviation-vs-the-standard-error-of-the-mean.html#the-sample-standard-deviation-vs.-the-standard-error-of-the-mean"><span class="toc-section-number">5.1</span> The sample standard deviation vs. the standard error of the mean</a><ul>
<li><a href="5-1-the-sample-standard-deviation-vs-the-standard-error-of-the-mean.html#sample-standard-deviation"><span class="toc-section-number">5.1.1</span> Sample standard deviation</a></li>
<li><a href="5-1-the-sample-standard-deviation-vs-the-standard-error-of-the-mean.html#standard-error-of-the-mean"><span class="toc-section-number">5.1.2</span> Standard error of the mean</a></li>
</ul></li>
<li class="has-sub"><a href="5-2-using-google-sheets-to-generate-fake-data-to-explore-the-standard-error.html#using-google-sheets-to-generate-fake-data-to-explore-the-standard-error"><span class="toc-section-number">5.2</span> Using Google Sheets to generate fake data to explore the standard error</a><ul>
<li><a href="5-2-using-google-sheets-to-generate-fake-data-to-explore-the-standard-error.html#steps"><span class="toc-section-number">5.2.1</span> Steps</a></li>
</ul></li>
<li class="has-sub"><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#using-r-to-generate-fake-data-to-explore-the-standard-error"><span class="toc-section-number">5.3</span> Using R to generate fake data to explore the standard error</a><ul>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-i"><span class="toc-section-number">5.3.1</span> part I</a></li>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-ii---means"><span class="toc-section-number">5.3.2</span> part II - means</a></li>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-iii---how-do-sd-and-se-change-as-sample-size-n-increases"><span class="toc-section-number">5.3.3</span> part III - how do SD and SE change as sample size (n) increases?</a></li>
<li><a href="5-3-using-r-to-generate-fake-data-to-explore-the-standard-error.html#part-iv-generating-fake-data-with-for-loops"><span class="toc-section-number">5.3.4</span> Part IV – Generating fake data with for-loops</a></li>
</ul></li>
<li class="has-sub"><a href="5-4-bootstrap.html#bootstrap"><span class="toc-section-number">5.4</span> Bootstrapped standard errors</a><ul>
<li><a href="5-4-bootstrap.html#an-example-of-bootstrapped-standard-errors-using-vole-data"><span class="toc-section-number">5.4.1</span> An example of bootstrapped standard errors using vole data</a></li>
</ul></li>
<li class="has-sub"><a href="5-5-confidence-interval.html#confidence-interval"><span class="toc-section-number">5.5</span> Confidence Interval</a><ul>
<li><a href="5-5-confidence-interval.html#interpretation-of-a-confidence-interval"><span class="toc-section-number">5.5.1</span> Interpretation of a confidence interval</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="6-p-values.html#p-values"><span class="toc-section-number">6</span> P-values</a><ul>
<li><a href="6-1-a-p-value-is-the-probability-of-sampling-a-value-as-or-more-extreme-than-the-test-statistic-if-sampling-from-a-null-distribution.html#a-p-value-is-the-probability-of-sampling-a-value-as-or-more-extreme-than-the-test-statistic-if-sampling-from-a-null-distribution"><span class="toc-section-number">6.1</span> A <em>p</em>-value is the probability of sampling a value as or more extreme than the test statistic if sampling from a null distribution</a></li>
<li><a href="6-2-pump-your-intuition-creating-a-null-distribution.html#pump-your-intuition-creating-a-null-distribution"><span class="toc-section-number">6.2</span> Pump your intuition – Creating a null distribution</a></li>
<li><a href="6-3-a-null-distribution-of-t-values-the-t-distribution.html#a-null-distribution-of-t-values-the-t-distribution"><span class="toc-section-number">6.3</span> A null distribution of <em>t</em>-values – the <em>t</em> distribution</a></li>
<li><a href="6-4-p-values-from-the-perspective-of-permutation.html#p-values-from-the-perspective-of-permutation"><span class="toc-section-number">6.4</span> P-values from the perspective of permutation</a></li>
<li><a href="6-5-parametric-vs-non-parametric-statistics.html#parametric-vs.-non-parametric-statistics"><span class="toc-section-number">6.5</span> Parametric vs. non-parametric statistics</a></li>
<li class="has-sub"><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#frequentist-probability-and-the-interpretation-of-p-values"><span class="toc-section-number">6.6</span> frequentist probability and the interpretation of p-values</a><ul>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#background"><span class="toc-section-number">6.6.1</span> Background</a></li>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#this-book-covers-frequentist-approaches-to-statistical-modeling-and-when-a-probability-arises-such-as-the-p-value-of-a-test-statistic-this-will-be-a-frequentist-probability."><span class="toc-section-number">6.6.2</span> This book covers frequentist approaches to statistical modeling and when a probability arises, such as the <em>p</em>-value of a test statistic, this will be a frequentist probability.</a></li>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#two-interpretations-of-the-p-value"><span class="toc-section-number">6.6.3</span> Two interpretations of the <em>p</em>-value</a></li>
<li><a href="6-6-frequentist-probability-and-the-interpretation-of-p-values.html#nhst"><span class="toc-section-number">6.6.4</span> NHST</a></li>
</ul></li>
<li class="has-sub"><a href="6-7-some-major-misconceptions-of-the-p-value.html#some-major-misconceptions-of-the-p-value"><span class="toc-section-number">6.7</span> Some major misconceptions of the <em>p</em>-value</a><ul>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-p-is-the-probability-that-the-null-is-true-and-1-p-is-probability-that-the-alternative-is-true"><span class="toc-section-number">6.7.1</span> Misconception: <em>p</em> is the probability that the null is true <em>and</em> <span class="math inline">\(1-p\)</span> is probability that the alternative is true</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-a-p-value-is-repeatable"><span class="toc-section-number">6.7.2</span> Misconception: a <em>p</em>-value is repeatable</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-0.05-is-the-lifetime-rate-of-false-discoveries"><span class="toc-section-number">6.7.3</span> Misconception: 0.05 is the lifetime rate of false discoveries</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-a-low-p-value-indicates-an-important-effect"><span class="toc-section-number">6.7.4</span> Misconception: a low <em>p</em>-value indicates an important effect</a></li>
<li><a href="6-7-some-major-misconceptions-of-the-p-value.html#misconception-a-low-p-value-indicates-high-model-fit-or-high-predictive-capacity"><span class="toc-section-number">6.7.5</span> Misconception: a low <em>p</em>-value indicates high model fit or high predictive capacity</a></li>
</ul></li>
<li><a href="6-8-what-the-p-value-does-not-mean.html#what-the-p-value-does-not-mean"><span class="toc-section-number">6.8</span> What the <em>p</em>-value does not mean</a></li>
<li class="has-sub"><a href="6-9-recommendations.html#recommendations"><span class="toc-section-number">6.9</span> Recommendations</a><ul>
<li><a href="6-9-recommendations.html#primary-sources-for-recommendations"><span class="toc-section-number">6.9.1</span> Primary sources for recommendations</a></li>
</ul></li>
<li><a href="6-10-problems.html#problems"><span class="toc-section-number">6.10</span> Problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-errors-in-inference.html#errors-in-inference"><span class="toc-section-number">7</span> Errors in inference</a><ul>
<li class="has-sub"><a href="7-1-classical-nhst-concepts-of-wrong.html#classical-nhst-concepts-of-wrong"><span class="toc-section-number">7.1</span> Classical NHST concepts of wrong</a><ul>
<li><a href="7-1-classical-nhst-concepts-of-wrong.html#type-i-error"><span class="toc-section-number">7.1.1</span> Type I error</a></li>
<li><a href="7-1-classical-nhst-concepts-of-wrong.html#power"><span class="toc-section-number">7.1.2</span> Power</a></li>
</ul></li>
<li class="has-sub"><a href="7-2-a-non-neyman-pearson-concept-of-power.html#a-non-neyman-pearson-concept-of-power"><span class="toc-section-number">7.2</span> A non-Neyman-Pearson concept of power</a><ul>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#estimation-error"><span class="toc-section-number">7.2.1</span> Estimation error</a></li>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#coverage"><span class="toc-section-number">7.2.2</span> Coverage</a></li>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#type-s-error"><span class="toc-section-number">7.2.3</span> Type S error</a></li>
<li><a href="7-2-a-non-neyman-pearson-concept-of-power.html#type-m-error"><span class="toc-section-number">7.2.4</span> Type M error</a></li>
</ul></li>
</ul></li>
<li><a href="part-v-introduction-to-linear-models.html#part-v-introduction-to-linear-models">Part V: Introduction to Linear Models</a></li>
<li class="has-sub"><a href="8-an-introduction-to-linear-models.html#an-introduction-to-linear-models"><span class="toc-section-number">8</span> An introduction to linear models</a><ul>
<li class="has-sub"><a href="8-1-two-specifications-of-a-linear-model.html#two-specifications-of-a-linear-model"><span class="toc-section-number">8.1</span> Two specifications of a linear model</a><ul>
<li><a href="8-1-two-specifications-of-a-linear-model.html#the-error-draw-specification"><span class="toc-section-number">8.1.1</span> The “error draw” specification</a></li>
<li><a href="8-1-two-specifications-of-a-linear-model.html#the-conditional-draw-specification"><span class="toc-section-number">8.1.2</span> The “conditional draw” specification</a></li>
<li><a href="8-1-two-specifications-of-a-linear-model.html#comparing-the-two-ways-of-specifying-the-linear-model"><span class="toc-section-number">8.1.3</span> Comparing the two ways of specifying the linear model</a></li>
</ul></li>
<li class="has-sub"><a href="8-2-a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables.html#a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables"><span class="toc-section-number">8.2</span> A linear model can be fit to data with continuous, discrete, or categorical <span class="math inline">\(X\)</span> variables</a><ul>
<li><a href="8-2-a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-continuous-or-discrete"><span class="toc-section-number">8.2.1</span> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is continuous or discrete</a></li>
<li><a href="8-2-a-linear-model-can-be-fit-to-data-with-continuous-discrete-or-categorical-x-variables.html#fitting-linear-models-to-experimental-data-in-which-the-x-variable-is-categorical"><span class="toc-section-number">8.2.2</span> Fitting linear models to experimental data in which the <span class="math inline">\(X\)</span> variable is categorical</a></li>
</ul></li>
<li><a href="8-3-statistical-models-are-used-for-prediction-explanation-and-description.html#statistical-models-are-used-for-prediction-explanation-and-description"><span class="toc-section-number">8.3</span> Statistical models are used for prediction, explanation, and description</a></li>
<li><a href="8-4-what-do-we-call-the-x-and-y-variables.html#what-do-we-call-the-x-and-y-variables"><span class="toc-section-number">8.4</span> What do we call the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables?</a></li>
<li><a href="8-5-modeling-strategy.html#modeling-strategy"><span class="toc-section-number">8.5</span> Modeling strategy</a></li>
<li><a href="8-6-predictions-from-the-model.html#predictions-from-the-model"><span class="toc-section-number">8.6</span> Predictions from the model</a></li>
<li class="has-sub"><a href="8-7-inference-from-the-model.html#inference-from-the-model"><span class="toc-section-number">8.7</span> Inference from the model</a><ul>
<li><a href="8-7-inference-from-the-model.html#assumptions-for-inference-with-a-statistical-model"><span class="toc-section-number">8.7.1</span> Assumptions for inference with a statistical model</a></li>
<li><a href="8-7-inference-from-the-model.html#specific-assumptions-for-inference-with-a-linear-model"><span class="toc-section-number">8.7.2</span> Specific assumptions for inference with a linear model</a></li>
</ul></li>
<li><a href="8-8-linear-modelregression-model-orstatistical-model.html#linear-modelregression-model-orstatistical-model"><span class="toc-section-number">8.8</span> “linear model,”regression model“, or”statistical model"?</a></li>
</ul></li>
<li class="has-sub"><a href="9-linear-models-with-a-single-continuous-x.html#linear-models-with-a-single-continuous-x"><span class="toc-section-number">9</span> Linear models with a single, continuous <em>X</em></a><ul>
<li class="has-sub"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#a-linear-model-with-a-single-continuous-x-is-classical-regression"><span class="toc-section-number">9.1</span> A linear model with a single, continuous <em>X</em> is classical “regression”</a><ul>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#analysis-of-green-down-data"><span class="toc-section-number">9.1.1</span> Analysis of “green-down” data</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#learning-from-the-green-down-example"><span class="toc-section-number">9.1.2</span> Learning from the green-down example</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-explanation-causal-models"><span class="toc-section-number">9.1.3</span> Using a regression model for “explanation” – causal models</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-prediction-prediction-models"><span class="toc-section-number">9.1.4</span> Using a regression model for prediction – prediction models</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-creating-a-new-response-variable-comparing-slopes-of-longitudinal-data"><span class="toc-section-number">9.1.5</span> Using a regression model for creating a new response variable – comparing slopes of longitudinal data</a></li>
<li><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#using-a-regression-model-for-for-calibration"><span class="toc-section-number">9.1.6</span> Using a regression model for for calibration</a></li>
</ul></li>
<li class="has-sub"><a href="9-2-working-in-r-1.html#working-in-r-1"><span class="toc-section-number">9.2</span> Working in R</a><ul>
<li><a href="9-2-working-in-r-1.html#fitting-the-linear-model"><span class="toc-section-number">9.2.1</span> Fitting the linear model</a></li>
<li><a href="9-2-working-in-r-1.html#getting-to-know-the-linear-model-the-summary-function"><span class="toc-section-number">9.2.2</span> Getting to know the linear model: the <code>summary</code> function</a></li>
<li><a href="9-2-working-in-r-1.html#inference-the-coefficient-table-and-confidence-intervals"><span class="toc-section-number">9.2.3</span> Inference – the coefficient table and Confidence intervals</a></li>
<li><a href="9-2-working-in-r-1.html#how-good-is-our-model-model-checking"><span class="toc-section-number">9.2.4</span> How good is our model? – Model checking</a></li>
<li><a href="9-2-working-in-r-1.html#plotting-models-with-continuous-x"><span class="toc-section-number">9.2.5</span> Plotting models with continuous <em>X</em></a></li>
<li><a href="9-2-working-in-r-1.html#creating-a-table-of-predicted-values-and-95-prediction-intervals"><span class="toc-section-number">9.2.6</span> Creating a table of predicted values and 95% prediction intervals</a></li>
</ul></li>
<li class="has-sub"><a href="9-3-hidden-code.html#hidden-code"><span class="toc-section-number">9.3</span> Hidden code</a><ul>
<li><a href="9-3-hidden-code.html#import-and-plot-of-fig2c-ecosystem-warming-experimental-data"><span class="toc-section-number">9.3.1</span> Import and plot of fig2c (ecosystem warming experimental) data</a></li>
<li><a href="9-3-hidden-code.html#import-and-plot-efig_3d-ecosysem-warming-observational-data"><span class="toc-section-number">9.3.2</span> Import and plot efig_3d (Ecosysem warming observational) data</a></li>
<li><a href="9-3-hidden-code.html#import-and-plot-of-fig1f-methionine-restriction-data"><span class="toc-section-number">9.3.3</span> Import and plot of fig1f (methionine restriction) data</a></li>
</ul></li>
<li class="has-sub"><a href="9-4-try-it.html#try-it"><span class="toc-section-number">9.4</span> Try it</a><ul>
<li><a href="9-4-try-it.html#a-prediction-model-from-the-literature"><span class="toc-section-number">9.4.1</span> A prediction model from the literature</a></li>
</ul></li>
<li class="has-sub"><a href="9-5-intuition-pumps.html#intuition-pumps"><span class="toc-section-number">9.5</span> Intuition pumps</a><ul>
<li><a href="9-5-intuition-pumps.html#correlation-and-r2"><span class="toc-section-number">9.5.1</span> Correlation and $R^2</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="10-linear-models-with-a-single-categorical-x.html#linear-models-with-a-single-categorical-x"><span class="toc-section-number">10</span> Linear models with a single, categorical <em>X</em></a><ul>
<li class="has-sub"><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response."><span class="toc-section-number">10.1</span> A linear model with a single, categorical <em>X</em> variable estimates the effects of the levels of <em>X</em> on the response.</a><ul>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#example-1-two-treatment-levels-groups"><span class="toc-section-number">10.1.1</span> Example 1 – two treatment levels (“groups”)</a></li>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#understanding-the-analysis-with-two-treatment-levels"><span class="toc-section-number">10.1.2</span> Understanding the analysis with two treatment levels</a></li>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#example-2-three-treatment-levels-groups"><span class="toc-section-number">10.1.3</span> Example 2 – three treatment levels (“groups”)</a></li>
<li><a href="10-1-a-linear-model-with-a-single-categorical-x-variable-estimates-the-effects-of-the-levels-of-x-on-the-response-.html#understanding-the-analysis-with-three-or-more-treatment-levels"><span class="toc-section-number">10.1.4</span> Understanding the analysis with three (or more) treatment levels</a></li>
</ul></li>
<li class="has-sub"><a href="10-2-working-in-r-2.html#working-in-r-2"><span class="toc-section-number">10.2</span> Working in R</a><ul>
<li><a href="10-2-working-in-r-2.html#specifying-the-contrasts"><span class="toc-section-number">10.2.1</span> Specifying the contrasts</a></li>
<li><a href="10-2-working-in-r-2.html#adjustment-for-multiple-comparisons"><span class="toc-section-number">10.2.2</span> Adjustment for multiple comparisons</a></li>
<li><a href="10-2-working-in-r-2.html#plotting-models-with-a-single-categorical-x"><span class="toc-section-number">10.2.3</span> Plotting models with a single, categorical <span class="math inline">\(X\)</span></a></li>
</ul></li>
<li class="has-sub"><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#issues-in-inference-in-models-with-a-single-categorical-x"><span class="toc-section-number">10.3</span> Issues in inference in models with a single, categorical <span class="math inline">\(X\)</span></a><ul>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#lack-of-independence"><span class="toc-section-number">10.3.1</span> Lack of independence</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#heterogeneity-of-variances"><span class="toc-section-number">10.3.2</span> Heterogeneity of variances</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#the-conditional-response-isnt-normal"><span class="toc-section-number">10.3.3</span> The conditional response isn’t Normal</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#pre-post-designs"><span class="toc-section-number">10.3.4</span> Pre-post designs</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#longitudinal-designs"><span class="toc-section-number">10.3.5</span> Longitudinal designs</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#comparing-responses-normalized-to-a-standard"><span class="toc-section-number">10.3.6</span> Comparing responses normalized to a standard</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#comparing-responses-that-are-ratios"><span class="toc-section-number">10.3.7</span> Comparing responses that are ratios</a></li>
<li><a href="10-3-issues-in-inference-in-models-with-a-single-categorical-x.html#researcher-degrees-of-freedom"><span class="toc-section-number">10.3.8</span> Researcher degrees of freedom</a></li>
</ul></li>
<li class="has-sub"><a href="10-4-hidden-code-1.html#hidden-code-1"><span class="toc-section-number">10.4</span> Hidden Code</a><ul>
<li><a href="10-4-hidden-code-1.html#fig2a-data"><span class="toc-section-number">10.4.1</span> fig2a data</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="11-model-checking.html#model-checking"><span class="toc-section-number">11</span> Model Checking</a><ul>
<li><a href="11-1-all-statistical-analyses-should-be-followed-by-model-checking.html#all-statistical-analyses-should-be-followed-by-model-checking"><span class="toc-section-number">11.1</span> All statistical analyses should be followed by model checking</a></li>
<li class="has-sub"><a href="11-2-linear-model-assumptions.html#linear-model-assumptions"><span class="toc-section-number">11.2</span> Linear model assumptions</a><ul>
<li><a href="11-2-linear-model-assumptions.html#a-bit-about-iid"><span class="toc-section-number">11.2.1</span> A bit about IID</a></li>
</ul></li>
<li class="has-sub"><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#diagnostic-plots-use-the-residuals-from-the-model-fit"><span class="toc-section-number">11.3</span> Diagnostic plots use the residuals from the model fit</a><ul>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#residuals"><span class="toc-section-number">11.3.1</span> Residuals</a></li>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#a-normal-q-q-plot-is-used-to-check-for-characteristic-departures-from-normality"><span class="toc-section-number">11.3.2</span> A Normal Q-Q plot is used to check for characteristic departures from Normality</a></li>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#mapping-qq-plot-departures-from-normality"><span class="toc-section-number">11.3.3</span> Mapping QQ-plot departures from Normality</a></li>
<li><a href="11-3-diagnostic-plots-use-the-residuals-from-the-model-fit.html#model-checking-homoskedasticity"><span class="toc-section-number">11.3.4</span> Model checking homoskedasticity</a></li>
</ul></li>
<li class="has-sub"><a href="11-4-using-r.html#using-r"><span class="toc-section-number">11.4</span> Using R</a><ul>
<li><a href="11-4-using-r.html#normal-q-q-plots"><span class="toc-section-number">11.4.1</span> Normal Q-Q plots</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="12-model-fitting-and-model-fit-ols.html#model-fitting-and-model-fit-ols"><span class="toc-section-number">12</span> Model Fitting and Model Fit (OLS)</a><ul>
<li><a href="12-1-least-squares-estimation-and-the-decomposition-of-variance.html#least-squares-estimation-and-the-decomposition-of-variance"><span class="toc-section-number">12.1</span> Least Squares Estimation and the Decomposition of Variance</a></li>
<li><a href="12-2-ols-regression.html#ols-regression"><span class="toc-section-number">12.2</span> OLS regression</a></li>
<li><a href="12-3-how-well-does-the-model-fit-the-data-r2-and-variance-explained.html#how-well-does-the-model-fit-the-data-r2-and-variance-explained"><span class="toc-section-number">12.3</span> How well does the model fit the data? <span class="math inline">\(R^2\)</span> and “variance explained”</a></li>
</ul></li>
<li class="has-sub"><a href="13-best-practices-issues-in-inference.html#best-practices-issues-in-inference"><span class="toc-section-number">13</span> Best practices – issues in inference</a><ul>
<li class="has-sub"><a href="13-1-multiple-testing.html#multiple-testing"><span class="toc-section-number">13.1</span> Multiple testing</a><ul>
<li><a href="13-1-multiple-testing.html#some-background"><span class="toc-section-number">13.1.1</span> Some background</a></li>
<li><a href="13-1-multiple-testing.html#multiple-testing-working-in-r"><span class="toc-section-number">13.1.2</span> Multiple testing – working in R</a></li>
<li><a href="13-1-multiple-testing.html#false-discovery-rate"><span class="toc-section-number">13.1.3</span> False Discovery Rate</a></li>
</ul></li>
<li><a href="13-2-difference-in-p-is-not-different.html#difference-in-p-is-not-different"><span class="toc-section-number">13.2</span> difference in p is not different</a></li>
<li class="has-sub"><a href="13-3-inference-when-data-are-not-normal.html#inference-when-data-are-not-normal"><span class="toc-section-number">13.3</span> Inference when data are not Normal</a><ul>
<li><a href="13-3-inference-when-data-are-not-normal.html#working-in-r-3"><span class="toc-section-number">13.3.1</span> Working in R</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#bootstrap-confidence-intervals"><span class="toc-section-number">13.3.2</span> Bootstrap Confidence Intervals</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#permutation-test"><span class="toc-section-number">13.3.3</span> Permutation test</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#non-parametric-tests"><span class="toc-section-number">13.3.4</span> Non-parametric tests</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#log-transformations"><span class="toc-section-number">13.3.5</span> Log transformations</a></li>
<li><a href="13-3-inference-when-data-are-not-normal.html#performance-of-parametric-tests-and-alternatives"><span class="toc-section-number">13.3.6</span> Performance of parametric tests and alternatives</a></li>
</ul></li>
</ul></li>
<li><a href="part-vi-more-than-one-x-multivariable-models.html#part-vi-more-than-one-x-multivariable-models">Part VI: More than one <span class="math inline">\(X\)</span> – Multivariable Models</a></li>
<li class="has-sub"><a href="14-adding-covariates-to-a-linear-model.html#adding-covariates-to-a-linear-model"><span class="toc-section-number">14</span> Adding covariates to a linear model</a><ul>
<li><a href="14-1-adding-covariates-can-increases-the-precision-of-the-effect-of-interest.html#adding-covariates-can-increases-the-precision-of-the-effect-of-interest"><span class="toc-section-number">14.1</span> Adding covariates can increases the precision of the effect of interest</a></li>
<li class="has-sub"><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data"><span class="toc-section-number">14.2</span> Understanding a linear model with an added covariate – heart necrosis data</a><ul>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#fit-the-model-1"><span class="toc-section-number">14.2.1</span> Fit the model</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#plot-the-model-1"><span class="toc-section-number">14.2.2</span> Plot the model</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#interpretation-of-the-model-coefficients"><span class="toc-section-number">14.2.3</span> Interpretation of the model coefficients</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#everything-adds-up"><span class="toc-section-number">14.2.4</span> Everything adds up</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#interpretation-of-the-estimated-marginal-means"><span class="toc-section-number">14.2.5</span> Interpretation of the estimated marginal means</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#interpretation-of-the-contrasts"><span class="toc-section-number">14.2.6</span> Interpretation of the contrasts</a></li>
<li><a href="14-2-understanding-a-linear-model-with-an-added-covariate-heart-necrosis-data.html#adding-the-covariate-improves-inference"><span class="toc-section-number">14.2.7</span> Adding the covariate improves inference</a></li>
</ul></li>
<li class="has-sub"><a href="14-3-understanding-interaction-effects-with-covariates.html#understanding-interaction-effects-with-covariates"><span class="toc-section-number">14.3</span> Understanding interaction effects with covariates</a><ul>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#fit-the-model-2"><span class="toc-section-number">14.3.1</span> Fit the model</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#plot-the-model-with-interaction-effect"><span class="toc-section-number">14.3.2</span> Plot the model with interaction effect</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#interpretation-of-the-model-coefficients-1"><span class="toc-section-number">14.3.3</span> Interpretation of the model coefficients</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#what-is-the-effect-of-a-treatment-if-interactions-are-modeled-it-depends."><span class="toc-section-number">14.3.4</span> What is the effect of a treatment, if interactions are modeled? – it depends.</a></li>
<li><a href="14-3-understanding-interaction-effects-with-covariates.html#which-model-do-we-use-mathcalm_1-or-mathcalm_2"><span class="toc-section-number">14.3.5</span> Which model do we use, <span class="math inline">\(\mathcal{M}_1\)</span> or <span class="math inline">\(\mathcal{M}_2\)</span>?</a></li>
</ul></li>
<li><a href="14-4-understanding-ancova-tables.html#understanding-ancova-tables"><span class="toc-section-number">14.4</span> Understanding ANCOVA tables</a></li>
<li class="has-sub"><a href="14-5-working-in-r-4.html#working-in-r-4"><span class="toc-section-number">14.5</span> Working in R</a><ul>
<li><a href="14-5-working-in-r-4.html#importing-the-heart-necrosis-data"><span class="toc-section-number">14.5.1</span> Importing the heart necrosis data</a></li>
<li><a href="14-5-working-in-r-4.html#fitting-the-model"><span class="toc-section-number">14.5.2</span> Fitting the model</a></li>
<li><a href="14-5-working-in-r-4.html#ancova-tables"><span class="toc-section-number">14.5.3</span> ANCOVA tables</a></li>
<li><a href="14-5-working-in-r-4.html#plotting-the-model"><span class="toc-section-number">14.5.4</span> Plotting the model</a></li>
</ul></li>
<li class="has-sub"><a href="14-6-best-practices.html#best-practices"><span class="toc-section-number">14.6</span> Best practices</a><ul>
<li><a href="14-6-best-practices.html#do-not-use-a-ratio-of-partwhole-as-a-response-variable-instead-add-the-denominator-as-a-covariate"><span class="toc-section-number">14.6.1</span> Do not use a ratio of part:whole as a response variable – instead add the denominator as a covariate</a></li>
<li><a href="14-6-best-practices.html#do-not-use-change-from-baseline-as-a-response-variable-instead-add-the-baseline-measure-as-a-covariate"><span class="toc-section-number">14.6.2</span> Do not use change from baseline as a response variable – instead add the baseline measure as a covariate</a></li>
<li><a href="14-6-best-practices.html#do-not-test-for-balance-of-baseline-measures"><span class="toc-section-number">14.6.3</span> Do not “test for balance” of baseline measures</a></li>
</ul></li>
<li><a href="14-7-best-practices-2-use-a-covariate-instead-of-normalizing-a-response.html#best-practices-2-use-a-covariate-instead-of-normalizing-a-response"><span class="toc-section-number">14.7</span> Best practices 2: Use a covariate instead of normalizing a response</a></li>
</ul></li>
<li class="has-sub"><a href="15-two-or-more-categorical-x-factorial-designs.html#two-or-more-categorical-x-factorial-designs"><span class="toc-section-number">15</span> Two (or more) Categorical <span class="math inline">\(X\)</span> – Factorial designs</a><ul>
<li class="has-sub"><a href="15-1-factorial-experiments.html#factorial-experiments"><span class="toc-section-number">15.1</span> Factorial experiments</a><ul>
<li><a href="15-1-factorial-experiments.html#model-coefficients-an-interaction-effect-is-what-is-leftover-after-adding-the-treatment-effects-to-the-control"><span class="toc-section-number">15.1.1</span> Model coefficients: an interaction effect is what is leftover after adding the treatment effects to the control</a></li>
<li><a href="15-1-factorial-experiments.html#what-is-the-biological-meaning-of-an-interaction-effect"><span class="toc-section-number">15.1.2</span> What is the biological meaning of an interaction effect?</a></li>
<li><a href="15-1-factorial-experiments.html#the-interpretation-of-the-coefficients-in-a-factorial-model-is-entirely-dependent-on-the-reference"><span class="toc-section-number">15.1.3</span> The interpretation of the coefficients in a factorial model is entirely dependent on the reference…</a></li>
<li><a href="15-1-factorial-experiments.html#estimated-marginal-means"><span class="toc-section-number">15.1.4</span> Estimated marginal means</a></li>
<li><a href="15-1-factorial-experiments.html#in-a-factorial-model-there-are-multiple-effects-of-each-factor-simple-effects"><span class="toc-section-number">15.1.5</span> In a factorial model, there are multiple effects of each factor (simple effects)</a></li>
<li><a href="15-1-factorial-experiments.html#marginal-effects"><span class="toc-section-number">15.1.6</span> Marginal effects</a></li>
<li><a href="15-1-factorial-experiments.html#the-additive-model"><span class="toc-section-number">15.1.7</span> The additive model</a></li>
<li><a href="15-1-factorial-experiments.html#reduce-models-for-the-right-reason"><span class="toc-section-number">15.1.8</span> Reduce models for the right reason</a></li>
<li><a href="15-1-factorial-experiments.html#what-about-models-with-more-than-two-factors"><span class="toc-section-number">15.1.9</span> What about models with more than two factors?</a></li>
</ul></li>
<li class="has-sub"><a href="15-2-reporting-results.html#reporting-results"><span class="toc-section-number">15.2</span> Reporting results</a><ul>
<li><a href="15-2-reporting-results.html#text-results"><span class="toc-section-number">15.2.1</span> Text results</a></li>
</ul></li>
<li class="has-sub"><a href="15-3-working-in-r-5.html#working-in-r-5"><span class="toc-section-number">15.3</span> Working in R</a><ul>
<li><a href="15-3-working-in-r-5.html#model-formula"><span class="toc-section-number">15.3.1</span> Model formula</a></li>
<li><a href="15-3-working-in-r-5.html#modeled-means"><span class="toc-section-number">15.3.2</span> Modeled means</a></li>
<li><a href="15-3-working-in-r-5.html#marginal-means"><span class="toc-section-number">15.3.3</span> Marginal means</a></li>
<li><a href="15-3-working-in-r-5.html#contrasts"><span class="toc-section-number">15.3.4</span> Contrasts</a></li>
<li><a href="15-3-working-in-r-5.html#simple-effects"><span class="toc-section-number">15.3.5</span> Simple effects</a></li>
<li><a href="15-3-working-in-r-5.html#marginal-effects-1"><span class="toc-section-number">15.3.6</span> Marginal effects</a></li>
<li><a href="15-3-working-in-r-5.html#plotting-results"><span class="toc-section-number">15.3.7</span> Plotting results</a></li>
</ul></li>
<li><a href="15-4-problems-1.html#problems-1"><span class="toc-section-number">15.4</span> Problems</a></li>
</ul></li>
<li class="has-sub"><a href="16-anova-tables.html#anova-tables"><span class="toc-section-number">16</span> ANOVA Tables</a><ul>
<li><a href="16-1-summary-of-usage.html#summary-of-usage"><span class="toc-section-number">16.1</span> Summary of usage</a></li>
<li><a href="16-2-example-a-one-way-anova-using-the-vole-data.html#example-a-one-way-anova-using-the-vole-data"><span class="toc-section-number">16.2</span> Example: a one-way ANOVA using the vole data</a></li>
<li class="has-sub"><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#example-a-two-way-anova-using-the-urchin-data"><span class="toc-section-number">16.3</span> Example: a two-way ANOVA using the urchin data</a><ul>
<li><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#how-to-read-an-anova-table"><span class="toc-section-number">16.3.1</span> How to read an ANOVA table</a></li>
<li><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#how-to-read-anova-results-reported-in-the-text"><span class="toc-section-number">16.3.2</span> How to read ANOVA results reported in the text</a></li>
<li><a href="16-3-example-a-two-way-anova-using-the-urchin-data.html#better-practice-estimates-and-their-uncertainty"><span class="toc-section-number">16.3.3</span> Better practice – estimates and their uncertainty</a></li>
</ul></li>
<li class="has-sub"><a href="16-4-unbalanced-designs.html#unbalanced-designs"><span class="toc-section-number">16.4</span> Unbalanced designs</a><ul>
<li><a href="16-4-unbalanced-designs.html#what-is-going-on-in-unbalanced-anova-type-i-ii-iii-sum-of-squares"><span class="toc-section-number">16.4.1</span> What is going on in unbalanced ANOVA? – Type I, II, III sum of squares</a></li>
<li><a href="16-4-unbalanced-designs.html#back-to-interpretation-of-main-effects"><span class="toc-section-number">16.4.2</span> Back to interpretation of main effects</a></li>
<li><a href="16-4-unbalanced-designs.html#the-anova-tables-for-type-i-ii-and-iii-sum-of-squares-are-the-same-if-the-design-is-balanced."><span class="toc-section-number">16.4.3</span> The anova tables for Type I, II, and III sum of squares are the same if the design is balanced.</a></li>
</ul></li>
<li class="has-sub"><a href="16-5-working-in-r-6.html#working-in-r-6"><span class="toc-section-number">16.5</span> Working in R</a><ul>
<li><a href="16-5-working-in-r-6.html#type-i-sum-of-squares-in-r"><span class="toc-section-number">16.5.1</span> Type I sum of squares in R</a></li>
<li><a href="16-5-working-in-r-6.html#type-ii-and-iii-sum-of-squares"><span class="toc-section-number">16.5.2</span> Type II and III Sum of Squares</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="17-predictive-models.html#predictive-models"><span class="toc-section-number">17</span> Predictive Models</a><ul>
<li><a href="17-1-overfitting.html#overfitting"><span class="toc-section-number">17.1</span> Overfitting</a></li>
<li class="has-sub"><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#model-building-vs.-variable-selection-vs.-model-selection"><span class="toc-section-number">17.2</span> Model building vs. Variable selection vs. Model selection</a><ul>
<li><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#stepwise-regression"><span class="toc-section-number">17.2.1</span> Stepwise regression</a></li>
<li><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#cross-validation"><span class="toc-section-number">17.2.2</span> Cross-validation</a></li>
<li><a href="17-2-model-building-vs-variable-selection-vs-model-selection.html#penalization"><span class="toc-section-number">17.2.3</span> Penalization</a></li>
</ul></li>
<li><a href="17-3-shrinkage.html#shrinkage"><span class="toc-section-number">17.3</span> Shrinkage</a></li>
</ul></li>
<li><a href="part-vii-expanding-the-linear-model.html#part-vii-expanding-the-linear-model">Part VII – Expanding the Linear Model</a></li>
<li class="has-sub"><a href="18-models-with-random-effects-blocking-and-pseudoreplication.html#models-with-random-effects-blocking-and-pseudoreplication"><span class="toc-section-number">18</span> Models with random effects – Blocking and pseudoreplication</a><ul>
<li><a href="18-1-random-effects.html#random-effects"><span class="toc-section-number">18.1</span> Random effects</a></li>
<li><a href="18-2-random-effects-in-statistical-models.html#random-effects-in-statistical-models"><span class="toc-section-number">18.2</span> Random effects in statistical models</a></li>
<li><a href="18-3-linear-mixed-models-are-flexible.html#linear-mixed-models-are-flexible"><span class="toc-section-number">18.3</span> Linear mixed models are flexible</a></li>
<li class="has-sub"><a href="18-4-blocking.html#blocking"><span class="toc-section-number">18.4</span> Blocking</a><ul>
<li><a href="18-4-blocking.html#visualing-variation-due-to-blocks"><span class="toc-section-number">18.4.1</span> Visualing variation due to blocks</a></li>
<li><a href="18-4-blocking.html#blocking-increases-precision-of-point-estimates"><span class="toc-section-number">18.4.2</span> Blocking increases precision of point estimates</a></li>
</ul></li>
<li class="has-sub"><a href="18-5-pseudoreplication.html#pseudoreplication"><span class="toc-section-number">18.5</span> Pseudoreplication</a><ul>
<li><a href="18-5-pseudoreplication.html#visualizing-pseduoreplication"><span class="toc-section-number">18.5.1</span> Visualizing pseduoreplication</a></li>
</ul></li>
<li><a href="18-6-mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model.html#mapping-nhst-to-estimation-a-paired-t-test-is-a-special-case-of-a-linear-mixed-model"><span class="toc-section-number">18.6</span> Mapping NHST to estimation: A paired t-test is a special case of a linear mixed model</a></li>
<li><a href="18-7-advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling.html#advanced-topic-linear-mixed-models-shrink-coefficients-by-partial-pooling"><span class="toc-section-number">18.7</span> Advanced topic – Linear mixed models shrink coefficients by partial pooling</a></li>
<li class="has-sub"><a href="18-8-working-in-r-7.html#working-in-r-7"><span class="toc-section-number">18.8</span> Working in R</a><ul>
<li><a href="18-8-working-in-r-7.html#coral-data"><span class="toc-section-number">18.8.1</span> coral data</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="19-models-for-longitudinal-experiments-pre-post-designs.html#models-for-longitudinal-experiments-pre-post-designs"><span class="toc-section-number">19</span> Models for longitudinal experiments – pre-post designs</a><ul>
<li><a href="19-1-best-practice-models.html#best-practice-models"><span class="toc-section-number">19.1</span> Best practice models</a></li>
<li><a href="19-2-common-alternatives-that-are-not-recommended.html#common-alternatives-that-are-not-recommended"><span class="toc-section-number">19.2</span> Common alternatives that are not recommended</a></li>
<li><a href="19-3-advanced-models.html#advanced-models"><span class="toc-section-number">19.3</span> Advanced models</a></li>
<li class="has-sub"><a href="19-4-understanding-the-alternative-models.html#understanding-the-alternative-models"><span class="toc-section-number">19.4</span> Understanding the alternative models</a><ul>
<li><a href="19-4-understanding-the-alternative-models.html#m1-linear-model-with-the-baseline-measure-as-the-covariate-ancova-model"><span class="toc-section-number">19.4.1</span> (M1) Linear model with the baseline measure as the covariate (ANCOVA model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m2-linear-model-of-the-change-score-change-score-model"><span class="toc-section-number">19.4.2</span> (M2) Linear model of the change score (change-score model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m3-linear-model-of-post-baseline-values-without-the-baseline-as-a-covariate-post-model"><span class="toc-section-number">19.4.3</span> (M3) Linear model of post-baseline values without the baseline as a covariate (post model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m4-linear-model-with-factorial-fixed-effects-fixed-effects-model"><span class="toc-section-number">19.4.4</span> (M4) Linear model with factorial fixed effects (fixed-effects model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m5-repeated-measures-anova"><span class="toc-section-number">19.4.5</span> (M5) Repeated measures ANOVA</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m6-linear-mixed-model"><span class="toc-section-number">19.4.6</span> (M6) Linear mixed model</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m7-linear-model-with-correlated-error"><span class="toc-section-number">19.4.7</span> (M7) Linear model with correlated error</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#m8-constrained-fixed-effects-model-with-correlated-error-clda-model"><span class="toc-section-number">19.4.8</span> (M8) Constrained fixed effects model with correlated error (cLDA model)</a></li>
<li><a href="19-4-understanding-the-alternative-models.html#comparison-table"><span class="toc-section-number">19.4.9</span> Comparison table</a></li>
</ul></li>
<li class="has-sub"><a href="19-5-example-1-a-single-post-baseline-measure-pre-post-design.html#example-1-a-single-post-baseline-measure-pre-post-design"><span class="toc-section-number">19.5</span> Example 1 – a single post-baseline measure (pre-post design)</a><ul>
<li><a href="19-5-example-1-a-single-post-baseline-measure-pre-post-design.html#analysis"><span class="toc-section-number">19.5.1</span> Analysis</a></li>
</ul></li>
<li><a href="19-6-working-in-r-8.html#working-in-r-8"><span class="toc-section-number">19.6</span> Working in R</a></li>
</ul></li>
<li class="has-sub"><a href="20-generalized-linear-models-i-count-data.html#generalized-linear-models-i-count-data"><span class="toc-section-number">20</span> Generalized linear models I: Count data</a><ul>
<li><a href="20-1-the-generalized-linear-model.html#the-generalized-linear-model"><span class="toc-section-number">20.1</span> The generalized linear model</a></li>
<li class="has-sub"><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish"><span class="toc-section-number">20.2</span> Count data example – number of trematode worm larvae in eyes of threespine stickleback fish</a><ul>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#modeling-strategy-1"><span class="toc-section-number">20.2.1</span> Modeling strategy</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#checking-the-model-i-a-normal-q-q-plot"><span class="toc-section-number">20.2.2</span> Checking the model I – a Normal Q-Q plot</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#checking-the-model-ii-scale-location-plot-for-checking-homoskedasticity"><span class="toc-section-number">20.2.3</span> Checking the model II – scale-location plot for checking homoskedasticity</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#two-distributions-for-count-data-poisson-and-negative-binomial"><span class="toc-section-number">20.2.4</span> Two distributions for count data – Poisson and Negative Binomial</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#fitting-a-glm-with-a-poisson-distribution-to-the-worm-data"><span class="toc-section-number">20.2.5</span> Fitting a GLM with a Poisson distribution to the worm data</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#model-checking-fits-to-count-data"><span class="toc-section-number">20.2.6</span> Model checking fits to count data</a></li>
<li><a href="20-2-count-data-example-number-of-trematode-worm-larvae-in-eyes-of-threespine-stickleback-fish.html#fitting-a-glm-with-a-negative-binomial-distribution-to-the-worm-data"><span class="toc-section-number">20.2.7</span> Fitting a GLM with a Negative Binomial distribution to the worm data</a></li>
</ul></li>
<li class="has-sub"><a href="20-3-working-in-r-9.html#working-in-r-9"><span class="toc-section-number">20.3</span> Working in R</a><ul>
<li><a href="20-3-working-in-r-9.html#fitting-a-glm-to-count-data"><span class="toc-section-number">20.3.1</span> Fitting a GLM to count data</a></li>
<li><a href="20-3-working-in-r-9.html#fitting-a-generalized-linear-mixed-model-glmm-to-count-data"><span class="toc-section-number">20.3.2</span> Fitting a generalized linear mixed model (GLMM) to count data</a></li>
<li><a href="20-3-working-in-r-9.html#fitting-a-generalized-linear-model-to-continouus-data"><span class="toc-section-number">20.3.3</span> Fitting a generalized linear model to continouus data</a></li>
</ul></li>
<li><a href="20-4-problems-2.html#problems-2"><span class="toc-section-number">20.4</span> Problems</a></li>
</ul></li>
<li class="has-sub"><a href="21-linear-models-with-heterogenous-variance.html#linear-models-with-heterogenous-variance"><span class="toc-section-number">21</span> Linear models with heterogenous variance</a><ul>
<li><a href="21-1-gls.html#gls"><span class="toc-section-number">21.1</span> gls</a></li>
</ul></li>
<li><a href="part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models.html#part-v-expanding-the-linear-model-generalized-linear-models-and-multilevel-linear-mixed-models">Part V: Expanding the Linear Model – Generalized Linear Models and Multilevel (Linear Mixed) Models</a></li>
<li class="has-sub"><a href="22-plotting-functions-ggplotsci.html#plotting-functions-ggplotsci"><span class="toc-section-number">22</span> Plotting functions (#ggplotsci)</a><ul>
<li><a href="22-1-odd-even.html#odd-even"><span class="toc-section-number">22.1</span> odd-even</a></li>
<li><a href="22-2-estimate-response-and-effects-with-emmeans.html#estimate-response-and-effects-with-emmeans"><span class="toc-section-number">22.2</span> estimate response and effects with emmeans</a></li>
<li><a href="22-3-emm-table.html#emm_table"><span class="toc-section-number">22.3</span> emm_table</a></li>
<li><a href="22-4-pairs-table.html#pairs_table"><span class="toc-section-number">22.4</span> pairs_table</a></li>
<li><a href="22-5-gg-mean-error.html#gg_mean_error"><span class="toc-section-number">22.5</span> gg_mean_error</a></li>
<li><a href="22-6-gg-ancova.html#gg_ancova"><span class="toc-section-number">22.6</span> gg_ancova</a></li>
<li><a href="22-7-gg-mean-ci-ancova.html#gg_mean_ci_ancova"><span class="toc-section-number">22.7</span> gg_mean_ci_ancova</a></li>
<li><a href="22-8-gg-effects.html#gg_effects"><span class="toc-section-number">22.8</span> gg_effects</a></li>
</ul></li>
<li class="has-sub"><a href="appendix-1-getting-started-with-r.html#appendix-1-getting-started-with-r">Appendix 1: Getting Started with R</a><ul>
<li class="has-sub"><a href="22-9-get-your-computer-ready.html#get-your-computer-ready"><span class="toc-section-number">22.9</span> Get your computer ready</a><ul>
<li><a href="22-9-get-your-computer-ready.html#start-here"><span class="toc-section-number">22.9.1</span> Start here</a></li>
<li><a href="22-9-get-your-computer-ready.html#install-r"><span class="toc-section-number">22.9.2</span> Install R</a></li>
<li><a href="22-9-get-your-computer-ready.html#install-r-studio"><span class="toc-section-number">22.9.3</span> Install R Studio</a></li>
<li><a href="22-9-get-your-computer-ready.html#install-r-markdown-1"><span class="toc-section-number">22.9.4</span> Install R Markdown</a></li>
<li><a href="22-9-get-your-computer-ready.html#optional-alternative-latex-installations"><span class="toc-section-number">22.9.5</span> (optional) Alternative LaTeX installations</a></li>
</ul></li>
<li><a href="22-10-start-learning-r-studio.html#start-learning-r-studio"><span class="toc-section-number">22.10</span> Start learning R Studio</a></li>
</ul></li>
<li><a href="appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r.html#appendix-2-online-resources-for-getting-started-with-statistical-modeling-in-r">Appendix 2: Online Resources for Getting Started with Statistical Modeling in R</a></li>
<li class="has-sub"><a href="appendix-3-fake-data-simulations.html#appendix-3-fake-data-simulations">Appendix 3: Fake Data Simulations</a><ul>
<li><a href="22-11-performance-of-blocking-relative-to-a-linear-model.html#performance-of-blocking-relative-to-a-linear-model"><span class="toc-section-number">22.11</span> Performance of Blocking relative to a linear model</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="a-linear-model-with-a-single-continuous-x-is-classical-regression" class="section level2">
<h2><span class="header-section-number">9.1</span> A linear model with a single, continuous <em>X</em> is classical “regression”</h2>
<div id="analysis-of-green-down-data" class="section level3">
<h3><span class="header-section-number">9.1.1</span> Analysis of “green-down” data</h3>
<p>To introduce some principles of modeling with a single continuous <span class="math inline">\(X\)</span> variable, I’ll use a dataset from</p>
<p><a href="https://doi.org/10.1038/s41586-018-0399-1" target="_blank">Richardson, A.D., Hufkens, K., Milliman, T. et al. Ecosystem warming extends vegetation activity but heightens vulnerability to cold temperatures. Nature 560, 368–371 (2018).</a></p>
<p><a href="https://www.nature.com/articles/s41586-018-0399-1#Sec15" target="_blank">Source data</a></p>
<p>The data are from a <a href="https://mnspruce.ornl.gov" target="_blank">long-term experiment on the effects of warming and CO2 on a high-carbon northern temperate peatland</a> and is the focal dataset of the study. The experiment involves 10 large, temperature and CO2 controlled enclosures. CO2 is set to 400 ppm in five enclosures and 900 ppm in five enclosures. Temperature of the five enclosures within each CO2 level is set to 0, 2.25, 4.5, 6.75, or 9 °C above ambient temperature. The multiple temperature levels is a <strong>regression design</strong>, which allows a researcher to measure non-linear effects. Read more about the experimental design and the <a href="https://mnspruce.ornl.gov/design" target="_blank">beautiful implementation</a>.</p>
<p>The question pursued is in this study is, what is the causal effect of warming on the timing (or phenology) of the transition into photosynthetic activity (“green-up”) in the spring and of the transition out of photosynthetic activity (“green-down”) in the fall? The researchers measured these transition dates, or Day of Year (DOY), using foliage color. Here, we focus on the transition out of photosynthesis or “green-down” DOY.</p>
<p><strong>Import the data</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Examine the data</strong></li>
</ol>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-1"></a>gg1 &lt;-<span class="st"> </span><span class="kw">qplot</span>(<span class="dt">x =</span> temperature,</span>
<span id="cb217-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-2"></a>      <span class="dt">y =</span> transition_date,</span>
<span id="cb217-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-3"></a>      <span class="dt">data =</span> fig2c) <span class="op">+</span></span>
<span id="cb217-4"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-4"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</span>
<span id="cb217-5"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-5"></a>gg2 &lt;-<span class="st"> </span><span class="kw">qplot</span>(<span class="dt">x =</span> temperature,</span>
<span id="cb217-6"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-6"></a>      <span class="dt">y =</span> transition_date,</span>
<span id="cb217-7"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-7"></a>      <span class="dt">data =</span> fig2c) <span class="op">+</span></span>
<span id="cb217-8"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-8"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">2</span>))</span>
<span id="cb217-9"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-9"></a>gg3 &lt;-<span class="st"> </span><span class="kw">qplot</span>(<span class="dt">x =</span> temperature,</span>
<span id="cb217-10"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-10"></a>      <span class="dt">y =</span> transition_date,</span>
<span id="cb217-11"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-11"></a>      <span class="dt">data =</span> fig2c) <span class="op">+</span></span>
<span id="cb217-12"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-12"></a><span class="st">  </span><span class="kw">geom_smooth</span>()</span>
<span id="cb217-13"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb217-13"></a><span class="kw">plot_grid</span>(gg1, gg2, gg3, <span class="dt">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-vet-1.png" width="576" /></p>
<p>No plot shows any obvious outlier that might be due to measurement blunders or curation error. The linear regression in the left-most plot clearly shows that a linear response is sufficient to capture the effect of temperature on day of green-down.</p>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>choose a model</strong>. Because the <span class="math inline">\(X\)</span> variable (<span class="math inline">\(temperature\)</span>) was experimentally set to five levels, the data could reasonably be modeled using either a linear model with a categorical <span class="math inline">\(X\)</span> or a linear model with a continuous <span class="math inline">\(X\)</span>. The advantage of modeling <span class="math inline">\(temperature\)</span> as a continuous variable is that there is only one effect, the slope of the regression line. If modeled as a categorical factor with five levels, there are, at a minimum, four interesting effects (the difference in means between each non-reference level and reference (temperature = 0) level). Also, for inference, modeling <span class="math inline">\(temperature\)</span> as a continuous variable increases power for hypothesis tests.</p></li>
<li><p><strong>fit the model</strong></p></li>
</ol>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb218-1"></a><span class="co"># Step 1: fit the model</span></span>
<span id="cb218-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb218-2"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(transition_date <span class="op">~</span><span class="st"> </span>temperature, <span class="dt">data =</span> fig2c)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li><strong>check the model</strong></li>
</ol>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb219-1"></a><span class="co"># check normality assumption</span></span>
<span id="cb219-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb219-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb219-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb219-3"></a><span class="kw">qqPlot</span>(m1, <span class="dt">id=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-check-qq-1.png" width="576" /></p>
<p>The Q-Q plot indicates the distribution of residuals is well within that expected for a normal sample and there is no cause for concern with inference.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb220-1"></a><span class="co"># check homogeneity assumption</span></span>
<span id="cb220-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb220-2"></a><span class="kw">spreadLevelPlot</span>(m1, <span class="dt">id=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-check-spread-1.png" width="576" /></p>
<pre><code>## 
## Suggested power transformation:  0.6721303</code></pre>
<p>The spread-location plot shows no conspicuous trend in how the spread changes with the conditonal mean. There is no cause for concern with inference.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>inference from the model</strong></li>
</ol>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb222-1"></a>m1_coeff &lt;-<span class="st"> </span><span class="kw">summary</span>(m1) <span class="op">%&gt;%</span></span>
<span id="cb222-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb222-2"></a><span class="st">  </span><span class="kw">coef</span>()</span>
<span id="cb222-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb222-3"></a>m1_confint &lt;-<span class="st"> </span><span class="kw">confint</span>(m1)</span>
<span id="cb222-4"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb222-4"></a>m1_coeff &lt;-<span class="st"> </span><span class="kw">cbind</span>(m1_coeff, m1_confint)</span>
<span id="cb222-5"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb222-5"></a>m1_coeff</span></code></pre></div>
<pre><code>##               Estimate Std. Error   t value     Pr(&gt;|t|)      2.5 %
## (Intercept) 289.458750  3.0593949 94.613071 1.738650e-13 282.403773
## temperature   4.982745  0.5541962  8.990941 1.866888e-05   3.704767
##                 97.5 %
## (Intercept) 296.513728
## temperature   6.260724</code></pre>
<p>The effect of added temperature on the day of green-down is 4.98 d per 1 °C (95% CI: 3.7, 6.3; p &lt; 0.001).</p>
<ol start="6" style="list-style-type: decimal">
<li><strong>plot the model</strong></li>
</ol>
<div class="figure"><span id="fig:continuous-x-plot"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-plot-1.png" alt="Modification of the published Figure 2c showing the experimental effect of warming on the date of autumn green-down (the transition to fall foliage color) in a mixed shrub community. The bottom panel is a scatterplot. The regression line shows the expected value of Y (transition day of year) given a value of X (added temperature). The slope of the regression line is the estimate of the effect. The estimate and 95% confidence interval of the estimate are given in the top panel." width="576" />
<p class="caption">
Figure 9.1: Modification of the published Figure 2c showing the experimental effect of warming on the date of autumn green-down (the transition to fall foliage color) in a mixed shrub community. The bottom panel is a scatterplot. The regression line shows the expected value of Y (transition day of year) given a value of X (added temperature). The slope of the regression line is the estimate of the effect. The estimate and 95% confidence interval of the estimate are given in the top panel.
</p>
</div>
<ol start="7" style="list-style-type: decimal">
<li>Report the results</li>
</ol>
<p>The modeled effect of added temperature is Slope: 4.98 (3.7, 6.26) d per 1 °C (<a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#fig:continuous-x-plot">9.1</a>).</p>
</div>
<div id="learning-from-the-green-down-example" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Learning from the green-down example</h3>
<p>Figure <a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#fig:continuous-x-plot">9.1</a> is a <strong>scatterplot</strong> with the green-down DOY for the mixed-shrub community on the <span class="math inline">\(Y\)</span> axis and added temperature on the <span class="math inline">\(X\)</span> axis. The line through the data is a regression line, which is the expected value of <em>Y</em> (green-down DOY) given a specific value of <em>X</em> (added temperature). The slope of the line is the <strong>effect</strong> of added temperature on timing of green-down. The intercept of the regression line is the value of the response (day of green-down) when <span class="math inline">\(X\)</span> is equal to zero. Very often, this value is not of interest although the value should be reported to allow predictions from the model. Also very often, the value of the intercept is not meaningful because a value of <span class="math inline">\(X = 0\)</span> is far outside the range of measured <span class="math inline">\(X\)</span>, or the value is absurd because it is impossible (for example, if investigating the effect of body weight on metabolic rate, the value <span class="math inline">\(weight = 0\)</span> is impossible).</p>
<p>The intercept and slope are the coefficients of the model fit to the data, which is</p>
<p><span class="math display" id="eq:continuous-x-fit">\[\begin{equation}
day_i = b_0 + b_1 temperature_i + e_i
\tag{9.1}
\end{equation}\]</span></p>
<p>where <em>day</em> is the day of green-down, <em>temperature</em> is the added temperature, and <em>i</em> refers (or “indexes”) the <em>i</em>th enclosure. This model completely reconstructs the day of green-down for all ten enclosures. For example, the day of green-down for enclosure 8 is</p>
<p><span class="math display">\[\begin{equation}
332 = 289.458750 + 4.982745 \times 6.73 + 9.00737
\end{equation}\]</span></p>
<p>The coefficients in the model are estimates of the parameters of the <strong>generating model</strong> fit to the data</p>
<p><span class="math display" id="eq:continuous-x-m1">\[\begin{align}
day &amp;= \beta_0 + \beta_1 temperature + \varepsilon\\
\varepsilon &amp;\sim N(0, \sigma^2)
\tag{9.2}
\end{align}\]</span></p>
<p>A generating model of the data is used to make inference, for example, a measure of uncertainty in a prediction in the timing of green-down with future warming, or a measure of uncertainty about the effect of temperature on green-down.</p>
</div>
<div id="using-a-regression-model-for-explanation-causal-models" class="section level3">
<h3><span class="header-section-number">9.1.3</span> Using a regression model for “explanation” – causal models</h3>
<p>In this text, “explanatory” means “causal” and a goal of explanatory modeling is the estimate of causal effects using a <strong>causal interpretation</strong> of the linear model (=regression) coefficients. “What what? I learned in my stats 101 course that we cannot interpret regression coefficients causally”.</p>
<p>Statisticians (and statistics textbooks) have been quite rigid that a regression coefficient has a descriptive (or “observational”, see below) interpretation but not a causal interpretation. At the same time, statisticians (and statistics textbooks) do not seem to have any issue with interpeting the modeled effects from an experiment causally, since this is how they are interpreted. But if the modeled effects are simply coefficients from a linear (= regression) model, then this historical practice is muddled.</p>
<p>Part of this muddled history arises from the use of “regression” for models fit to observational data with one or more continuous <span class="math inline">\(X\)</span> variables and the use of “ANOVA” for models fit to experimental data with one or more categorical <span class="math inline">\(X\)</span>. This separation seems to have blinded statisticians from working on the formal probabilistic statements underlying causal interpretations of effect estimates in ANOVA and the synthesis of these statements with the probabilistic statements in regression modeling. Two major approaches to developing formal, probabilistic statements of causal modeling in statistics are the <strong>Rubin causal model</strong> and the <strong>do-operator</strong> of Pearl. Despite the gigantic progress in these approaches, little to none of this has found its way into biostatistics textbooks.</p>
<div id="what-a-regression-coefficient-means" class="section level4">
<h4><span class="header-section-number">9.1.3.1</span> What a regression coefficient means</h4>
<p>A linear (“regression”) model coefficient, such as the coefficient for temperature, <span class="math inline">\(\beta_1\)</span>, has two interpretations, an <strong>observational</strong> interpretation and a <strong>causal interpretation</strong>. To understand these interpretations, it’s useful to remember that a predicted value from a regression model is a <strong>conditional mean</strong></p>
<p><span class="math display" id="eq:continuous-x-conditional-mean">\[\begin{equation}
\textrm{E}[day|temperature] = \beta_0 + \beta_1 temperature
\tag{9.3}
\end{equation}\]</span></p>
<p>In words “the expected value of day conditional on temperature is beta-knot plus beta-one times temperature”. An <strong>expected value</strong> is a long run average – if we had an infinite number of enclosures with <span class="math inline">\(temperature=x\)</span> (where <span class="math inline">\(x\)</span> is a specific value of added temperature, say 2.5 °C), the average <span class="math inline">\(day\)</span> of these enclosures is <span class="math inline">\(\beta_0 + \beta_1 x\)</span>.</p>
<p>The parameter <span class="math inline">\(\beta_1\)</span> is a <em>difference</em> in conditional means.</p>
<p><span class="math display" id="eq:beta">\[\begin{equation}
\beta_1 = \textrm{E}[day|temperature = x+1] - \textrm{E}[day|temperature = x]
\tag{9.4}
\end{equation}\]</span></p>
<p>In words, “beta-one is the expected value of day of green-down when the temperature equals x + 1 minus the expected value of day of green-down when the temperature equals x.” A very short way to state this is “beta-one is a difference in conditional means”.</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p>tl;dr. Note that the “+ 1” in this definition is mere convenience. Since the slope of a line is <span class="math inline">\(\frac{y_2 - y_1}{x_2 - x_1}\)</span>, where (<span class="math inline">\(x_1\)</span>, <span class="math inline">\(y_1\)</span>) and (<span class="math inline">\(x_2\)</span>, <span class="math inline">\(y_2\)</span>) are the coordinates of any two points on the line, it is convenient to choose two points that differ in <span class="math inline">\(X\)</span> by one unit, which makes the fraction equal to the numerator only. The numerator is a difference in conditional means. It is also why the units of a regression coefficient are "per unit of <span class="math inline">\(X\)</span> even if defined as a difference in two <span class="math inline">\(Y\)</span> values.</p>
</div>
<p>The difference between observational and causal interpretations of <span class="math inline">\(\beta_1\)</span> depends on the “event” conditioned on in <span class="math inline">\(\textrm{E}[day|temperature]\)</span>. Let’s start with the causal interpretation, which is how we should think about the regression coefficients in the green-down experiment.</p>
</div>
<div id="causal-interpretation-conditional-on-doing-x-x" class="section level4">
<h4><span class="header-section-number">9.1.3.2</span> Causal interpretation – conditional on “doing” X = x</h4>
<p>In the causal interpretation of regression, <span class="math inline">\(\textrm{E}[day|temperature]\)</span> is conditioned on “doing” a real or hypothetical intervention in the system where we set the value of <span class="math inline">\(temperature\)</span> to a specific value <span class="math inline">\(x\)</span> ("<span class="math inline">\(temperature=x\)</span>), while keeping everything else about the system the same. This can be stated explicitly as <span class="math inline">\(\textrm{E}[day|\;do\;temperature = x]\)</span>. Using the do-operator, we can interpret <span class="math inline">\(\beta_1\)</span> as an <strong>effect coefficient</strong>.</p>
<p><span class="math display">\[\begin{equation}
\beta_1 = \textrm{E}[day|\;do\;temperature = x+1] - \textrm{E}[day|\;do\;temperature = x]
\end{equation}\]</span></p>
<p>In words, “beta-one is the expected value of day of green-down were we to set the temperature to x + 1, minus the expected value of day of green-down were we to set the temperature to x.”</p>
<div style="background-color:#cccccc; text-align:left; vertical-align: middle; padding:20px 47px;">
<p>tl;dr. In the green-down experiment, the researchers didn’t set the temperature in the intervened enclosures to the ambient temperature + 1 but to ambient + 2.25, ambient + 4.5, ambient + 6.75, and ambient + 9.0. Again (see tl;dr above), the + 1 is mere convenience in the definition.</p>
</div>
</div>
<div id="observational-interpretation-conditional-on-seeing-x-x." class="section level4">
<h4><span class="header-section-number">9.1.3.3</span> Observational interpretation – conditional on “seeing” X = x.</h4>
<p>In the observational interpretation of regression, <span class="math inline">\(\textrm{E}[day|temperature]\)</span> is conditioned on sampling data and “seeing” a value of <span class="math inline">\(temperature\)</span>. We can state this explicitly as <span class="math inline">\(\textrm{E}[day|\;see\;temperature]\)</span>. From this, we can interpret <span class="math inline">\(\beta_1\)</span> as an <strong>observational coefficient</strong></p>
<p><span class="math display">\[\begin{equation}
\beta_1 = \textrm{E}[day|\;see\;temperature = x+1] - \textrm{E}[day|\;see \;temperature = x]
\end{equation}\]</span></p>
<p>In words, “beta-one is the expected value of day of green-down when see that temperature equals x + 1 minus the expected value of day of green-down when we see that temperature equals x.” To understand what I mean by “observational”, let’s imagine that the green-down data do not come from an experiment in which the researchers intervened and set the added temperature to a specifc value but from ten sites that naturally vary in mean annual temperature. Or from a single site with 10 years of data, with some years warmer and some years colder. Data from this kind of study is <strong>observational</strong> – the researcher didn’t intervene and set the <span class="math inline">\(X\)</span> values but merely observed the <span class="math inline">\(X\)</span> values.</p>
<p>If we sample (or “see”) a site with a mean annual temperature that is 2.5 °C above a reference value, the expected day of green-down is <span class="math inline">\(\textrm{E}[day|temperature = 2.5 °C]\)</span>. That is, values near <span class="math inline">\(\textrm{E}[day|temperature = 2.5 °C]\)</span> are more probable than values away from <span class="math inline">\(\textrm{E}[day|temperature = 2.5 °C]\)</span>. Or, if the only information that we have about this site is a mean annual temperature that is 2.5 °C above some reference, then our best prediction of the day of green-down would be <span class="math inline">\(\textrm{E}[day|temperature = 2.5 °C]\)</span>. We do not claim that the 4.98 day delay in green-down is caused by the warmer temperature, only that this is the expected delay relative to the reference having seen the data.</p>
<p>The seeing interpretation of a regression coefficient is <strong>descriptive</strong>– it is a description of a mathematical relationship. In this interpretation, the coefficient is not causal in the sense of what the expected <strong>response</strong> in <span class="math inline">\(Y\)</span> would be were we to intervene in the system and change <span class="math inline">\(X\)</span> from <span class="math inline">\(x\)</span> to <span class="math inline">\(x+1\)</span>.</p>
</div>
<div id="omitted-variable-bias" class="section level4">
<h4><span class="header-section-number">9.1.3.4</span> Omitted variable bias</h4>
<p>What is the consequence of interpreting a regression coefficient causally instead of observationally?</p>
<div class="figure"><span id="fig:continuous-x-dag"></span>
<img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-dag-1.png" alt="a Directed Acyclic (or causal) Graph of a hypothetical world where the day of green-down is caused by two, correlated environmental variables, temperature and moisture, and to a noise factor (U) that represents an unspecified set of additional variables that are not correlated to either temperature or moisture." width="576" />
<p class="caption">
Figure 9.2: a Directed Acyclic (or causal) Graph of a hypothetical world where the day of green-down is caused by two, correlated environmental variables, temperature and moisture, and to a noise factor (U) that represents an unspecified set of additional variables that are not correlated to either temperature or moisture.
</p>
</div>
<p>Let’s expand the thought experiment where we have an observational data set of green down dates. In this thought experiment, only two variables systematically affect green-down DOY. The first is the temperature that the plants experience; the effect of <span class="math inline">\(temperature\)</span> is <span class="math inline">\(\beta_1\)</span>. The second is the soil moisture that the plants experience; the effect of <span class="math inline">\(moisture\)</span> is <span class="math inline">\(\beta_2\)</span>. <span class="math inline">\(temperature\)</span> and <span class="math inline">\(moisture\)</span> are correlated with a value <span class="math inline">\(\rho\)</span>. This causal model is graphically represented by the <strong>causal graph</strong> above.</p>
<p>Lets fit two linear models.</p>
<p><span class="math display">\[\begin{align}
(\mathcal{M}_1)\; day &amp;= b_0 + b_1 \; temperature + b_2 \; moisture + \varepsilon\\
(\mathcal{M}_2)\; day &amp;= b_0 + b_1 \; temperature + \varepsilon
\end{align}\]</span></p>
<p><span class="math inline">\(\mathcal{M}_1\)</span> the linear model including both <span class="math inline">\(temperature\)</span> and <span class="math inline">\(moisture\)</span> as <span class="math inline">\(X\)</span> variables and <span class="math inline">\(\mathcal{M}_2\)</span> the linear model including only <span class="math inline">\(temperature\)</span> as an <span class="math inline">\(X\)</span> variable. Given the true causal model above, <span class="math inline">\(b_1\)</span> is an <strong>unbiased</strong> estimate of the true causal effect of temperature <span class="math inline">\(\beta_1\)</span> in <span class="math inline">\(\mathcal{M}_1\)</span> because the expected value of <span class="math inline">\(b_1\)</span> is <span class="math inline">\(\beta_1\)</span>. By contrast, <span class="math inline">\(b_1\)</span> is a <strong>biased</strong> estimate of the true causal effect of temperature <span class="math inline">\(\beta_1\)</span> in <span class="math inline">\(\mathcal{M}_2\)</span>. The expected value of <span class="math inline">\(b_1\)</span> in <span class="math inline">\(\mathcal{M}_2\)</span> is the true, causal effect plus a bias term.</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(b_1|\mathcal{M}_1) = \beta + \rho \alpha \frac{\sigma_{moisture}}{\sigma_{temperature}}
\end{equation}\]</span></p>
<p>This bias (<span class="math inline">\(\rho \alpha \frac{\sigma_{moisture}}{\sigma_{temperature}}\)</span>) is <strong>omitted variable bias</strong>. The omitted variable <span class="math inline">\(moisture\)</span> is an unmeasured, <strong>confounding variable</strong>. A variable <span class="math inline">\(X_2\)</span> is a confounder for variable <span class="math inline">\(X_1\)</span> if <span class="math inline">\(X_2\)</span> has both a correlation with <span class="math inline">\(X_1\)</span> and a path to the response <span class="math inline">\(Y\)</span> that is not through <span class="math inline">\(X_1\)</span>. With ommitted variable bias, as we sample more and more data, our estimate of the effect doesn’t converge on the truth but the truth plus some bias.</p>
</div>
<div id="causal-modeling-with-experimental-versus-observational-data" class="section level4">
<h4><span class="header-section-number">9.1.3.5</span> Causal modeling with experimental versus observational data</h4>
<p>Causal interpretation requires conditioning on “doing X=x”. For the green-down data, “doing X=x” is achieved by the random treatment assignment of the enclosures. How does random treatment assignment achieve this? Look again at Figure <a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#fig:continuous-x-dag">9.2</a>. If the values of <span class="math inline">\(treatment\)</span> are randomly assigned, then, by definition, the expected value of the correlation between <span class="math inline">\(treatment\)</span> and <span class="math inline">\(moisture\)</span> is zero. In fact, the expected value of the correlation between <span class="math inline">\(treatment\)</span> and any measurable variable at the study site is zero. Given, this, the expected value of the regression coefficient for <span class="math inline">\(temperature\)</span> (<span class="math inline">\(b_1\)</span>) is <span class="math inline">\(\beta\)</span> because <span class="math inline">\(\rho=0\)</span>. That is, the estimate of the true effect is unbiased. It doesn’t matter if <span class="math inline">\(moisture\)</span>, or any other variable, is excluded from the model. (That said, we may want to include moisture or other variables in the model to increase precision of the causal effect. This is addressed in the chapter “Models with Covariates”). This is what an experiment does and why experiments are used to answer causal questions.</p>
<p>Can we use observational data for causal modeling? Yes, but the methods for this are outside of the scope of this text. The mathematical foundation for this is known as <strong>path analysis</strong>, which was developed by geneticist and evolutionary biologist Sewell Wright (I include this because this work has inspired much of how I think about biology and because he is both my academic grandfather and great-grandfather). Causal analysis of observational data in biology is rare outside of ecology and epidemiology. Good starting points for the modern development of causal analysis are <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/" target="_blank">Hernán MA and Robins JM (2020)</a> and <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-genom-083117-021731" target="_blank">Burgess et al. (2018)</a>. A gentle introduction is <a href="https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/" target="_blank">Pearl and Mackenzie (2018)</a>.</p>
</div>
</div>
<div id="using-a-regression-model-for-prediction-prediction-models" class="section level3">
<h3><span class="header-section-number">9.1.4</span> Using a regression model for prediction – prediction models</h3>
<p>The researchers in the green-down study also presented estimates of the effect of temperature on green-down using two observational datasets. Let’s use the one in Extended Data Figure 3d to explore using a regression model for prediction. The data are taken from measurements of the day of green-down over an 86 year period at a single site. The response variable is <span class="math inline">\(green\_down\_anomaly\)</span> (the difference between the day of green down for the year and the mean of these days over the 86 years). The predictor variable is <span class="math inline">\(autumn\_temp\_anomaly\)</span> (the difference between the mean temperature over the year and the mean of these means).</p>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-pred-fig-1.png" width="576" /></p>
<p>The plot in figure <a href="#fig:continuous-x-pred-fig"><strong>??</strong></a> shows the regression line of a linear model fit to the data. Two statistics are given in the plot.</p>
<ol style="list-style-type: decimal">
<li>The <em>p</em>-value of the slope (the coefficient <span class="math inline">\(b_1\)</span> of <span class="math inline">\(autumn\_temp\_anomaly\)</span>)</li>
<li>The <span class="math inline">\(R^2\)</span> of the model fit.</li>
</ol>
<p>In addition, two intervals are shown.</p>
<ol style="list-style-type: decimal">
<li>95% <strong>confidence interval</strong> of the expected values in blue. The width of this band is a measure of the precision of the estimates of expected values.</li>
<li>95% <strong>prediction interval</strong> of the predictions in gray. The width of this band is a measure of how well the model predicts.</li>
</ol>
<p>It is important that researchers knows what each of these statistics and bands are, when to compute them and when to ignore them them, and what to say about each when communicating the results.</p>
<div id="ci-and-p-value" class="section level4">
<h4><span class="header-section-number">9.1.4.1</span> 95% CI and <em>p</em>-value</h4>
<p>Both the 95% confidence interval of the expected values and the <em>p</em>-value are a function of the standard error of the slope coefficient <span class="math inline">\(b_1\)</span> and so are complimentary statistics. The <em>p</em>-value is the probability of sampling the null that results in a <span class="math inline">\(t\)</span>-value as or more extreme than the observed <em>t</em> for the coefficient <span class="math inline">\(b_1\)</span>. This null includes the hypothesis <span class="math inline">\(\beta_1 = 0\)</span>. The 95% confidence interval of the expected values is the band containing expected values (mean <span class="math inline">\(green\_down\_anomaly\)</span> conditional on <span class="math inline">\(autumn\_temp\_anomaly\)</span>) that are compatible with the data. There are a couple of useful ways of thinking about this band.</p>
<ol style="list-style-type: decimal">
<li>The band captures an infinite number of regression lines that are compatible with the data. Some are more steep and predict smaller expected values at the low end of <span class="math inline">\(autumn\_temp\_anomaly\)</span> and higher expected values at the high end of <span class="math inline">\(autumn\_temp\_anomaly\)</span>. Others are less steep and predict higher expected values at the low end of <span class="math inline">\(autumn\_temp\_anomaly\)</span> and lower expected values at the high end of <span class="math inline">\(autumn\_temp\_anomaly\)</span>.</li>
<li>The band captures the 95% CI of the conditional mean at every value of <span class="math inline">\(X\)</span>. Consider the 95% CI of the conditional mean at the mean value of <span class="math inline">\(X\)</span>. As we move away from this mean value (lower to higher <span class="math inline">\(X\)</span>), the 95% CI of the conditional mean increases.</li>
</ol>
<p>A 95% CI and <em>p</em>-value are useful statistics to report if the purpose is <em>causal modeling</em>, as in the example above using the experimental green-down data (where the 95% CI was not presented as a confidence band of the expected values but a CI of the estimate of the effect of added temperature). A 95% CI and <em>p</em>-value are also useful statistics to report if the purpose is <em>descriptive modeling</em>, simply wanting to know how the conditional mean of the response is related to an <span class="math inline">\(X\)</span> variable.</p>
</div>
<div id="prediction-interval-and-r2" class="section level4">
<h4><span class="header-section-number">9.1.4.2</span> 95% prediction interval and <span class="math inline">\(R^2\)</span></h4>
<p>Both the <span class="math inline">\(R^2\)</span> and the 95% prediction interval are a function of the <em>population</em> variability of <span class="math inline">\(green\_down\_anomaly\)</span> conditional on <span class="math inline">\(autumn\_temp\_anomaly\)</span> (the spread of points along a vertical axis about the regression line) and are complimentary statistics. Briefly,</p>
<ol style="list-style-type: decimal">
<li>the <span class="math inline">\(R^2\)</span> is a measure of the fraction of the variance in the response that is accounted by the model (some sources say “explained by the model” but this is an odd use of “explain”). It is a number between 0 and 1 and is a measure of “predictability” if the goal is prediction modeling.</li>
<li>The 95% prediction interval will contain a new observation 95% of the time. It provides bounds on a <strong>prediction</strong> – given a new observation, there is a 95% probability that the interval at <span class="math inline">\(x_{new}\)</span> will contain <span class="math inline">\(y_{new}\)</span>.</li>
</ol>
<p>To understand <span class="math inline">\(R^2\)</span> and the 95% prediction interval a bit better, let’s back up.</p>
<p><span class="math display">\[\begin{equation}
green\_down\_anomaly_i = b_0 + b_1 autumn\_temp\_anomaly_i + e_i
(\#eq:doy_fit)
\end{equation}\]</span></p>
<p>Model @ref(eq:eq:doy_fit) recovers the measured value of <span class="math inline">\(green\_down\_anomaly\)</span> for any year, given the <span class="math inline">\(autumn\_temp\_anomaly\)</span> for the year. The equation includes the linear predictor (<span class="math inline">\(b_0 + b_1 autumn\_temp\_anomaly_i\)</span>) and the <strong>residual</strong> from the predictor (<span class="math inline">\(e_i\)</span>). The predictor part of @ref(eq:doy_fit) is used to compute <span class="math inline">\(\hat{y}\)</span> (“y hat”).</p>
<p><span class="math display">\[\begin{equation}
\hat{y}_i = b_0 + b_1 autumn\_temp\_anomaly_i
(\#eq:doy_hat)
\end{equation}\]</span></p>
<p>The <span class="math inline">\(\hat{y}\)</span> are <strong>fitted values</strong>, if the values are computed from the data that were used for the fit, or <strong>predicted values</strong> (or simply the <strong>prediction</strong>), if the values are computed from values of the predictor variables outside the set used to fit the model. For the purpose of plotting, generally, with models with categorical factors as <span class="math inline">\(X\)</span>, I prefer either <strong>modeled values</strong> or <strong>conditional means</strong> to fitted values.</p>
</div>
<div id="r2" class="section level4">
<h4><span class="header-section-number">9.1.4.3</span> <span class="math inline">\(R^2\)</span></h4>
<p>A good model accounts for a sizable fraction of the total variance in the response. This fraction is the <span class="math inline">\(R^2\)</span> value, which is given in <code>summary(m1)</code> and accessed directly with</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb224-1"></a><span class="kw">summary</span>(m1)<span class="op">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.1305754</code></pre>
<p><span class="math inline">\(R^2\)</span> is the fraction of the total variance of <span class="math inline">\(Y\)</span> that is generated by the linear predictor.</p>
<p><span class="math display">\[\begin{equation}
R^2 = \frac{\mathrm{VAR}(\hat{y})}{\mathrm{VAR}(y)}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb226-1"></a>yhat &lt;-<span class="st"> </span><span class="kw">fitted</span>(m1)</span>
<span id="cb226-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb226-2"></a>y &lt;-<span class="st"> </span>efig_3d[, green_down_anomaly]</span>
<span id="cb226-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb226-3"></a><span class="kw">var</span>(yhat)<span class="op">/</span><span class="kw">var</span>(y)</span></code></pre></div>
<pre><code>## [1] 0.1305754</code></pre>
<p><span class="math inline">\(R^2\)</span> will vary from zero (the model accounts for nothing) to one (the model accounts for everything). <span class="math inline">\(R^2\)</span> is often described as the fraction of total variation <em>explained</em> by the model" but the usage of “explain” is observational and not causal. Because of the ambiguous usage of “explain” in statistics, I prefer to avoid the word.</p>
<p>It can be useful sometimes to think of <span class="math inline">\(R^2\)</span> in terms of <strong>residual error</strong>, which is the variance of the residuals from the model. The larger the residual error, the smaller the <span class="math inline">\(R^2\)</span>, or</p>
<p><span class="math display">\[\begin{equation}
R^2 = 1 - \frac{\mathrm{VAR}(e)}{\mathrm{VAR}(y)}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb228-1"></a>e &lt;-<span class="st"> </span><span class="kw">residuals</span>(m1)</span>
<span id="cb228-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb228-2"></a>y &lt;-<span class="st"> </span>efig_3d[, green_down_anomaly]</span>
<span id="cb228-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb228-3"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">var</span>(e)<span class="op">/</span><span class="kw">var</span>(y)</span></code></pre></div>
<pre><code>## [1] 0.1305754</code></pre>
<p>The smaller the residuals, the higher the <span class="math inline">\(R^2\)</span> and the closer the predicted values are to the measured values. The sum of the model variance and residual variance equals the total variance and, consequently, <span class="math inline">\(R^2\)</span> is a signal to signal + noise ratio. The noise in <span class="math inline">\(R^2\)</span> is the sampling variance of the individual measures. The noise in a <em>t</em>-value is the sampling variance of the parameter (for m1, this is the sampling variance of <span class="math inline">\(b_1\)</span>). This is an important distinction because it means that <em>t</em> and <span class="math inline">\(R^2\)</span> are not related 1:1. In a simple model with only a single <span class="math inline">\(X\)</span>, one might expect <span class="math inline">\(R^2\)</span> to be big if the <em>p</em>-value for the slope is tiny, but this isn’t necessarily true because of the different meaning of noise in each. A study with a very large sample size <span class="math inline">\(n\)</span> can have a tiny <em>p</em>-value <em>and</em> a small <span class="math inline">\(R^2\)</span>. A <em>p</em>-value is not a good indicator of predictability. <span class="math inline">\(R^2\)</span> is. This is explored more below.</p>
</div>
<div id="prediction-interval" class="section level4">
<h4><span class="header-section-number">9.1.4.4</span> Prediction interval</h4>
<p>A good prediction model has high predictability, meaning the range of predicted values is narrow. A 95% CI is a reasonable range to communicate. For any decision making using prediction, it is better to look at numbers than a band on a plot.</p>
<table>
<thead>
<tr class="header">
<th align="right">Autumn Temp Anomaly (°C)</th>
<th align="right">Expected (days)</th>
<th align="right">2.5% (days)</th>
<th align="right">97.5% (days)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.5</td>
<td align="right">0.8</td>
<td align="right">-8.7</td>
<td align="right">10.3</td>
</tr>
<tr class="even">
<td align="right">1.0</td>
<td align="right">1.6</td>
<td align="right">-7.9</td>
<td align="right">11.1</td>
</tr>
<tr class="odd">
<td align="right">1.5</td>
<td align="right">2.4</td>
<td align="right">-7.2</td>
<td align="right">12.0</td>
</tr>
<tr class="even">
<td align="right">2.0</td>
<td align="right">3.2</td>
<td align="right">-6.4</td>
<td align="right">12.8</td>
</tr>
<tr class="odd">
<td align="right">2.5</td>
<td align="right">4.0</td>
<td align="right">-5.7</td>
<td align="right">13.7</td>
</tr>
</tbody>
</table>
<p>Given these data and the fit model, if we see a 2 °C increase in mean fall temperature, we expect the autumn green-down to extend 3.2 days. This expectation is an average. We’d expect 95% of actual values to range between -6.4 days and 12.8 days. This is a lot of variability. Any prediction has a reasonable probability of being over a week early or late. This may seem surprising given the <em>p</em>-value of the fit, which is 0.0006. But the <em>p</em>-value is not a reliable indicator of predictability. It is a statistic related to the blue band, not the gray band.</p>
<p>To understand this prediction interval a bit more, and why a <em>p</em>-value is not a good indicator of predictability, it’s useful to understand what makes a prediction interval “wide”. The width of the prediction interval is a function of two kinds of variability</p>
<ol style="list-style-type: decimal">
<li>The variance of the expected value at a specific value of <span class="math inline">\(X\)</span>. This is the square of the standard error of <span class="math inline">\(b_1\)</span>. The blue band is communicating the CI based on this variance. The <em>p</em>-value is related to the wideth of this band.</li>
<li>The variance of <span class="math inline">\(Y\)</span> at a specific value of <span class="math inline">\(X\)</span>. This variance is <span class="math inline">\(\sigma^2\)</span>. It is useful for learning to think about the equation for the estimate of this variance.</li>
</ol>
<p><span class="math display">\[\begin{equation}
\hat\sigma^2 = \frac{\sum{e_i^2}}{N-2}
\end{equation}\]</span></p>
<p>Again, <span class="math inline">\(e_i\)</span> is the residual for the <em>i</em>th case. The denominator (<span class="math inline">\(N-2\)</span>) is the degrees of freedom of the model. Computing <span class="math inline">\(\hat\sigma^2\)</span> manually helps to insure that we understand what is going on.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb230-1"></a><span class="kw">summary</span>(m1)<span class="op">$</span>sigma <span class="co"># R&#39;s calculation of sigma hat</span></span></code></pre></div>
<pre><code>## [1] 4.736643</code></pre>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb232-1"></a>df &lt;-<span class="st"> </span><span class="kw">summary</span>(m1)<span class="op">$</span>df[<span class="dv">2</span>] <span class="co"># R&#39;s calculation of df. Check that this is n-2!</span></span>
<span id="cb232-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb232-2"></a><span class="kw">sqrt</span>(<span class="kw">sum</span>(e<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>df)</span></code></pre></div>
<pre><code>## [1] 4.736643</code></pre>
<p>Remember that an assumption of the linear models that we are working with at this point is, this variance is constant for all values of <span class="math inline">\(X\)</span>, so we have a single <span class="math inline">\(\sigma\)</span>. Later, we will cover linear models that model heterogeneity in this variance. <span class="math inline">\(\sigma\)</span> is a function of variability in the population – it is the population standard deviation conditional on <span class="math inline">\(X\)</span>.</p>
<p>Importantly, predictability is a function of both these components of variability. As a consequence, it is <span class="math inline">\(R^2\)</span>, and not the <em>p</em>-value, that is the indicator of predictability. In the observational green-down data, even if we had thousands of years of data, we would still have a pretty low <span class="math inline">\(R^2\)</span> because of the population variability of <span class="math inline">\(green\_down\_anomaly\)</span> at a given <span class="math inline">\(autumn\_temp\_anomaly\)</span>.</p>
</div>
<div id="median-absolute-error-and-root-mean-square-error-are-absolute-measures-of-predictability" class="section level4">
<h4><span class="header-section-number">9.1.4.5</span> Median Absolute Error and Root Mean Square Error are absolute measures of predictability</h4>
<p>A <em>p</em>-value is not <em>at all</em> a good guide to predictability. <span class="math inline">\(R^2\)</span> is proportional to predictability but is not really useful in any absolute sense. If we want to predict the effect of warming on the day of green-down, I would like to have a measure of predictability in the units of green-down, which is days. The prediction interval gives this for any value of <span class="math inline">\(X\)</span>. But what about an overall measure of predictability?</p>
<p>Three overall measures of predictability are</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\hat{\sigma}\)</span>, the estimate of <span class="math inline">\(\sigma\)</span>. This is the standard deviation of the sample conditional on <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(RMSE\)</span>, the root mean squared error. This is</li>
</ol>
<p><span class="math display">\[\begin{align}
SSE &amp;= \sum{(y_i - \hat{y}_i)^2}\\
MSE &amp;= \frac{SSE}{N}\\
RMSE &amp;= \sqrt{MSE}
\end{align}\]</span></p>
<p><span class="math inline">\(SSE\)</span> (“sum of squared error”) is the sum of the squared residuals (<span class="math inline">\(y_i - \hat{y}_i\)</span>) of the model. <span class="math inline">\(MSE\)</span> (“mean squared error”) is the mean of the squared errors. <span class="math inline">\(RMSE\)</span> is the square root of the mean squared error. <span class="math inline">\(RMSE\)</span> is almost equal to <span class="math inline">\(\hat{\sigma}\)</span>. The difference is the denominator, which is <span class="math inline">\(N\)</span> in the computation of <span class="math inline">\(RMSE\)</span> and <span class="math inline">\(df\)</span> (the degrees of freedom of the model, which is <span class="math inline">\(N\)</span> minus the number of fit parameters) in the computation of <span class="math inline">\(\hat{\sigma}\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(MAE\)</span>, the mean absolute error. This is</li>
</ol>
<p><span class="math display">\[\begin{equation}
MAE = \frac{1}{N}\sum{|y_i - \hat{y}_i|}
\end{equation}\]</span></p>
<table>
<thead>
<tr class="header">
<th align="right">sigma</th>
<th align="right">RMSE</th>
<th align="right">MAE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4.74</td>
<td align="right">4.68</td>
<td align="right">3.58</td>
</tr>
<tr class="even">
<td align="right">If the g</td>
<td align="right">oal of</td>
<td align="right">an analysis is prediction, one of these statistics should be reported. For the model fit to the observational green-down data in Extended Figure 3d, these three statistics are given in Table <a href="#table:continuous-x-average-error"><strong>??</strong></a> above (to two decimal places simply to show numerical difference between <span class="math inline">\(\hat{\sigma}\)</span> and <span class="math inline">\(RMSE\)</span>). All of these are measures of an “average” prediction error in the units of the response. The average error is either 4.7 or 3.6 days, depending on which statistic we report. Why the difference? Both <span class="math inline">\(\hat{\sigma}\)</span> and <span class="math inline">\(RMSE\)</span> are functions of squared error and so big differences between predicted and actual value are emphasized. If an error of 6 days is more than twice as bad than an error of 3 days, report <span class="math inline">\(RMSE\)</span>. Why <span class="math inline">\(RMSE\)</span> and not <span class="math inline">\(\hat{\sigma}\)</span>? Simply because researchers using prediction models are more familiar with <span class="math inline">\(RMSE\)</span>. If an error of 6 days is <em>not</em> more than twice as bad than an error of 3 days, report <span class="math inline">\(MAE\)</span>.</td>
</tr>
</tbody>
</table>
</div>
<div id="prediction-modeling-is-more-sophisticated-than-presented-here" class="section level4">
<h4><span class="header-section-number">9.1.4.6</span> Prediction modeling is more sophisticated than presented here</h4>
<p>For data where the response is a non-linear function of the predictor, or for data with many predictor variables, researchers will often build a model using a <strong>model selection</strong> method. Stepwise regression is a classical model selection method that is commonly taught in intro biostatistics and commonly used by researchers. Stepwise regression as a method of model selection has many well-known problems and should be avoided.</p>
<p>Some <em>excellent</em> books that are useful for building models and model selection are</p>
<ol style="list-style-type: decimal">
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank">The Elements of Statistical Learning</a></li>
<li><a href="https://avehtari.github.io/ROS-Examples/" target="_blank">Regression and Other Stories</a></li>
<li><a href="http://hbiostat.org/doc/rms/4day.html" target="_blank">Regression Modeling Strategies</a></li>
</ol>
</div>
</div>
<div id="using-a-regression-model-for-creating-a-new-response-variable-comparing-slopes-of-longitudinal-data" class="section level3">
<h3><span class="header-section-number">9.1.5</span> Using a regression model for creating a new response variable – comparing slopes of longitudinal data</h3>
<p>In the study in this example, the researchers compared the growth rate of tumors in mice fed normal chow versus mice with a methionine restricted diet. Growth rate wasn’t actually compared. Instead, the researchers used a <em>t</em>-test to compare the size of the tumor measured at six different days. A problem with multiple <em>t</em>-tests for this dataset is that the errors (residuals from the model) on one day are correlated with the errors from another day because of the repeated measures on each mouse. This correlation will inflate Type I error rate.</p>
<p>Instead of six <em>t</em>-tests, a better strategy for these data is to use a regression to calculate a tumor growth rate for each mouse. There are sixteen mice so this is sixteen fit models. Here I use a “for loop” to fit the model to the data from a single mouse and use the slope (<span class="math inline">\(b_1\)</span>) as the estimate of the tumor growth rate for that mouse.</p>
<p>Use a for-loop to estimate growth rate for each mouse. In each pass through the loop</p>
<ol style="list-style-type: decimal">
<li>the subset of fig1f (the data in long format) belonging to mouse <em>i</em> is created</li>
<li>the linear model <code>volume ~ day</code> is fit to the subset</li>
<li>the coefficient of day (the slope, <span class="math inline">\(b_1\)</span>) is inserted in mouse <em>i</em>’s row in the column “growth” in the data.table “fig1f_wide”.</li>
</ol>
<p>At the end of the loop, we have the data.table fig1f_wide which has one row for each mouse, a column for the treatment factor (diet) and a column called “growth” containing each mouse’s growth rate. There are also columns of tumor volume for each mouse on each day but these are ignored.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-1"></a>N &lt;-<span class="st"> </span><span class="kw">nrow</span>(fig1f_wide)</span>
<span id="cb234-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-2"></a>id_list &lt;-<span class="st"> </span>fig1f_wide[, id]</span>
<span id="cb234-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N){</span>
<span id="cb234-4"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-4"></a>  mouse_i_data &lt;-<span class="st"> </span>fig1f[id <span class="op">==</span><span class="st"> </span>id_list[i]] <span class="co"># subset</span></span>
<span id="cb234-5"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-5"></a>  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(volume <span class="op">~</span><span class="st"> </span>day, <span class="dt">data =</span> mouse_i_data)</span>
<span id="cb234-6"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-6"></a>  fig1f_wide[id <span class="op">==</span><span class="st"> </span>id_list[i], growth <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">coef</span>(fit)[<span class="dv">2</span>]]</span>
<span id="cb234-7"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-7"></a>}</span>
<span id="cb234-8"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-8"></a><span class="co"># View(fig1f_wide)</span></span>
<span id="cb234-9"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-9"></a><span class="co"># qplot(x = treatment, y = growth, data = fig1f_wide)</span></span>
<span id="cb234-10"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb234-10"></a><span class="co"># qplot(x = day, y = volume, color = treatment, data = fig1f) + geom_smooth(aes(group = id), method = &quot;lm&quot;, se = FALSE)</span></span></code></pre></div>
<p>Step 3. <strong>fit the model</strong></p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb235-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(growth <span class="op">~</span><span class="st"> </span>treatment, <span class="dt">data =</span> fig1f_wide)</span></code></pre></div>
<p>Step 5. <strong>inference from the model</strong></p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb236-1"></a>m1_coef &lt;-<span class="st"> </span><span class="kw">summary</span>(m1) <span class="op">%&gt;%</span></span>
<span id="cb236-2"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb236-2"></a><span class="st">  </span>coef</span>
<span id="cb236-3"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb236-3"></a>m1_ci &lt;-<span class="st"> </span><span class="kw">confint</span>(m1)</span>
<span id="cb236-4"><a href="9-1-a-linear-model-with-a-single-continuous-x-is-classical-regression.html#cb236-4"></a>(m1_coef_table &lt;-<span class="st"> </span><span class="kw">cbind</span>(m1_coef, m1_ci))</span></code></pre></div>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)     2.5 %
## (Intercept)  52.63406   3.102096 16.967258 9.865155e-11  45.98072
## treatmentMR -23.57616   4.387026 -5.374065 9.809457e-05 -32.98540
##                97.5 %
## (Intercept)  59.28739
## treatmentMR -14.16693</code></pre>
<p>Step 6. <strong>plot the model</strong></p>
<p><img src="Walker-elementary-statistical-modeling-draft_files/figure-html/continuous-x-long-plot-1.png" width="576" /></p>
</div>
<div id="using-a-regression-model-for-for-calibration" class="section level3">
<h3><span class="header-section-number">9.1.6</span> Using a regression model for for calibration</h3>
</div>
</div>
<p style="text-align: center;">
<a href="9-linear-models-with-a-single-continuous-x.html"><button class="btn btn-default">Previous</button></a>
<a href="9-2-working-in-r-1.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
